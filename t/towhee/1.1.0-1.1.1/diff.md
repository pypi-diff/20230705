# Comparing `tmp/towhee-1.1.0-py3-none-any.whl.zip` & `tmp/towhee-1.1.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,154 +1,154 @@
-Zip file size: 221205 bytes, number of entries: 152
--rw-r--r--  2.0 unx     5836 b- defN 23-Jun-09 07:02 towhee/__init__.py
--rw-r--r--  2.0 unx      665 b- defN 22-Aug-19 02:52 towhee/__main__.py
--rw-r--r--  2.0 unx     2527 b- defN 23-Jun-09 07:02 towhee/data_loader.py
--rw-r--r--  2.0 unx      619 b- defN 22-Aug-19 02:52 towhee/command/__init__.py
--rw-r--r--  2.0 unx     1627 b- defN 23-Mar-13 07:00 towhee/command/cmdline.py
--rw-r--r--  2.0 unx     4668 b- defN 22-Oct-08 02:27 towhee/command/develop.py
--rw-r--r--  2.0 unx     4223 b- defN 23-Mar-13 07:00 towhee/command/execute.py
--rw-r--r--  2.0 unx     4908 b- defN 22-Oct-08 02:27 towhee/command/repo.py
--rw-r--r--  2.0 unx     5240 b- defN 22-Oct-08 02:27 towhee/command/user.py
--rw-r--r--  2.0 unx        0 b- defN 22-Aug-19 02:52 towhee/data/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Aug-19 02:52 towhee/data/dataset/__init__.py
--rw-r--r--  2.0 unx     1255 b- defN 23-May-17 03:38 towhee/data/dataset/dataset.py
--rw-r--r--  2.0 unx     2918 b- defN 22-Oct-08 02:27 towhee/data/dataset/image_datasets.py
--rw-r--r--  2.0 unx      714 b- defN 22-Nov-03 09:21 towhee/datacollection/__init__.py
--rw-r--r--  2.0 unx     8283 b- defN 23-May-04 09:35 towhee/datacollection/data_collection.py
--rw-r--r--  2.0 unx     3448 b- defN 22-Nov-03 09:21 towhee/datacollection/entity.py
--rw-r--r--  2.0 unx      627 b- defN 22-Oct-12 06:36 towhee/datacollection/mixins/__init__.py
--rw-r--r--  2.0 unx     1900 b- defN 23-May-17 03:38 towhee/datacollection/mixins/display.py
--rw-r--r--  2.0 unx     1093 b- defN 23-May-04 09:35 towhee/hub/__init__.py
--rw-r--r--  2.0 unx     5178 b- defN 23-May-04 09:35 towhee/hub/cache_manager.py
--rw-r--r--  2.0 unx     6414 b- defN 23-Jun-09 07:02 towhee/hub/downloader.py
--rw-r--r--  2.0 unx     4697 b- defN 22-Oct-08 02:27 towhee/hub/operator_manager.py
--rw-r--r--  2.0 unx     3755 b- defN 22-Oct-08 02:27 towhee/hub/pipeline_manager.py
--rw-r--r--  2.0 unx    10289 b- defN 23-Mar-03 09:49 towhee/hub/repo_manager.py
--rw-r--r--  2.0 unx      777 b- defN 23-Mar-13 07:00 towhee/operator/__init__.py
--rw-r--r--  2.0 unx     7747 b- defN 23-Jun-09 07:02 towhee/operator/base.py
--rw-r--r--  2.0 unx      944 b- defN 23-Jun-09 07:02 towhee/operator/nop.py
--rw-r--r--  2.0 unx      975 b- defN 23-Feb-06 09:20 towhee/pipelines/__init__.py
--rw-r--r--  2.0 unx      947 b- defN 23-Mar-13 07:00 towhee/pipelines/_builtin_pipeline.py
--rw-r--r--  2.0 unx     1547 b- defN 23-Jun-09 07:02 towhee/pipelines/insert_milvus.py
--rw-r--r--  2.0 unx     1654 b- defN 23-Jun-09 07:02 towhee/pipelines/search_milvus.py
--rw-r--r--  2.0 unx     2953 b- defN 23-Jun-09 07:02 towhee/pipelines/sentence_embedding.py
--rw-r--r--  2.0 unx     2388 b- defN 23-Jun-09 07:02 towhee/pipelines/text_image_embedding.py
--rw-r--r--  2.0 unx     6891 b- defN 23-Jun-09 07:02 towhee/pipelines/video_copy_detection.py
--rw-r--r--  2.0 unx     4858 b- defN 23-Jun-09 07:02 towhee/pipelines/video_embedding.py
--rw-r--r--  2.0 unx     1004 b- defN 23-Mar-13 07:00 towhee/runtime/__init__.py
--rw-r--r--  2.0 unx     9344 b- defN 23-Jun-09 07:02 towhee/runtime/auto_config.py
--rw-r--r--  2.0 unx     2854 b- defN 23-Jun-09 07:02 towhee/runtime/auto_pipes.py
--rw-r--r--  2.0 unx     3771 b- defN 23-Jun-09 07:02 towhee/runtime/check_utils.py
--rw-r--r--  2.0 unx     1508 b- defN 23-May-04 09:35 towhee/runtime/constants.py
--rw-r--r--  2.0 unx    21806 b- defN 23-Jun-09 07:02 towhee/runtime/dag_repr.py
--rw-r--r--  2.0 unx    10047 b- defN 23-May-04 09:35 towhee/runtime/data_queue.py
--rw-r--r--  2.0 unx     4392 b- defN 23-Jun-09 07:02 towhee/runtime/factory.py
--rw-r--r--  2.0 unx     3420 b- defN 23-Jun-09 07:02 towhee/runtime/node_config.py
--rw-r--r--  2.0 unx     2838 b- defN 23-Jun-09 07:02 towhee/runtime/node_repr.py
--rw-r--r--  2.0 unx    18802 b- defN 23-Jun-09 07:02 towhee/runtime/pipeline.py
--rw-r--r--  2.0 unx     2420 b- defN 23-May-04 09:35 towhee/runtime/pipeline_loader.py
--rw-r--r--  2.0 unx     2821 b- defN 23-Jun-09 07:02 towhee/runtime/runtime_conf.py
--rw-r--r--  2.0 unx    10298 b- defN 23-Jun-09 07:02 towhee/runtime/runtime_pipeline.py
--rw-r--r--  2.0 unx     2314 b- defN 23-Jun-09 07:02 towhee/runtime/schema_repr.py
--rw-r--r--  2.0 unx     1563 b- defN 23-May-04 09:35 towhee/runtime/time_profiler.py
--rw-r--r--  2.0 unx     2776 b- defN 23-May-04 09:35 towhee/runtime/nodes/__init__.py
--rw-r--r--  2.0 unx     2246 b- defN 23-May-04 09:35 towhee/runtime/nodes/_concat.py
--rw-r--r--  2.0 unx     2323 b- defN 23-May-04 09:35 towhee/runtime/nodes/_filter.py
--rw-r--r--  2.0 unx     2066 b- defN 23-May-04 09:35 towhee/runtime/nodes/_flat_map.py
--rw-r--r--  2.0 unx     3093 b- defN 23-May-04 09:35 towhee/runtime/nodes/_map.py
--rw-r--r--  2.0 unx     1383 b- defN 23-May-04 09:35 towhee/runtime/nodes/_output.py
--rw-r--r--  2.0 unx     3246 b- defN 23-May-04 09:35 towhee/runtime/nodes/_reduce.py
--rw-r--r--  2.0 unx     1266 b- defN 23-May-04 09:35 towhee/runtime/nodes/_single_input.py
--rw-r--r--  2.0 unx     3692 b- defN 23-May-04 09:35 towhee/runtime/nodes/_time_window.py
--rw-r--r--  2.0 unx     2632 b- defN 23-May-04 09:35 towhee/runtime/nodes/_window.py
--rw-r--r--  2.0 unx     2630 b- defN 23-May-04 09:35 towhee/runtime/nodes/_window_all.py
--rw-r--r--  2.0 unx     3666 b- defN 23-May-04 09:35 towhee/runtime/nodes/_window_base.py
--rw-r--r--  2.0 unx     6468 b- defN 23-Jun-09 07:02 towhee/runtime/nodes/node.py
--rw-r--r--  2.0 unx      872 b- defN 22-Oct-28 02:52 towhee/runtime/operator_manager/__init__.py
--rw-r--r--  2.0 unx     4604 b- defN 23-May-04 09:35 towhee/runtime/operator_manager/operator_action.py
--rw-r--r--  2.0 unx     6712 b- defN 23-Jun-09 07:02 towhee/runtime/operator_manager/operator_loader.py
--rw-r--r--  2.0 unx     3953 b- defN 23-Jun-09 07:02 towhee/runtime/operator_manager/operator_pool.py
--rw-r--r--  2.0 unx     2867 b- defN 23-Mar-13 07:00 towhee/runtime/operator_manager/operator_registry.py
--rw-r--r--  2.0 unx     1951 b- defN 22-Oct-28 02:52 towhee/runtime/operator_manager/uri.py
--rw-r--r--  2.0 unx      592 b- defN 22-Oct-08 02:27 towhee/serve/__init__.py
--rw-r--r--  2.0 unx     4190 b- defN 23-Jun-09 07:02 towhee/serve/server_builder.py
--rw-r--r--  2.0 unx      773 b- defN 23-Feb-06 09:20 towhee/serve/triton/__init__.py
--rw-r--r--  2.0 unx      816 b- defN 23-Mar-13 07:00 towhee/serve/triton/constant.py
--rw-r--r--  2.0 unx     2330 b- defN 23-Mar-13 07:00 towhee/serve/triton/docker_image_builder.py
--rw-r--r--  2.0 unx     4495 b- defN 23-Jun-09 07:02 towhee/serve/triton/model_to_triton.py
--rw-r--r--  2.0 unx     3483 b- defN 23-Mar-15 09:15 towhee/serve/triton/pipe_to_triton.py
--rw-r--r--  2.0 unx     4284 b- defN 23-Jun-09 07:02 towhee/serve/triton/pipeline_builder.py
--rw-r--r--  2.0 unx     4044 b- defN 23-May-17 03:38 towhee/serve/triton/pipeline_client.py
--rw-r--r--  2.0 unx     2408 b- defN 23-Feb-06 09:20 towhee/serve/triton/triton_client.py
--rw-r--r--  2.0 unx     2547 b- defN 23-Mar-13 07:00 towhee/serve/triton/triton_config_builder.py
--rw-r--r--  2.0 unx     1499 b- defN 22-Nov-30 03:44 towhee/serve/triton/triton_files.py
--rw-r--r--  2.0 unx      706 b- defN 22-Nov-30 03:44 towhee/serve/triton/bls/__init__.py
--rw-r--r--  2.0 unx     2813 b- defN 23-May-17 03:38 towhee/serve/triton/bls/pipeline_model.py
--rw-r--r--  2.0 unx      934 b- defN 22-Aug-19 02:52 towhee/serve/triton/bls/python_backend_wrapper.py
--rw-r--r--  2.0 unx      592 b- defN 22-Aug-19 02:52 towhee/serve/triton/bls/caller/__init__.py
--rw-r--r--  2.0 unx     3437 b- defN 22-Oct-08 02:27 towhee/serve/triton/bls/caller/local_caller.py
--rw-r--r--  2.0 unx      592 b- defN 22-Aug-19 02:52 towhee/serve/triton/bls/mock/__init__.py
--rw-r--r--  2.0 unx     4727 b- defN 23-Feb-06 09:20 towhee/serve/triton/bls/mock/mock_pb_util.py
--rw-r--r--  2.0 unx     2699 b- defN 22-Nov-30 03:44 towhee/serve/triton/bls/mock/mock_triton_client.py
--rw-r--r--  2.0 unx      750 b- defN 23-May-04 09:35 towhee/serve/triton/dockerfiles/DockerfileCuda113
--rw-r--r--  2.0 unx      748 b- defN 23-May-04 09:35 towhee/serve/triton/dockerfiles/DockerfileCuda114
--rw-r--r--  2.0 unx      748 b- defN 23-May-04 09:35 towhee/serve/triton/dockerfiles/DockerfileCuda116
--rw-r--r--  2.0 unx      748 b- defN 23-Jun-09 07:02 towhee/serve/triton/dockerfiles/DockerfileCuda117
--rw-r--r--  2.0 unx      956 b- defN 23-May-04 09:35 towhee/serve/triton/dockerfiles/DockerfileCuda117dev
--rw-r--r--  2.0 unx     1317 b- defN 23-Mar-13 07:00 towhee/serve/triton/dockerfiles/__init__.py
--rw-r--r--  2.0 unx      754 b- defN 23-May-04 09:35 towhee/tools/__init__.py
--rw-r--r--  2.0 unx     5942 b- defN 23-May-17 03:38 towhee/tools/data_visualizer.py
--rw-r--r--  2.0 unx     1983 b- defN 23-May-04 09:35 towhee/tools/graph_visualizer.py
--rw-r--r--  2.0 unx    11912 b- defN 23-May-04 09:35 towhee/tools/profilers.py
--rw-r--r--  2.0 unx     6863 b- defN 23-May-17 03:38 towhee/tools/visualizer.py
--rw-r--r--  2.0 unx      940 b- defN 23-Mar-01 09:42 towhee/trainer/__init__.py
--rw-r--r--  2.0 unx    26591 b- defN 23-Feb-06 09:20 towhee/trainer/callback.py
--rw-r--r--  2.0 unx    10668 b- defN 23-Feb-17 09:42 towhee/trainer/metrics.py
--rw-r--r--  2.0 unx     8861 b- defN 22-Aug-19 02:52 towhee/trainer/modelcard.py
--rw-r--r--  2.0 unx    14904 b- defN 22-Aug-19 02:52 towhee/trainer/scheduler.py
--rw-r--r--  2.0 unx    34675 b- defN 23-Feb-17 09:42 towhee/trainer/trainer.py
--rw-r--r--  2.0 unx    14667 b- defN 23-Feb-17 09:42 towhee/trainer/training_config.py
--rw-r--r--  2.0 unx        0 b- defN 22-Aug-19 02:52 towhee/trainer/optimization/__init__.py
--rw-r--r--  2.0 unx     7830 b- defN 22-Aug-19 02:52 towhee/trainer/optimization/adafactor.py
--rw-r--r--  2.0 unx     5148 b- defN 22-Aug-19 02:52 towhee/trainer/optimization/adamw.py
--rw-r--r--  2.0 unx    12006 b- defN 22-Aug-19 02:52 towhee/trainer/optimization/optimization.py
--rw-r--r--  2.0 unx      592 b- defN 22-Aug-19 02:52 towhee/trainer/utils/__init__.py
--rw-r--r--  2.0 unx     1563 b- defN 23-May-17 03:38 towhee/trainer/utils/file_utils.py
--rw-r--r--  2.0 unx     5600 b- defN 23-May-17 03:38 towhee/trainer/utils/layer_freezer.py
--rw-r--r--  2.0 unx    16453 b- defN 22-Oct-08 02:27 towhee/trainer/utils/plot_utils.py
--rw-r--r--  2.0 unx     9017 b- defN 22-Aug-19 02:52 towhee/trainer/utils/trainer_utils.py
--rw-r--r--  2.0 unx      872 b- defN 23-Mar-13 07:00 towhee/types/__init__.py
--rw-r--r--  2.0 unx     2341 b- defN 22-Aug-19 02:52 towhee/types/arg.py
--rw-r--r--  2.0 unx     2141 b- defN 22-Aug-19 02:52 towhee/types/audio_frame.py
--rw-r--r--  2.0 unx     2443 b- defN 22-Aug-19 02:52 towhee/types/image.py
--rw-r--r--  2.0 unx     2016 b- defN 22-Oct-08 02:27 towhee/types/image_utils.py
--rw-r--r--  2.0 unx     2649 b- defN 22-Aug-19 02:52 towhee/types/video_frame.py
--rw-r--r--  2.0 unx      592 b- defN 22-Oct-08 02:27 towhee/utils/__init__.py
--rw-r--r--  2.0 unx     3928 b- defN 23-May-17 03:38 towhee/utils/console_table.py
--rw-r--r--  2.0 unx     1178 b- defN 22-Aug-19 02:52 towhee/utils/cv2_utils.py
--rw-r--r--  2.0 unx     1403 b- defN 23-Feb-06 09:20 towhee/utils/dependency_control.py
--rw-r--r--  2.0 unx     7744 b- defN 22-Aug-19 02:52 towhee/utils/git_utils.py
--rw-r--r--  2.0 unx     7243 b- defN 23-Jun-09 07:02 towhee/utils/html_table.py
--rw-r--r--  2.0 unx     1381 b- defN 22-Aug-19 02:52 towhee/utils/hub_file_utils.py
--rw-r--r--  2.0 unx    13166 b- defN 23-May-04 09:35 towhee/utils/hub_utils.py
--rw-r--r--  2.0 unx     1301 b- defN 23-Feb-06 09:20 towhee/utils/lazy_import.py
--rw-r--r--  2.0 unx      894 b- defN 22-Aug-19 02:52 towhee/utils/log.py
--rw-r--r--  2.0 unx     2975 b- defN 22-Oct-08 02:27 towhee/utils/matplotlib_utils.py
--rw-r--r--  2.0 unx     4385 b- defN 22-Oct-08 02:27 towhee/utils/ndarray_utils.py
--rw-r--r--  2.0 unx     1156 b- defN 23-Feb-06 09:20 towhee/utils/onnx_utils.py
--rw-r--r--  2.0 unx     2571 b- defN 22-Aug-19 02:52 towhee/utils/pil_utils.py
--rw-r--r--  2.0 unx     8448 b- defN 22-Aug-19 02:52 towhee/utils/repo_normalize.py
--rw-r--r--  2.0 unx     3628 b- defN 23-May-17 03:38 towhee/utils/serializer.py
--rw-r--r--  2.0 unx     1102 b- defN 22-Oct-08 02:27 towhee/utils/singleton.py
--rw-r--r--  2.0 unx     1538 b- defN 23-Feb-06 09:20 towhee/utils/triton_httpclient.py
--rw-r--r--  2.0 unx     2535 b- defN 22-Oct-08 02:27 towhee/utils/yaml_utils.py
--rw-r--r--  2.0 unx      592 b- defN 22-Aug-19 02:52 towhee/utils/thirdparty/__init__.py
--rw-r--r--  2.0 unx      845 b- defN 23-Feb-17 09:42 towhee/utils/thirdparty/dill_util.py
--rw-r--r--  2.0 unx     1230 b- defN 22-Oct-08 02:27 towhee/utils/thirdparty/ipython_utils.py
--rw-r--r--  2.0 unx     1130 b- defN 22-Oct-08 02:27 towhee/utils/thirdparty/pandas_utils.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Jun-09 07:05 towhee-1.1.0.dist-info/LICENSE
--rw-r--r--  2.0 unx    13967 b- defN 23-Jun-09 07:05 towhee-1.1.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Jun-09 07:05 towhee-1.1.0.dist-info/WHEEL
--rw-r--r--  2.0 unx      114 b- defN 23-Jun-09 07:05 towhee-1.1.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        7 b- defN 23-Jun-09 07:05 towhee-1.1.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    13488 b- defN 23-Jun-09 07:05 towhee-1.1.0.dist-info/RECORD
-152 files, 642862 bytes uncompressed, 199819 bytes compressed:  68.9%
+Zip file size: 222014 bytes, number of entries: 152
+-rw-r--r--  2.0 unx     5836 b- defN 23-Jul-04 06:36 towhee/__init__.py
+-rw-r--r--  2.0 unx      665 b- defN 23-Jul-04 06:36 towhee/__main__.py
+-rw-r--r--  2.0 unx     2527 b- defN 23-Jul-04 06:36 towhee/data_loader.py
+-rw-r--r--  2.0 unx      619 b- defN 23-Jul-04 06:36 towhee/command/__init__.py
+-rw-r--r--  2.0 unx     1627 b- defN 23-Jul-04 06:36 towhee/command/cmdline.py
+-rw-r--r--  2.0 unx     4668 b- defN 23-Jul-04 06:36 towhee/command/develop.py
+-rw-r--r--  2.0 unx     4223 b- defN 23-Jul-04 06:36 towhee/command/execute.py
+-rw-r--r--  2.0 unx     4908 b- defN 23-Jul-04 06:36 towhee/command/repo.py
+-rw-r--r--  2.0 unx     5240 b- defN 23-Jul-04 06:36 towhee/command/user.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-04 06:36 towhee/data/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-04 06:36 towhee/data/dataset/__init__.py
+-rw-r--r--  2.0 unx     1255 b- defN 23-Jul-04 06:36 towhee/data/dataset/dataset.py
+-rw-r--r--  2.0 unx     2918 b- defN 23-Jul-04 06:36 towhee/data/dataset/image_datasets.py
+-rw-r--r--  2.0 unx      714 b- defN 23-Jul-04 06:36 towhee/datacollection/__init__.py
+-rw-r--r--  2.0 unx     8283 b- defN 23-Jul-04 06:36 towhee/datacollection/data_collection.py
+-rw-r--r--  2.0 unx     3448 b- defN 23-Jul-04 06:36 towhee/datacollection/entity.py
+-rw-r--r--  2.0 unx      627 b- defN 23-Jul-04 06:36 towhee/datacollection/mixins/__init__.py
+-rw-r--r--  2.0 unx     1900 b- defN 23-Jul-04 06:36 towhee/datacollection/mixins/display.py
+-rw-r--r--  2.0 unx     1093 b- defN 23-Jul-04 06:36 towhee/hub/__init__.py
+-rw-r--r--  2.0 unx     5178 b- defN 23-Jul-04 06:36 towhee/hub/cache_manager.py
+-rw-r--r--  2.0 unx     6414 b- defN 23-Jul-04 06:36 towhee/hub/downloader.py
+-rw-r--r--  2.0 unx     4697 b- defN 23-Jul-04 06:36 towhee/hub/operator_manager.py
+-rw-r--r--  2.0 unx     3755 b- defN 23-Jul-04 06:36 towhee/hub/pipeline_manager.py
+-rw-r--r--  2.0 unx    10289 b- defN 23-Jul-04 06:36 towhee/hub/repo_manager.py
+-rw-r--r--  2.0 unx      777 b- defN 23-Jul-04 06:36 towhee/operator/__init__.py
+-rw-r--r--  2.0 unx     7747 b- defN 23-Jul-04 06:36 towhee/operator/base.py
+-rw-r--r--  2.0 unx      944 b- defN 23-Jul-04 06:36 towhee/operator/nop.py
+-rw-r--r--  2.0 unx      975 b- defN 23-Jul-04 06:36 towhee/pipelines/__init__.py
+-rw-r--r--  2.0 unx      947 b- defN 23-Jul-04 06:36 towhee/pipelines/_builtin_pipeline.py
+-rw-r--r--  2.0 unx     1547 b- defN 23-Jul-04 06:36 towhee/pipelines/insert_milvus.py
+-rw-r--r--  2.0 unx     1654 b- defN 23-Jul-04 06:36 towhee/pipelines/search_milvus.py
+-rw-r--r--  2.0 unx     2953 b- defN 23-Jul-04 06:36 towhee/pipelines/sentence_embedding.py
+-rw-r--r--  2.0 unx     2388 b- defN 23-Jul-04 06:36 towhee/pipelines/text_image_embedding.py
+-rw-r--r--  2.0 unx     6891 b- defN 23-Jul-04 06:36 towhee/pipelines/video_copy_detection.py
+-rw-r--r--  2.0 unx     4858 b- defN 23-Jul-04 06:36 towhee/pipelines/video_embedding.py
+-rw-r--r--  2.0 unx     1004 b- defN 23-Jul-04 06:36 towhee/runtime/__init__.py
+-rw-r--r--  2.0 unx     9344 b- defN 23-Jul-04 06:36 towhee/runtime/auto_config.py
+-rw-r--r--  2.0 unx     2854 b- defN 23-Jul-04 06:36 towhee/runtime/auto_pipes.py
+-rw-r--r--  2.0 unx     3771 b- defN 23-Jul-04 06:36 towhee/runtime/check_utils.py
+-rw-r--r--  2.0 unx     1508 b- defN 23-Jul-04 06:36 towhee/runtime/constants.py
+-rw-r--r--  2.0 unx    21806 b- defN 23-Jul-04 06:36 towhee/runtime/dag_repr.py
+-rw-r--r--  2.0 unx    10047 b- defN 23-Jul-04 06:36 towhee/runtime/data_queue.py
+-rw-r--r--  2.0 unx     4392 b- defN 23-Jul-04 06:36 towhee/runtime/factory.py
+-rw-r--r--  2.0 unx     3420 b- defN 23-Jul-04 06:36 towhee/runtime/node_config.py
+-rw-r--r--  2.0 unx     2838 b- defN 23-Jul-04 06:36 towhee/runtime/node_repr.py
+-rw-r--r--  2.0 unx    18802 b- defN 23-Jul-04 06:36 towhee/runtime/pipeline.py
+-rw-r--r--  2.0 unx     2420 b- defN 23-Jul-04 06:36 towhee/runtime/pipeline_loader.py
+-rw-r--r--  2.0 unx     2821 b- defN 23-Jul-04 06:36 towhee/runtime/runtime_conf.py
+-rw-r--r--  2.0 unx    10298 b- defN 23-Jul-04 06:36 towhee/runtime/runtime_pipeline.py
+-rw-r--r--  2.0 unx     2314 b- defN 23-Jul-04 06:36 towhee/runtime/schema_repr.py
+-rw-r--r--  2.0 unx     1563 b- defN 23-Jul-04 06:36 towhee/runtime/time_profiler.py
+-rw-r--r--  2.0 unx     2776 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/__init__.py
+-rw-r--r--  2.0 unx     2246 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_concat.py
+-rw-r--r--  2.0 unx     2323 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_filter.py
+-rw-r--r--  2.0 unx     2066 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_flat_map.py
+-rw-r--r--  2.0 unx     3093 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_map.py
+-rw-r--r--  2.0 unx     1383 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_output.py
+-rw-r--r--  2.0 unx     3246 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_reduce.py
+-rw-r--r--  2.0 unx     1266 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_single_input.py
+-rw-r--r--  2.0 unx     3692 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_time_window.py
+-rw-r--r--  2.0 unx     2632 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_window.py
+-rw-r--r--  2.0 unx     2630 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_window_all.py
+-rw-r--r--  2.0 unx     3666 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/_window_base.py
+-rw-r--r--  2.0 unx     6468 b- defN 23-Jul-04 06:36 towhee/runtime/nodes/node.py
+-rw-r--r--  2.0 unx      872 b- defN 23-Jul-04 06:36 towhee/runtime/operator_manager/__init__.py
+-rw-r--r--  2.0 unx     4604 b- defN 23-Jul-04 06:36 towhee/runtime/operator_manager/operator_action.py
+-rw-r--r--  2.0 unx     6712 b- defN 23-Jul-04 06:36 towhee/runtime/operator_manager/operator_loader.py
+-rw-r--r--  2.0 unx     3953 b- defN 23-Jul-04 06:36 towhee/runtime/operator_manager/operator_pool.py
+-rw-r--r--  2.0 unx     2867 b- defN 23-Jul-04 06:36 towhee/runtime/operator_manager/operator_registry.py
+-rw-r--r--  2.0 unx     1951 b- defN 23-Jul-04 06:36 towhee/runtime/operator_manager/uri.py
+-rw-r--r--  2.0 unx      592 b- defN 23-Jul-04 06:36 towhee/serve/__init__.py
+-rw-r--r--  2.0 unx     4190 b- defN 23-Jul-04 06:36 towhee/serve/server_builder.py
+-rw-r--r--  2.0 unx      773 b- defN 23-Jul-04 06:36 towhee/serve/triton/__init__.py
+-rw-r--r--  2.0 unx      816 b- defN 23-Jul-04 06:36 towhee/serve/triton/constant.py
+-rw-r--r--  2.0 unx     2330 b- defN 23-Jul-04 06:36 towhee/serve/triton/docker_image_builder.py
+-rw-r--r--  2.0 unx     4495 b- defN 23-Jul-04 06:36 towhee/serve/triton/model_to_triton.py
+-rw-r--r--  2.0 unx     3483 b- defN 23-Jul-04 06:36 towhee/serve/triton/pipe_to_triton.py
+-rw-r--r--  2.0 unx     4284 b- defN 23-Jul-04 06:36 towhee/serve/triton/pipeline_builder.py
+-rw-r--r--  2.0 unx     4044 b- defN 23-Jul-04 06:36 towhee/serve/triton/pipeline_client.py
+-rw-r--r--  2.0 unx     2408 b- defN 23-Jul-04 06:36 towhee/serve/triton/triton_client.py
+-rw-r--r--  2.0 unx     2547 b- defN 23-Jul-04 06:36 towhee/serve/triton/triton_config_builder.py
+-rw-r--r--  2.0 unx     1499 b- defN 23-Jul-04 06:36 towhee/serve/triton/triton_files.py
+-rw-r--r--  2.0 unx      706 b- defN 23-Jul-04 06:36 towhee/serve/triton/bls/__init__.py
+-rw-r--r--  2.0 unx     2813 b- defN 23-Jul-04 06:36 towhee/serve/triton/bls/pipeline_model.py
+-rw-r--r--  2.0 unx      934 b- defN 23-Jul-04 06:36 towhee/serve/triton/bls/python_backend_wrapper.py
+-rw-r--r--  2.0 unx      592 b- defN 23-Jul-04 06:36 towhee/serve/triton/bls/caller/__init__.py
+-rw-r--r--  2.0 unx     3437 b- defN 23-Jul-04 06:36 towhee/serve/triton/bls/caller/local_caller.py
+-rw-r--r--  2.0 unx      592 b- defN 23-Jul-04 06:36 towhee/serve/triton/bls/mock/__init__.py
+-rw-r--r--  2.0 unx     4727 b- defN 23-Jul-04 06:36 towhee/serve/triton/bls/mock/mock_pb_util.py
+-rw-r--r--  2.0 unx     2699 b- defN 23-Jul-04 06:36 towhee/serve/triton/bls/mock/mock_triton_client.py
+-rw-r--r--  2.0 unx      750 b- defN 23-Jul-04 06:36 towhee/serve/triton/dockerfiles/DockerfileCuda113
+-rw-r--r--  2.0 unx      748 b- defN 23-Jul-04 06:36 towhee/serve/triton/dockerfiles/DockerfileCuda114
+-rw-r--r--  2.0 unx      748 b- defN 23-Jul-04 06:36 towhee/serve/triton/dockerfiles/DockerfileCuda116
+-rw-r--r--  2.0 unx      748 b- defN 23-Jul-04 06:36 towhee/serve/triton/dockerfiles/DockerfileCuda117
+-rw-r--r--  2.0 unx      956 b- defN 23-Jul-04 06:36 towhee/serve/triton/dockerfiles/DockerfileCuda117dev
+-rw-r--r--  2.0 unx     1317 b- defN 23-Jul-04 06:36 towhee/serve/triton/dockerfiles/__init__.py
+-rw-r--r--  2.0 unx      754 b- defN 23-Jul-04 06:36 towhee/tools/__init__.py
+-rw-r--r--  2.0 unx     5942 b- defN 23-Jul-04 06:36 towhee/tools/data_visualizer.py
+-rw-r--r--  2.0 unx     1983 b- defN 23-Jul-04 06:36 towhee/tools/graph_visualizer.py
+-rw-r--r--  2.0 unx    11912 b- defN 23-Jul-04 06:36 towhee/tools/profilers.py
+-rw-r--r--  2.0 unx     6863 b- defN 23-Jul-04 06:36 towhee/tools/visualizer.py
+-rw-r--r--  2.0 unx      940 b- defN 23-Jul-04 06:36 towhee/trainer/__init__.py
+-rw-r--r--  2.0 unx    26591 b- defN 23-Jul-04 06:36 towhee/trainer/callback.py
+-rw-r--r--  2.0 unx    10668 b- defN 23-Jul-04 06:36 towhee/trainer/metrics.py
+-rw-r--r--  2.0 unx     8861 b- defN 23-Jul-04 06:36 towhee/trainer/modelcard.py
+-rw-r--r--  2.0 unx    14904 b- defN 23-Jul-04 06:36 towhee/trainer/scheduler.py
+-rw-r--r--  2.0 unx    34675 b- defN 23-Jul-04 06:36 towhee/trainer/trainer.py
+-rw-r--r--  2.0 unx    14667 b- defN 23-Jul-04 06:36 towhee/trainer/training_config.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-04 06:36 towhee/trainer/optimization/__init__.py
+-rw-r--r--  2.0 unx     7830 b- defN 23-Jul-04 06:36 towhee/trainer/optimization/adafactor.py
+-rw-r--r--  2.0 unx     5148 b- defN 23-Jul-04 06:36 towhee/trainer/optimization/adamw.py
+-rw-r--r--  2.0 unx    12006 b- defN 23-Jul-04 06:36 towhee/trainer/optimization/optimization.py
+-rw-r--r--  2.0 unx      592 b- defN 23-Jul-04 06:36 towhee/trainer/utils/__init__.py
+-rw-r--r--  2.0 unx     1563 b- defN 23-Jul-04 06:36 towhee/trainer/utils/file_utils.py
+-rw-r--r--  2.0 unx     5600 b- defN 23-Jul-04 06:36 towhee/trainer/utils/layer_freezer.py
+-rw-r--r--  2.0 unx    16453 b- defN 23-Jul-04 06:36 towhee/trainer/utils/plot_utils.py
+-rw-r--r--  2.0 unx     9017 b- defN 23-Jul-04 06:36 towhee/trainer/utils/trainer_utils.py
+-rw-r--r--  2.0 unx      872 b- defN 23-Jul-04 06:36 towhee/types/__init__.py
+-rw-r--r--  2.0 unx     2341 b- defN 23-Jul-04 06:36 towhee/types/arg.py
+-rw-r--r--  2.0 unx     2141 b- defN 23-Jul-04 06:36 towhee/types/audio_frame.py
+-rw-r--r--  2.0 unx     2443 b- defN 23-Jul-04 06:36 towhee/types/image.py
+-rw-r--r--  2.0 unx     2016 b- defN 23-Jul-04 06:36 towhee/types/image_utils.py
+-rw-r--r--  2.0 unx     2649 b- defN 23-Jul-04 06:36 towhee/types/video_frame.py
+-rw-r--r--  2.0 unx      592 b- defN 23-Jul-04 06:36 towhee/utils/__init__.py
+-rw-r--r--  2.0 unx     3928 b- defN 23-Jul-04 06:36 towhee/utils/console_table.py
+-rw-r--r--  2.0 unx     1178 b- defN 23-Jul-04 06:36 towhee/utils/cv2_utils.py
+-rw-r--r--  2.0 unx     1403 b- defN 23-Jul-04 06:36 towhee/utils/dependency_control.py
+-rw-r--r--  2.0 unx     7744 b- defN 23-Jul-04 06:36 towhee/utils/git_utils.py
+-rw-r--r--  2.0 unx     7243 b- defN 23-Jul-04 06:36 towhee/utils/html_table.py
+-rw-r--r--  2.0 unx     1381 b- defN 23-Jul-04 06:36 towhee/utils/hub_file_utils.py
+-rw-r--r--  2.0 unx    13166 b- defN 23-Jul-04 06:36 towhee/utils/hub_utils.py
+-rw-r--r--  2.0 unx     1301 b- defN 23-Jul-04 06:36 towhee/utils/lazy_import.py
+-rw-r--r--  2.0 unx      894 b- defN 23-Jul-04 06:36 towhee/utils/log.py
+-rw-r--r--  2.0 unx     2975 b- defN 23-Jul-04 06:36 towhee/utils/matplotlib_utils.py
+-rw-r--r--  2.0 unx     4385 b- defN 23-Jul-04 06:36 towhee/utils/ndarray_utils.py
+-rw-r--r--  2.0 unx     1156 b- defN 23-Jul-04 06:36 towhee/utils/onnx_utils.py
+-rw-r--r--  2.0 unx     2571 b- defN 23-Jul-04 06:36 towhee/utils/pil_utils.py
+-rw-r--r--  2.0 unx     8448 b- defN 23-Jul-04 06:36 towhee/utils/repo_normalize.py
+-rw-r--r--  2.0 unx     3628 b- defN 23-Jul-04 06:36 towhee/utils/serializer.py
+-rw-r--r--  2.0 unx     1102 b- defN 23-Jul-04 06:36 towhee/utils/singleton.py
+-rw-r--r--  2.0 unx     1538 b- defN 23-Jul-04 06:36 towhee/utils/triton_httpclient.py
+-rw-r--r--  2.0 unx     2535 b- defN 23-Jul-04 06:36 towhee/utils/yaml_utils.py
+-rw-r--r--  2.0 unx      592 b- defN 23-Jul-04 06:36 towhee/utils/thirdparty/__init__.py
+-rw-r--r--  2.0 unx      845 b- defN 23-Jul-04 06:36 towhee/utils/thirdparty/dill_util.py
+-rw-r--r--  2.0 unx     1230 b- defN 23-Jul-04 06:36 towhee/utils/thirdparty/ipython_utils.py
+-rw-r--r--  2.0 unx     1130 b- defN 23-Jul-04 06:36 towhee/utils/thirdparty/pandas_utils.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-Jul-04 10:20 towhee-1.1.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx    18509 b- defN 23-Jul-04 10:20 towhee-1.1.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Jul-04 10:20 towhee-1.1.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx      114 b- defN 23-Jul-04 10:20 towhee-1.1.1.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        7 b- defN 23-Jul-04 10:20 towhee-1.1.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    13488 b- defN 23-Jul-04 10:20 towhee-1.1.1.dist-info/RECORD
+152 files, 647404 bytes uncompressed, 200628 bytes compressed:  69.0%
```

## zipnote {}

```diff
@@ -432,26 +432,26 @@
 
 Filename: towhee/utils/thirdparty/ipython_utils.py
 Comment: 
 
 Filename: towhee/utils/thirdparty/pandas_utils.py
 Comment: 
 
-Filename: towhee-1.1.0.dist-info/LICENSE
+Filename: towhee-1.1.1.dist-info/LICENSE
 Comment: 
 
-Filename: towhee-1.1.0.dist-info/METADATA
+Filename: towhee-1.1.1.dist-info/METADATA
 Comment: 
 
-Filename: towhee-1.1.0.dist-info/WHEEL
+Filename: towhee-1.1.1.dist-info/WHEEL
 Comment: 
 
-Filename: towhee-1.1.0.dist-info/entry_points.txt
+Filename: towhee-1.1.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: towhee-1.1.0.dist-info/top_level.txt
+Filename: towhee-1.1.1.dist-info/top_level.txt
 Comment: 
 
-Filename: towhee-1.1.0.dist-info/RECORD
+Filename: towhee-1.1.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## Comparing `towhee-1.1.0.dist-info/LICENSE` & `towhee-1.1.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `towhee-1.1.0.dist-info/METADATA` & `towhee-1.1.1.dist-info/METADATA`

 * *Files 24% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: towhee
-Version: 1.1.0
+Version: 1.1.1
 Summary: Towhee is a framework that helps you encode your unstructured data into embeddings.
 Home-page: https://github.com/towhee-io/towhee
 Author: Towhee Team
 Author-email: towhee-team@zilliz.com
 License: http://www.apache.org/licenses/LICENSE-2.0
 Platform: unix
 Platform: linux
@@ -14,15 +14,15 @@
 License-File: LICENSE
 Requires-Dist: requests (>=2.12.5)
 Requires-Dist: tqdm (>=4.59.0)
 Requires-Dist: tabulate
 Requires-Dist: numpy
 Requires-Dist: twine
 Requires-Dist: tenacity
-Requires-Dist: pydantic
+Requires-Dist: pydantic (<2)
 Requires-Dist: contextvars ; python_version <= "3.6"
 Requires-Dist: importlib-resources ; python_version<'3.7'
 
 &nbsp;
 
 <p align="center">
     <img src="towhee_logo.png#gh-light-mode-only" width="60%"/>
@@ -47,80 +47,169 @@
   <a href="https://twitter.com/towheeio">
     <img src="https://img.shields.io/badge/follow-twitter-blue?style=flat" alt="twitter"/>
   </a>
   <a href="https://www.apache.org/licenses/LICENSE-2.0">
     <img src="https://img.shields.io/badge/license-apache2.0-green?style=flat" alt="license"/>
   </a>
   <a href="https://github.com/towhee-io/towhee/actions/workflows/pylint.yml">
-    <img src="https://github.com/towhee-io/towhee/actions/workflows/pylint.yml/badge.svg" alt="github actions"/>
-  </a>
-  <a href="https://pypi.org/project/towhee/">
-    <img src="https://img.shields.io/pypi/v/towhee?label=Release&color&logo=Python" alt="github actions"/>
+    <img src="https://img.shields.io/github/workflow/status/towhee-io/towhee/Workflow%20for%20pylint/main?label=pylint&style=flat" alt="github actions"/>
   </a>
   <a href="https://app.codecov.io/gh/towhee-io/towhee">
     <img src="https://img.shields.io/codecov/c/github/towhee-io/towhee?style=flat" alt="coverage"/>
   </a>
 </div>
 
 &nbsp;
 
-[Towhee](https://towhee.io) is a cutting-edge framework designed to streamline the processing of unstructured data through the use of Large Language Model (LLM) based pipeline orchestration. It is uniquely positioned to extract invaluable insights from diverse unstructured data types, including lengthy text, images, audio and video files. Leveraging the capabilities of generative AI and the SOTA deep learning models, Towhee is capable of transforming this unprocessed data into specific formats such as text, image, or embeddings. These can then be efficiently loaded into an appropriate storage system like a vector database. Developers can initially build an intuitive data processing pipeline prototype with user friendly Pythonic APU, then optimize it for production environments.
-
-🎨 Multi Modalities: Towhee is capable of handling a wide range of data types. Whether it's image data, video clips, text, audio files, or even molecular structures, Towhee can process them all. 
-
-📃    LLM Pipeline orchestration:  Towhee offers flexibility to adapt to different Large Language Models (LLMs). Additionally, it allows for hosting open-source large models locally. Moreover, Towhee provides features like prompt management and knowledge retrieval, making the interaction with these LLMs more efficient and effective.
-
-🎓 Rich Operators: Towhee provides a wide range of ready-to-use state-of-the-art models across five domains: CV, NLP, multimodal, audio, and medical. With over 140 models like BERT and CLIP and rich functionalities like video decoding, audio slicing, frame sampling,  and dimensionality reduction, it assists in efficiently building data processing pipelines. 
-
-🔌   Prebuilt ETL Pipelines: Towhee offers ready-to-use ETL (Extract, Transform, Load) pipelines for common tasks such as Retrieval-Augmented Generation, Text Image search, and Video copy detection. This means you don't need to be an AI expert to build applications using these features. 
-⚡️  High performance backend: Leveraging the power of the Triton Inference Server, Towhee can speed up model serving on both CPU and GPU using platforms like TensorRT, Pytorch, and ONNX. Moreover, you can transform your Python pipeline into a high-performance docker container with just a few lines of code, enabling efficient deployment and scaling.
-
-🐍 Pythonic API: Towhee includes a Pythonic method-chaining API for describing custom data processing pipelines. We also support schemas, which makes processing unstructured data as easy as handling tabular data.
+[Towhee](https://towhee.io) makes it easy to build neural data processing pipelines for AI applications.
+We provide hundreds of models, algorithms, and transformations that can be used as standard pipeline building blocks.
+You can use Towhee's Pythonic API to build a prototype of your pipeline and
+automatically optimize it for production-ready environments.
+
+:art:&emsp;**Various Modalities:** Towhee supports data processing on a variety of modalities, including images, videos, text, audio, molecular structures, etc.
+
+:mortar_board:&emsp;**SOTA Models:** Towhee provides SOTA models across 5 fields (CV, NLP, Multimodal, Audio, Medical), 15 tasks, and 140+ model architectures. These include BERT, CLIP, ViT, SwinTransformer, MAE, and data2vec, all pretrained and ready to use.
+
+:package:&emsp;**Data Processing:** Towhee also provides traditional methods alongside neural network models to help you build practical data processing pipelines. We have a rich pool of operators available, such as video decoding, audio slicing, frame sampling, feature vector dimension reduction, ensembling, and database operations.
+
+:snake:&emsp;**Pythonic API:** Towhee includes a Pythonic method-chaining API for describing custom data processing pipelines. We also support schemas, which makes processing unstructured data as easy as handling tabular data.
+
+## What's New
+**v1.0.0rc1 May. 4, 2023**
+* Add trainer to operators: 
+[*timm*](https://towhee.io/image-embedding/timm), [*isc*](https://towhee.io/image-embedding/isc), [*transformers*](https://towhee.io/text-embedding/transformers), [*clip*](https://towhee.io/image-text-embedding/clip)
+* Add GPU video decoder: 
+[*VPF*](https://towhee.io/video-decode/VPF)
+* All towhee pipelines can be converted into Nvidia Triton services.
+
+
+**v0.9.0 Dec. 2, 2022**
+* Added one video classification model:
+[*Vis4mer*](https://github.com/towhee-io/towhee/tree/branch0.9.0/towhee/models/vis4mer)
+* Added three visual backbones:
+[*MCProp*](https://github.com/towhee-io/towhee/tree/branch0.9.0/towhee/models/mcprop), 
+[*RepLKNet*](https://github.com/towhee-io/towhee/tree/branch0.9.0/towhee/models/replknet), 
+[*Shunted Transformer*](https://github.com/towhee-io/towhee/tree/branch0.9.0/towhee/models/shunted_transformer)
+* Add two code search operators:
+[*code_search.codebert*](https://towhee.io/code-search/codebert), 
+[*code_search.unixcoder*](https://towhee.io/code-search/unixcoder)
+* Add five image captioning operators: 
+[*image_captioning.expansionnet-v2*](https://towhee.io/image-captioning/expansionnet-v2), 
+[*image_captioning.magic*](https://towhee.io/image-captioning/magic),
+[*image_captioning.clip_caption_reward*](https://towhee.io/image-captioning/clip-caption-reward), 
+[*image_captioning.blip*](https://towhee.io/image-captioning/blip), 
+[*image_captioning.clipcap*](https://towhee.io/image-captioning/clipcap)
+* Add five image-text embedding operators: 
+[*image_text_embedding.albef*](https://towhee.io/image-text-embedding/albef), 
+[*image_text_embedding.ru_clip*](https://towhee.io/image-text-embedding/ru-clip), 
+[*image_text_embedding.japanese_clip*](https://towhee.io/image-text-embedding/japanese-clip),
+[*image_text_embedding.taiyi*](https://towhee.io/image-text-embedding/taiyi),
+[*image_text_embedding.slip*](https://towhee.io/image-text-embedding/slip)
+* Add one machine-translation operator: 
+[*machine_translation.opus_mt*](https://towhee.io/machine-translation/opus-mt)
+* Add one filter-tiny-segments operator:
+[*video-copy-detection.filter-tiny-segments*](https://towhee.io/video-copy-detection/filter-tiny-segments)
+* Add an advanced tutorial for audio fingerprinting: 
+[*Audio Fingerprint II: Music Detection with Temporal Localization*](https://github.com/towhee-io/examples/blob/main/audio/audio_fingerprint/audio_fingerprint_advanced.ipynb) (increased accuracy from 84% to 90%)
+
+**v0.8.1 Sep. 30, 2022**
+
+* Added four visual backbones:
+[*ISC*](https://github.com/towhee-io/towhee/tree/branch0.8.1/towhee/models/isc),
+[*MetaFormer*](https://github.com/towhee-io/towhee/tree/branch0.8.1/towhee/models/metaformer),
+[*ConvNext*](https://github.com/towhee-io/towhee/tree/branch0.8.1/towhee/models/convnext),
+[*HorNet*](https://github.com/towhee-io/towhee/tree/branch0.8.1/towhee/models/hornet)
+* Add two video de-copy operators:
+[*select-video*](https://towhee.io/video-copy-detection/select-video), 
+[*temporal-network*](https://towhee.io/video-copy-detection/temporal-network)
+* Add one image embedding operator specifically designed for image retrieval and video de-copy with SOTA performance on VCSL dataset:
+[*isc*](https://towhee.io/image-embedding/isc)
+* Add one audio embedding operator specified for audio fingerprint:
+[*audio_embedding.nnfp*](https://towhee.io/audio-embedding/nnfp) (with pretrained weights)
+* Add one tutorial for video de-copy: 
+[*How to Build a Video Segment Copy Detection System*](https://github.com/towhee-io/examples/blob/main/video/video_deduplication/segment_level/video_deduplication_at_segment_level.ipynb)
+* Add one beginner tutorial for audio fingerprint:
+[*Audio Fingerprint I: Build a Demo with Towhee & Milvus*](https://github.com/towhee-io/examples/blob/main/audio/audio_fingerprint/audio_fingerprint_beginner.ipynb)
+
+
+**v0.8.0 Aug. 16, 2022**
+
+* Towhee now supports generating an Nvidia Triton Server from a Towhee pipeline, with aditional support for GPU image decoding.
+* Added one audio fingerprinting model: 
+[*nnfp*](https://github.com/towhee-io/towhee/tree/branch0.8.0/towhee/models/nnfp)
+* Added two image embedding models: 
+[*RepMLP*](https://github.com/towhee-io/towhee/tree/branch0.8.0/towhee/models/repmlp), [**WaveViT**](https://github.com/towhee-io/towhee/tree/branch0.8.0/towhee/models/wave_vit)
+
+**v0.7.3 Jul. 27, 2022**
+* Added one multimodal (text/image) model:
+[*CoCa*](https://github.com/towhee-io/towhee/tree/branch0.7.3/towhee/models/coca).
+* Added two video models for grounded situation recognition & repetitive action counting:
+[*CoFormer*](https://github.com/towhee-io/towhee/tree/branch0.7.3/towhee/models/coformer),
+[*TransRAC*](https://github.com/towhee-io/towhee/tree/branch0.7.3/towhee/models/transrac).
+* Added two SoTA models for image tasks (image retrieval, image classification, etc.):
+[*CVNet*](https://github.com/towhee-io/towhee/tree/branch0.7.3/towhee/models/cvnet),
+[*MaxViT*](https://github.com/towhee-io/towhee/tree/branch0.7.3/towhee/models/max_vit)
+
+**v0.7.1 Jul. 1, 2022**
+* Added one image embedding model:
+[*MPViT*](https://towhee.io/image-embedding/mpvit).
+* Added two video retrieval models:
+[*BridgeFormer*](https://towhee.io/video-text-embedding/bridge-former),
+[*collaborative-experts*](https://towhee.io/video-text-embedding/collaborative-experts).
+* Added FAISS-based ANNSearch operators: *to_faiss*, *faiss_search*.
+
+**v0.7.0 Jun. 24, 2022**
+
+* Added six video understanding/classification models:
+[*Video Swin Transformer*](https://towhee.io/action-classification/video-swin-transformer), 
+[*TSM*](https://towhee.io/action-classification/tsm), 
+[*Uniformer*](https://towhee.io/action-classification/uniformer), 
+[*OMNIVORE*](https://towhee.io/action-classification/omnivore), 
+[*TimeSformer*](https://towhee.io/action-classification/timesformer), 
+[*MoViNets*](https://towhee.io/action-classification/movinet).
+* Added four video retrieval models:
+[*CLIP4Clip*](https://towhee.io/video-text-embedding/clip4clip), 
+[*DRL*](https://towhee.io/video-text-embedding/drl), 
+[*Frozen in Time*](https://towhee.io/video-text-embedding/frozen-in-time), 
+[*MDMMT*](https://towhee.io/video-text-embedding/mdmmt).
+
+**v0.6.1  May. 13, 2022**
+
+* Added three text-image retrieval models:
+[*CLIP*](https://towhee.io/image-text-embedding/clip),
+[*BLIP*](https://towhee.io/image-text-embedding/blip),
+[*LightningDOT*](https://towhee.io/image-text-embedding/lightningdot).
+* Added six video understanding/classification models from PyTorchVideo:
+[*I3D*](https://towhee.io/action-classification/pytorchvideo),
+[*C2D*](https://towhee.io/action-classification/pytorchvideo),
+[*Slow*](https://towhee.io/action-classification/pytorchvideo),
+[*SlowFast*](https://towhee.io/action-classification/pytorchvideo),
+[*X3D*](https://towhee.io/action-classification/pytorchvideo),
+[*MViT*](https://towhee.io/action-classification/pytorchvideo).
 
 ## Getting started
 
 Towhee requires Python 3.6+. You can install Towhee via `pip`:
 
 ```bash
 pip install towhee towhee.models
 ```
 
-### Pipeline
+If you run into any pip-related install problems, please try to upgrade pip with `pip install -U pip`.
 
-### Pre-defined Pipeline
+Let's try your first Towhee pipeline. Below is an example for how to create a CLIP-based cross modal retrieval pipeline.
 
-Towhee provides some pre-defined pipelines to help users quickly implement some functions. 
-Currently implemented are: 
-- [Sentence Embedding](https://towhee.io/tasks/detail/pipeline/sentence-similarity)
-- [Image Embedding](https://towhee.io/tasks/detail/pipeline/text-image-search)
-- [Video deduplication](https://towhee.io/tasks/detail/pipeline/video-copy-detection)
-- [Question Answer with Docs](https://towhee.io/tasks/detail/pipeline/retrieval-augmented-generation)
-
-All pipelines can be found on Towhee Hub. Here is an example of using the sentence_embedding pipeline: 
+The example needs towhee 1.0.0, which can be installed with `pip install towhee==1.0.0`, The latest usage [documentation](https://towhee.readthedocs.io/en/main/index.html).
 
 ```python
-from towhee import AutoPipes, AutoConfig
-# get the built-in sentence_similarity pipeline
-config = AutoConfig.load_config('sentence_embedding')
-config.model = 'paraphrase-albert-small-v2'
-config.device = 0
-sentence_embedding = AutoPipes.pipeline('sentence_embedding', config=config)
-
-# generate embedding for one sentence
-embedding = sentence_embedding('how are you?').get()
-# batch generate embeddings for multi-sentences
-embeddings = sentence_embedding.batch(['how are you?', 'how old are you?'])
-embeddings = [e.get() for e in embeddings]
-```
-### Custom pipelines 
-
-If you can't find the pipeline you want in towhee hub, you can also implement custom pipelines through the towhee Python API. In the following example, we will create a cross-modal retrieval pipeline based on CLIP.
-```python
 
+from glob import glob
 from towhee import ops, pipe, DataCollection
+
+
 # create image embeddings and build index
 p = (
     pipe.input('file_name')
     .map('file_name', 'img', ops.image_decode.cv2())
     .map('img', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch32', modality='image'))
     .map('vec', 'vec', ops.towhee.np_normalize())
     .map(('vec', 'file_name'), (), ops.ann_insert.faiss_index('./faiss', 512))
@@ -128,17 +217,20 @@
 )
 
 for f_name in ['https://raw.githubusercontent.com/towhee-io/towhee/main/assets/dog1.png',
                'https://raw.githubusercontent.com/towhee-io/towhee/main/assets/dog2.png',
                'https://raw.githubusercontent.com/towhee-io/towhee/main/assets/dog3.png']:
     p(f_name)
 
-# Flush faiss data into disk. 
-p.flush()
-# search image by textdecode = ops.image_decode.cv2('rgb')
+# Delete the pipeline object, make sure the faiss data is written to disk. 
+del p
+
+
+# search image by text
+decode = ops.image_decode.cv2('rgb')
 p = (
     pipe.input('text')
     .map('text', 'vec', ops.image_text_embedding.clip(model_name='clip_vit_base_patch32', modality='text'))
     .map('vec', 'vec', ops.towhee.np_normalize())
     # faiss op result format:  [[id, score, [file_name], ...]
     .map('vec', 'row', ops.ann_search.faiss_index('./faiss', 3))
     .map('row', 'images', lambda x: [decode(item[2][0]) for item in x])
@@ -146,32 +238,28 @@
 )
 
 DataCollection(p('a cat')).show()
 
 ```
 <img src="assets/towhee_example.png" style="width: 60%; height: 60%">
 
+Learn more examples from the [Towhee Examples](https://github.com/towhee-io/examples).
 
 ## Core Concepts
 
 Towhee is composed of four main building blocks - `Operators`, `Pipelines`, `DataCollection API` and `Engine`.
 
 - __Operators__: An operator is a single building block of a neural data processing pipeline. Different implementations of operators are categorized by tasks, with each task having a standard interface. An operator can be a deep learning model, a data processing method, or a Python function.
 
 - __Pipelines__: A pipeline is composed of several operators interconnected in the form of a DAG (directed acyclic graph). This DAG can direct complex functionalities, such as embedding feature extraction, data tagging, and cross modal data analysis.
 
-- __DataCollection API__: A Pythonic and method-chaining style API for building custom pipelines, providing multiple data conversion interfaces: map, filter, flat_map, concat, window, time_window, and window_all. Through these interfaces, complex data processing pipelines can be built quickly to process unstructured data such as video, audio, text, images, etc.
+- __DataCollection API__: A Pythonic and method-chaining style API for building custom pipelines. A pipeline defined by the DataColltion API can be run locally on a laptop for fast prototyping and then be converted to a docker image, with end-to-end optimizations, for production-ready environments.
 
 - __Engine__: The engine sits at Towhee's core. Given a pipeline, the engine will drive dataflow among individual operators, schedule tasks, and monitor compute resource usage (CPU/GPU/etc). We provide a basic engine within Towhee to run pipelines on a single-instance machine and a Triton-based engine for docker containers.
 
-## Resource
-- TowheeHub: https://towhee.io/
-- docs: https://towhee.readthedocs.io/en/latest/
-- examples: https://github.com/towhee-io/examples
-
 ## Contributing
 
 Writing code is not the only way to contribute! Submitting issues, answering questions, and improving documentation are just some of the many ways you can help our growing community. Check out our [contributing page](https://github.com/towhee-io/towhee/blob/main/CONTRIBUTING.md) for more information.
 
 Special thanks goes to these folks for contributing to Towhee, either on Github, our Towhee Hub, or elsewhere:
 <br><!-- Do not remove start of hero-bot --><br>
 <img src="https://img.shields.io/badge/all--contributors-33-orange"><br>
```

### html2text {}

```diff
@@ -1,119 +1,180 @@
-Metadata-Version: 2.1 Name: towhee Version: 1.1.0 Summary: Towhee is a
+Metadata-Version: 2.1 Name: towhee Version: 1.1.1 Summary: Towhee is a
 framework that helps you encode your unstructured data into embeddings. Home-
 page: https://github.com/towhee-io/towhee Author: Towhee Team Author-email:
 towhee-team@zilliz.com License: http://www.apache.org/licenses/LICENSE-2.0
 Platform: unix Platform: linux Platform: osx Platform: win32 Description-
 Content-Type: text/markdown License-File: LICENSE Requires-Dist: requests
 (>=2.12.5) Requires-Dist: tqdm (>=4.59.0) Requires-Dist: tabulate Requires-
 Dist: numpy Requires-Dist: twine Requires-Dist: tenacity Requires-Dist:
-pydantic Requires-Dist: contextvars ; python_version <= "3.6" Requires-Dist:
-importlib-resources ; python_version<'3.7'  
+pydantic (<2) Requires-Dist: contextvars ; python_version <= "3.6" Requires-
+Dist: importlib-resources ; python_version<'3.7'  
 [towhee_logo.png#gh-light-mode-only] [assets/towhee_logo_dark.png#gh-dark-mode-
                                      only]
                    **** x2vec, Towhee is all you need! ****
                        **** ENGLISH | ä¸­æææ¡£ ****
-[join-slack] [twitter] [license] [github_actions] [github_actions] [coverage]
-  [Towhee](https://towhee.io) is a cutting-edge framework designed to
-streamline the processing of unstructured data through the use of Large
-Language Model (LLM) based pipeline orchestration. It is uniquely positioned to
-extract invaluable insights from diverse unstructured data types, including
-lengthy text, images, audio and video files. Leveraging the capabilities of
-generative AI and the SOTA deep learning models, Towhee is capable of
-transforming this unprocessed data into specific formats such as text, image,
-or embeddings. These can then be efficiently loaded into an appropriate storage
-system like a vector database. Developers can initially build an intuitive data
-processing pipeline prototype with user friendly Pythonic APU, then optimize it
-for production environments. ð¨âMulti Modalities: Towhee is capable of
-handling a wide range of data types. Whether it's image data, video clips,
-text, audio files, or even molecular structures, Towhee can process them all.
-ð LLM Pipeline orchestration: Towhee offers flexibility to adapt to
-different Large Language Models (LLMs). Additionally, it allows for hosting
-open-source large models locally. Moreover, Towhee provides features like
-prompt management and knowledge retrieval, making the interaction with these
-LLMs more efficient and effective. ðâRich Operators: Towhee provides a
-wide range of ready-to-use state-of-the-art models across five domains: CV,
-NLP, multimodal, audio, and medical. With over 140 models like BERT and CLIP
-and rich functionalities like video decoding, audio slicing, frame sampling,
-and dimensionality reduction, it assists in efficiently building data
-processing pipelines. ð Prebuilt ETL Pipelines: Towhee offers ready-to-use
-ETL (Extract, Transform, Load) pipelines for common tasks such as Retrieval-
-Augmented Generation, Text Image search, and Video copy detection. This means
-you don't need to be an AI expert to build applications using these features.
-â¡ï¸ High performance backend: Leveraging the power of the Triton Inference
-Server, Towhee can speed up model serving on both CPU and GPU using platforms
-like TensorRT, Pytorch, and ONNX. Moreover, you can transform your Python
-pipeline into a high-performance docker container with just a few lines of
-code, enabling efficient deployment and scaling. ðâPythonic API: Towhee
-includes a Pythonic method-chaining API for describing custom data processing
-pipelines. We also support schemas, which makes processing unstructured data as
-easy as handling tabular data. ## Getting started Towhee requires Python 3.6+.
-You can install Towhee via `pip`: ```bash pip install towhee towhee.models ```
-### Pipeline ### Pre-defined Pipeline Towhee provides some pre-defined
-pipelines to help users quickly implement some functions. Currently implemented
-are: - [Sentence Embedding](https://towhee.io/tasks/detail/pipeline/sentence-
-similarity) - [Image Embedding](https://towhee.io/tasks/detail/pipeline/text-
-image-search) - [Video deduplication](https://towhee.io/tasks/detail/pipeline/
-video-copy-detection) - [Question Answer with Docs](https://towhee.io/tasks/
-detail/pipeline/retrieval-augmented-generation) All pipelines can be found on
-Towhee Hub. Here is an example of using the sentence_embedding pipeline:
-```python from towhee import AutoPipes, AutoConfig # get the built-in
-sentence_similarity pipeline config = AutoConfig.load_config
-('sentence_embedding') config.model = 'paraphrase-albert-small-v2'
-config.device = 0 sentence_embedding = AutoPipes.pipeline('sentence_embedding',
-config=config) # generate embedding for one sentence embedding =
-sentence_embedding('how are you?').get() # batch generate embeddings for multi-
-sentences embeddings = sentence_embedding.batch(['how are you?', 'how old are
-you?']) embeddings = [e.get() for e in embeddings] ``` ### Custom pipelines If
-you can't find the pipeline you want in towhee hub, you can also implement
-custom pipelines through the towhee Python API. In the following example, we
-will create a cross-modal retrieval pipeline based on CLIP. ```python from
+[join-slack] [twitter] [license] [github_actions] [coverage]
+  [Towhee](https://towhee.io) makes it easy to build neural data processing
+pipelines for AI applications. We provide hundreds of models, algorithms, and
+transformations that can be used as standard pipeline building blocks. You can
+use Towhee's Pythonic API to build a prototype of your pipeline and
+automatically optimize it for production-ready environments. :art:
+&emsp;**Various Modalities:** Towhee supports data processing on a variety of
+modalities, including images, videos, text, audio, molecular structures, etc. :
+mortar_board:&emsp;**SOTA Models:** Towhee provides SOTA models across 5 fields
+(CV, NLP, Multimodal, Audio, Medical), 15 tasks, and 140+ model architectures.
+These include BERT, CLIP, ViT, SwinTransformer, MAE, and data2vec, all
+pretrained and ready to use. :package:&emsp;**Data Processing:** Towhee also
+provides traditional methods alongside neural network models to help you build
+practical data processing pipelines. We have a rich pool of operators
+available, such as video decoding, audio slicing, frame sampling, feature
+vector dimension reduction, ensembling, and database operations. :snake:
+&emsp;**Pythonic API:** Towhee includes a Pythonic method-chaining API for
+describing custom data processing pipelines. We also support schemas, which
+makes processing unstructured data as easy as handling tabular data. ## What's
+New **v1.0.0rc1 May. 4, 2023** * Add trainer to operators: [*timm*](https://
+towhee.io/image-embedding/timm), [*isc*](https://towhee.io/image-embedding/
+isc), [*transformers*](https://towhee.io/text-embedding/transformers), [*clip*]
+(https://towhee.io/image-text-embedding/clip) * Add GPU video decoder: [*VPF*]
+(https://towhee.io/video-decode/VPF) * All towhee pipelines can be converted
+into Nvidia Triton services. **v0.9.0 Dec. 2, 2022** * Added one video
+classification model: [*Vis4mer*](https://github.com/towhee-io/towhee/tree/
+branch0.9.0/towhee/models/vis4mer) * Added three visual backbones: [*MCProp*]
+(https://github.com/towhee-io/towhee/tree/branch0.9.0/towhee/models/mcprop),
+[*RepLKNet*](https://github.com/towhee-io/towhee/tree/branch0.9.0/towhee/
+models/replknet), [*Shunted Transformer*](https://github.com/towhee-io/towhee/
+tree/branch0.9.0/towhee/models/shunted_transformer) * Add two code search
+operators: [*code_search.codebert*](https://towhee.io/code-search/codebert),
+[*code_search.unixcoder*](https://towhee.io/code-search/unixcoder) * Add five
+image captioning operators: [*image_captioning.expansionnet-v2*](https://
+towhee.io/image-captioning/expansionnet-v2), [*image_captioning.magic*](https:/
+/towhee.io/image-captioning/magic), [*image_captioning.clip_caption_reward*]
+(https://towhee.io/image-captioning/clip-caption-reward),
+[*image_captioning.blip*](https://towhee.io/image-captioning/blip),
+[*image_captioning.clipcap*](https://towhee.io/image-captioning/clipcap) * Add
+five image-text embedding operators: [*image_text_embedding.albef*](https://
+towhee.io/image-text-embedding/albef), [*image_text_embedding.ru_clip*](https:/
+/towhee.io/image-text-embedding/ru-clip),
+[*image_text_embedding.japanese_clip*](https://towhee.io/image-text-embedding/
+japanese-clip), [*image_text_embedding.taiyi*](https://towhee.io/image-text-
+embedding/taiyi), [*image_text_embedding.slip*](https://towhee.io/image-text-
+embedding/slip) * Add one machine-translation operator:
+[*machine_translation.opus_mt*](https://towhee.io/machine-translation/opus-mt)
+* Add one filter-tiny-segments operator: [*video-copy-detection.filter-tiny-
+segments*](https://towhee.io/video-copy-detection/filter-tiny-segments) * Add
+an advanced tutorial for audio fingerprinting: [*Audio Fingerprint II: Music
+Detection with Temporal Localization*](https://github.com/towhee-io/examples/
+blob/main/audio/audio_fingerprint/audio_fingerprint_advanced.ipynb) (increased
+accuracy from 84% to 90%) **v0.8.1 Sep. 30, 2022** * Added four visual
+backbones: [*ISC*](https://github.com/towhee-io/towhee/tree/branch0.8.1/towhee/
+models/isc), [*MetaFormer*](https://github.com/towhee-io/towhee/tree/
+branch0.8.1/towhee/models/metaformer), [*ConvNext*](https://github.com/towhee-
+io/towhee/tree/branch0.8.1/towhee/models/convnext), [*HorNet*](https://
+github.com/towhee-io/towhee/tree/branch0.8.1/towhee/models/hornet) * Add two
+video de-copy operators: [*select-video*](https://towhee.io/video-copy-
+detection/select-video), [*temporal-network*](https://towhee.io/video-copy-
+detection/temporal-network) * Add one image embedding operator specifically
+designed for image retrieval and video de-copy with SOTA performance on VCSL
+dataset: [*isc*](https://towhee.io/image-embedding/isc) * Add one audio
+embedding operator specified for audio fingerprint: [*audio_embedding.nnfp*]
+(https://towhee.io/audio-embedding/nnfp) (with pretrained weights) * Add one
+tutorial for video de-copy: [*How to Build a Video Segment Copy Detection
+System*](https://github.com/towhee-io/examples/blob/main/video/
+video_deduplication/segment_level/video_deduplication_at_segment_level.ipynb) *
+Add one beginner tutorial for audio fingerprint: [*Audio Fingerprint I: Build a
+Demo with Towhee & Milvus*](https://github.com/towhee-io/examples/blob/main/
+audio/audio_fingerprint/audio_fingerprint_beginner.ipynb) **v0.8.0 Aug. 16,
+2022** * Towhee now supports generating an Nvidia Triton Server from a Towhee
+pipeline, with aditional support for GPU image decoding. * Added one audio
+fingerprinting model: [*nnfp*](https://github.com/towhee-io/towhee/tree/
+branch0.8.0/towhee/models/nnfp) * Added two image embedding models: [*RepMLP*]
+(https://github.com/towhee-io/towhee/tree/branch0.8.0/towhee/models/repmlp),
+[**WaveViT**](https://github.com/towhee-io/towhee/tree/branch0.8.0/towhee/
+models/wave_vit) **v0.7.3 Jul. 27, 2022** * Added one multimodal (text/image)
+model: [*CoCa*](https://github.com/towhee-io/towhee/tree/branch0.7.3/towhee/
+models/coca). * Added two video models for grounded situation recognition &
+repetitive action counting: [*CoFormer*](https://github.com/towhee-io/towhee/
+tree/branch0.7.3/towhee/models/coformer), [*TransRAC*](https://github.com/
+towhee-io/towhee/tree/branch0.7.3/towhee/models/transrac). * Added two SoTA
+models for image tasks (image retrieval, image classification, etc.): [*CVNet*]
+(https://github.com/towhee-io/towhee/tree/branch0.7.3/towhee/models/cvnet),
+[*MaxViT*](https://github.com/towhee-io/towhee/tree/branch0.7.3/towhee/models/
+max_vit) **v0.7.1 Jul. 1, 2022** * Added one image embedding model: [*MPViT*]
+(https://towhee.io/image-embedding/mpvit). * Added two video retrieval models:
+[*BridgeFormer*](https://towhee.io/video-text-embedding/bridge-former),
+[*collaborative-experts*](https://towhee.io/video-text-embedding/collaborative-
+experts). * Added FAISS-based ANNSearch operators: *to_faiss*, *faiss_search*.
+**v0.7.0 Jun. 24, 2022** * Added six video understanding/classification models:
+[*Video Swin Transformer*](https://towhee.io/action-classification/video-swin-
+transformer), [*TSM*](https://towhee.io/action-classification/tsm),
+[*Uniformer*](https://towhee.io/action-classification/uniformer), [*OMNIVORE*]
+(https://towhee.io/action-classification/omnivore), [*TimeSformer*](https://
+towhee.io/action-classification/timesformer), [*MoViNets*](https://towhee.io/
+action-classification/movinet). * Added four video retrieval models:
+[*CLIP4Clip*](https://towhee.io/video-text-embedding/clip4clip), [*DRL*](https:
+//towhee.io/video-text-embedding/drl), [*Frozen in Time*](https://towhee.io/
+video-text-embedding/frozen-in-time), [*MDMMT*](https://towhee.io/video-text-
+embedding/mdmmt). **v0.6.1 May. 13, 2022** * Added three text-image retrieval
+models: [*CLIP*](https://towhee.io/image-text-embedding/clip), [*BLIP*](https:/
+/towhee.io/image-text-embedding/blip), [*LightningDOT*](https://towhee.io/
+image-text-embedding/lightningdot). * Added six video understanding/
+classification models from PyTorchVideo: [*I3D*](https://towhee.io/action-
+classification/pytorchvideo), [*C2D*](https://towhee.io/action-classification/
+pytorchvideo), [*Slow*](https://towhee.io/action-classification/pytorchvideo),
+[*SlowFast*](https://towhee.io/action-classification/pytorchvideo), [*X3D*]
+(https://towhee.io/action-classification/pytorchvideo), [*MViT*](https://
+towhee.io/action-classification/pytorchvideo). ## Getting started Towhee
+requires Python 3.6+. You can install Towhee via `pip`: ```bash pip install
+towhee towhee.models ``` If you run into any pip-related install problems,
+please try to upgrade pip with `pip install -U pip`. Let's try your first
+Towhee pipeline. Below is an example for how to create a CLIP-based cross modal
+retrieval pipeline. The example needs towhee 1.0.0, which can be installed with
+`pip install towhee==1.0.0`, The latest usage [documentation](https://
+towhee.readthedocs.io/en/main/index.html). ```python from glob import glob from
 towhee import ops, pipe, DataCollection # create image embeddings and build
 index p = ( pipe.input('file_name') .map('file_name', 'img',
 ops.image_decode.cv2()) .map('img', 'vec', ops.image_text_embedding.clip
 (model_name='clip_vit_base_patch32', modality='image')) .map('vec', 'vec',
 ops.towhee.np_normalize()) .map(('vec', 'file_name'), (),
 ops.ann_insert.faiss_index('./faiss', 512)) .output() ) for f_name in ['https:/
 /raw.githubusercontent.com/towhee-io/towhee/main/assets/dog1.png', 'https://
 raw.githubusercontent.com/towhee-io/towhee/main/assets/dog2.png', 'https://
 raw.githubusercontent.com/towhee-io/towhee/main/assets/dog3.png']: p(f_name) #
-Flush faiss data into disk. p.flush() # search image by textdecode =
-ops.image_decode.cv2('rgb') p = ( pipe.input('text') .map('text', 'vec',
-ops.image_text_embedding.clip(model_name='clip_vit_base_patch32',
-modality='text')) .map('vec', 'vec', ops.towhee.np_normalize()) # faiss op
-result format: [[id, score, [file_name], ...] .map('vec', 'row',
-ops.ann_search.faiss_index('./faiss', 3)) .map('row', 'images', lambda x:
-[decode(item[2][0]) for item in x]) .output('text', 'images') ) DataCollection
-(p('a cat')).show() ``` [assets/towhee_example.png] ## Core Concepts Towhee is
-composed of four main building blocks - `Operators`, `Pipelines`,
-`DataCollection API` and `Engine`. - __Operators__: An operator is a single
-building block of a neural data processing pipeline. Different implementations
-of operators are categorized by tasks, with each task having a standard
-interface. An operator can be a deep learning model, a data processing method,
-or a Python function. - __Pipelines__: A pipeline is composed of several
-operators interconnected in the form of a DAG (directed acyclic graph). This
-DAG can direct complex functionalities, such as embedding feature extraction,
-data tagging, and cross modal data analysis. - __DataCollection API__: A
-Pythonic and method-chaining style API for building custom pipelines, providing
-multiple data conversion interfaces: map, filter, flat_map, concat, window,
-time_window, and window_all. Through these interfaces, complex data processing
-pipelines can be built quickly to process unstructured data such as video,
-audio, text, images, etc. - __Engine__: The engine sits at Towhee's core. Given
-a pipeline, the engine will drive dataflow among individual operators, schedule
-tasks, and monitor compute resource usage (CPU/GPU/etc). We provide a basic
-engine within Towhee to run pipelines on a single-instance machine and a
-Triton-based engine for docker containers. ## Resource - TowheeHub: https://
-towhee.io/ - docs: https://towhee.readthedocs.io/en/latest/ - examples: https:/
-/github.com/towhee-io/examples ## Contributing Writing code is not the only way
-to contribute! Submitting issues, answering questions, and improving
-documentation are just some of the many ways you can help our growing
-community. Check out our [contributing page](https://github.com/towhee-io/
-towhee/blob/main/CONTRIBUTING.md) for more information. Special thanks goes to
-these folks for contributing to Towhee, either on Github, our Towhee Hub, or
-elsewhere:
+Delete the pipeline object, make sure the faiss data is written to disk. del p
+# search image by text decode = ops.image_decode.cv2('rgb') p = ( pipe.input
+('text') .map('text', 'vec', ops.image_text_embedding.clip
+(model_name='clip_vit_base_patch32', modality='text')) .map('vec', 'vec',
+ops.towhee.np_normalize()) # faiss op result format: [[id, score, [file_name],
+...] .map('vec', 'row', ops.ann_search.faiss_index('./faiss', 3)) .map('row',
+'images', lambda x: [decode(item[2][0]) for item in x]) .output('text',
+'images') ) DataCollection(p('a cat')).show() ``` [assets/towhee_example.png]
+Learn more examples from the [Towhee Examples](https://github.com/towhee-io/
+examples). ## Core Concepts Towhee is composed of four main building blocks -
+`Operators`, `Pipelines`, `DataCollection API` and `Engine`. - __Operators__:
+An operator is a single building block of a neural data processing pipeline.
+Different implementations of operators are categorized by tasks, with each task
+having a standard interface. An operator can be a deep learning model, a data
+processing method, or a Python function. - __Pipelines__: A pipeline is
+composed of several operators interconnected in the form of a DAG (directed
+acyclic graph). This DAG can direct complex functionalities, such as embedding
+feature extraction, data tagging, and cross modal data analysis. -
+__DataCollection API__: A Pythonic and method-chaining style API for building
+custom pipelines. A pipeline defined by the DataColltion API can be run locally
+on a laptop for fast prototyping and then be converted to a docker image, with
+end-to-end optimizations, for production-ready environments. - __Engine__: The
+engine sits at Towhee's core. Given a pipeline, the engine will drive dataflow
+among individual operators, schedule tasks, and monitor compute resource usage
+(CPU/GPU/etc). We provide a basic engine within Towhee to run pipelines on a
+single-instance machine and a Triton-based engine for docker containers. ##
+Contributing Writing code is not the only way to contribute! Submitting issues,
+answering questions, and improving documentation are just some of the many ways
+you can help our growing community. Check out our [contributing page](https://
+github.com/towhee-io/towhee/blob/main/CONTRIBUTING.md) for more information.
+Special thanks goes to these folks for contributing to Towhee, either on
+Github, our Towhee Hub, or elsewhere:
 
 [https://img.shields.io/badge/all--contributors-33-orange]
 [https://avatars.githubusercontent.com/u/34787227?v=4] [https://
 avatars.githubusercontent.com/u/72550076?v=4] [https://
 avatars.githubusercontent.com/u/57477222?v=4] [https://
 avatars.githubusercontent.com/u/109071306?v=4] [https://
 avatars.githubusercontent.com/u/21202514?v=4] [https://
```

## Comparing `towhee-1.1.0.dist-info/RECORD` & `towhee-1.1.1.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -140,13 +140,13 @@
 towhee/utils/singleton.py,sha256=H3n3l8gicm-6udX0-2vNV-QysrNAhTBNut7OzTGJjAc,1102
 towhee/utils/triton_httpclient.py,sha256=qoafN9GXE--tZkqKGsqYoQho6-q7hicFwt9EDYCLCPg,1538
 towhee/utils/yaml_utils.py,sha256=qZ0Mvcbh_qD2ymgRMQyal8Cp6w3d3I4q6ttCoaA7WQ0,2535
 towhee/utils/thirdparty/__init__.py,sha256=CeCaoChD6XAbWtan8cl1tZ0mD2QokRuoG_IPrSqyvxk,592
 towhee/utils/thirdparty/dill_util.py,sha256=YwnUvKa9sm566UHE5mw_8Jmu8YYvaBgVhVr27ckFr-c,845
 towhee/utils/thirdparty/ipython_utils.py,sha256=r0coEqQidnouFbSzVx3Q_dSgu45PPnUgDZwiTcm-FuE,1230
 towhee/utils/thirdparty/pandas_utils.py,sha256=W_1RdRIuyZ95L2x2pv9xbvZRW6hvGMKJ2Y_PLO2hWvE,1130
-towhee-1.1.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-towhee-1.1.0.dist-info/METADATA,sha256=V883jhOQYlhU7h4Is-dWUx4RDdtFw0sjXeU3Hi4aXyo,13967
-towhee-1.1.0.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
-towhee-1.1.0.dist-info/entry_points.txt,sha256=Li9rdXM7RZW5O7NR9d9OOQV9D99bK1Fv4BilWvB1btk,114
-towhee-1.1.0.dist-info/top_level.txt,sha256=s8O0-CAA8lmENHKY-FR5ojkSAmqEOEkrpg6ITjplm4A,7
-towhee-1.1.0.dist-info/RECORD,,
+towhee-1.1.1.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+towhee-1.1.1.dist-info/METADATA,sha256=BSBbEb9wALINOHmMnyQBhn3wdX3x4fyAoI7cwHKV3VY,18509
+towhee-1.1.1.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+towhee-1.1.1.dist-info/entry_points.txt,sha256=Li9rdXM7RZW5O7NR9d9OOQV9D99bK1Fv4BilWvB1btk,114
+towhee-1.1.1.dist-info/top_level.txt,sha256=s8O0-CAA8lmENHKY-FR5ojkSAmqEOEkrpg6ITjplm4A,7
+towhee-1.1.1.dist-info/RECORD,,
```

