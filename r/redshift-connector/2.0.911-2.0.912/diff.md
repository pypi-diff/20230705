# Comparing `tmp/redshift_connector-2.0.911-py3-none-any.whl.zip` & `tmp/redshift_connector-2.0.912-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,47 +1,47 @@
-Zip file size: 112616 bytes, number of entries: 45
--rw-r--r--  2.0 unx    17905 b- defN 23-Jun-05 16:20 redshift_connector/__init__.py
--rw-r--r--  2.0 unx     5716 b- defN 23-Jun-05 16:20 redshift_connector/config.py
--rw-r--r--  2.0 unx    95283 b- defN 23-Jun-05 16:20 redshift_connector/core.py
--rw-r--r--  2.0 unx     8205 b- defN 23-Jun-05 16:20 redshift_connector/credentials_holder.py
--rw-r--r--  2.0 unx    99031 b- defN 23-Jun-05 16:20 redshift_connector/cursor.py
--rw-r--r--  2.0 unx     3994 b- defN 23-Jun-05 16:20 redshift_connector/error.py
--rw-r--r--  2.0 unx    16994 b- defN 23-Jun-05 16:20 redshift_connector/iam_helper.py
--rw-r--r--  2.0 unx    11042 b- defN 23-Jun-05 16:20 redshift_connector/idp_auth_helper.py
--rw-r--r--  2.0 unx     3566 b- defN 23-Jun-05 16:20 redshift_connector/interval.py
--rw-r--r--  2.0 unx     3390 b- defN 23-Jun-05 16:20 redshift_connector/native_plugin_helper.py
--rw-r--r--  2.0 unx     2363 b- defN 23-Jun-05 16:20 redshift_connector/objects.py
--rw-r--r--  2.0 unx      762 b- defN 23-Jun-05 16:20 redshift_connector/pg_types.py
--rw-r--r--  2.0 unx    10092 b- defN 23-Jun-05 16:20 redshift_connector/redshift_property.py
--rw-r--r--  2.0 unx      214 b- defN 23-Jun-05 16:20 redshift_connector/version.py
--rw-r--r--  2.0 unx       61 b- defN 23-Jun-05 16:20 redshift_connector/auth/__init__.py
--rw-r--r--  2.0 unx     4349 b- defN 23-Jun-05 16:20 redshift_connector/auth/aws_credentials_provider.py
--rw-r--r--  2.0 unx     9870 b- defN 23-Jun-05 16:20 redshift_connector/files/redshift-ca-bundle.crt
--rw-r--r--  2.0 unx      741 b- defN 23-Jun-05 16:20 redshift_connector/plugin/__init__.py
--rw-r--r--  2.0 unx     5577 b- defN 23-Jun-05 16:20 redshift_connector/plugin/adfs_credentials_provider.py
--rw-r--r--  2.0 unx     7154 b- defN 23-Jun-05 16:20 redshift_connector/plugin/azure_credentials_provider.py
--rw-r--r--  2.0 unx    10640 b- defN 23-Jun-05 16:20 redshift_connector/plugin/browser_azure_credentials_provider.py
--rw-r--r--  2.0 unx    11479 b- defN 23-Jun-05 16:20 redshift_connector/plugin/browser_azure_oauth2_credentials_provider.py
--rw-r--r--  2.0 unx     4947 b- defN 23-Jun-05 16:20 redshift_connector/plugin/browser_saml_credentials_provider.py
--rw-r--r--  2.0 unx      432 b- defN 23-Jun-05 16:20 redshift_connector/plugin/credential_provider_constants.py
--rw-r--r--  2.0 unx      432 b- defN 23-Jun-05 16:20 redshift_connector/plugin/i_native_plugin.py
--rw-r--r--  2.0 unx     1493 b- defN 23-Jun-05 16:20 redshift_connector/plugin/i_plugin.py
--rw-r--r--  2.0 unx     1542 b- defN 23-Jun-05 16:20 redshift_connector/plugin/idp_credentials_provider.py
--rw-r--r--  2.0 unx     4806 b- defN 23-Jun-05 16:20 redshift_connector/plugin/jwt_credentials_provider.py
--rw-r--r--  2.0 unx      758 b- defN 23-Jun-05 16:20 redshift_connector/plugin/native_token_holder.py
--rw-r--r--  2.0 unx     6280 b- defN 23-Jun-05 16:20 redshift_connector/plugin/okta_credentials_provider.py
--rw-r--r--  2.0 unx     6656 b- defN 23-Jun-05 16:20 redshift_connector/plugin/ping_credentials_provider.py
--rw-r--r--  2.0 unx    11128 b- defN 23-Jun-05 16:20 redshift_connector/plugin/saml_credentials_provider.py
--rw-r--r--  2.0 unx      892 b- defN 23-Jun-05 16:20 redshift_connector/utils/__init__.py
--rw-r--r--  2.0 unx     1913 b- defN 23-Jun-05 16:20 redshift_connector/utils/array_util.py
--rw-r--r--  2.0 unx     1442 b- defN 23-Jun-05 16:20 redshift_connector/utils/driver_info.py
--rw-r--r--  2.0 unx     1616 b- defN 23-Jun-05 16:20 redshift_connector/utils/extensible_digest.py
--rw-r--r--  2.0 unx     1087 b- defN 23-Jun-05 16:20 redshift_connector/utils/logging_utils.py
--rw-r--r--  2.0 unx     1675 b- defN 23-Jun-05 16:20 redshift_connector/utils/oids.py
--rw-r--r--  2.0 unx    24077 b- defN 23-Jun-05 16:20 redshift_connector/utils/type_utils.py
--rw-r--r--  2.0 unx    10142 b- defN 23-Jun-05 16:21 redshift_connector-2.0.911.dist-info/LICENSE
--rw-r--r--  2.0 unx    61356 b- defN 23-Jun-05 16:21 redshift_connector-2.0.911.dist-info/METADATA
--rw-r--r--  2.0 unx       67 b- defN 23-Jun-05 16:21 redshift_connector-2.0.911.dist-info/NOTICE
--rw-r--r--  2.0 unx       93 b- defN 23-Jun-05 16:21 redshift_connector-2.0.911.dist-info/WHEEL
--rw-r--r--  2.0 unx       19 b- defN 23-Jun-05 16:21 redshift_connector-2.0.911.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     4420 b- defN 23-Jun-05 16:21 redshift_connector-2.0.911.dist-info/RECORD
-45 files, 475701 bytes uncompressed, 105350 bytes compressed:  77.9%
+Zip file size: 114742 bytes, number of entries: 45
+-rw-r--r--  2.0 unx    17905 b- defN 23-Jul-05 16:19 redshift_connector/__init__.py
+-rw-r--r--  2.0 unx     5716 b- defN 23-Jul-05 16:19 redshift_connector/config.py
+-rw-r--r--  2.0 unx    96086 b- defN 23-Jul-05 16:19 redshift_connector/core.py
+-rw-r--r--  2.0 unx     8205 b- defN 23-Jul-05 16:19 redshift_connector/credentials_holder.py
+-rw-r--r--  2.0 unx    99340 b- defN 23-Jul-05 16:19 redshift_connector/cursor.py
+-rw-r--r--  2.0 unx     3994 b- defN 23-Jul-05 16:19 redshift_connector/error.py
+-rw-r--r--  2.0 unx    24915 b- defN 23-Jul-05 16:19 redshift_connector/iam_helper.py
+-rw-r--r--  2.0 unx    11064 b- defN 23-Jul-05 16:19 redshift_connector/idp_auth_helper.py
+-rw-r--r--  2.0 unx     3566 b- defN 23-Jul-05 16:19 redshift_connector/interval.py
+-rw-r--r--  2.0 unx     3390 b- defN 23-Jul-05 16:19 redshift_connector/native_plugin_helper.py
+-rw-r--r--  2.0 unx     2363 b- defN 23-Jul-05 16:19 redshift_connector/objects.py
+-rw-r--r--  2.0 unx      762 b- defN 23-Jul-05 16:19 redshift_connector/pg_types.py
+-rw-r--r--  2.0 unx    11806 b- defN 23-Jul-05 16:19 redshift_connector/redshift_property.py
+-rw-r--r--  2.0 unx      214 b- defN 23-Jul-05 16:19 redshift_connector/version.py
+-rw-r--r--  2.0 unx       61 b- defN 23-Jul-05 16:19 redshift_connector/auth/__init__.py
+-rw-r--r--  2.0 unx     4349 b- defN 23-Jul-05 16:19 redshift_connector/auth/aws_credentials_provider.py
+-rw-r--r--  2.0 unx     9870 b- defN 23-Jul-05 16:19 redshift_connector/files/redshift-ca-bundle.crt
+-rw-r--r--  2.0 unx      741 b- defN 23-Jul-05 16:19 redshift_connector/plugin/__init__.py
+-rw-r--r--  2.0 unx     5643 b- defN 23-Jul-05 16:19 redshift_connector/plugin/adfs_credentials_provider.py
+-rw-r--r--  2.0 unx     7216 b- defN 23-Jul-05 16:19 redshift_connector/plugin/azure_credentials_provider.py
+-rw-r--r--  2.0 unx    10696 b- defN 23-Jul-05 16:19 redshift_connector/plugin/browser_azure_credentials_provider.py
+-rw-r--r--  2.0 unx    11479 b- defN 23-Jul-05 16:19 redshift_connector/plugin/browser_azure_oauth2_credentials_provider.py
+-rw-r--r--  2.0 unx     4947 b- defN 23-Jul-05 16:19 redshift_connector/plugin/browser_saml_credentials_provider.py
+-rw-r--r--  2.0 unx      432 b- defN 23-Jul-05 16:19 redshift_connector/plugin/credential_provider_constants.py
+-rw-r--r--  2.0 unx      432 b- defN 23-Jul-05 16:19 redshift_connector/plugin/i_native_plugin.py
+-rw-r--r--  2.0 unx     1493 b- defN 23-Jul-05 16:19 redshift_connector/plugin/i_plugin.py
+-rw-r--r--  2.0 unx     1542 b- defN 23-Jul-05 16:19 redshift_connector/plugin/idp_credentials_provider.py
+-rw-r--r--  2.0 unx     4806 b- defN 23-Jul-05 16:19 redshift_connector/plugin/jwt_credentials_provider.py
+-rw-r--r--  2.0 unx      758 b- defN 23-Jul-05 16:19 redshift_connector/plugin/native_token_holder.py
+-rw-r--r--  2.0 unx     6280 b- defN 23-Jul-05 16:19 redshift_connector/plugin/okta_credentials_provider.py
+-rw-r--r--  2.0 unx     6691 b- defN 23-Jul-05 16:19 redshift_connector/plugin/ping_credentials_provider.py
+-rw-r--r--  2.0 unx    11128 b- defN 23-Jul-05 16:19 redshift_connector/plugin/saml_credentials_provider.py
+-rw-r--r--  2.0 unx      892 b- defN 23-Jul-05 16:19 redshift_connector/utils/__init__.py
+-rw-r--r--  2.0 unx     1913 b- defN 23-Jul-05 16:19 redshift_connector/utils/array_util.py
+-rw-r--r--  2.0 unx     1442 b- defN 23-Jul-05 16:19 redshift_connector/utils/driver_info.py
+-rw-r--r--  2.0 unx     1616 b- defN 23-Jul-05 16:19 redshift_connector/utils/extensible_digest.py
+-rw-r--r--  2.0 unx     2160 b- defN 23-Jul-05 16:19 redshift_connector/utils/logging_utils.py
+-rw-r--r--  2.0 unx     1675 b- defN 23-Jul-05 16:19 redshift_connector/utils/oids.py
+-rw-r--r--  2.0 unx    24077 b- defN 23-Jul-05 16:19 redshift_connector/utils/type_utils.py
+-rw-r--r--  2.0 unx    10142 b- defN 23-Jul-05 16:20 redshift_connector-2.0.912.dist-info/LICENSE
+-rw-r--r--  2.0 unx    61458 b- defN 23-Jul-05 16:20 redshift_connector-2.0.912.dist-info/METADATA
+-rw-r--r--  2.0 unx       67 b- defN 23-Jul-05 16:20 redshift_connector-2.0.912.dist-info/NOTICE
+-rw-r--r--  2.0 unx       93 b- defN 23-Jul-05 16:20 redshift_connector-2.0.912.dist-info/WHEEL
+-rw-r--r--  2.0 unx       19 b- defN 23-Jul-05 16:20 redshift_connector-2.0.912.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     4420 b- defN 23-Jul-05 16:20 redshift_connector-2.0.912.dist-info/RECORD
+45 files, 487864 bytes uncompressed, 107476 bytes compressed:  78.0%
```

## zipnote {}

```diff
@@ -111,26 +111,26 @@
 
 Filename: redshift_connector/utils/oids.py
 Comment: 
 
 Filename: redshift_connector/utils/type_utils.py
 Comment: 
 
-Filename: redshift_connector-2.0.911.dist-info/LICENSE
+Filename: redshift_connector-2.0.912.dist-info/LICENSE
 Comment: 
 
-Filename: redshift_connector-2.0.911.dist-info/METADATA
+Filename: redshift_connector-2.0.912.dist-info/METADATA
 Comment: 
 
-Filename: redshift_connector-2.0.911.dist-info/NOTICE
+Filename: redshift_connector-2.0.912.dist-info/NOTICE
 Comment: 
 
-Filename: redshift_connector-2.0.911.dist-info/WHEEL
+Filename: redshift_connector-2.0.912.dist-info/WHEEL
 Comment: 
 
-Filename: redshift_connector-2.0.911.dist-info/top_level.txt
+Filename: redshift_connector-2.0.912.dist-info/top_level.txt
 Comment: 
 
-Filename: redshift_connector-2.0.911.dist-info/RECORD
+Filename: redshift_connector-2.0.912.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## redshift_connector/core.py

```diff
@@ -390,14 +390,28 @@
 
         try:
             os_version: str = CLIENT_PLATFORM()
         except:
             os_version = "unknown"
         return os_version
 
+    @staticmethod
+    def __get_host_address_info(host: str, port: int):
+        """
+        Returns IPv4 address and port given a host name and port
+        """
+        # https://docs.python.org/3/library/socket.html#socket.getaddrinfo
+        response = socket.getaddrinfo(host=host, port=port, family=socket.AF_INET)
+        _logger.debug("getaddrinfo response {}".format(response))
+
+        if not response:
+            raise InterfaceError("Unable to determine ip for host {} port {}".format(host, port))
+
+        return response[0][4]
+
     def __init__(
         self: "Connection",
         user: str,
         password: str,
         database: str,
         host: str = "localhost",
         port: int = 5439,
@@ -589,15 +603,19 @@
                 self._usock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
             else:
                 raise ProgrammingError("one of host or unix_sock must be provided")
             if timeout is not None:
                 self._usock.settimeout(timeout)
 
             if unix_sock is None and host is not None:
-                self._usock.connect((host, port))
+                hostport: typing.Tuple[str, int] = Connection.__get_host_address_info(host, port)
+                _logger.debug(
+                    "Attempting to create connection socket with address {} {}".format(hostport[0], str(hostport[1]))
+                )
+                self._usock.connect(hostport)
             elif unix_sock is not None:
                 self._usock.connect(unix_sock)
 
             # For Redshift, we the default ssl approve is True
             # create ssl connection with Redshift CA certificates and check the hostname
             if ssl is True:
                 try:
```

## redshift_connector/cursor.py

```diff
@@ -357,14 +357,20 @@
             param_list = [[split_table_name[0], c] for c in columns]
         temp = self.paramstyle
         self.paramstyle = DbApiParamstyle.QMARK.value
         try:
             for params in param_list:
                 self.execute(q, params)
                 res = self.fetchone()
+                if res is None:
+                    raise InterfaceError(
+                        "Invalid column name. No results were returned when performing column name validity check. Query: {} Parameters: {}".format(
+                            q, params
+                        )
+                    )
                 if typing.cast(typing.List[int], res)[0] != 1:
                     raise InterfaceError("Invalid column name: {} specified for table: {}".format(params[1], table))
         except:
             raise
         finally:
             # reset paramstyle to it's original value
             self.paramstyle = temp
```

## redshift_connector/iam_helper.py

```diff
@@ -37,16 +37,19 @@
         PLUGIN = enum.auto()
 
     class GetClusterCredentialsAPIType(enum.Enum):
         """
         Defines supported Python SDK methods used for Redshift credential retrieval
         """
 
+        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift-serverless/client/get_credentials.html#
         SERVERLESS_V1 = "get_credentials()"
+        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift/client/get_cluster_credentials.html
         IAM_V1 = "get_cluster_credentials()"
+        # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift/client/get_cluster_credentials_with_iam.html#
         IAM_V2 = "get_cluster_credentials_with_iam()"
 
         @staticmethod
         def can_support_v2(provider_type: "IamHelper.IAMAuthenticationType") -> bool:
             """
             Determines if user provided connection options and boto3 version support group federation.
             """
@@ -64,56 +67,73 @@
     @staticmethod
     def get_cluster_credentials_api_type(
         info: RedshiftProperty, provider_type: "IamHelper.IAMAuthenticationType"
     ) -> GetClusterCredentialsAPIType:
         """
         Returns an enum representing the Python SDK method to use for getting temporary IAM credentials.
         """
+        _logger.debug("Determining which API to use for retrieving Redshift instance credentials")
+
         if not info._is_serverless:
+            _logger.debug("Redshift provisioned")
             if not info.group_federation:
+                _logger.debug("group_federation disabled")
                 return IamHelper.GetClusterCredentialsAPIType.IAM_V1
             elif IamHelper.GetClusterCredentialsAPIType.can_support_v2(provider_type):
                 return IamHelper.GetClusterCredentialsAPIType.IAM_V2
             else:
                 raise InterfaceError("Authentication with plugin is not supported for group federation")
         elif not info.group_federation:
+            _logger.debug("Redshift serverless")
+            _logger.debug("group_federation disabled")
             return IamHelper.GetClusterCredentialsAPIType.SERVERLESS_V1
         elif IamHelper.GetClusterCredentialsAPIType.can_support_v2(provider_type):
-            return IamHelper.GetClusterCredentialsAPIType.IAM_V2
+            if info.is_cname:
+                raise InterfaceError("Custom cluster names are not supported for Redshift Serverless")
+            else:
+                return IamHelper.GetClusterCredentialsAPIType.IAM_V2
         else:
             raise InterfaceError("Authentication with plugin is not supported for group federation")
 
     @staticmethod
     def set_iam_properties(info: RedshiftProperty) -> RedshiftProperty:
         """
         Helper function to handle connection properties and ensure required parameters are specified.
         Parameters
         """
         provider_type: IamHelper.IAMAuthenticationType = IamHelper.IAMAuthenticationType.NONE
+        info.set_is_cname()
         # set properties present for both IAM, Native authentication
         IamHelper.set_auth_properties(info)
 
         if info._is_serverless and info.iam:
             if IdpAuthHelper.get_pkg_version("boto3") < Version("1.24.11"):
                 raise ModuleNotFoundError(
                     "boto3 >= 1.24.11 required for authentication with Amazon Redshift serverless. "
                     "Please upgrade the installed version of boto3 to use this functionality."
                 )
 
+        if info.iam and info.is_cname:
+            if IdpAuthHelper.get_pkg_version("boto3") < Version("1.26.157"):
+                raise ModuleNotFoundError(
+                    "boto3 >= 1.26.157 required for authentication with Amazon Redshift using custom domain name. "
+                    "Please upgrade the installed version of boto3 to use this functionality."
+                )
+
         if info.is_serverless_host:
             # consider overridden connection parameters
             if not info.region:
                 info.set_region_from_host()
             if not info.serverless_acct_id:
                 info.set_serverless_acct_id()
             if not info.serverless_work_group:
                 info.set_serverless_work_group_from_host()
 
         if info.iam is True:
-            if info.cluster_identifier is None and not info._is_serverless:
+            if info.cluster_identifier is None and not info._is_serverless and not info.is_cname:
                 raise InterfaceError(
                     "Invalid connection property setting. cluster_identifier must be provided when IAM is enabled"
                 )
             IamHelper.set_iam_credentials(info)
         # Check for Browser based OAuth Native authentication
         NativeAuthPluginHelper.set_native_auth_plugin_properties(info)
         return info
@@ -169,16 +189,25 @@
                 if (len(info.db_groups) == 0) and (len(db_groups) > 0):
                     if force_lowercase:
                         info.db_groups = [group.lower() for group in db_groups]
                     else:
                         info.db_groups = db_groups
 
         if not isinstance(provider, INativePlugin):
+            # If the Redshift instance has been identified as using a custom domain name, the hostname must
+            # be determined using the redshift client from boto3 API
+            if info.is_cname is True:
+                IamHelper.set_cluster_identifier(provider, info)
+
+            # Redshift database credentials  will be determined using the redshift client from boto3 API
             IamHelper.set_cluster_credentials(provider, info)
 
+            # Redshift instance host and port must be retrieved
+            IamHelper.set_cluster_host_and_port(provider, info)
+
     @staticmethod
     def get_credentials_cache_key(info: RedshiftProperty, cred_provider: typing.Union[IPlugin, AWSCredentialsProvider]):
         db_groups: str = ""
 
         if len(info.db_groups) > 0:
             info.put("db_groups", sorted(info.db_groups))
             db_groups = ",".join(info.db_groups)
@@ -233,131 +262,258 @@
                 provider_type = IamHelper.IAMAuthenticationType.IAM_KEYS_WITH_SESSION
             else:
                 provider_type = IamHelper.IAMAuthenticationType.IAM_KEYS
 
         return provider_type
 
     @staticmethod
-    def set_cluster_credentials(
-        cred_provider: typing.Union[IPlugin, AWSCredentialsProvider], info: RedshiftProperty
-    ) -> None:
+    def get_boto3_redshift_client(cred_provider: typing.Union[IPlugin, AWSCredentialsProvider], info: RedshiftProperty):
         """
-        Calls the AWS SDK methods to return temporary credentials.
-        The expiration date is returned as the local time set by the client machines OS.
+        Returns a boto3 client configured for Amazon Redshift using AWS credentials provided by user, system, or IdP.
         """
         import boto3  # type: ignore
         import botocore  # type: ignore
 
+        session_args: typing.Dict[str, str] = {
+            "service_name": "redshift-serverless" if info._is_serverless else "redshift"
+        }
+        for opt_key, opt_val in (("region_name", info.region), ("endpoint_url", info.endpoint_url)):
+            if opt_val is not None:
+                session_args[opt_key] = opt_val
+
         try:
             credentials_holder: typing.Union[
                 CredentialsHolder, ABCAWSCredentialsHolder
             ] = cred_provider.get_credentials()  # type: ignore
             session_credentials: typing.Dict[str, str] = credentials_holder.get_session_credentials()
 
-            redshift_client: str = "redshift-serverless" if info._is_serverless else "redshift"
-            _logger.debug("boto3.client(service_name={}) being used for IAM auth".format(redshift_client))
-
-            for opt_key, opt_val in (("region_name", info.region), ("endpoint_url", info.endpoint_url)):
-                if opt_val is not None:
-                    session_credentials[opt_key] = opt_val
+            _logger.debug("boto3.client(service_name={}) being used for IAM auth".format(session_args["service_name"]))
 
             # if AWS credentials were used to create a boto3.Session object, use it
             if credentials_holder.has_associated_session:
                 cached_session: boto3.Session = typing.cast(
                     ABCAWSCredentialsHolder, credentials_holder
                 ).get_boto_session()
-                client = cached_session.client(service_name=redshift_client, region_name=info.region)
+
+                client = cached_session.client(**session_args)
+
             else:
-                client = boto3.client(service_name=redshift_client, **session_credentials)
+                client = boto3.client(**{**session_credentials, **session_args})
+            return client
+        except botocore.exceptions.ClientError as e:
+            _logger.error("ClientError when establishing boto3 client: %s", e)
+            raise e
+        except Exception as e:
+            _logger.error("Other Exception when establishing boto3 client: %s", e)
+            raise e
+
+    @staticmethod
+    def set_cluster_identifier(
+        cred_provider: typing.Union[IPlugin, AWSCredentialsProvider], info: RedshiftProperty
+    ) -> None:
+        """
+        Retrieves the hostname of a Redshift instance using custom domain name using boto3 API
+        """
+        import boto3  # type: ignore
+        import botocore  # type: ignore
+
+        client = IamHelper.get_boto3_redshift_client(cred_provider, info)
+
+        try:
+            _logger.debug("Redshift custom domain name in use. Determining cluster identifier.")
+            response = client.describe_custom_domain_associations(CustomDomainName=info.host)
+            cluster_identifier: str = response["Associations"][0]["CertificateAssociations"][0]["ClusterIdentifier"]
+            _logger.debug("Retrieved cluster_identifier={}".format(cluster_identifier))
+            info.put(key="cluster_identifier", value=cluster_identifier)
+        except Exception as e:
+            if info.cluster_identifier is None or info.cluster_identifier == "":
+                _logger.error(
+                    "Other Exception when requesting cluster identifier for Redshift with custom domain: %s", e
+                )
+                raise e
+            else:
+                _logger.error(
+                    "User provided cluster_identifier. Assuming cluster is using NLB/custom domain name. Using cluster_identifier"
+                )
+
+    @staticmethod
+    def set_cluster_host_and_port(
+        cred_provider: typing.Union[IPlugin, AWSCredentialsProvider], info: RedshiftProperty
+    ) -> None:
+        """
+        Sets RedshiftProperty attributes for host and port using user configured connection properties and AWS SDK API calls.
+        """
+        import boto3  # type: ignore
+        import botocore  # type: ignore
 
+        try:
+            # we must fetch the Redshift instance host and port name if either are unspecified by the user
             if info.host is None or info.host == "" or info.port is None or info.port == "":
+                _logger.debug("retrieving Redshift instance host and port from boto3 redshift client")
                 response: dict
+                client = IamHelper.get_boto3_redshift_client(cred_provider, info)
 
                 if info._is_serverless:
                     if not info.serverless_work_group:
                         raise InterfaceError("Serverless workgroup is not set.")
                     response = client.get_workgroup(workgroupName=info.serverless_work_group)
                     info.put("host", response["workgroup"]["endpoint"]["address"])
                     info.put("port", response["workgroup"]["endpoint"]["port"])
                 else:
                     response = client.describe_clusters(ClusterIdentifier=info.cluster_identifier)
                     info.put("host", response["Clusters"][0]["Endpoint"]["Address"])
                     info.put("port", response["Clusters"][0]["Endpoint"]["Port"])
+            _logger.debug("host={} port={}".format(info.host, info.port))
+        except botocore.exceptions.ClientError as e:
+            _logger.error("ClientError when requesting cluster identifier for Redshift with custom domain: %s", e)
+            raise e
+        except Exception as e:
+            _logger.error("Other Exception when requesting cluster identifier for Redshift with custom domain: %s", e)
+            raise e
+
+    @staticmethod
+    def set_cluster_credentials(
+        cred_provider: typing.Union[IPlugin, AWSCredentialsProvider], info: RedshiftProperty
+    ) -> None:
+        """
+        Calls the AWS SDK methods to return temporary credentials.
+        The expiration date is returned as the local time set by the client machines OS.
+        """
+        import boto3  # type: ignore
+        import botocore  # type: ignore
+        from botocore.exceptions import ClientError
 
-            cred: typing.Optional[typing.Dict[str, typing.Union[str, datetime.datetime]]] = None
+        client = IamHelper.get_boto3_redshift_client(cred_provider, info)
+        cred: typing.Optional[typing.Dict[str, typing.Union[str, datetime.datetime]]] = None
 
-            if info.iam_disable_cache is False:
-                _logger.debug("iam_disable_cache=False")
-                # temporary credentials are cached by redshift_connector and will be used if they have not expired
-                cache_key: str = IamHelper.get_credentials_cache_key(info, cred_provider)
-                cred = IamHelper.credentials_cache.get(cache_key, None)
-
-                _logger.debug(
-                    "Searching credential cache for temporary AWS credentials. Found: {} Expiration: {}".format(
-                        bool(cache_key in IamHelper.credentials_cache),
-                        cred["Expiration"] if cred is not None else "N/A",
-                    )
+        if info.iam_disable_cache is False:
+            _logger.debug("iam_disable_cache=False")
+            # temporary credentials are cached by redshift_connector and will be used if they have not expired
+            cache_key: str = IamHelper.get_credentials_cache_key(info, cred_provider)
+            cred = IamHelper.credentials_cache.get(cache_key, None)
+
+            _logger.debug(
+                "Searching credential cache for temporary AWS credentials. Found: {} Expiration: {}".format(
+                    bool(cache_key in IamHelper.credentials_cache),
+                    cred["Expiration"] if cred is not None else "N/A",
                 )
+            )
 
-            if cred is None or typing.cast(datetime.datetime, cred["Expiration"]) < datetime.datetime.now(tz=tzutc()):
-                # retries will occur by default ref:
-                # https://boto3.amazonaws.com/v1/documentation/api/latest/guide/retries.html#legacy-retry-mode
-                _logger.debug("Credentials expired or not found...requesting from boto")
-                provider_type: IamHelper.IAMAuthenticationType = IamHelper.get_authentication_type(cred_provider)
-                get_creds_api_version: IamHelper.GetClusterCredentialsAPIType = (
-                    IamHelper.get_cluster_credentials_api_type(info, provider_type)
+        if cred is None or typing.cast(datetime.datetime, cred["Expiration"]) < datetime.datetime.now(tz=tzutc()):
+            # retries will occur by default ref:
+            # https://boto3.amazonaws.com/v1/documentation/api/latest/guide/retries.html#legacy-retry-mode
+            _logger.debug("Credentials expired or not found...requesting from boto")
+            provider_type: IamHelper.IAMAuthenticationType = IamHelper.get_authentication_type(cred_provider)
+            get_creds_api_version: IamHelper.GetClusterCredentialsAPIType = IamHelper.get_cluster_credentials_api_type(
+                info, provider_type
+            )
+            _logger.debug("boto3 get_credentials api version: {} will be used".format(get_creds_api_version.value))
+
+            if get_creds_api_version == IamHelper.GetClusterCredentialsAPIType.SERVERLESS_V1:
+                # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift-serverless/client/get_credentials.html#
+                get_cred_args: typing.Dict[str, str] = {"dbName": info.db_name}
+                if info.serverless_work_group:
+                    get_cred_args["workgroupName"] = info.serverless_work_group
+
+                _logger.debug("Calling get_credentials with parameters {}".format(get_cred_args))
+                cred = typing.cast(
+                    typing.Dict[str, typing.Union[str, datetime.datetime]],
+                    client.get_credentials(**get_cred_args),
                 )
-                _logger.debug("boto3 get_credentials api version: {} will be used".format(get_creds_api_version.value))
+                # re-map expiration for compatibility with redshift credential response
+                cred["Expiration"] = cred["expiration"]
+                del cred["expiration"]
+            elif get_creds_api_version == IamHelper.GetClusterCredentialsAPIType.IAM_V2:
+                # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift/client/get_cluster_credentials_with_iam.html#
+                request_params = {
+                    "DbName": info.db_name,
+                    "DurationSeconds": info.duration,
+                }
 
-                if get_creds_api_version == IamHelper.GetClusterCredentialsAPIType.SERVERLESS_V1:
-                    get_cred_args: typing.Dict[str, str] = {"dbName": info.db_name}
-                    if info.serverless_work_group:
-                        get_cred_args["workgroupName"] = info.serverless_work_group
+                if info.is_cname:
+                    request_params["CustomDomainName"] = info.host
+                else:
+                    request_params["ClusterIdentifier"] = info.cluster_identifier
+                _logger.debug("Calling get_cluster_credentials_with_iam with parameters {}".format(request_params))
 
+                try:
                     cred = typing.cast(
                         typing.Dict[str, typing.Union[str, datetime.datetime]],
-                        client.get_credentials(**get_cred_args),
-                    )
-                    # re-map expiration for compatibility with redshift credential response
-                    cred["Expiration"] = cred["expiration"]
-                    del cred["expiration"]
-                elif get_creds_api_version == IamHelper.GetClusterCredentialsAPIType.IAM_V2:
-                    cred = typing.cast(
-                        typing.Dict[str, typing.Union[str, datetime.datetime]],
-                        client.get_cluster_credentials_with_iam(
-                            DbName=info.db_name,
-                            ClusterIdentifier=info.cluster_identifier,
-                            DurationSeconds=info.duration,
-                        ),
+                        client.get_cluster_credentials_with_iam(**request_params),
                     )
+                except ClientError as e:
+                    if info.is_cname:
+                        _logger.debug(
+                            "Failed to get_cluster_credentials_with_iam. Assuming cluster incorrectly classified as cname, retrying..."
+                        )
+                        del request_params["CustomDomainName"]
+                        request_params["ClusterIdentifier"] = info.cluster_identifier
+
+                        _logger.debug(
+                            "Retrying calling get_cluster_credentials_with_iam with parameters {}".format(
+                                request_params
+                            )
+                        )
+
+                        cred = typing.cast(
+                            typing.Dict[str, typing.Union[str, datetime.datetime]],
+                            client.get_cluster_credentials_with_iam(**request_params),
+                        )
+                    else:
+                        raise e
+
+            else:
+                if info.db_user is None or info.db_user == "":
+                    raise InterfaceError("Connection parameter db_user must be specified when using IAM authentication")
+                # https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/redshift/client/get_cluster_credentials.html
+                request_params = {
+                    "DbUser": info.db_user,
+                    "DbName": info.db_name,
+                    "DbGroups": info.db_groups,
+                    "AutoCreate": info.auto_create,
+                }
+
+                if info.is_cname:
+                    request_params["CustomDomainName"] = info.host
                 else:
+                    request_params["ClusterIdentifier"] = info.cluster_identifier
+
+                _logger.debug("Calling get_cluster_credentials with parameters {}".format(request_params))
+
+                try:
                     cred = typing.cast(
                         typing.Dict[str, typing.Union[str, datetime.datetime]],
-                        client.get_cluster_credentials(
-                            DbUser=info.db_user,
-                            DbName=info.db_name,
-                            DbGroups=info.db_groups,
-                            ClusterIdentifier=info.cluster_identifier,
-                            AutoCreate=info.auto_create,
-                        ),
+                        client.get_cluster_credentials(**request_params),
                     )
+                except ClientError as e:
+                    if info.is_cname:
+                        _logger.debug(
+                            "Failed to get_cluster_credentials. Assuming cluster incorrectly classified as cname, retrying..."
+                        )
+                        del request_params["CustomDomainName"]
+                        request_params["ClusterIdentifier"] = info.cluster_identifier
+
+                        _logger.debug(
+                            "Retrying calling get_cluster_credentials with parameters {}".format(request_params)
+                        )
+
+                        cred = typing.cast(
+                            typing.Dict[str, typing.Union[str, datetime.datetime]],
+                            client.get_cluster_credentials(**request_params),
+                        )
 
-                if info.iam_disable_cache is False:
-                    IamHelper.credentials_cache[cache_key] = typing.cast(
-                        typing.Dict[str, typing.Union[str, datetime.datetime]], cred
-                    )
-            # redshift-serverless api json response payload slightly differs
-            if info._is_serverless:
-                info.put("user_name", typing.cast(str, cred["dbUser"]))
-                info.put("password", typing.cast(str, cred["dbPassword"]))
-            else:
-                info.put("user_name", typing.cast(str, cred["DbUser"]))
-                info.put("password", typing.cast(str, cred["DbPassword"]))
+                    else:
+                        raise e
 
-            _logger.debug("Using temporary aws credentials with expiration: {}".format(cred.get("Expiration")))
+            if info.iam_disable_cache is False:
+                IamHelper.credentials_cache[cache_key] = typing.cast(
+                    typing.Dict[str, typing.Union[str, datetime.datetime]], cred
+                )
+        # redshift-serverless api json response payload slightly differs
+        if info._is_serverless:
+            info.put("user_name", typing.cast(str, cred["dbUser"]))
+            info.put("password", typing.cast(str, cred["dbPassword"]))
+        else:
+            info.put("user_name", typing.cast(str, cred["DbUser"]))
+            info.put("password", typing.cast(str, cred["DbPassword"]))
 
-        except botocore.exceptions.ClientError as e:
-            _logger.error("ClientError: %s", e)
-            raise e
-        except Exception as e:
-            _logger.error("other Exception: %s", e)
-            raise e
+        _logger.debug("Using temporary aws credentials with expiration: {}".format(cred.get("Expiration")))
```

## redshift_connector/idp_auth_helper.py

```diff
@@ -104,15 +104,15 @@
                         iam_access_key_id=typing.cast(str, info.access_key_id),
                         iam_secret_key=typing.cast(str, info.secret_access_key),
                         iam_session_token=info.session_token,
                         info=info,
                     )
                     info.put_all(resp)
 
-            if info.cluster_identifier is None and not info._is_serverless:
+            if info.cluster_identifier is None and not info._is_serverless and not info.is_cname:
                 raise InterfaceError(
                     "Invalid connection property setting. cluster_identifier must be provided when IAM is enabled"
                 )
 
             if info.credentials_provider is not None:
                 if info.auth_profile is None and any(
                     (info.access_key_id, info.secret_access_key, info.session_token, info.profile)
```

## redshift_connector/redshift_property.py

```diff
@@ -1,15 +1,18 @@
+import logging
 import typing
 
 from redshift_connector.config import DEFAULT_PROTOCOL_VERSION
-from redshift_connector.error import ProgrammingError
 
 SERVERLESS_HOST_PATTERN: str = r"(.+)\.(.+).redshift-serverless(-dev)?\.amazonaws\.com(.)*"
 SERVERLESS_WITH_WORKGROUP_HOST_PATTERN: str = r"(.+)\.(.+)\.(.+).redshift-serverless(-dev)?\.amazonaws\.com(.)*"
 IAM_URL_PATTERN: str = r"^(https)://[-a-zA-Z0-9+&@#/%?=~_!:,.']*[-a-zA-Z0-9+&@#/%=~_']"
+PROVISIONED_HOST_PATTERN: str = r"(.+)\.(.+)\.(.+).redshift(-dev)?\.amazonaws\.com(.)*"
+
+_logger: logging.Logger = logging.getLogger(__name__)
 
 
 class RedshiftProperty:
     def __init__(self: "RedshiftProperty", **kwargs):
         """
         Initialize a RedshiftProperty object.
         """
@@ -114,14 +117,16 @@
             self.provider_name: typing.Optional[str] = None
             self.scope: str = ""
             self.numeric_to_float: bool = False
             self.is_serverless: bool = False
             self.serverless_acct_id: typing.Optional[str] = None
             self.serverless_work_group: typing.Optional[str] = None
             self.group_federation: bool = False
+            # flag indicating if host name and RedshiftProperty indicate Redshift with custom domain name is used
+            self.is_cname: bool = False
 
         else:
             for k, v in kwargs.items():
                 setattr(self, k, v)
 
     def __str__(self: "RedshiftProperty") -> str:
         rp = self.__dict__
@@ -158,17 +163,52 @@
         import re
 
         return bool(re.fullmatch(pattern=SERVERLESS_HOST_PATTERN, string=str(self.host))) or bool(
             re.fullmatch(pattern=SERVERLESS_WITH_WORKGROUP_HOST_PATTERN, string=str(self.host))
         )
 
     @property
-    def _is_serverless(self):
+    def is_provisioned_host(self: "RedshiftProperty") -> bool:
+        """
+        Returns True if host matches Regex for Redshift provisioned. Otherwise returns False.
+        """
+        if not self.host:
+            return False
+
+        import re
+
+        return bool(re.fullmatch(pattern=PROVISIONED_HOST_PATTERN, string=str(self.host)))
+
+    def set_is_cname(self: "RedshiftProperty") -> None:
+        """
+        Sets RedshiftProperty is_cname attribute based on RedshiftProperty attribute values and host name Regex matching.
+        """
+        is_cname: bool = False
+        _logger.debug("determining if host indicates Redshift instance with custom name")
+
+        if self.is_provisioned_host:
+            _logger.debug("cluster identified as Redshift provisioned")
+        elif self.is_serverless_host:
+            _logger.debug("cluster identified as Redshift serverless")
+        elif self.is_serverless:
+            if self.serverless_work_group is not None:
+                _logger.debug("cluster identified as Redshift serverless with NLB")
+            else:
+                _logger.debug("cluster identified as Redshift serverless with with custom name")
+                is_cname = True
+        else:
+            _logger.debug("cluster identified as Redshift provisioned with with custom name/NLB")
+            is_cname = True
+
+        self.put(key="is_cname", value=is_cname)
+
+    @property
+    def _is_serverless(self: "RedshiftProperty"):
         """
-        Returns True if host patches serverless pattern or if is_serverless flag set by user
+        Returns True if host matches serverless pattern or if is_serverless flag set by user. Otherwise returns False.
         """
         return self.is_serverless_host or self.is_serverless
 
     def set_serverless_acct_id(self: "RedshiftProperty") -> None:
         """
         Sets the AWS account id as parsed from the Redshift serverless endpoint.
         """
```

## redshift_connector/version.py

```diff
@@ -1,5 +1,5 @@
 # Store the version here so:
 # 1) we don't load dependencies by storing it in __init__.py
 # 2) we can import it in setup.py for the same reason
 # 3) we can import it into your module module
-__version__ = "2.0.911"
+__version__ = "2.0.912"
```

## redshift_connector/plugin/adfs_credentials_provider.py

```diff
@@ -57,15 +57,15 @@
                 "Verify RedshiftProperties are correct"
             )
             raise InterfaceError(e)
         except requests.exceptions.RequestException as e:
             _logger.error("A unknown error occurred when requesting SAML assertion to refresh credentials")
             raise InterfaceError(e)
 
-        _logger.debug(response.text)
+        _logger.debug("ADFS form based authentication response length: {}".format(len(response.text)))
 
         try:
             soup = bs4.BeautifulSoup(response.text, features="lxml")
         except Exception as e:
             _logger.error("An error occurred while parsing response: {}".format(str(e)))
             raise InterfaceError(e)
```

## redshift_connector/plugin/azure_credentials_provider.py

```diff
@@ -99,15 +99,15 @@
                 "A error occurred when requesting authentication from Azure. Verify RedshiftProperties are correct"
             )
             raise InterfaceError(e)
         except requests.exceptions.RequestException as e:
             _logger.error("A unknown error occurred when requesting authentication from Azure.")
             raise InterfaceError(e)
 
-        _logger.debug(response.text)
+        _logger.debug("Azure Oauth authentication response length: {}".format(len(response.text)))
 
         # parse the JSON response to grab access_token field which contains Base64 encoded SAML
         # Assertion and decode it
         saml_assertion: str = ""
         try:
             saml_assertion = response.json()["access_token"]
         except Exception as e:
```

## redshift_connector/plugin/browser_azure_credentials_provider.py

```diff
@@ -144,15 +144,15 @@
                 "A error occurred when requesting authentication from Azure. Verify RedshiftProperties are correct"
             )
             raise InterfaceError(e)
         except requests.exceptions.RequestException as e:
             _logger.error("A unknown error occurred when requesting authentication from Azure")
             raise InterfaceError(e)
 
-        _logger.debug(response.text)
+        _logger.debug("Azure authentication response length: {}".format(len(response.text)))
 
         try:
             saml_assertion: str = response.json()["access_token"]
         except TypeError as e:
             _logger.error("Failed to decode saml assertion returned from Azure")
             raise InterfaceError(e)
         except KeyError as e:
```

## redshift_connector/plugin/ping_credentials_provider.py

```diff
@@ -61,15 +61,15 @@
                     "Verify RedshiftProperties are correct"
                 )
                 raise InterfaceError(e)
             except requests.exceptions.RequestException as e:
                 _logger.error("A unknown error occurred when requesting SAML assertion to refresh credentials")
                 raise InterfaceError(e)
 
-            _logger.debug(response.content)
+            _logger.debug("response length: {}".format(len(response.content)))
 
             try:
                 soup = bs4.BeautifulSoup(response.text)
             except Exception as e:
                 _logger.error("An error occurred while parsing response: {}".format(str(e)))
                 raise InterfaceError(e)
```

## redshift_connector/utils/logging_utils.py

```diff
@@ -8,31 +8,82 @@
 def make_divider_block() -> str:
     return "=" * 35
 
 
 def mask_secure_info_in_props(info: "RedshiftProperty") -> "RedshiftProperty":
     from redshift_connector import RedshiftProperty
 
+    logging_allow_list: typing.Tuple[str, ...] = (
+        # "access_key_id",
+        "allow_db_user_override",
+        "app_id",
+        "app_name",
+        "application_name",
+        "auth_profile",
+        "auto_create",
+        # "client_id",
+        "client_protocol_version",
+        # "client_secret",
+        "cluster_identifier",
+        "credentials_provider",
+        "database_metadata_current_db_only",
+        "db_groups",
+        "db_name",
+        "db_user",
+        "duration",
+        "endpoint_url",
+        "force_lowercase",
+        "group_federation",
+        "host",
+        "iam",
+        "iam_disable_cache",
+        "idp_host",
+        "idpPort",
+        "idp_response_timeout",
+        "idp_tenant",
+        "is_serverless",
+        "listen_port",
+        "login_url",
+        "max_prepared_statements",
+        "numeric_to_float",
+        "partner_sp_id",
+        # "password",
+        "port",
+        "preferred_role",
+        "principal",
+        "profile",
+        "provider_name",
+        "region",
+        "replication",
+        "role_arn",
+        "role_session_name",
+        "scope",
+        # "secret_access_key",
+        "serverless_acct_id",
+        "serverless_work_group",
+        # "session_token",
+        "source_address",
+        "ssl",
+        "ssl_insecure",
+        "sslmode",
+        "tcp_keepalive",
+        "timeout",
+        "unix_sock",
+        "user_name",
+        # "web_identity_token",
+    )
+
     if info is None:
         return info
-    secure_info_found: bool = False
-    placeholder_value: str = "***"
 
-    temp: RedshiftProperty = copy.deepcopy(info)
+    temp: RedshiftProperty = RedshiftProperty()
 
     def is_populated(field: typing.Optional[str]):
         return field is not None and field != ""
 
-    if is_populated(temp.password):
-        secure_info_found = True
-        temp.password = placeholder_value
-    if is_populated(temp.access_key_id):
-        secure_info_found = True
-        temp.access_key_id = placeholder_value
-    if is_populated(temp.secret_access_key):
-        secure_info_found = True
-        temp.secret_access_key = placeholder_value
-    if is_populated(temp.session_token):
-        secure_info_found = True
-        temp.session_token = placeholder_value
+    for parameter, value in info.__dict__.items():
+        if parameter in logging_allow_list:
+            temp.put(parameter, value)
+        elif is_populated(value):
+            temp.put(parameter, "***")
 
-    return temp if secure_info_found else info
+    return temp
```

## Comparing `redshift_connector-2.0.911.dist-info/LICENSE` & `redshift_connector-2.0.912.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `redshift_connector-2.0.911.dist-info/METADATA` & `redshift_connector-2.0.912.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: redshift-connector
-Version: 2.0.911
+Version: 2.0.912
 Summary: Redshift interface library
 Home-page: https://github.com/aws/amazon-redshift-python-driver
 Author: Amazon Web Services
 Author-email: redshift-drivers@amazon.com
 License: Apache License 2.0
 Keywords: redshift dbapi
 Platform: UNKNOWN
@@ -13,14 +13,16 @@
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.6
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: Implementation
 Classifier: Programming Language :: Python :: Implementation :: CPython
 Classifier: Programming Language :: Python :: Implementation :: Jython
 Classifier: Programming Language :: Python :: Implementation :: PyPy
 Classifier: Operating System :: OS Independent
 Classifier: Topic :: Database :: Front-Ends
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
```

## Comparing `redshift_connector-2.0.911.dist-info/RECORD` & `redshift_connector-2.0.912.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,45 +1,45 @@
 redshift_connector/__init__.py,sha256=y406EJKqfT1-HaynlhxEzsdoafksQ9rDviY80xCDN5c,17905
 redshift_connector/config.py,sha256=FPgVMSl0l431JuKZF-xhmq8gL5Wgb0hRqW1bWOtTbEY,5716
-redshift_connector/core.py,sha256=nPj-lFkuQyeouz9y4fyWR2WMDIZG87BPBWL1UklrlcA,95283
+redshift_connector/core.py,sha256=CZTqJnthw3M7JfnWZdLXHTAJtUILluGLaYnqdJ7M_wk,96086
 redshift_connector/credentials_holder.py,sha256=fJ-ygCyGRymoQ3UQNTlXoWcXQzAGc0ylniXqpStcuwk,8205
-redshift_connector/cursor.py,sha256=Dao6OQObzHU2xbBdeLlLYQ7wnjA3jjndJOraGqE55u0,99031
+redshift_connector/cursor.py,sha256=HdVO31aOiMjFysryttr8bns4_zNG_s_t3y0yiu1q9tI,99340
 redshift_connector/error.py,sha256=Af_kEIMj9VmQ9ol5J1g2GB9jii3LRmYyxMLj7dvp13o,3994
-redshift_connector/iam_helper.py,sha256=8D1LvLPIHWaMn-BqEmp_tU8fcDHTWwSLWAF8xM1W4Wo,16994
-redshift_connector/idp_auth_helper.py,sha256=Zch-xqD59uedS7fu65zWeUWpQc7aXnBpM6pxpbXan8M,11042
+redshift_connector/iam_helper.py,sha256=iOEaTUOk-KMdYKVEvwvZ3goLDIUsjeX6FPpgUyi736k,24915
+redshift_connector/idp_auth_helper.py,sha256=tVbnUF7OaAgtzFLZWFJN8owpzWqxi1AXEnpb7X1DZO4,11064
 redshift_connector/interval.py,sha256=DWASZf5E-HCGcSZ56KtRNgQSitox2zQtsQ4yU0R5a2M,3566
 redshift_connector/native_plugin_helper.py,sha256=kmatMyBmNqHWb5kRwB1SDwa-O4fAB1ebhUTOdE4JUDQ,3390
 redshift_connector/objects.py,sha256=CR050qJB7gp0-jBDZ22rxgmmbdi3UF-Pg5CN0hRXgC4,2363
 redshift_connector/pg_types.py,sha256=A-1I8ArT5MHW1YoRocIe-68FYBGQAxQEwwNooEaURaQ,762
-redshift_connector/redshift_property.py,sha256=U5Ftb2tIuG59903qv6KE0MDetRpUHkYCXufN_On236w,10092
-redshift_connector/version.py,sha256=Xcn6md8BmIz7lGlpRLj1A7UCaxlk9C0Z52bHqc1BK6g,214
+redshift_connector/redshift_property.py,sha256=DaGHdprIzDt7lowVHei23aDTOa1-cXGQFxgM8ijq0A0,11806
+redshift_connector/version.py,sha256=x3R9KLADgo-bixL5n2q4aKjPqbpJkWr5k_829YMqX4A,214
 redshift_connector/auth/__init__.py,sha256=2UUlehVekwvYWKgH1OVhuL81EtKRISiZk5NAFpDZCRU,61
 redshift_connector/auth/aws_credentials_provider.py,sha256=RRwsCYzIgMt6KRdL-rw5ZuRaA7ydtGeoK9O1amDQ3RQ,4349
 redshift_connector/files/redshift-ca-bundle.crt,sha256=792ZdTc-pJa_hdkZt0xVzdrmoXLP3_7XJNif7z6Ge58,9870
 redshift_connector/plugin/__init__.py,sha256=K-1U25W7O1gM3DCXuenXsUAt8y0R4tXzkWJuHMjUiQ4,741
-redshift_connector/plugin/adfs_credentials_provider.py,sha256=VXLRLZb4UI0AUR1xati3v5u7W55OHevrBh3dXmYEo88,5577
-redshift_connector/plugin/azure_credentials_provider.py,sha256=Q6Rv6uHV3Y_pF1CrlHUkWYdv6jzBEwNnD_aabYvBMI0,7154
-redshift_connector/plugin/browser_azure_credentials_provider.py,sha256=oM6y_YyuDkg0_7lkoJwE_WLLvrPP9ezaFhKmjNxxLvE,10640
+redshift_connector/plugin/adfs_credentials_provider.py,sha256=XDRk5T66cGSKdvYeFpxw-tro1chTD0EOrOvd5fvzvqg,5643
+redshift_connector/plugin/azure_credentials_provider.py,sha256=7vU3iNrJcdHSsDVn9EOhx4HbQh1qOy4fIYLFqoI6lWs,7216
+redshift_connector/plugin/browser_azure_credentials_provider.py,sha256=5HDLVdnDZB-JnZxl7LuBWB5BS9-FQLDy_YfkXiEioUE,10696
 redshift_connector/plugin/browser_azure_oauth2_credentials_provider.py,sha256=56oW_7X1XY2ion8ekrdnkMHI5mcSe7WO17_kjcfD38o,11479
 redshift_connector/plugin/browser_saml_credentials_provider.py,sha256=qj-J7tnLhF5JyMZ_BXfk4TVoXQ102SL2Xy8IZpxt510,4947
 redshift_connector/plugin/credential_provider_constants.py,sha256=K1Bi_2_7ZDU9FBDRX9Cf55DTHduV_2uCMSVO_phdK38,432
 redshift_connector/plugin/i_native_plugin.py,sha256=u35Gu1XMEKhrFd65c_oOlA6xgmylyY8u9YQweDQ9114,432
 redshift_connector/plugin/i_plugin.py,sha256=aAiCI_omfzT2XtX1KP3_Q9ufXaLq--UNagmd6ekJ9Hs,1493
 redshift_connector/plugin/idp_credentials_provider.py,sha256=_pIKSjNJ1QrKvt2Yh_Kg_HIkyOsFhFOg2sOsNwsFhlE,1542
 redshift_connector/plugin/jwt_credentials_provider.py,sha256=xLp9F4tuOHaqQvF3Uv_HY2faOOZ4x9XZeNGvYfOXfb4,4806
 redshift_connector/plugin/native_token_holder.py,sha256=27L5QeWQcqaqDWE5dnh8kzp9_HF1IuD5wkuS8hjRkT0,758
 redshift_connector/plugin/okta_credentials_provider.py,sha256=f8F7TAmsVJO5ldi0eadTQ--yZSVhQcNTd9gejvcvkV8,6280
-redshift_connector/plugin/ping_credentials_provider.py,sha256=dmdZtTrZDTAZWq-xmXvB3_c5Tv8-dbaZhqyEn3svCuw,6656
+redshift_connector/plugin/ping_credentials_provider.py,sha256=LLnmZIoCdU0IjtIXEr5zxB3WRSKnyLr4KMU0Yj7QNbE,6691
 redshift_connector/plugin/saml_credentials_provider.py,sha256=o3zc_4jqVTJNBowgWxNZH80x_fdHM3qJj033yJBHWWQ,11128
 redshift_connector/utils/__init__.py,sha256=jQPPXxIRYJ0KgcExi34mXEbXVIF0Pyf6rdTOpIBU3w8,892
 redshift_connector/utils/array_util.py,sha256=V0ALkEuwzfmEEKqRmgRQN77H0CBeHZI-ltE9SH1zjCM,1913
 redshift_connector/utils/driver_info.py,sha256=2L_CLxvWP7DeEpzXSfw6M0SB0AjtDqXdVkLI2zKc6T0,1442
 redshift_connector/utils/extensible_digest.py,sha256=ZZNr8ruzpN3DdBhvn6ifIGmAJ-O-OP0BCI0R7b5hzzM,1616
-redshift_connector/utils/logging_utils.py,sha256=g4RjWyGLMcXcXn5RXDmiIxFBXWlRQmlPven_EKPR4oA,1087
+redshift_connector/utils/logging_utils.py,sha256=JknQmLWBZmeW7oLNSk8YD-oDUtJ0kjrOm8OnVTtFcOc,2160
 redshift_connector/utils/oids.py,sha256=shPEnM8egn2u5vlkjZozrpCf5txRMmikbtKxCuu-Y38,1675
 redshift_connector/utils/type_utils.py,sha256=iH-bSxrtczIO7hQWYAlUfgUQa78kTGrekIVgkT1wu5o,24077
-redshift_connector-2.0.911.dist-info/LICENSE,sha256=CeipvOyAZxBGUsFoaFqwkx54aPnIKEtm9a5u2uXxEws,10142
-redshift_connector-2.0.911.dist-info/METADATA,sha256=P43XEikhLjqkrcEJD80B3fZxxCg0wYo8IAE8_i-LjmA,61356
-redshift_connector-2.0.911.dist-info/NOTICE,sha256=1CkO1kwu3Q_OHYTj-d-yiBJA_lNN73a4zSntavaD4oc,67
-redshift_connector-2.0.911.dist-info/WHEEL,sha256=XHhP4NZKzYpC5PqCMnZLMbQyjVLCf7mGMN72SS0pQ1U,93
-redshift_connector-2.0.911.dist-info/top_level.txt,sha256=jaX7d_6R_L5fi_cdB2Pe-b5-5RkoOMCMyKpj6g6qZr0,19
-redshift_connector-2.0.911.dist-info/RECORD,,
+redshift_connector-2.0.912.dist-info/LICENSE,sha256=CeipvOyAZxBGUsFoaFqwkx54aPnIKEtm9a5u2uXxEws,10142
+redshift_connector-2.0.912.dist-info/METADATA,sha256=nDwC3giSdeV8HhRAOwRQHu7_-6CsawVvJm9mVrN2Oj0,61458
+redshift_connector-2.0.912.dist-info/NOTICE,sha256=1CkO1kwu3Q_OHYTj-d-yiBJA_lNN73a4zSntavaD4oc,67
+redshift_connector-2.0.912.dist-info/WHEEL,sha256=XHhP4NZKzYpC5PqCMnZLMbQyjVLCf7mGMN72SS0pQ1U,93
+redshift_connector-2.0.912.dist-info/top_level.txt,sha256=jaX7d_6R_L5fi_cdB2Pe-b5-5RkoOMCMyKpj6g6qZr0,19
+redshift_connector-2.0.912.dist-info/RECORD,,
```

