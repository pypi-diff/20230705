# Comparing `tmp/polars_lts_cpu-0.18.4.tar.gz` & `tmp/polars_lts_cpu-0.18.5.tar.gz`

## Comparing `polars_lts_cpu-0.18.4.tar` & `polars_lts_cpu-0.18.5.tar`

### file list

```diff
@@ -1,1246 +1,1264 @@
--rw-r--r--   0        0        0     1353 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/LICENSE
--rw-r--r--   0     1001      123    16770 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/json/deserialize.rs
--rw-r--r--   0     1001      123     6564 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/json/infer_schema.rs
--rw-r--r--   0     1001      123      189 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/json/mod.rs
--rw-r--r--   0     1001      123       30 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/lib.rs
--rw-r--r--   0     1001      123     1198 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/ndjson/deserialize.rs
--rw-r--r--   0     1001      123     4828 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/ndjson/file.rs
--rw-r--r--   0     1001      123      143 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/ndjson/mod.rs
--rw-r--r--   0        0        0     1592 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/LICENSE
--rw-r--r--   0     1001      123      144 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/README.md
--rw-r--r--   0     1001      123     1975 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/default_arrays.rs
--rw-r--r--   0     1001      123     1791 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/fixed_size_list.rs
--rw-r--r--   0     1001      123     3773 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/get.rs
--rw-r--r--   0     1001      123     6664 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/list.rs
--rw-r--r--   0     1001      123     8165 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/mod.rs
--rw-r--r--   0     1001      123      878 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/null.rs
--rw-r--r--   0     1001      123     1125 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/slice.rs
--rw-r--r--   0     1001      123     2253 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/utf8.rs
--rw-r--r--   0     1001      123     2294 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/bit_util.rs
--rw-r--r--   0     1001      123       17 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/bitmap/mod.rs
--rw-r--r--   0     1001      123      819 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/bitmap/mutable.rs
--rw-r--r--   0     1001      123      370 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/add.rs
--rw-r--r--   0     1001      123     2181 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/commutative.rs
--rw-r--r--   0     1001      123     1482 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/div.rs
--rw-r--r--   0     1001      123     1028 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mod.rs
--rw-r--r--   0     1001      123     1177 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mul.rs
--rw-r--r--   0     1001      123      508 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/sub.rs
--rw-r--r--   0     1001      123       51 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/mod.rs
--rw-r--r--   0     1001      123        1 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arity.rs
--rw-r--r--   0     1001      123      727 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/bitwise.rs
--rw-r--r--   0     1001      123     1206 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/cast.rs
--rw-r--r--   0     1001      123     3964 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/decimal.rs
--rw-r--r--   0     1001      123     1250 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/mod.rs
--rw-r--r--   0     1001      123      391 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/take/bitmap.rs
--rw-r--r--   0     1001      123     2767 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/take/boolean.rs
--rw-r--r--   0     1001      123     3487 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/take/fixed_size_list.rs
--rw-r--r--   0     1001      123    25290 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/take/mod.rs
--rw-r--r--   0     1001      123      797 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/tile.rs
--rw-r--r--   0     1001      123     1102 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/conversion.rs
--rw-r--r--   0     1001      123     1609 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/data_types.rs
--rw-r--r--   0     1001      123       25 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/error.rs
--rw-r--r--   0     1001      123       28 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/export.rs
--rw-r--r--   0     1001      123       26 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/floats/mod.rs
--rw-r--r--   0     1001      123     2066 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/floats/ord.rs
--rw-r--r--   0     1001      123     1273 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/index.rs
--rw-r--r--   0     1001      123      984 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/is_valid.rs
--rw-r--r--   0     1001      123     4783 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/agg_mean.rs
--rw-r--r--   0     1001      123     1074 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/comparison.rs
--rw-r--r--   0     1001      123     1068 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/concatenate.rs
--rw-r--r--   0     1001      123     5161 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/ewm/average.rs
--rw-r--r--   0     1001      123     1808 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs
--rw-r--r--   0     1001      123    25065 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs
--rw-r--r--   0     1001      123     1406 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/float.rs
--rw-r--r--   0     1001      123     4908 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/list.rs
--rw-r--r--   0     1001      123     1885 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs
--rw-r--r--   0     1001      123     9783 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/mod.rs
--rw-r--r--   0     1001      123     3923 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs
--rw-r--r--   0     1001      123     2019 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs
--rw-r--r--   0     1001      123    16187 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs
--rw-r--r--   0     1001      123     3839 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs
--rw-r--r--   0     1001      123    11729 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs
--rw-r--r--   0     1001      123     5684 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs
--rw-r--r--   0     1001      123     7745 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs
--rw-r--r--   0     1001      123     1879 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs
--rw-r--r--   0     1001      123    14722 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs
--rw-r--r--   0     1001      123    10055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs
--rw-r--r--   0     1001      123    11643 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs
--rw-r--r--   0     1001      123     4821 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs
--rw-r--r--   0     1001      123     6856 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs
--rw-r--r--   0     1001      123     8109 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/window.rs
--rw-r--r--   0     1001      123     4753 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/set.rs
--rw-r--r--   0     1001      123     4529 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/sort_partition.rs
--rw-r--r--   0     1001      123     2948 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs
--rw-r--r--   0     1001      123     5974 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs
--rw-r--r--   0     1001      123      231 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/sorted_join/mod.rs
--rw-r--r--   0     1001      123      842 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/string.rs
--rw-r--r--   0     1001      123     2310 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/take_agg/boolean.rs
--rw-r--r--   0     1001      123     4315 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/take_agg/mod.rs
--rw-r--r--   0     1001      123     2606 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/take_agg/var.rs
--rw-r--r--   0     1001      123     3672 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/time.rs
--rw-r--r--   0     1001      123      341 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/lib.rs
--rw-r--r--   0     1001      123      496 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/prelude.rs
--rw-r--r--   0     1001      123      534 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/slice.rs
--rw-r--r--   0     1001      123      183 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/time_zone.rs
--rw-r--r--   0     1001      123      998 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/trusted_len/boolean.rs
--rw-r--r--   0     1001      123     2821 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/trusted_len/mod.rs
--rw-r--r--   0     1001      123     2054 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs
--rw-r--r--   0     1001      123      158 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/trusted_len/rev.rs
--rw-r--r--   0     1001      123     5233 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/utils.rs
--rw-r--r--   0        0        0    10626 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/LICENSE
--rw-r--r--   0     1001      123     3472 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/Makefile
--rw-r--r--   0     1001      123      215 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/build.rs
--rw-r--r--   0     1001      123       78 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/clippy.toml
--rw-r--r--   0     1001      123    17602 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/src/docs/eager.rs
--rw-r--r--   0     1001      123     8794 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/src/docs/lazy.rs
--rw-r--r--   0     1001      123       50 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/src/docs/mod.rs
--rw-r--r--   0     1001      123     3797 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/src/docs/performance.rs
--rw-r--r--   0     1001      123       59 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/src/export.rs
--rw-r--r--   0     1001      123    20214 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/src/lib.rs
--rw-r--r--   0     1001      123      387 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/src/prelude.rs
--rw-r--r--   0     1001      123       54 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/src/sql.rs
--rw-r--r--   0     1001      123     4272 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/date_like.rs
--rw-r--r--   0     1001      123     2401 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/groupby.rs
--rw-r--r--   0     1001      123    17836 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/joins.rs
--rw-r--r--   0     1001      123      545 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/list.rs
--rw-r--r--   0     1001      123      198 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/mod.rs
--rw-r--r--   0     1001      123       24 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/ops/mod.rs
--rw-r--r--   0     1001      123      457 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/ops/take.rs
--rw-r--r--   0     1001      123     6259 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/pivot.rs
--rw-r--r--   0     1001      123     1102 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/random.rs
--rw-r--r--   0     1001      123    11096 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/rolling_window.rs
--rw-r--r--   0     1001      123     1093 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/series.rs
--rw-r--r--   0     1001      123      370 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/utils.rs
--rw-r--r--   0     1001      123    30423 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/csv.rs
--rw-r--r--   0     1001      123     4490 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/ipc_stream.rs
--rw-r--r--   0     1001      123     7043 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/json.rs
--rw-r--r--   0     1001      123      378 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/mod.rs
--rw-r--r--   0     1001      123      531 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/parquet.rs
--rw-r--r--   0     1001      123     1530 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/joins.rs
--rw-r--r--   0     1001      123     2452 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/aggregation.rs
--rw-r--r--   0     1001      123      821 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/cse.rs
--rw-r--r--   0     1001      123      500 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/explodes.rs
--rw-r--r--   0     1001      123     2279 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/apply.rs
--rw-r--r--   0     1001      123    10285 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/arity.rs
--rw-r--r--   0     1001      123     1065 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/expand.rs
--rw-r--r--   0     1001      123     1008 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/filter.rs
--rw-r--r--   0     1001      123      428 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/is_in.rs
--rw-r--r--   0     1001      123      121 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/mod.rs
--rw-r--r--   0     1001      123      659 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/slice.rs
--rw-r--r--   0     1001      123    10657 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/window.rs
--rw-r--r--   0     1001      123      579 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/folds.rs
--rw-r--r--   0     1001      123      557 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/functions.rs
--rw-r--r--   0     1001      123     4482 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/groupby.rs
--rw-r--r--   0     1001      123     1681 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs
--rw-r--r--   0     1001      123      691 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/mod.rs
--rw-r--r--   0     1001      123     5747 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/predicate_queries.rs
--rw-r--r--   0     1001      123     4483 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/projection_queries.rs
--rw-r--r--   0     1001      123     6584 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/queries.rs
--rw-r--r--   0     1001      123      141 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/main.rs
--rw-r--r--   0     1001      123    12591 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/schema.rs
--rw-r--r--   0     1001      123     2061 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/time/date_range.rs
--rw-r--r--   0        0        0     6077 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/LICENSE
--rw-r--r--   0     1001      123      358 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/README.md
--rw-r--r--   0     1001      123     1796 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dot.rs
--rw-r--r--   0     1001      123     4479 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/eval.rs
--rw-r--r--   0     1001      123     7115 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/functions.rs
--rw-r--r--   0     1001      123      164 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/into.rs
--rw-r--r--   0     1001      123     6754 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/list.rs
--rw-r--r--   0     1001      123     2899 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/mod.rs
--rw-r--r--   0     1001      123     1182 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs
--rw-r--r--   0     1001      123     9285 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/csv.rs
--rw-r--r--   0     1001      123     4316 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/file_list_reader.rs
--rw-r--r--   0     1001      123     2261 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/ipc.rs
--rw-r--r--   0     1001      123    49023 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/mod.rs
--rw-r--r--   0     1001      123     3414 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/ndjson.rs
--rw-r--r--   0     1001      123     2734 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/parquet.rs
--rw-r--r--   0     1001      123     2892 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/pivot.rs
--rw-r--r--   0     1001      123      459 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/python.rs
--rw-r--r--   0     1001      123     6374 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/lib.rs
--rw-r--r--   0     1001      123     1049 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs
--rw-r--r--   0     1001      123      776 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs
--rw-r--r--   0     1001      123      670 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs
--rw-r--r--   0     1001      123     1555 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs
--rw-r--r--   0     1001      123     3986 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs
--rw-r--r--   0     1001      123     4125 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs
--rw-r--r--   0     1001      123    13599 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs
--rw-r--r--   0     1001      123     4883 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs
--rw-r--r--   0     1001      123     5859 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs
--rw-r--r--   0     1001      123     6753 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs
--rw-r--r--   0     1001      123     2045 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs
--rw-r--r--   0     1001      123     1761 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs
--rw-r--r--   0     1001      123     2854 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs
--rw-r--r--   0     1001      123     1963 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs
--rw-r--r--   0     1001      123     4303 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs
--rw-r--r--   0     1001      123     1209 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs
--rw-r--r--   0     1001      123     2421 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs
--rw-r--r--   0     1001      123      548 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs
--rw-r--r--   0     1001      123     2197 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs
--rw-r--r--   0     1001      123     2015 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs
--rw-r--r--   0     1001      123      663 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs
--rw-r--r--   0     1001      123     4041 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs
--rw-r--r--   0     1001      123      838 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs
--rw-r--r--   0     1001      123     1335 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/exotic.rs
--rw-r--r--   0     1001      123    21959 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs
--rw-r--r--   0     1001      123     2689 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs
--rw-r--r--   0     1001      123    18331 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs
--rw-r--r--   0     1001      123    17674 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs
--rw-r--r--   0     1001      123     2583 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/cache.rs
--rw-r--r--   0     1001      123     3153 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs
--rw-r--r--   0     1001      123     6326 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs
--rw-r--r--   0     1001      123     1996 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs
--rw-r--r--   0     1001      123     5809 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs
--rw-r--r--   0     1001      123     4131 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs
--rw-r--r--   0     1001      123     5304 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs
--rw-r--r--   0     1001      123    23566 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs
--rw-r--r--   0     1001      123    10091 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs
--rw-r--r--   0     1001      123     4332 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs
--rw-r--r--   0     1001      123    13549 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs
--rw-r--r--   0     1001      123     8331 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs
--rw-r--r--   0     1001      123    14360 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs
--rw-r--r--   0     1001      123    31558 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs
--rw-r--r--   0     1001      123     2039 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs
--rw-r--r--   0     1001      123      414 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/mod.rs
--rw-r--r--   0     1001      123     2005 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs
--rw-r--r--   0     1001      123    24050 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs
--rw-r--r--   0     1001      123    20552 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs
--rw-r--r--   0     1001      123       87 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/planner/mod.rs
--rw-r--r--   0     1001      123    10203 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/state.rs
--rw-r--r--   0     1001      123     2583 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/checks.rs
--rw-r--r--   0     1001      123     9280 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/construct_pipeline.rs
--rw-r--r--   0     1001      123    16847 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/convert_alp.rs
--rw-r--r--   0     1001      123      116 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/mod.rs
--rw-r--r--   0     1001      123     5827 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs
--rw-r--r--   0     1001      123      722 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/prelude.rs
--rw-r--r--   0     1001      123    14990 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/aggregations.rs
--rw-r--r--   0     1001      123     2339 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/arity.rs
--rw-r--r--   0     1001      123     7276 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/cse.rs
--rw-r--r--   0     1001      123    12759 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/io.rs
--rw-r--r--   0     1001      123     4166 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/logical.rs
--rw-r--r--   0     1001      123     4273 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/mod.rs
--rw-r--r--   0     1001      123    15770 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/optimization_checks.rs
--rw-r--r--   0     1001      123     6772 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/predicate_queries.rs
--rw-r--r--   0     1001      123     3165 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/projection_queries.rs
--rw-r--r--   0     1001      123    47687 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/queries.rs
--rw-r--r--   0     1001      123     9519 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/streaming.rs
--rw-r--r--   0     1001      123     2893 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/tpch.rs
--rw-r--r--   0     1001      123     1028 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/utils.rs
--rw-r--r--   0        0        0     3439 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/LICENSE
--rw-r--r--   0     1001      123      132 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/README.md
--rw-r--r--   0     1001      123     2382 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/array/min_max.rs
--rw-r--r--   0     1001      123      267 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/array/mod.rs
--rw-r--r--   0     1001      123     1512 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/array/namespace.rs
--rw-r--r--   0     1001      123     4108 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/array/sum_mean.rs
--rw-r--r--   0     1001      123      234 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/binary/mod.rs
--rw-r--r--   0     1001      123     3549 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs
--rw-r--r--   0     1001      123    11023 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/interpolate.rs
--rw-r--r--   0     1001      123     1687 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/count.rs
--rw-r--r--   0     1001      123     2419 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/hash.rs
--rw-r--r--   0     1001      123     7861 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs
--rw-r--r--   0     1001      123      511 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/mod.rs
--rw-r--r--   0     1001      123    19010 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs
--rw-r--r--   0     1001      123     7633 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs
--rw-r--r--   0     1001      123     2435 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs
--rw-r--r--   0     1001      123      545 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/mod.rs
--rw-r--r--   0     1001      123     9452 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs
--rw-r--r--   0     1001      123     6795 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/set.rs
--rw-r--r--   0     1001      123     8781 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/case.rs
--rw-r--r--   0     1001      123     8593 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs
--rw-r--r--   0     1001      123     2345 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs
--rw-r--r--   0     1001      123      514 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs
--rw-r--r--   0     1001      123    14951 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs
--rw-r--r--   0     1001      123     4053 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs
--rw-r--r--   0     1001      123      439 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/sum.rs
--rw-r--r--   0     1001      123     2486 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/top_k.rs
--rw-r--r--   0     1001      123     7727 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs
--rw-r--r--   0     1001      123    18232 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/join/mod.rs
--rw-r--r--   0     1001      123     4291 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/mod.rs
--rw-r--r--   0     1001      123    10257 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/pivot/mod.rs
--rw-r--r--   0     1001      123    13486 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/pivot/positioning.rs
--rw-r--r--   0     1001      123      237 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/lib.rs
--rw-r--r--   0     1001      123      290 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/prelude.rs
--rw-r--r--   0     1001      123       25 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/mod.rs
--rw-r--r--   0     1001      123     9623 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs
--rw-r--r--   0     1001      123      118 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/approx_algo/mod.rs
--rw-r--r--   0     1001      123     2016 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/approx_unique.rs
--rw-r--r--   0     1001      123    11866 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs
--rw-r--r--   0     1001      123     3688 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/floor_divide.rs
--rw-r--r--   0     1001      123     5245 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/fused.rs
--rw-r--r--   0     1001      123     3423 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/is_first.rs
--rw-r--r--   0     1001      123     2975 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/is_unique.rs
--rw-r--r--   0     1001      123     3626 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/log.rs
--rw-r--r--   0     1001      123     1187 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/mod.rs
--rw-r--r--   0     1001      123     1769 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/rolling.rs
--rw-r--r--   0     1001      123     7642 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/search_sorted.rs
--rw-r--r--   0     1001      123     2603 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/to_dummies.rs
--rw-r--r--   0     1001      123     2067 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/various.rs
--rw-r--r--   0        0        0     1998 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/LICENSE
--rw-r--r--   0     1001      123      165 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/README.md
--rw-r--r--   0     1001      123       98 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/mod.rs
--rw-r--r--   0     1001      123     1219 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/filter.rs
--rw-r--r--   0     1001      123     4103 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/function.rs
--rw-r--r--   0     1001      123      266 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/mod.rs
--rw-r--r--   0     1001      123      682 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/pass.rs
--rw-r--r--   0     1001      123      548 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs
--rw-r--r--   0     1001      123     3553 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/projection.rs
--rw-r--r--   0     1001      123     3559 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/reproject.rs
--rw-r--r--   0     1001      123     6479 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs
--rw-r--r--   0     1001      123    11288 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs
--rw-r--r--   0     1001      123     1207 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs
--rw-r--r--   0     1001      123     1888 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs
--rw-r--r--   0     1001      123     4554 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs
--rw-r--r--   0     1001      123     1746 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs
--rw-r--r--   0     1001      123     5413 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs
--rw-r--r--   0     1001      123     4951 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs
--rw-r--r--   0     1001      123      211 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mod.rs
--rw-r--r--   0     1001      123      856 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs
--rw-r--r--   0     1001      123     4294 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs
--rw-r--r--   0     1001      123     4109 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs
--rw-r--r--   0     1001      123     7404 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs
--rw-r--r--   0     1001      123    10554 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs
--rw-r--r--   0     1001      123     3589 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs
--rw-r--r--   0     1001      123     2767 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs
--rw-r--r--   0     1001      123     6326 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs
--rw-r--r--   0     1001      123     3116 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/source.rs
--rw-r--r--   0     1001      123    10194 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs
--rw-r--r--   0     1001      123     2119 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs
--rw-r--r--   0     1001      123     4695 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs
--rw-r--r--   0     1001      123     1887 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs
--rw-r--r--   0     1001      123    20783 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs
--rw-r--r--   0     1001      123    23825 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs
--rw-r--r--   0     1001      123     2457 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs
--rw-r--r--   0     1001      123     9239 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/io.rs
--rw-r--r--   0     1001      123     5451 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs
--rw-r--r--   0     1001      123    11949 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs
--rw-r--r--   0     1001      123    11756 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs
--rw-r--r--   0     1001      123      178 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/joins/mod.rs
--rw-r--r--   0     1001      123     2241 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/memory.rs
--rw-r--r--   0     1001      123      589 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/mod.rs
--rw-r--r--   0     1001      123     1492 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs
--rw-r--r--   0     1001      123     1824 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs
--rw-r--r--   0     1001      123     3108 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/slice.rs
--rw-r--r--   0     1001      123      130 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/sort/mod.rs
--rw-r--r--   0     1001      123     6774 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs
--rw-r--r--   0     1001      123     7279 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs
--rw-r--r--   0     1001      123     5953 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs
--rw-r--r--   0     1001      123     3908 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs
--rw-r--r--   0     1001      123      526 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/utils.rs
--rw-r--r--   0     1001      123     5984 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/csv.rs
--rw-r--r--   0     1001      123     1231 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/frame.rs
--rw-r--r--   0     1001      123      987 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs
--rw-r--r--   0     1001      123      366 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/mod.rs
--rw-r--r--   0     1001      123     4335 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/parquet.rs
--rw-r--r--   0     1001      123     1146 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/reproject.rs
--rw-r--r--   0     1001      123     1022 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/union.rs
--rw-r--r--   0     1001      123      448 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/expressions.rs
--rw-r--r--   0     1001      123      272 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/lib.rs
--rw-r--r--   0     1001      123      719 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/chunks.rs
--rw-r--r--   0     1001      123      474 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/context.rs
--rw-r--r--   0     1001      123      223 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/mod.rs
--rw-r--r--   0     1001      123      514 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/operator.rs
--rw-r--r--   0     1001      123      626 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/sink.rs
--rw-r--r--   0     1001      123      241 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/source.rs
--rw-r--r--   0     1001      123        1 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/pipeline/config.rs
--rw-r--r--   0     1001      123    21321 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/pipeline/convert.rs
--rw-r--r--   0     1001      123    20362 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs
--rw-r--r--   0     1001      123     1155 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/pipeline/mod.rs
--rw-r--r--   0        0        0     1106 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/LICENSE
--rw-r--r--   0     1001      123      466 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/README.md
--rw-r--r--   0     1001      123    23236 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/context.rs
--rw-r--r--   0     1001      123    23921 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/functions.rs
--rw-r--r--   0     1001      123     2122 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/keywords.rs
--rw-r--r--   0     1001      123      239 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/lib.rs
--rw-r--r--   0     1001      123    20933 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/sql_expr.rs
--rw-r--r--   0     1001      123     4572 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/table_functions.rs
--rw-r--r--   0     1001      123     1682 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_cumulative.rs
--rw-r--r--   0     1001      123     3063 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_io.rs
--rw-r--r--   0     1001      123     1539 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_math.rs
--rw-r--r--   0     1001      123      860 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_meta.rs
--rw-r--r--   0     1001      123     2982 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_string.rs
--rw-r--r--   0     1001      123     1056 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_7436.rs
--rw-r--r--   0     1001      123      888 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_7437.rs
--rw-r--r--   0     1001      123      652 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_7440.rs
--rw-r--r--   0     1001      123      700 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_8395.rs
--rw-r--r--   0     1001      123     1062 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_8419.rs
--rw-r--r--   0     1001      123      982 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/ops_distinct_on.rs
--rw-r--r--   0     1001      123    15811 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/simple_exprs.rs
--rw-r--r--   0     1001      123     3343 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/statements.rs
--rw-r--r--   0        0        0     2037 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/LICENSE
--rw-r--r--   0     1001      123      143 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/README.md
--rw-r--r--   0     1001      123     3569 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/date.rs
--rw-r--r--   0     1001      123     6465 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/datetime.rs
--rw-r--r--   0     1001      123     3305 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/duration.rs
--rw-r--r--   0     1001      123     5607 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/kernels.rs
--rw-r--r--   0     1001      123     1062 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/mod.rs
--rw-r--r--   0     1001      123     6737 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs
--rw-r--r--   0     1001      123     2582 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs
--rw-r--r--   0     1001      123    11122 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs
--rw-r--r--   0     1001      123      413 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/mod.rs
--rw-r--r--   0     1001      123     4810 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs
--rw-r--r--   0     1001      123     2372 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/time.rs
--rw-r--r--   0     1001      123    21334 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs
--rw-r--r--   0     1001      123    18997 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs
--rw-r--r--   0     1001      123     3975 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs
--rw-r--r--   0     1001      123    10548 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs
--rw-r--r--   0     1001      123     3340 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/date_range.rs
--rw-r--r--   0     1001      123    34703 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/groupby/dynamic.rs
--rw-r--r--   0     1001      123       88 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/groupby/mod.rs
--rw-r--r--   0     1001      123      621 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/lib.rs
--rw-r--r--   0     1001      123     2976 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/month_end.rs
--rw-r--r--   0     1001      123     3365 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/month_start.rs
--rw-r--r--   0     1001      123      274 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/prelude.rs
--rw-r--r--   0     1001      123     1381 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/round.rs
--rw-r--r--   0     1001      123     3992 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/_trait.rs
--rw-r--r--   0     1001      123      136 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/boolean.rs
--rw-r--r--   0     1001      123      140 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/categoricals.rs
--rw-r--r--   0     1001      123      133 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/date.rs
--rw-r--r--   0     1001      123      137 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/datetime.rs
--rw-r--r--   0     1001      123      137 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/duration.rs
--rw-r--r--   0     1001      123     1863 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/floats.rs
--rw-r--r--   0     1001      123     1792 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/integers.rs
--rw-r--r--   0     1001      123      133 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/list.rs
--rw-r--r--   0     1001      123      486 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/mod.rs
--rw-r--r--   0     1001      123      155 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/object.rs
--rw-r--r--   0     1001      123      135 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/struct_.rs
--rw-r--r--   0     1001      123      133 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/time.rs
--rw-r--r--   0     1001      123      133 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/utf8.rs
--rw-r--r--   0     1001      123    12791 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/mod.rs
--rw-r--r--   0     1001      123     1443 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/truncate.rs
--rw-r--r--   0     1001      123     6845 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/upsample.rs
--rw-r--r--   0     1001      123     2511 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/utils.rs
--rw-r--r--   0     1001      123     1524 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/bounds.rs
--rw-r--r--   0     1001      123     2672 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/calendar.rs
--rw-r--r--   0     1001      123    25015 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/duration.rs
--rw-r--r--   0     1001      123    20201 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/groupby.rs
--rw-r--r--   0     1001      123      503 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/mod.rs
--rw-r--r--   0     1001      123    23627 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/test.rs
--rw-r--r--   0     1001      123    10657 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/window.rs
--rw-r--r--   0        0        0     5291 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/LICENSE
--rw-r--r--   0     1001      123       45 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/constants.rs
--rw-r--r--   0     1001      123    17253 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dot.rs
--rw-r--r--   0     1001      123     4789 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/arithmetic.rs
--rw-r--r--   0     1001      123     3992 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/arity.rs
--rw-r--r--   0     1001      123     1278 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/array.rs
--rw-r--r--   0     1001      123      935 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/binary.rs
--rw-r--r--   0     1001      123      650 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/cat.rs
--rw-r--r--   0     1001      123    10232 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/dt.rs
--rw-r--r--   0     1001      123     9542 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/expr.rs
--rw-r--r--   0     1001      123     8359 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/expr_dyn_fn.rs
--rw-r--r--   0     1001      123      753 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/from.rs
--rw-r--r--   0     1001      123       85 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/abs.rs
--rw-r--r--   0     1001      123     1431 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs
--rw-r--r--   0     1001      123     1074 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/array.rs
--rw-r--r--   0     1001      123     1327 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs
--rw-r--r--   0     1001      123     4221 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs
--rw-r--r--   0     1001      123     1910 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs
--rw-r--r--   0     1001      123     1216 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs
--rw-r--r--   0     1001      123      344 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/clip.rs
--rw-r--r--   0     1001      123      257 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/concat.rs
--rw-r--r--   0     1001      123     6125 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/correlation.rs
--rw-r--r--   0     1001      123     1593 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs
--rw-r--r--   0     1001      123    10067 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs
--rw-r--r--   0     1001      123      782 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs
--rw-r--r--   0     1001      123     2567 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs
--rw-r--r--   0     1001      123      992 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/fused.rs
--rw-r--r--   0     1001      123     8119 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/list.rs
--rw-r--r--   0     1001      123      581 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/log.rs
--rw-r--r--   0     1001      123    21448 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs
--rw-r--r--   0     1001      123      462 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/nan.rs
--rw-r--r--   0     1001      123     3132 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs
--rw-r--r--   0     1001      123      152 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/rolling.rs
--rw-r--r--   0     1001      123      260 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/round.rs
--rw-r--r--   0     1001      123      200 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/row_hash.rs
--rw-r--r--   0     1001      123    14678 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs
--rw-r--r--   0     1001      123      306 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/search_sorted.rs
--rw-r--r--   0     1001      123     3812 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs
--rw-r--r--   0     1001      123     1238 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs
--rw-r--r--   0     1001      123      972 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs
--rw-r--r--   0     1001      123    22249 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs
--rw-r--r--   0     1001      123     1017 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs
--rw-r--r--   0     1001      123     5509 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs
--rw-r--r--   0     1001      123     6112 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs
--rw-r--r--   0     1001      123      170 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/unique.rs
--rw-r--r--   0     1001      123     1155 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/arity.rs
--rw-r--r--   0     1001      123      611 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/coerce.rs
--rw-r--r--   0     1001      123     2717 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/concat.rs
--rw-r--r--   0     1001      123     4525 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/correlation.rs
--rw-r--r--   0     1001      123     8736 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/horizontal.rs
--rw-r--r--   0     1001      123     1044 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/index.rs
--rw-r--r--   0     1001      123      968 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/mod.rs
--rw-r--r--   0     1001      123     9827 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/range.rs
--rw-r--r--   0     1001      123     1308 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/selectors.rs
--rw-r--r--   0     1001      123     1973 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/syntactic_sugar.rs
--rw-r--r--   0     1001      123    11328 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/temporal.rs
--rw-r--r--   0     1001      123    10213 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/list.rs
--rw-r--r--   0     1001      123     3772 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/meta.rs
--rw-r--r--   0     1001      123    61502 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/mod.rs
--rw-r--r--   0     1001      123       40 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/names.rs
--rw-r--r--   0     1001      123     2658 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/options.rs
--rw-r--r--   0     1001      123     6632 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/python_udf.rs
--rw-r--r--   0     1001      123     1068 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/selector.rs
--rw-r--r--   0     1001      123    17626 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/string.rs
--rw-r--r--   0     1001      123     2715 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/struct_.rs
--rw-r--r--   0     1001      123       38 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/frame/mod.rs
--rw-r--r--   0     1001      123      933 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/frame/opt_state.rs
--rw-r--r--   0     1001      123      466 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/global.rs
--rw-r--r--   0     1001      123      175 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/lib.rs
--rw-r--r--   0     1001      123     8318 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs
--rw-r--r--   0     1001      123    11920 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs
--rw-r--r--   0     1001      123    25683 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/alp.rs
--rw-r--r--   0     1001      123     1622 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs
--rw-r--r--   0     1001      123     1428 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/apply.rs
--rw-r--r--   0     1001      123    24898 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/builder.rs
--rw-r--r--   0     1001      123    29993 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/conversion.rs
--rw-r--r--   0     1001      123      301 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/debug.rs
--rw-r--r--   0     1001      123    15470 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/format.rs
--rw-r--r--   0     1001      123      895 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs
--rw-r--r--   0     1001      123      137 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/explode.rs
--rw-r--r--   0     1001      123     1169 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs
--rw-r--r--   0     1001      123    11905 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs
--rw-r--r--   0     1001      123     1330 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs
--rw-r--r--   0     1001      123    10140 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/iterator.rs
--rw-r--r--   0     1001      123    10559 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/lit.rs
--rw-r--r--   0     1001      123     8072 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/mod.rs
--rw-r--r--   0     1001      123     7416 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs
--rw-r--r--   0     1001      123    15277 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs
--rw-r--r--   0     1001      123     2889 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs
--rw-r--r--   0     1001      123     3236 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs
--rw-r--r--   0     1001      123     3994 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs
--rw-r--r--   0     1001      123    14479 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs
--rw-r--r--   0     1001      123     1556 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs
--rw-r--r--   0     1001      123     6017 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/fused.rs
--rw-r--r--   0     1001      123     6774 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs
--rw-r--r--   0     1001      123     1222 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs
--rw-r--r--   0     1001      123    28901 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs
--rw-r--r--   0     1001      123     2571 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs
--rw-r--r--   0     1001      123    15756 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs
--rw-r--r--   0     1001      123     1755 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs
--rw-r--r--   0     1001      123     3930 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs
--rw-r--r--   0     1001      123     1799 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs
--rw-r--r--   0     1001      123     3269 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs
--rw-r--r--   0     1001      123     2638 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs
--rw-r--r--   0     1001      123    15752 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs
--rw-r--r--   0     1001      123    26507 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs
--rw-r--r--   0     1001      123     3707 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs
--rw-r--r--   0     1001      123     2639 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs
--rw-r--r--   0     1001      123     3501 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs
--rw-r--r--   0     1001      123    27269 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs
--rw-r--r--   0     1001      123     3492 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs
--rw-r--r--   0     1001      123    13232 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs
--rw-r--r--   0     1001      123     4181 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs
--rw-r--r--   0     1001      123     9725 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs
--rw-r--r--   0     1001      123    20215 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs
--rw-r--r--   0     1001      123    10585 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/options.rs
--rw-r--r--   0     1001      123    18601 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/projection.rs
--rw-r--r--   0     1001      123     6144 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs
--rw-r--r--   0     1001      123    13026 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/schema.rs
--rw-r--r--   0     1001      123      832 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/prelude.rs
--rw-r--r--   0     1001      123    12428 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/utils.rs
--rw-r--r--   0        0        0      954 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/LICENSE
--rw-r--r--   0     1001      123      137 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/README.md
--rw-r--r--   0     1001      123     1916 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/decode.rs
--rw-r--r--   0     1001      123    13364 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/encode.rs
--rw-r--r--   0     1001      123     7719 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/fixed.rs
--rw-r--r--   0     1001      123    13846 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/lib.rs
--rw-r--r--   0     1001      123     3019 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/row.rs
--rw-r--r--   0     1001      123      682 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/utils.rs
--rw-r--r--   0     1001      123     8679 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/variable.rs
--rw-r--r--   0        0        0      894 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-error/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-error/LICENSE
--rw-r--r--   0     1001      123      145 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-error/README.md
--rw-r--r--   0     1001      123     6719 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-error/src/lib.rs
--rw-r--r--   0        0        0     5484 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/LICENSE
--rw-r--r--   0     1001      123      144 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/README.md
--rw-r--r--   0     1001      123     5158 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/arithmetic/decimal.rs
--rw-r--r--   0     1001      123     8275 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/arithmetic/mod.rs
--rw-r--r--   0     1001      123     9417 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/arithmetic/numeric.rs
--rw-r--r--   0     1001      123     3588 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/array/iterator.rs
--rw-r--r--   0     1001      123     2551 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/array/mod.rs
--rw-r--r--   0     1001      123     6448 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/bitwise.rs
--rw-r--r--   0     1001      123     2298 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/binary.rs
--rw-r--r--   0     1001      123     1207 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs
--rw-r--r--   0     1001      123     4311 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/fixed_size_list.rs
--rw-r--r--   0     1001      123     1556 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/from.rs
--rw-r--r--   0     1001      123    20366 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/list.rs
--rw-r--r--   0     1001      123     8969 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/mod.rs
--rw-r--r--   0     1001      123     1410 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs
--rw-r--r--   0     1001      123     2291 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs
--rw-r--r--   0     1001      123    16475 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/cast.rs
--rw-r--r--   0     1001      123    49461 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs
--rw-r--r--   0     1001      123    10060 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs
--rw-r--r--   0     1001      123      551 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/drop.rs
--rw-r--r--   0     1001      123      963 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/float.rs
--rw-r--r--   0     1001      123     7175 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/from.rs
--rw-r--r--   0     1001      123    42339 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs
--rw-r--r--   0     1001      123     1453 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs
--rw-r--r--   0     1001      123       28 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/iterator/par/mod.rs
--rw-r--r--   0     1001      123     1129 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs
--rw-r--r--   0     1001      123       21 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/kernels/mod.rs
--rw-r--r--   0     1001      123     2347 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/kernels/take.rs
--rw-r--r--   0     1001      123     7963 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/list/iterator.rs
--rw-r--r--   0     1001      123     3242 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/list/mod.rs
--rw-r--r--   0     1001      123    19831 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs
--rw-r--r--   0     1001      123     3688 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs
--rw-r--r--   0     1001      123     4270 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs
--rw-r--r--   0     1001      123    10219 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs
--rw-r--r--   0     1001      123     1400 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs
--rw-r--r--   0     1001      123      358 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/full.rs
--rw-r--r--   0     1001      123      192 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/mod.rs
--rw-r--r--   0     1001      123     2731 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs
--rw-r--r--   0     1001      123     2172 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs
--rw-r--r--   0     1001      123      925 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs
--rw-r--r--   0     1001      123     6417 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs
--rw-r--r--   0     1001      123     1604 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/date.rs
--rw-r--r--   0     1001      123     4105 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs
--rw-r--r--   0     1001      123     4443 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs
--rw-r--r--   0     1001      123     2434 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/duration.rs
--rw-r--r--   0     1001      123     2556 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/mod.rs
--rw-r--r--   0     1001      123      476 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/struct_/from.rs
--rw-r--r--   0     1001      123    15983 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs
--rw-r--r--   0     1001      123     1182 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/time.rs
--rw-r--r--   0     1001      123    23489 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/mod.rs
--rw-r--r--   0     1001      123     7200 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ndarray.rs
--rw-r--r--   0     1001      123     4484 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/builder.rs
--rw-r--r--   0     1001      123     1547 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs
--rw-r--r--   0     1001      123     3124 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs
--rw-r--r--   0     1001      123     7054 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs
--rw-r--r--   0     1001      123     3410 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs
--rw-r--r--   0     1001      123      137 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/is_valid.rs
--rw-r--r--   0     1001      123     4419 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/iterator.rs
--rw-r--r--   0     1001      123     4806 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/mod.rs
--rw-r--r--   0     1001      123     2956 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/registry.rs
--rw-r--r--   0     1001      123      272 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/abs.rs
--rw-r--r--   0     1001      123    32691 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs
--rw-r--r--   0     1001      123    10025 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs
--rw-r--r--   0     1001      123     2880 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs
--rw-r--r--   0     1001      123    10551 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs
--rw-r--r--   0     1001      123     4526 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/append.rs
--rw-r--r--   0     1001      123    28257 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/apply.rs
--rw-r--r--   0     1001      123    12799 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs
--rw-r--r--   0     1001      123     6236 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs
--rw-r--r--   0     1001      123    11537 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs
--rw-r--r--   0     1001      123     1737 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs
--rw-r--r--   0     1001      123     4801 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs
--rw-r--r--   0     1001      123      908 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/decimal.rs
--rw-r--r--   0     1001      123     7056 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs
--rw-r--r--   0     1001      123    19462 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/explode.rs
--rw-r--r--   0     1001      123     8691 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/explode_and_offsets.rs
--rw-r--r--   0     1001      123     9103 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/extend.rs
--rw-r--r--   0     1001      123    13777 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs
--rw-r--r--   0     1001      123     6356 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/filter.rs
--rw-r--r--   0     1001      123     5876 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/full.rs
--rw-r--r--   0     1001      123        1 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/interpolate.rs
--rw-r--r--   0     1001      123    16797 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs
--rw-r--r--   0     1001      123        1 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/len.rs
--rw-r--r--   0     1001      123     2658 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/min_max_binary.rs
--rw-r--r--   0     1001      123    23276 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/mod.rs
--rw-r--r--   0     1001      123     2414 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs
--rw-r--r--   0     1001      123      593 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs
--rw-r--r--   0     1001      123     4375 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs
--rw-r--r--   0     1001      123     2771 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs
--rw-r--r--   0     1001      123    10267 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs
--rw-r--r--   0     1001      123    12518 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/set.rs
--rw-r--r--   0     1001      123     7391 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/shift.rs
--rw-r--r--   0     1001      123     2299 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs
--rw-r--r--   0     1001      123     5528 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs
--rw-r--r--   0     1001      123     7543 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs
--rw-r--r--   0     1001      123    31165 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs
--rw-r--r--   0     1001      123      380 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/slice.rs
--rw-r--r--   0     1001      123    22089 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs
--rw-r--r--   0     1001      123     7848 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs
--rw-r--r--   0     1001      123      301 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/take_every.rs
--rw-r--r--   0     1001      123    16256 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs
--rw-r--r--   0     1001      123     6275 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs
--rw-r--r--   0     1001      123     6072 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs
--rw-r--r--   0     1001      123      459 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/tile.rs
--rw-r--r--   0     1001      123    11626 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs
--rw-r--r--   0     1001      123    14620 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs
--rw-r--r--   0     1001      123     5846 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/zip.rs
--rw-r--r--   0     1001      123     9093 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/random.rs
--rw-r--r--   0     1001      123     1875 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs
--rw-r--r--   0     1001      123     2826 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/date.rs
--rw-r--r--   0     1001      123    10497 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs
--rw-r--r--   0     1001      123     3201 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs
--rw-r--r--   0     1001      123      595 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs
--rw-r--r--   0     1001      123     3042 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/time.rs
--rw-r--r--   0     1001      123      872 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/to_vec.rs
--rw-r--r--   0     1001      123     8114 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/trusted_len.rs
--rw-r--r--   0     1001      123    25939 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs
--rw-r--r--   0     1001      123     7944 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/cloud.rs
--rw-r--r--   0     1001      123     1549 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/config.rs
--rw-r--r--   0     1001      123     4469 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/_serde.rs
--rw-r--r--   0     1001      123     2509 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/aliases.rs
--rw-r--r--   0     1001      123    42659 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/any_value.rs
--rw-r--r--   0     1001      123    13349 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/dtype.rs
--rw-r--r--   0     1001      123     5609 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/field.rs
--rw-r--r--   0     1001      123     8059 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/mod.rs
--rw-r--r--   0     1001      123     2016 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/time_unit.rs
--rw-r--r--   0     1001      123      118 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/mod.rs
--rw-r--r--   0     1001      123      898 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs
--rw-r--r--   0     1001      123      481 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_3.rs
--rw-r--r--   0     1001      123      293 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_4.rs
--rw-r--r--   0     1001      123      499 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_5.rs
--rw-r--r--   0     1001      123      288 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_6.rs
--rw-r--r--   0     1001      123     1071 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_7.rs
--rw-r--r--   0     1001      123      819 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_8.rs
--rw-r--r--   0     1001      123      596 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_9.rs
--rw-r--r--   0     1001      123       43 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/mod.rs
--rw-r--r--   0     1001      123       25 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/error.rs
--rw-r--r--   0     1001      123      263 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/export.rs
--rw-r--r--   0     1001      123    36432 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/fmt.rs
--rw-r--r--   0     1001      123     5177 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/arithmetic.rs
--rw-r--r--   0     1001      123     9916 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/asof_join/asof.rs
--rw-r--r--   0     1001      123    35761 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/asof_join/groups.rs
--rw-r--r--   0     1001      123     7168 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/asof_join/mod.rs
--rw-r--r--   0     1001      123      559 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/chunks.rs
--rw-r--r--   0     1001      123     5181 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/cross_join.rs
--rw-r--r--   0     1001      123    16760 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/explode.rs
--rw-r--r--   0     1001      123     1019 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/from.rs
--rw-r--r--   0     1001      123    19219 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs
--rw-r--r--   0     1001      123     4113 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/boolean.rs
--rw-r--r--   0     1001      123     7749 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs
--rw-r--r--   0     1001      123    40479 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs
--rw-r--r--   0     1001      123     5634 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/utf8.rs
--rw-r--r--   0     1001      123      218 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/expr.rs
--rw-r--r--   0     1001      123    22901 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/hashing.rs
--rw-r--r--   0     1001      123    14380 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/into_groups.rs
--rw-r--r--   0     1001      123    39623 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/mod.rs
--rw-r--r--   0     1001      123    10637 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/perfect.rs
--rw-r--r--   0     1001      123    19780 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/proxy.rs
--rw-r--r--   0     1001      123     5406 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/args.rs
--rw-r--r--   0     1001      123    13329 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/mod.rs
--rw-r--r--   0     1001      123    22364 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs
--rw-r--r--   0     1001      123     2413 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs
--rw-r--r--   0     1001      123    17372 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs
--rw-r--r--   0     1001      123     4608 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs
--rw-r--r--   0     1001      123     6434 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs
--rw-r--r--   0     1001      123     4564 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs
--rw-r--r--   0     1001      123     3913 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs
--rw-r--r--   0     1001      123    12313 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs
--rw-r--r--   0     1001      123     3865 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/zip_outer.rs
--rw-r--r--   0     1001      123   126103 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/mod.rs
--rw-r--r--   0     1001      123    27652 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/row/av_buffer.rs
--rw-r--r--   0     1001      123     5183 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/row/dataframe.rs
--rw-r--r--   0     1001      123     5976 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/row/mod.rs
--rw-r--r--   0     1001      123     9875 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/row/transpose.rs
--rw-r--r--   0     1001      123     2811 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/top_k.rs
--rw-r--r--   0     1001      123     1388 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/upstream_traits.rs
--rw-r--r--   0     1001      123    10198 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/functions.rs
--rw-r--r--   0     1001      123     2149 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/fx.rs
--rw-r--r--   0     1001      123     1503 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/identity.rs
--rw-r--r--   0     1001      123      457 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/mod.rs
--rw-r--r--   0     1001      123     2684 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/partition.rs
--rw-r--r--   0     1001      123    17704 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/vector_hasher.rs
--rw-r--r--   0     1001      123     1896 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/lib.rs
--rw-r--r--   0     1001      123    15733 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/named_from.rs
--rw-r--r--   0     1001      123     2423 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/prelude.rs
--rw-r--r--   0     1001      123    17667 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/schema.rs
--rw-r--r--   0     1001      123     3995 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/serde/chunked_array.rs
--rw-r--r--   0     1001      123     1094 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/serde/df.rs
--rw-r--r--   0     1001      123     4752 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/serde/mod.rs
--rw-r--r--   0     1001      123     9938 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/serde/series.rs
--rw-r--r--   0     1001      123    18543 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/any_value.rs
--rw-r--r--   0     1001      123    28755 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs
--rw-r--r--   0     1001      123      222 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/arithmetic/mod.rs
--rw-r--r--   0     1001      123     3546 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/arithmetic/owned.rs
--rw-r--r--   0     1001      123    19293 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/comparison.rs
--rw-r--r--   0     1001      123    29575 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/from.rs
--rw-r--r--   0     1001      123     6080 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/array.rs
--rw-r--r--   0     1001      123     9089 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/binary.rs
--rw-r--r--   0     1001      123    10835 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/boolean.rs
--rw-r--r--   0     1001      123    12800 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/categorical.rs
--rw-r--r--   0     1001      123    18214 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/dates_time.rs
--rw-r--r--   0     1001      123    15034 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/datetime.rs
--rw-r--r--   0     1001      123     7981 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/decimal.rs
--rw-r--r--   0     1001      123    14734 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/duration.rs
--rw-r--r--   0     1001      123    14063 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/floats.rs
--rw-r--r--   0     1001      123     6078 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/list.rs
--rw-r--r--   0     1001      123    18396 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/mod.rs
--rw-r--r--   0     1001      123     5522 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/null.rs
--rw-r--r--   0     1001      123     7939 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/object.rs
--rw-r--r--   0     1001      123    11788 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/struct_.rs
--rw-r--r--   0     1001      123     9607 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/utf8.rs
--rw-r--r--   0     1001      123     4471 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/into.rs
--rw-r--r--   0     1001      123     6241 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/iterator.rs
--rw-r--r--   0     1001      123    39074 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/mod.rs
--rw-r--r--   0     1001      123      853 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/diff.rs
--rw-r--r--   0     1001      123     5814 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/downcast.rs
--rw-r--r--   0     1001      123     3601 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/ewm.rs
--rw-r--r--   0     1001      123      413 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/extend.rs
--rw-r--r--   0     1001      123      562 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/mod.rs
--rw-r--r--   0     1001      123     5974 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/moment.rs
--rw-r--r--   0     1001      123     2908 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/null.rs
--rw-r--r--   0     1001      123     1347 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/pct_change.rs
--rw-r--r--   0     1001      123     4620 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/round.rs
--rw-r--r--   0     1001      123     5073 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/to_list.rs
--rw-r--r--   0     1001      123     1476 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/unique.rs
--rw-r--r--   0     1001      123    18408 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/series_trait.rs
--rw-r--r--   0     1001      123     2912 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/unstable.rs
--rw-r--r--   0     1001      123     7077 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/testing.rs
--rw-r--r--   0     1001      123      508 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/tests.rs
--rw-r--r--   0     1001      123     2492 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/utils/flatten.rs
--rw-r--r--   0     1001      123    30596 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/utils/mod.rs
--rw-r--r--   0     1001      123     1600 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/utils/series.rs
--rw-r--r--   0     1001      123    13201 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/utils/supertype.rs
--rw-r--r--   0        0        0      827 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-algo/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-algo/LICENSE
--rw-r--r--   0     1001      123      142 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-algo/README.md
--rw-r--r--   0     1001      123     7548 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-algo/src/algo.rs
--rw-r--r--   0     1001      123       88 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-algo/src/lib.rs
--rw-r--r--   0     1001      123       28 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-algo/src/prelude.rs
--rw-r--r--   0        0        0     4397 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/LICENSE
--rw-r--r--   0     1001      123      138 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/README.md
--rw-r--r--   0     1001      123     2383 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/avro/mod.rs
--rw-r--r--   0     1001      123     3608 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/avro/read.rs
--rw-r--r--   0     1001      123     2622 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/avro/write.rs
--rw-r--r--   0     1001      123     4505 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/cloud/adaptors.rs
--rw-r--r--   0     1001      123     9506 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/cloud/glob.rs
--rw-r--r--   0     1001      123     3089 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/cloud/mod.rs
--rw-r--r--   0     1001      123    28829 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/buffer.rs
--rw-r--r--   0     1001      123     1815 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/mod.rs
--rw-r--r--   0     1001      123    19446 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/parser.rs
--rw-r--r--   0     1001      123    22226 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/read.rs
--rw-r--r--   0     1001      123    10846 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs
--rw-r--r--   0     1001      123    13938 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs
--rw-r--r--   0     1001      123    30724 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/read_impl/mod.rs
--rw-r--r--   0     1001      123    11466 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/splitfields.rs
--rw-r--r--   0     1001      123    24531 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/utils.rs
--rw-r--r--   0     1001      123     2796 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/write.rs
--rw-r--r--   0     1001      123    14759 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/write_impl.rs
--rw-r--r--   0     1001      123      184 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/export.rs
--rw-r--r--   0     1001      123     7586 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/ipc_file.rs
--rw-r--r--   0     1001      123     9227 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/ipc_stream.rs
--rw-r--r--   0     1001      123     3253 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/mmap.rs
--rw-r--r--   0     1001      123      401 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/mod.rs
--rw-r--r--   0     1001      123     8287 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/write.rs
--rw-r--r--   0     1001      123     1471 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/write_async.rs
--rw-r--r--   0     1001      123    11044 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/json/mod.rs
--rw-r--r--   0     1001      123     4771 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/lib.rs
--rw-r--r--   0     1001      123     1969 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/mmap.rs
--rw-r--r--   0     1001      123     7228 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ndjson/buffer.rs
--rw-r--r--   0     1001      123    11979 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ndjson/core.rs
--rw-r--r--   0     1001      123       37 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ndjson/mod.rs
--rw-r--r--   0     1001      123      273 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/options.rs
--rw-r--r--   0     1001      123     7360 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/async_impl.rs
--rw-r--r--   0     1001      123     3093 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/mmap.rs
--rw-r--r--   0     1001      123     3132 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/mod.rs
--rw-r--r--   0     1001      123     4784 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/predicates.rs
--rw-r--r--   0     1001      123     9623 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/read.rs
--rw-r--r--   0     1001      123    17320 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/read_impl.rs
--rw-r--r--   0     1001      123    10052 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/write.rs
--rw-r--r--   0     1001      123     5334 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/partition.rs
--rw-r--r--   0     1001      123     1455 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/predicates.rs
--rw-r--r--   0     1001      123      621 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/prelude.rs
--rw-r--r--   0     1001      123      417 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/tests.rs
--rw-r--r--   0     1001      123     4374 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/utils.rs
--rw-r--r--   0        0        0      587 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/Cargo.toml
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/LICENSE
--rw-r--r--   0     1001      123      141 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/README.md
--rw-r--r--   0     1001      123      151 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/aliases.rs
--rw-r--r--   0     1001      123     2862 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/arena.rs
--rw-r--r--   0     1001      123     1379 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/atomic.rs
--rw-r--r--   0     1001      123     2659 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/cell.rs
--rw-r--r--   0     1001      123     1015 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/contention_pool.rs
--rw-r--r--   0     1001      123      509 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/error.rs
--rw-r--r--   0     1001      123      271 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/fmt.rs
--rw-r--r--   0     1001      123      763 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/functions.rs
--rw-r--r--   0     1001      123     2709 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/iter/enumerate_idx.rs
--rw-r--r--   0     1001      123       61 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/iter/mod.rs
--rw-r--r--   0     1001      123      503 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/lib.rs
--rw-r--r--   0     1001      123      573 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/macros.rs
--rw-r--r--   0     1001      123      282 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/mem.rs
--rw-r--r--   0     1001      123     2642 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/slice.rs
--rw-r--r--   0     1001      123     2467 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/sort.rs
--rw-r--r--   0     1001      123     1115 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/sync.rs
--rw-r--r--   0     1001      123      504 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/sys.rs
--rw-r--r--   0     1001      123      697 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/unwrap.rs
--rw-r--r--   0     1001      123     2024 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/vec.rs
--rw-r--r--   0     1001      123      616 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/wasm.rs
--rw-r--r--   0        0        0     4393 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/Cargo.toml
--rw-r--r--   0     1001      123       76 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/.gitignore
--rw-r--r--   0     1001      123     1055 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/LICENSE
--rw-r--r--   0     1001      123     2414 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/Makefile
--rw-r--r--   0     1001      123    12006 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/README.md
--rw-r--r--   0     1001      123      651 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/build.rs
--rw-r--r--   0     1001      123       32 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/.gitignore
--rw-r--r--   0     1001      123      679 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/Makefile
--rw-r--r--   0     1001      123      318 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/_templates/api_redirect.html
--rw-r--r--   0     1001      123      151 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/_templates/autosummary/accessor.rst
--rw-r--r--   0     1001      123      160 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/_templates/autosummary/accessor_attribute.rst
--rw-r--r--   0     1001      123      168 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/_templates/autosummary/accessor_callable.rst
--rw-r--r--   0     1001      123      157 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/_templates/autosummary/accessor_method.rst
--rw-r--r--   0     1001      123      836 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/_templates/autosummary/class.rst
--rw-r--r--   0     1001      123       94 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/_templates/autosummary/class_without_autosummary.rst
--rw-r--r--   0     1001      123      406 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/_templates/sidebar-nav-bs.html
--rw-r--r--   0     1001      123      491 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/requirements-docs.txt
--rw-r--r--   0     1001      123     1164 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/run_live_docs_server.py
--rw-r--r--   0     1001      123     1567 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/_static/css/custom.css
--rw-r--r--   0     1001      123     7297 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/conf.py
--rw-r--r--   0     1001      123       51 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/index.rst
--rw-r--r--   0     1001      123     6767 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/api.rst
--rw-r--r--   0     1001      123     2069 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/config.rst
--rw-r--r--   0     1001      123      274 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/aggregation.rst
--rw-r--r--   0     1001      123      221 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/attributes.rst
--rw-r--r--   0     1001      123      142 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/computation.rst
--rw-r--r--   0     1001      123      319 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/descriptive.rst
--rw-r--r--   0     1001      123      319 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/export.rst
--rw-r--r--   0     1001      123      464 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/groupby.rst
--rw-r--r--   0     1001      123      379 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/index.rst
--rw-r--r--   0     1001      123      189 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/miscellaneous.rst
--rw-r--r--   0     1001      123     1538 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/dataframe/modify_select.rst
--rw-r--r--   0     1001      123      673 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/datatypes.rst
--rw-r--r--   0     1001      123      421 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/exceptions.rst
--rw-r--r--   0     1001      123      391 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/aggregation.rst
--rw-r--r--   0     1001      123      267 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/array.rst
--rw-r--r--   0     1001      123      309 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/binary.rst
--rw-r--r--   0     1001      123      338 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/boolean.rst
--rw-r--r--   0     1001      123      237 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/categories.rst
--rw-r--r--   0     1001      123      221 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/columns.rst
--rw-r--r--   0     1001      123     1095 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/computation.rst
--rw-r--r--   0     1001      123     1130 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/functions.rst
--rw-r--r--   0     1001      123      470 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/index.rst
--rw-r--r--   0     1001      123      722 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/list.rst
--rw-r--r--   0     1001      123      432 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/meta.rst
--rw-r--r--   0     1001      123      159 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/miscellaneous.rst
--rw-r--r--   0     1001      123      977 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/modify_select.rst
--rw-r--r--   0     1001      123      679 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/operators.rst
--rw-r--r--   0     1001      123      977 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/string.rst
--rw-r--r--   0     1001      123      254 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/struct.rst
--rw-r--r--   0     1001      123     1036 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/temporal.rst
--rw-r--r--   0     1001      123       98 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/expressions/window.rst
--rw-r--r--   0     1001      123      836 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/functions.rst
--rw-r--r--   0     1001      123      405 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/index.rst
--rw-r--r--   0     1001      123     1294 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/io.rst
--rw-r--r--   0     1001      123      277 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/lazyframe/aggregation.rst
--rw-r--r--   0     1001      123      179 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/lazyframe/attributes.rst
--rw-r--r--   0     1001      123      146 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/lazyframe/descriptive.rst
--rw-r--r--   0     1001      123      497 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/lazyframe/groupby.rst
--rw-r--r--   0     1001      123      354 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/lazyframe/index.rst
--rw-r--r--   0     1001      123      455 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/lazyframe/miscellaneous.rst
--rw-r--r--   0     1001      123     1013 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/lazyframe/modify_select.rst
--rw-r--r--   0     1001      123     3279 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/selectors.rst
--rw-r--r--   0     1001      123      358 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/aggregation.rst
--rw-r--r--   0     1001      123      277 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/array.rst
--rw-r--r--   0     1001      123      257 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/attributes.rst
--rw-r--r--   0     1001      123      321 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/binary.rst
--rw-r--r--   0     1001      123      117 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/boolean.rst
--rw-r--r--   0     1001      123      241 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/categories.rst
--rw-r--r--   0     1001      123     1103 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/computation.rst
--rw-r--r--   0     1001      123      744 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/descriptive.rst
--rw-r--r--   0     1001      123      240 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/export.rst
--rw-r--r--   0     1001      123      437 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/index.rst
--rw-r--r--   0     1001      123      776 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/list.rst
--rw-r--r--   0     1001      123      236 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/miscellaneous.rst
--rw-r--r--   0     1001      123     1077 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/modify_select.rst
--rw-r--r--   0     1001      123     1049 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/string.rst
--rw-r--r--   0     1001      123      421 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/struct.rst
--rw-r--r--   0     1001      123     1192 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/series/temporal.rst
--rw-r--r--   0     1001      123      503 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/sql.rst
--rw-r--r--   0     1001      123     8067 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/testing.rst
--rw-r--r--   0     1001      123      168 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/docs/source/reference/utils.rst
--rw-r--r--   0     1001      123     6304 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/__init__.py
--rw-r--r--   0     1001      123      280 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/_reexport.py
--rw-r--r--   0     1001      123    13229 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/api.py
--rw-r--r--   0     1001      123    29763 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/config.py
--rw-r--r--   0     1001      123    28105 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/convert.py
--rw-r--r--   0     1001      123       77 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/dataframe/__init__.py
--rw-r--r--   0     1001      123     5227 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/dataframe/_html.py
--rw-r--r--   0     1001      123   313419 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/dataframe/frame.py
--rw-r--r--   0     1001      123    40637 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/dataframe/groupby.py
--rw-r--r--   0     1001      123     2692 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/datatypes/__init__.py
--rw-r--r--   0     1001      123    17722 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/datatypes/classes.py
--rw-r--r--   0     1001      123     1603 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/datatypes/constants.py
--rw-r--r--   0     1001      123     4701 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/datatypes/constructor.py
--rw-r--r--   0     1001      123    15786 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/datatypes/convert.py
--rw-r--r--   0     1001      123     7338 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/dependencies.py
--rw-r--r--   0     1001      123     3573 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/exceptions.py
--rw-r--r--   0     1001      123       61 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/__init__.py
--rw-r--r--   0     1001      123     3020 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/array.py
--rw-r--r--   0     1001      123     2704 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/binary.py
--rw-r--r--   0     1001      123     1698 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/categorical.py
--rw-r--r--   0     1001      123    77648 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/datetime.py
--rw-r--r--   0     1001      123   309474 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/expr.py
--rw-r--r--   0     1001      123    23905 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/list.py
--rw-r--r--   0     1001      123     4050 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/meta.py
--rw-r--r--   0     1001      123    60085 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/string.py
--rw-r--r--   0     1001      123     5426 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/expr/struct.py
--rw-r--r--   0     1001      123     2068 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/functions/__init__.py
--rw-r--r--   0     1001      123    16541 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/functions/as_datatype.py
--rw-r--r--   0     1001      123    18853 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/functions/eager.py
--rw-r--r--   0     1001      123    72529 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/functions/lazy.py
--rw-r--r--   0     1001      123    18145 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/functions/range.py
--rw-r--r--   0     1001      123     6027 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/functions/repeat.py
--rw-r--r--   0     1001      123     6139 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/functions/whenthen.py
--rw-r--r--   0     1001      123      952 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/__init__.py
--rw-r--r--   0     1001      123     6264 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/_utils.py
--rw-r--r--   0     1001      123      861 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/avro.py
--rw-r--r--   0     1001      123      144 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/csv/__init__.py
--rw-r--r--   0     1001      123     1072 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/csv/_utils.py
--rw-r--r--   0     1001      123     4681 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/csv/batched_reader.py
--rw-r--r--   0     1001      123    35482 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/csv/functions.py
--rw-r--r--   0     1001      123     5627 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/database.py
--rw-r--r--   0     1001      123    11047 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/delta.py
--rw-r--r--   0     1001      123       75 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/excel/__init__.py
--rw-r--r--   0     1001      123    18449 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/excel/_write_utils.py
--rw-r--r--   0     1001      123     6466 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/excel/functions.py
--rw-r--r--   0     1001      123      142 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/ipc/__init__.py
--rw-r--r--   0     1001      123     1227 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/ipc/anonymous_scan.py
--rw-r--r--   0     1001      123     5804 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/ipc/functions.py
--rw-r--r--   0     1001      123      502 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/json.py
--rw-r--r--   0     1001      123     2207 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/ndjson.py
--rw-r--r--   0     1001      123      170 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/parquet/__init__.py
--rw-r--r--   0     1001      123     1259 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/parquet/anonymous_scan.py
--rw-r--r--   0     1001      123     7177 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/parquet/functions.py
--rw-r--r--   0     1001      123      136 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/pyarrow_dataset/__init__.py
--rw-r--r--   0     1001      123     2186 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/pyarrow_dataset/anonymous_scan.py
--rw-r--r--   0     1001      123     3601 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/io/pyarrow_dataset/functions.py
--rw-r--r--   0     1001      123       77 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/lazyframe/__init__.py
--rw-r--r--   0     1001      123   169447 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/lazyframe/frame.py
--rw-r--r--   0     1001      123    24078 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/lazyframe/groupby.py
--rw-r--r--   0     1001      123        0 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/py.typed
--rw-r--r--   0     1001      123    33639 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/selectors.py
--rw-r--r--   0     1001      123       69 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/__init__.py
--rw-r--r--   0     1001      123     1572 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/_numpy.py
--rw-r--r--   0     1001      123     2515 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/array.py
--rw-r--r--   0     1001      123     1913 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/binary.py
--rw-r--r--   0     1001      123     1692 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/categorical.py
--rw-r--r--   0     1001      123    51825 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/datetime.py
--rw-r--r--   0     1001      123    13196 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/list.py
--rw-r--r--   0     1001      123   167432 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/series.py
--rw-r--r--   0     1001      123    38879 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/string.py
--rw-r--r--   0     1001      123     2542 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/struct.py
--rw-r--r--   0     1001      123     5361 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/series/utils.py
--rw-r--r--   0     1001      123     7559 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/slice.py
--rw-r--r--   0     1001      123       75 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/sql/__init__.py
--rw-r--r--   0     1001      123    17409 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/sql/context.py
--rw-r--r--   0     1001      123     4793 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/string_cache.py
--rw-r--r--   0     1001      123      362 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/testing/__init__.py
--rw-r--r--   0     1001      123     1060 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/testing/_private.py
--rw-r--r--   0     1001      123    16964 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/testing/asserts.py
--rw-r--r--   0     1001      123      898 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/testing/parametric/__init__.py
--rw-r--r--   0     1001      123    28323 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/testing/parametric/primitives.py
--rw-r--r--   0     1001      123     3409 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/testing/parametric/profiles.py
--rw-r--r--   0     1001      123    12252 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/testing/parametric/strategies.py
--rw-r--r--   0     1001      123     6304 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/type_aliases.py
--rw-r--r--   0     1001      123     1157 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/__init__.py
--rw-r--r--   0     1001      123    56119 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/_construction.py
--rw-r--r--   0     1001      123     4937 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/_parse_expr_input.py
--rw-r--r--   0     1001      123      647 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/_scan.py
--rw-r--r--   0     1001      123      579 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/_wrap.py
--rw-r--r--   0     1001      123      683 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/build_info.py
--rw-r--r--   0     1001      123     8716 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/convert.py
--rw-r--r--   0     1001      123     7199 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/decorators.py
--rw-r--r--   0     1001      123     1660 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/meta.py
--rw-r--r--   0     1001      123      514 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/polars_version.py
--rw-r--r--   0     1001      123     2679 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/show_versions.py
--rw-r--r--   0     1001      123    12905 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/polars/utils/various.py
--rw-r--r--   0     1001      123     5337 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/pyproject.toml
--rw-r--r--   0     1001      123      698 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/requirements-dev.txt
--rw-r--r--   0     1001      123       68 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/requirements-lint.txt
--rw-r--r--   0     1001      123     1610 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/scripts/check_stacklevels.py
--rw-r--r--   0     1001      123    10980 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/apply/dataframe.rs
--rw-r--r--   0     1001      123     6428 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/apply/lazy.rs
--rw-r--r--   0     1001      123     8402 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/apply/mod.rs
--rw-r--r--   0     1001      123    90009 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/apply/series.rs
--rw-r--r--   0     1001      123       32 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/arrow_interop/mod.rs
--rw-r--r--   0     1001      123     1306 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/arrow_interop/to_py.rs
--rw-r--r--   0     1001      123     3902 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/arrow_interop/to_rust.rs
--rw-r--r--   0     1001      123     5250 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/batched_csv.rs
--rw-r--r--   0     1001      123    48666 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/conversion.rs
--rw-r--r--   0     1001      123    46071 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/dataframe.rs
--rw-r--r--   0     1001      123     3950 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/datatypes.rs
--rw-r--r--   0     1001      123     3288 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/error.rs
--rw-r--r--   0     1001      123      570 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/array.rs
--rw-r--r--   0     1001      123     2080 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/binary.rs
--rw-r--r--   0     1001      123      274 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/categorical.rs
--rw-r--r--   0     1001      123     5935 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/datetime.rs
--rw-r--r--   0     1001      123    34093 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/general.rs
--rw-r--r--   0     1001      123     3937 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/list.rs
--rw-r--r--   0     1001      123     2907 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/meta.rs
--rw-r--r--   0     1001      123      870 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/mod.rs
--rw-r--r--   0     1001      123     8366 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/string.rs
--rw-r--r--   0     1001      123      467 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/expr/struct.rs
--rw-r--r--   0     1001      123     9482 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/file.rs
--rw-r--r--   0     1001      123     3307 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/functions/eager.rs
--rw-r--r--   0     1001      123     1657 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/functions/io.rs
--rw-r--r--   0     1001      123    11977 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/functions/lazy.rs
--rw-r--r--   0     1001      123     1312 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/functions/meta.rs
--rw-r--r--   0     1001      123      217 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/functions/misc.rs
--rw-r--r--   0     1001      123       87 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/functions/mod.rs
--rw-r--r--   0     1001      123     1474 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/functions/whenthen.rs
--rw-r--r--   0     1001      123    30769 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/lazyframe.rs
--rw-r--r--   0     1001      123     2670 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/lazygroupby.rs
--rw-r--r--   0     1001      123     8268 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/lib.rs
--rw-r--r--   0     1001      123     1611 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/object.rs
--rw-r--r--   0     1001      123      122 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/prelude.rs
--rw-r--r--   0     1001      123      435 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/py_modules.rs
--rw-r--r--   0     1001      123     1964 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/series/aggregation.rs
--rw-r--r--   0     1001      123     5406 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/series/arithmetic.rs
--rw-r--r--   0     1001      123     5138 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/series/comparison.rs
--rw-r--r--   0     1001      123     9077 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/series/construction.rs
--rw-r--r--   0     1001      123     8971 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/series/export.rs
--rw-r--r--   0     1001      123    26606 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/series/mod.rs
--rw-r--r--   0     1001      123     4569 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/series/numpy_ufunc.rs
--rw-r--r--   0     1001      123     4046 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/series/set_at_idx.rs
--rw-r--r--   0     1001      123     1036 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/sql.rs
--rw-r--r--   0     1001      123     2335 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/src/utils.rs
--rw-r--r--   0     1001      123     6165 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/README.md
--rw-r--r--   0     1001      123     2189 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/benchmark/groupby-datagen.R
--rw-r--r--   0     1001      123     7963 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/benchmark/run_h2oai_benchmark.py
--rw-r--r--   0     1001      123     6530 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/benchmark/test_release.py
--rw-r--r--   0     1001      123     4589 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/docs/run_doctest.py
--rw-r--r--   0     1001      123        0 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/parametric/__init__.py
--rw-r--r--   0     1001      123      179 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/parametric/conftest.py
--rw-r--r--   0     1001      123     3856 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/parametric/test_dataframe.py
--rw-r--r--   0     1001      123     2398 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/parametric/test_groupby_rolling.py
--rw-r--r--   0     1001      123     1692 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/parametric/test_lazyframe.py
--rw-r--r--   0     1001      123      976 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/parametric/test_lit.py
--rw-r--r--   0     1001      123     6897 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/parametric/test_series.py
--rw-r--r--   0     1001      123     8299 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/parametric/test_testing.py
--rw-r--r--   0     1001      123        0 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/__init__.py
--rw-r--r--   0     1001      123     3382 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/conftest.py
--rw-r--r--   0     1001      123       86 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/__init__.py
--rw-r--r--   0     1001      123      973 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_array.py
--rw-r--r--   0     1001      123      847 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_binary.py
--rw-r--r--   0     1001      123     1420 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_bool.py
--rw-r--r--   0     1001      123    13228 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_categorical.py
--rw-r--r--   0     1001      123     5222 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_decimal.py
--rw-r--r--   0     1001      123      549 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_duration.py
--rw-r--r--   0     1001      123      423 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_integer.py
--rw-r--r--   0     1001      123    13216 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_list.py
--rw-r--r--   0     1001      123      284 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_null.py
--rw-r--r--   0     1001      123     2801 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_object.py
--rw-r--r--   0     1001      123    27749 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_struct.py
--rw-r--r--   0     1001      123    87954 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_temporal.py
--rw-r--r--   0     1001      123      418 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/datatypes/test_time.py
--rw-r--r--   0     1001      123        0 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/functions/__init__.py
--rw-r--r--   0     1001      123    13970 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/functions/test_as_datatype.py
--rw-r--r--   0     1001      123      480 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/functions/test_concat.py
--rw-r--r--   0     1001      123    15610 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/functions/test_functions.py
--rw-r--r--   0     1001      123    18470 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/functions/test_range.py
--rw-r--r--   0     1001      123     3724 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/functions/test_repeat.py
--rw-r--r--   0     1001      123      218 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/conftest.py
--rw-r--r--   0     1001      123       16 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/.part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet.crc
--rw-r--r--   0     1001      123       16 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/.part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet.crc
--rw-r--r--   0     1001      123       16 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/_delta_log/.00000000000000000000.json.crc
--rw-r--r--   0     1001      123       16 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/_delta_log/.00000000000000000001.json.crc
--rw-r--r--   0     1001      123      905 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json
--rw-r--r--   0     1001      123      936 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json
--rw-r--r--   0     1001      123      972 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet
--rw-r--r--   0     1001      123      690 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet
--rw-r--r--   0     1001      123        0 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/empty.csv
--rw-r--r--   0     1001      123     5959 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/example.xlsx
--rw-r--r--   0     1001      123      457 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods1.csv
--rw-r--r--   0     1001      123     2351 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods1.ipc
--rw-r--r--   0     1001      123     1713 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods1.ndjson
--rw-r--r--   0     1001      123     1427 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods1.parquet
--rw-r--r--   0     1001      123      455 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods2.csv
--rw-r--r--   0     1001      123     2351 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods2.ipc
--rw-r--r--   0     1001      123     1711 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods2.ndjson
--rw-r--r--   0     1001      123     1916 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods2.parquet
--rw-r--r--   0     1001      123      455 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods3.csv
--rw-r--r--   0     1001      123      457 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods4.csv
--rw-r--r--   0     1001      123      452 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/foods5.csv
--rw-r--r--   0     1001      123       49 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/gzipped.csv
--rw-r--r--   0     1001      123       57 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/small.csv
--rw-r--r--   0     1001      123      756 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/files/small.parquet
--rw-r--r--   0     1001      123     1884 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_avro.py
--rw-r--r--   0     1001      123    40088 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_csv.py
--rw-r--r--   0     1001      123     6336 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_database.py
--rw-r--r--   0     1001      123     6172 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_delta.py
--rw-r--r--   0     1001      123    11169 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_excel.py
--rw-r--r--   0     1001      123     5483 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_ipc.py
--rw-r--r--   0     1001      123     3986 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_json.py
--rw-r--r--   0     1001      123     7379 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_lazy_csv.py
--rw-r--r--   0     1001      123     2060 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_lazy_ipc.py
--rw-r--r--   0     1001      123     2867 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_lazy_json.py
--rw-r--r--   0     1001      123    11145 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_lazy_parquet.py
--rw-r--r--   0     1001      123     2012 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_other.py
--rw-r--r--   0     1001      123    14201 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_parquet.py
--rw-r--r--   0     1001      123      612 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_pickle.py
--rw-r--r--   0     1001      123     3686 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/io/test_pyarrow_dataset.py
--rw-r--r--   0     1001      123      509 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/__init__.py
--rw-r--r--   0     1001      123      589 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_array.py
--rw-r--r--   0     1001      123     3218 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_binary.py
--rw-r--r--   0     1001      123     2489 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_categorical.py
--rw-r--r--   0     1001      123    20480 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_datetime.py
--rw-r--r--   0     1001      123    14067 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_list.py
--rw-r--r--   0     1001      123     1829 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_meta.py
--rw-r--r--   0     1001      123    24050 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_string.py
--rw-r--r--   0     1001      123    19038 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_strptime.py
--rw-r--r--   0     1001      123      982 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/namespaces/test_struct.py
--rw-r--r--   0     1001      123       85 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/__init__.py
--rw-r--r--   0     1001      123     7755 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_aggregations.py
--rw-r--r--   0     1001      123    10643 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_apply.py
--rw-r--r--   0     1001      123     6932 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_arithmetic.py
--rw-r--r--   0     1001      123     4631 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_comparison.py
--rw-r--r--   0     1001      123     3275 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_drop.py
--rw-r--r--   0     1001      123     8813 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_explode.py
--rw-r--r--   0     1001      123     3664 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_filter.py
--rw-r--r--   0     1001      123     1801 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_folds.py
--rw-r--r--   0     1001      123    25037 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_groupby.py
--rw-r--r--   0     1001      123     7649 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_groupby_rolling.py
--rw-r--r--   0     1001      123     2983 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_is_in.py
--rw-r--r--   0     1001      123    18169 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_join.py
--rw-r--r--   0     1001      123    14952 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_join_asof.py
--rw-r--r--   0     1001      123      643 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_melt.py
--rw-r--r--   0     1001      123    10253 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_pivot.py
--rw-r--r--   0     1001      123    24216 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_rolling.py
--rw-r--r--   0     1001      123     2389 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_select.py
--rw-r--r--   0     1001      123    20770 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_sort.py
--rw-r--r--   0     1001      123     4273 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_statistics.py
--rw-r--r--   0     1001      123     4130 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_transpose.py
--rw-r--r--   0     1001      123      771 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_unique.py
--rw-r--r--   0     1001      123    11694 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_window.py
--rw-r--r--   0     1001      123     5480 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/operations/test_with_columns.py
--rw-r--r--   0     1001      123        0 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/streaming/__init__.py
--rw-r--r--   0     1001      123      196 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/streaming/conftest.py
--rw-r--r--   0     1001      123      908 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/streaming/test_ooc.py
--rw-r--r--   0     1001      123    18757 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/streaming/test_streaming.py
--rw-r--r--   0     1001      123     4775 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_api.py
--rw-r--r--   0     1001      123     1969 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_arity.py
--rw-r--r--   0     1001      123    20333 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_cfg.py
--rw-r--r--   0     1001      123    42903 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_constructors.py
--rw-r--r--   0     1001      123      454 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_context.py
--rw-r--r--   0     1001      123     1628 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_cse.py
--rw-r--r--   0     1001      123     5198 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_datatypes.py
--rw-r--r--   0     1001      123   120498 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_df.py
--rw-r--r--   0     1001      123     2396 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_empty.py
--rw-r--r--   0     1001      123    18809 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_errors.py
--rw-r--r--   0     1001      123     2741 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_expr_multi_cols.py
--rw-r--r--   0     1001      123    35226 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_exprs.py
--rw-r--r--   0     1001      123     3516 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_fmt.py
--rw-r--r--   0     1001      123     3763 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_interchange.py
--rw-r--r--   0     1001      123    38286 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_interop.py
--rw-r--r--   0     1001      123    49654 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_lazy.py
--rw-r--r--   0     1001      123     2463 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_polars_import.py
--rw-r--r--   0     1001      123     4610 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_predicates.py
--rw-r--r--   0     1001      123     7073 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_projections.py
--rw-r--r--   0     1001      123    11551 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_queries.py
--rw-r--r--   0     1001      123     4743 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_rows.py
--rw-r--r--   0     1001      123    13987 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_schema.py
--rw-r--r--   0     1001      123     9431 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_selectors.py
--rw-r--r--   0     1001      123     3816 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_serde.py
--rw-r--r--   0     1001      123    84086 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_series.py
--rw-r--r--   0     1001      123      657 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_single.py
--rw-r--r--   0     1001      123    16616 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_sql.py
--rw-r--r--   0     1001      123    35314 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/test_testing.py
--rw-r--r--   0     1001      123       41 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/utils/__init__.py
--rw-r--r--   0     1001      123      306 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/utils/test_build_info.py
--rw-r--r--   0     1001      123     2855 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/utils/test_parse_expr_input.py
--rw-r--r--   0     1001      123      247 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/utils/test_show_versions.py
--rw-r--r--   0     1001      123     5026 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/tests/unit/utils/test_utils.py
--rw-r--r--   0     1001      123    63897 2023-06-23 15:05:52.000000 polars_lts_cpu-0.18.4/Cargo.lock
--rw-r--r--   0        0        0    14553 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.4/PKG-INFO
+-rw-r--r--   0        0        0     1592 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/LICENSE
+-rw-r--r--   0     1001      123      144 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/README.md
+-rw-r--r--   0     1001      123     1975 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/default_arrays.rs
+-rw-r--r--   0     1001      123     1791 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/fixed_size_list.rs
+-rw-r--r--   0     1001      123     3773 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/get.rs
+-rw-r--r--   0     1001      123     6664 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/list.rs
+-rw-r--r--   0     1001      123     8165 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/mod.rs
+-rw-r--r--   0     1001      123      878 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/null.rs
+-rw-r--r--   0     1001      123     1125 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/slice.rs
+-rw-r--r--   0     1001      123     2253 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/utf8.rs
+-rw-r--r--   0     1001      123     2294 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/bit_util.rs
+-rw-r--r--   0     1001      123       17 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/bitmap/mod.rs
+-rw-r--r--   0     1001      123      819 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/bitmap/mutable.rs
+-rw-r--r--   0     1001      123      370 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/add.rs
+-rw-r--r--   0     1001      123     2181 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/commutative.rs
+-rw-r--r--   0     1001      123     1482 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/div.rs
+-rw-r--r--   0     1001      123     1028 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mod.rs
+-rw-r--r--   0     1001      123     1177 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mul.rs
+-rw-r--r--   0     1001      123      508 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/sub.rs
+-rw-r--r--   0     1001      123       51 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/mod.rs
+-rw-r--r--   0     1001      123        1 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arity.rs
+-rw-r--r--   0     1001      123      727 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/bitwise.rs
+-rw-r--r--   0     1001      123     1206 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/cast.rs
+-rw-r--r--   0     1001      123     3964 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/decimal.rs
+-rw-r--r--   0     1001      123     1250 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/mod.rs
+-rw-r--r--   0     1001      123      391 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/take/bitmap.rs
+-rw-r--r--   0     1001      123     2767 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/take/boolean.rs
+-rw-r--r--   0     1001      123     3489 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/take/fixed_size_list.rs
+-rw-r--r--   0     1001      123    25290 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/take/mod.rs
+-rw-r--r--   0     1001      123      797 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/tile.rs
+-rw-r--r--   0     1001      123     1102 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/conversion.rs
+-rw-r--r--   0     1001      123     1609 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/data_types.rs
+-rw-r--r--   0     1001      123       25 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/error.rs
+-rw-r--r--   0     1001      123       28 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/export.rs
+-rw-r--r--   0     1001      123       26 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/floats/mod.rs
+-rw-r--r--   0     1001      123     2066 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/floats/ord.rs
+-rw-r--r--   0     1001      123     1273 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/index.rs
+-rw-r--r--   0     1001      123      984 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/is_valid.rs
+-rw-r--r--   0     1001      123     4783 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/agg_mean.rs
+-rw-r--r--   0     1001      123     1074 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/comparison.rs
+-rw-r--r--   0     1001      123     1068 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/concatenate.rs
+-rw-r--r--   0     1001      123     5161 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/ewm/average.rs
+-rw-r--r--   0     1001      123     1808 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs
+-rw-r--r--   0     1001      123    25065 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs
+-rw-r--r--   0     1001      123     1406 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/float.rs
+-rw-r--r--   0     1001      123     4908 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/list.rs
+-rw-r--r--   0     1001      123     1885 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs
+-rw-r--r--   0     1001      123     9783 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/mod.rs
+-rw-r--r--   0     1001      123     3923 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs
+-rw-r--r--   0     1001      123     2019 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs
+-rw-r--r--   0     1001      123    16187 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs
+-rw-r--r--   0     1001      123     3848 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs
+-rw-r--r--   0     1001      123    13521 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs
+-rw-r--r--   0     1001      123     5684 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs
+-rw-r--r--   0     1001      123     7807 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs
+-rw-r--r--   0     1001      123     1879 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs
+-rw-r--r--   0     1001      123    14722 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs
+-rw-r--r--   0     1001      123    10055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs
+-rw-r--r--   0     1001      123    11643 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs
+-rw-r--r--   0     1001      123     4821 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs
+-rw-r--r--   0     1001      123     6856 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs
+-rw-r--r--   0     1001      123     8109 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/window.rs
+-rw-r--r--   0     1001      123     4753 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/set.rs
+-rw-r--r--   0     1001      123     4529 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/sort_partition.rs
+-rw-r--r--   0     1001      123     2948 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs
+-rw-r--r--   0     1001      123     5974 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs
+-rw-r--r--   0     1001      123      231 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/sorted_join/mod.rs
+-rw-r--r--   0     1001      123      842 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/string.rs
+-rw-r--r--   0     1001      123     2310 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/take_agg/boolean.rs
+-rw-r--r--   0     1001      123     4315 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/take_agg/mod.rs
+-rw-r--r--   0     1001      123     2606 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/take_agg/var.rs
+-rw-r--r--   0     1001      123     3672 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/time.rs
+-rw-r--r--   0     1001      123      341 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/lib.rs
+-rw-r--r--   0     1001      123      496 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/prelude.rs
+-rw-r--r--   0     1001      123      534 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/slice.rs
+-rw-r--r--   0     1001      123      183 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/time_zone.rs
+-rw-r--r--   0     1001      123      998 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/trusted_len/boolean.rs
+-rw-r--r--   0     1001      123     2821 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/trusted_len/mod.rs
+-rw-r--r--   0     1001      123     2054 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs
+-rw-r--r--   0     1001      123      158 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/trusted_len/rev.rs
+-rw-r--r--   0     1001      123     5233 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/utils.rs
+-rw-r--r--   0        0        0     6264 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/LICENSE
+-rw-r--r--   0     1001      123      358 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/README.md
+-rw-r--r--   0     1001      123     1796 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dot.rs
+-rw-r--r--   0     1001      123     4479 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/eval.rs
+-rw-r--r--   0     1001      123     7115 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/functions.rs
+-rw-r--r--   0     1001      123      164 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/into.rs
+-rw-r--r--   0     1001      123     6754 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/list.rs
+-rw-r--r--   0     1001      123     2899 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/mod.rs
+-rw-r--r--   0     1001      123     1182 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs
+-rw-r--r--   0     1001      123     9285 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/csv.rs
+-rw-r--r--   0     1001      123     4368 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/file_list_reader.rs
+-rw-r--r--   0     1001      123     2261 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/ipc.rs
+-rw-r--r--   0     1001      123    49541 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/mod.rs
+-rw-r--r--   0     1001      123     3382 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/ndjson.rs
+-rw-r--r--   0     1001      123     2734 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/parquet.rs
+-rw-r--r--   0     1001      123     2892 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/pivot.rs
+-rw-r--r--   0     1001      123      459 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/python.rs
+-rw-r--r--   0     1001      123     6374 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/lib.rs
+-rw-r--r--   0     1001      123     1049 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs
+-rw-r--r--   0     1001      123      776 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs
+-rw-r--r--   0     1001      123      670 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs
+-rw-r--r--   0     1001      123     1555 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs
+-rw-r--r--   0     1001      123     3986 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs
+-rw-r--r--   0     1001      123     4125 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs
+-rw-r--r--   0     1001      123    13599 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs
+-rw-r--r--   0     1001      123     4883 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs
+-rw-r--r--   0     1001      123     5859 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs
+-rw-r--r--   0     1001      123     6753 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs
+-rw-r--r--   0     1001      123     2045 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs
+-rw-r--r--   0     1001      123     1761 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs
+-rw-r--r--   0     1001      123     2854 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs
+-rw-r--r--   0     1001      123     1963 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs
+-rw-r--r--   0     1001      123     4303 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs
+-rw-r--r--   0     1001      123     1209 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs
+-rw-r--r--   0     1001      123     2421 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs
+-rw-r--r--   0     1001      123      548 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs
+-rw-r--r--   0     1001      123     2197 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs
+-rw-r--r--   0     1001      123     2015 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs
+-rw-r--r--   0     1001      123      663 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs
+-rw-r--r--   0     1001      123     4041 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs
+-rw-r--r--   0     1001      123      838 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs
+-rw-r--r--   0     1001      123     1335 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/exotic.rs
+-rw-r--r--   0     1001      123    21959 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs
+-rw-r--r--   0     1001      123     2689 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs
+-rw-r--r--   0     1001      123    18581 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs
+-rw-r--r--   0     1001      123    17674 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs
+-rw-r--r--   0     1001      123     2583 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/cache.rs
+-rw-r--r--   0     1001      123     3153 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs
+-rw-r--r--   0     1001      123     6326 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs
+-rw-r--r--   0     1001      123     1996 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs
+-rw-r--r--   0     1001      123     5809 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs
+-rw-r--r--   0     1001      123     4131 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs
+-rw-r--r--   0     1001      123     5304 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs
+-rw-r--r--   0     1001      123    23566 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs
+-rw-r--r--   0     1001      123    10091 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs
+-rw-r--r--   0     1001      123     4332 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs
+-rw-r--r--   0     1001      123    13549 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs
+-rw-r--r--   0     1001      123     8331 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs
+-rw-r--r--   0     1001      123    14360 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs
+-rw-r--r--   0     1001      123    31970 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs
+-rw-r--r--   0     1001      123     2039 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs
+-rw-r--r--   0     1001      123      414 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/mod.rs
+-rw-r--r--   0     1001      123     2005 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs
+-rw-r--r--   0     1001      123    24174 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs
+-rw-r--r--   0     1001      123    20552 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs
+-rw-r--r--   0     1001      123       87 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/planner/mod.rs
+-rw-r--r--   0     1001      123    10203 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/state.rs
+-rw-r--r--   0     1001      123     2583 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/checks.rs
+-rw-r--r--   0     1001      123     9280 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/construct_pipeline.rs
+-rw-r--r--   0     1001      123    16847 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/convert_alp.rs
+-rw-r--r--   0     1001      123      116 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/mod.rs
+-rw-r--r--   0     1001      123     5827 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs
+-rw-r--r--   0     1001      123      722 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/prelude.rs
+-rw-r--r--   0     1001      123    15000 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/aggregations.rs
+-rw-r--r--   0     1001      123     2339 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/arity.rs
+-rw-r--r--   0     1001      123     7276 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/cse.rs
+-rw-r--r--   0     1001      123    12752 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/io.rs
+-rw-r--r--   0     1001      123     4166 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/logical.rs
+-rw-r--r--   0     1001      123     4273 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/mod.rs
+-rw-r--r--   0     1001      123    15770 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/optimization_checks.rs
+-rw-r--r--   0     1001      123     6772 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/predicate_queries.rs
+-rw-r--r--   0     1001      123     3165 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/projection_queries.rs
+-rw-r--r--   0     1001      123    47685 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/queries.rs
+-rw-r--r--   0     1001      123     9519 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/streaming.rs
+-rw-r--r--   0     1001      123     2893 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/tpch.rs
+-rw-r--r--   0     1001      123     1028 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/utils.rs
+-rw-r--r--   0        0        0     3552 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/LICENSE
+-rw-r--r--   0     1001      123      132 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/README.md
+-rw-r--r--   0     1001      123     2382 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/array/min_max.rs
+-rw-r--r--   0     1001      123      267 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/array/mod.rs
+-rw-r--r--   0     1001      123     1512 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/array/namespace.rs
+-rw-r--r--   0     1001      123     4108 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/array/sum_mean.rs
+-rw-r--r--   0     1001      123      234 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/binary/mod.rs
+-rw-r--r--   0     1001      123     3549 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs
+-rw-r--r--   0     1001      123    11023 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/interpolate.rs
+-rw-r--r--   0     1001      123     1930 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/any_all.rs
+-rw-r--r--   0     1001      123     1687 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/count.rs
+-rw-r--r--   0     1001      123     2419 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/hash.rs
+-rw-r--r--   0     1001      123     7861 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs
+-rw-r--r--   0     1001      123      644 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/mod.rs
+-rw-r--r--   0     1001      123    19897 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs
+-rw-r--r--   0     1001      123    10391 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/sets.rs
+-rw-r--r--   0     1001      123     7633 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs
+-rw-r--r--   0     1001      123     2435 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs
+-rw-r--r--   0     1001      123      545 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/mod.rs
+-rw-r--r--   0     1001      123     9452 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs
+-rw-r--r--   0     1001      123     6795 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/set.rs
+-rw-r--r--   0     1001      123     8781 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/case.rs
+-rw-r--r--   0     1001      123     8593 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs
+-rw-r--r--   0     1001      123     2345 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs
+-rw-r--r--   0     1001      123      514 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs
+-rw-r--r--   0     1001      123    14951 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs
+-rw-r--r--   0     1001      123     4053 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs
+-rw-r--r--   0     1001      123      439 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/sum.rs
+-rw-r--r--   0     1001      123     2486 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/top_k.rs
+-rw-r--r--   0     1001      123     7727 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs
+-rw-r--r--   0     1001      123    18232 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/join/mod.rs
+-rw-r--r--   0     1001      123     4291 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/mod.rs
+-rw-r--r--   0     1001      123    10257 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/pivot/mod.rs
+-rw-r--r--   0     1001      123    13486 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/pivot/positioning.rs
+-rw-r--r--   0     1001      123      237 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/lib.rs
+-rw-r--r--   0     1001      123      290 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/prelude.rs
+-rw-r--r--   0     1001      123       25 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/mod.rs
+-rw-r--r--   0     1001      123     9623 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs
+-rw-r--r--   0     1001      123      118 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/approx_algo/mod.rs
+-rw-r--r--   0     1001      123     2016 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/approx_unique.rs
+-rw-r--r--   0     1001      123    11866 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs
+-rw-r--r--   0     1001      123     3669 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/cut.rs
+-rw-r--r--   0     1001      123     3688 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/floor_divide.rs
+-rw-r--r--   0     1001      123     5245 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/fused.rs
+-rw-r--r--   0     1001      123     3423 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/is_first.rs
+-rw-r--r--   0     1001      123     2975 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/is_unique.rs
+-rw-r--r--   0     1001      123     3626 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/log.rs
+-rw-r--r--   0     1001      123     1268 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/mod.rs
+-rw-r--r--   0     1001      123     1769 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/rolling.rs
+-rw-r--r--   0     1001      123     7642 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/search_sorted.rs
+-rw-r--r--   0     1001      123     2603 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/to_dummies.rs
+-rw-r--r--   0     1001      123     2067 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/various.rs
+-rw-r--r--   0        0        0     5424 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/LICENSE
+-rw-r--r--   0     1001      123       45 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/constants.rs
+-rw-r--r--   0     1001      123    17253 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dot.rs
+-rw-r--r--   0     1001      123     4789 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/arithmetic.rs
+-rw-r--r--   0     1001      123     3992 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/arity.rs
+-rw-r--r--   0     1001      123     1278 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/array.rs
+-rw-r--r--   0     1001      123      935 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/binary.rs
+-rw-r--r--   0     1001      123      650 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/cat.rs
+-rw-r--r--   0     1001      123    10729 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/dt.rs
+-rw-r--r--   0     1001      123     9542 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/expr.rs
+-rw-r--r--   0     1001      123     8359 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/expr_dyn_fn.rs
+-rw-r--r--   0     1001      123      753 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/from.rs
+-rw-r--r--   0     1001      123       85 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/abs.rs
+-rw-r--r--   0     1001      123     1431 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs
+-rw-r--r--   0     1001      123     1074 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/array.rs
+-rw-r--r--   0     1001      123     1327 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs
+-rw-r--r--   0     1001      123     4221 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs
+-rw-r--r--   0     1001      123     1910 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs
+-rw-r--r--   0     1001      123     1216 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs
+-rw-r--r--   0     1001      123      344 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/clip.rs
+-rw-r--r--   0     1001      123      257 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/concat.rs
+-rw-r--r--   0     1001      123     6125 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/correlation.rs
+-rw-r--r--   0     1001      123     1593 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs
+-rw-r--r--   0     1001      123    11615 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs
+-rw-r--r--   0     1001      123      782 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs
+-rw-r--r--   0     1001      123     2567 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs
+-rw-r--r--   0     1001      123      992 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/fused.rs
+-rw-r--r--   0     1001      123     8997 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/list.rs
+-rw-r--r--   0     1001      123      581 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/log.rs
+-rw-r--r--   0     1001      123    24898 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs
+-rw-r--r--   0     1001      123      462 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/nan.rs
+-rw-r--r--   0     1001      123     3132 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs
+-rw-r--r--   0     1001      123     1410 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/random.rs
+-rw-r--r--   0     1001      123     5146 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/range.rs
+-rw-r--r--   0     1001      123      152 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/rolling.rs
+-rw-r--r--   0     1001      123      260 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/round.rs
+-rw-r--r--   0     1001      123      200 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/row_hash.rs
+-rw-r--r--   0     1001      123    19251 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs
+-rw-r--r--   0     1001      123      306 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/search_sorted.rs
+-rw-r--r--   0     1001      123     3812 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs
+-rw-r--r--   0     1001      123     1238 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs
+-rw-r--r--   0     1001      123      972 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs
+-rw-r--r--   0     1001      123    22249 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs
+-rw-r--r--   0     1001      123     1017 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs
+-rw-r--r--   0     1001      123     8438 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs
+-rw-r--r--   0     1001      123     6112 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs
+-rw-r--r--   0     1001      123      170 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/unique.rs
+-rw-r--r--   0     1001      123     1155 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/arity.rs
+-rw-r--r--   0     1001      123      611 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/coerce.rs
+-rw-r--r--   0     1001      123     2717 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/concat.rs
+-rw-r--r--   0     1001      123     4525 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/correlation.rs
+-rw-r--r--   0     1001      123     8736 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/horizontal.rs
+-rw-r--r--   0     1001      123     1042 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/index.rs
+-rw-r--r--   0     1001      123      968 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/mod.rs
+-rw-r--r--   0     1001      123     4129 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/range.rs
+-rw-r--r--   0     1001      123     1308 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/selectors.rs
+-rw-r--r--   0     1001      123     1973 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/syntactic_sugar.rs
+-rw-r--r--   0     1001      123    11328 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/temporal.rs
+-rw-r--r--   0     1001      123    12282 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/list.rs
+-rw-r--r--   0     1001      123     4501 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/meta.rs
+-rw-r--r--   0     1001      123    61388 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/mod.rs
+-rw-r--r--   0     1001      123       40 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/names.rs
+-rw-r--r--   0     1001      123     2658 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/options.rs
+-rw-r--r--   0     1001      123     7017 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/python_udf.rs
+-rw-r--r--   0     1001      123     1432 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/random.rs
+-rw-r--r--   0     1001      123     1068 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/selector.rs
+-rw-r--r--   0     1001      123    17626 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/string.rs
+-rw-r--r--   0     1001      123     2715 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/struct_.rs
+-rw-r--r--   0     1001      123       38 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/frame/mod.rs
+-rw-r--r--   0     1001      123      933 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/frame/opt_state.rs
+-rw-r--r--   0     1001      123      466 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/global.rs
+-rw-r--r--   0     1001      123      175 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/lib.rs
+-rw-r--r--   0     1001      123    10651 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs
+-rw-r--r--   0     1001      123    11920 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs
+-rw-r--r--   0     1001      123    25683 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/alp.rs
+-rw-r--r--   0     1001      123     1622 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs
+-rw-r--r--   0     1001      123     1428 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/apply.rs
+-rw-r--r--   0     1001      123    25639 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/builder.rs
+-rw-r--r--   0     1001      123    29993 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/conversion.rs
+-rw-r--r--   0     1001      123      301 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/debug.rs
+-rw-r--r--   0     1001      123    15713 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/format.rs
+-rw-r--r--   0     1001      123      895 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs
+-rw-r--r--   0     1001      123      137 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/explode.rs
+-rw-r--r--   0     1001      123     1169 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs
+-rw-r--r--   0     1001      123    13288 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs
+-rw-r--r--   0     1001      123     1031 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/python_udf.rs
+-rw-r--r--   0     1001      123     1330 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs
+-rw-r--r--   0     1001      123    10157 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/iterator.rs
+-rw-r--r--   0     1001      123    10559 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/lit.rs
+-rw-r--r--   0     1001      123     8142 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/mod.rs
+-rw-r--r--   0     1001      123     7416 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs
+-rw-r--r--   0     1001      123    15277 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs
+-rw-r--r--   0     1001      123     2889 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs
+-rw-r--r--   0     1001      123     3236 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs
+-rw-r--r--   0     1001      123     4663 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs
+-rw-r--r--   0     1001      123    14479 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs
+-rw-r--r--   0     1001      123     1556 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs
+-rw-r--r--   0     1001      123     6017 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/fused.rs
+-rw-r--r--   0     1001      123     6778 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs
+-rw-r--r--   0     1001      123     1222 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs
+-rw-r--r--   0     1001      123    28901 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs
+-rw-r--r--   0     1001      123     2571 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs
+-rw-r--r--   0     1001      123    16171 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs
+-rw-r--r--   0     1001      123     1755 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs
+-rw-r--r--   0     1001      123     3930 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs
+-rw-r--r--   0     1001      123     1799 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs
+-rw-r--r--   0     1001      123     3269 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs
+-rw-r--r--   0     1001      123     2638 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs
+-rw-r--r--   0     1001      123    15874 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs
+-rw-r--r--   0     1001      123    26739 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs
+-rw-r--r--   0     1001      123     3707 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs
+-rw-r--r--   0     1001      123     2639 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs
+-rw-r--r--   0     1001      123     3509 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs
+-rw-r--r--   0     1001      123    27269 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs
+-rw-r--r--   0     1001      123     3496 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs
+-rw-r--r--   0     1001      123    13232 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs
+-rw-r--r--   0     1001      123     4181 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs
+-rw-r--r--   0     1001      123     9796 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs
+-rw-r--r--   0     1001      123    20215 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs
+-rw-r--r--   0     1001      123    10653 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/options.rs
+-rw-r--r--   0     1001      123    19151 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/projection.rs
+-rw-r--r--   0     1001      123     6144 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs
+-rw-r--r--   0     1001      123    13026 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/schema.rs
+-rw-r--r--   0     1001      123     6699 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/tree_format.rs
+-rw-r--r--   0     1001      123     3544 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/visitor/expr.rs
+-rw-r--r--   0     1001      123      930 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/visitor/mod.rs
+-rw-r--r--   0     1001      123     4408 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/visitor/visitors.rs
+-rw-r--r--   0     1001      123      832 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/prelude.rs
+-rw-r--r--   0     1001      123    12428 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/utils.rs
+-rw-r--r--   0        0        0     2037 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/LICENSE
+-rw-r--r--   0     1001      123      143 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/README.md
+-rw-r--r--   0     1001      123     1018 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/base_utc_offset.rs
+-rw-r--r--   0     1001      123     3569 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/date.rs
+-rw-r--r--   0     1001      123     6465 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/datetime.rs
+-rw-r--r--   0     1001      123     3305 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/duration.rs
+-rw-r--r--   0     1001      123     5607 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/kernels.rs
+-rw-r--r--   0     1001      123     1062 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/mod.rs
+-rw-r--r--   0     1001      123     6759 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs
+-rw-r--r--   0     1001      123     2582 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs
+-rw-r--r--   0     1001      123    11122 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs
+-rw-r--r--   0     1001      123      413 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/mod.rs
+-rw-r--r--   0     1001      123     4810 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs
+-rw-r--r--   0     1001      123     2372 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/time.rs
+-rw-r--r--   0     1001      123    21334 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs
+-rw-r--r--   0     1001      123    18997 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs
+-rw-r--r--   0     1001      123     3975 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs
+-rw-r--r--   0     1001      123    11229 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs
+-rw-r--r--   0     1001      123     3340 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/date_range.rs
+-rw-r--r--   0     1001      123      994 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/dst_offset.rs
+-rw-r--r--   0     1001      123    34703 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/groupby/dynamic.rs
+-rw-r--r--   0     1001      123       88 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/groupby/mod.rs
+-rw-r--r--   0     1001      123      769 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/lib.rs
+-rw-r--r--   0     1001      123     2976 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/month_end.rs
+-rw-r--r--   0     1001      123     3365 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/month_start.rs
+-rw-r--r--   0     1001      123      274 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/prelude.rs
+-rw-r--r--   0     1001      123     1381 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/round.rs
+-rw-r--r--   0     1001      123     3992 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/_trait.rs
+-rw-r--r--   0     1001      123      136 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/boolean.rs
+-rw-r--r--   0     1001      123      140 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/categoricals.rs
+-rw-r--r--   0     1001      123      133 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/date.rs
+-rw-r--r--   0     1001      123      137 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/datetime.rs
+-rw-r--r--   0     1001      123      137 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/duration.rs
+-rw-r--r--   0     1001      123     1863 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/floats.rs
+-rw-r--r--   0     1001      123     1792 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/integers.rs
+-rw-r--r--   0     1001      123      133 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/list.rs
+-rw-r--r--   0     1001      123      486 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/mod.rs
+-rw-r--r--   0     1001      123      155 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/object.rs
+-rw-r--r--   0     1001      123      135 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/struct_.rs
+-rw-r--r--   0     1001      123      133 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/time.rs
+-rw-r--r--   0     1001      123      133 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/utf8.rs
+-rw-r--r--   0     1001      123    12791 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/mod.rs
+-rw-r--r--   0     1001      123     1443 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/truncate.rs
+-rw-r--r--   0     1001      123     7619 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/upsample.rs
+-rw-r--r--   0     1001      123     2511 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/utils.rs
+-rw-r--r--   0     1001      123     1524 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/bounds.rs
+-rw-r--r--   0     1001      123     2672 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/calendar.rs
+-rw-r--r--   0     1001      123    25303 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/duration.rs
+-rw-r--r--   0     1001      123    20201 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/groupby.rs
+-rw-r--r--   0     1001      123      503 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/mod.rs
+-rw-r--r--   0     1001      123    23627 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/test.rs
+-rw-r--r--   0     1001      123    10657 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/window.rs
+-rw-r--r--   0        0        0      954 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/LICENSE
+-rw-r--r--   0     1001      123      137 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/README.md
+-rw-r--r--   0     1001      123     2377 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/decode.rs
+-rw-r--r--   0     1001      123    13364 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/encode.rs
+-rw-r--r--   0     1001      123     7767 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/fixed.rs
+-rw-r--r--   0     1001      123    13846 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/lib.rs
+-rw-r--r--   0     1001      123     3019 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/row.rs
+-rw-r--r--   0     1001      123      682 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/utils.rs
+-rw-r--r--   0     1001      123     8679 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/variable.rs
+-rw-r--r--   0        0        0     1998 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/LICENSE
+-rw-r--r--   0     1001      123      165 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/README.md
+-rw-r--r--   0     1001      123       98 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/mod.rs
+-rw-r--r--   0     1001      123     1219 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/filter.rs
+-rw-r--r--   0     1001      123     4103 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/function.rs
+-rw-r--r--   0     1001      123      266 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/mod.rs
+-rw-r--r--   0     1001      123      682 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/pass.rs
+-rw-r--r--   0     1001      123      548 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs
+-rw-r--r--   0     1001      123     3553 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/projection.rs
+-rw-r--r--   0     1001      123     3559 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/reproject.rs
+-rw-r--r--   0     1001      123     6479 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs
+-rw-r--r--   0     1001      123    11288 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs
+-rw-r--r--   0     1001      123     1207 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs
+-rw-r--r--   0     1001      123     1888 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs
+-rw-r--r--   0     1001      123     4554 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs
+-rw-r--r--   0     1001      123     1746 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs
+-rw-r--r--   0     1001      123     5413 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs
+-rw-r--r--   0     1001      123     4951 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs
+-rw-r--r--   0     1001      123      211 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mod.rs
+-rw-r--r--   0     1001      123      856 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs
+-rw-r--r--   0     1001      123     4294 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs
+-rw-r--r--   0     1001      123     4109 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs
+-rw-r--r--   0     1001      123     7404 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs
+-rw-r--r--   0     1001      123    10554 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs
+-rw-r--r--   0     1001      123     3589 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs
+-rw-r--r--   0     1001      123     2767 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs
+-rw-r--r--   0     1001      123     6326 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs
+-rw-r--r--   0     1001      123     3116 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/source.rs
+-rw-r--r--   0     1001      123    10194 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs
+-rw-r--r--   0     1001      123     2119 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs
+-rw-r--r--   0     1001      123     4695 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs
+-rw-r--r--   0     1001      123     1887 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs
+-rw-r--r--   0     1001      123    20783 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs
+-rw-r--r--   0     1001      123    23825 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs
+-rw-r--r--   0     1001      123     2457 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs
+-rw-r--r--   0     1001      123     9239 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/io.rs
+-rw-r--r--   0     1001      123     5451 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs
+-rw-r--r--   0     1001      123    12056 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs
+-rw-r--r--   0     1001      123    11658 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs
+-rw-r--r--   0     1001      123      178 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/joins/mod.rs
+-rw-r--r--   0     1001      123     2241 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/memory.rs
+-rw-r--r--   0     1001      123      589 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/mod.rs
+-rw-r--r--   0     1001      123     1492 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs
+-rw-r--r--   0     1001      123     1824 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs
+-rw-r--r--   0     1001      123     3108 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/slice.rs
+-rw-r--r--   0     1001      123      130 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/sort/mod.rs
+-rw-r--r--   0     1001      123     6774 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs
+-rw-r--r--   0     1001      123     7279 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs
+-rw-r--r--   0     1001      123    11679 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/sort/sink_multiple.rs
+-rw-r--r--   0     1001      123     3908 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs
+-rw-r--r--   0     1001      123      526 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/utils.rs
+-rw-r--r--   0     1001      123     5984 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/csv.rs
+-rw-r--r--   0     1001      123     1231 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/frame.rs
+-rw-r--r--   0     1001      123      987 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs
+-rw-r--r--   0     1001      123      366 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/mod.rs
+-rw-r--r--   0     1001      123     4335 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/parquet.rs
+-rw-r--r--   0     1001      123     1146 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/reproject.rs
+-rw-r--r--   0     1001      123     1022 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/union.rs
+-rw-r--r--   0     1001      123      448 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/expressions.rs
+-rw-r--r--   0     1001      123      272 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/lib.rs
+-rw-r--r--   0     1001      123      719 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/chunks.rs
+-rw-r--r--   0     1001      123      474 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/context.rs
+-rw-r--r--   0     1001      123      223 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/mod.rs
+-rw-r--r--   0     1001      123      514 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/operator.rs
+-rw-r--r--   0     1001      123      626 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/sink.rs
+-rw-r--r--   0     1001      123      241 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/source.rs
+-rw-r--r--   0     1001      123        1 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/pipeline/config.rs
+-rw-r--r--   0     1001      123    21320 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/pipeline/convert.rs
+-rw-r--r--   0     1001      123    20362 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs
+-rw-r--r--   0     1001      123     1155 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/pipeline/mod.rs
+-rw-r--r--   0        0        0     4397 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/LICENSE
+-rw-r--r--   0     1001      123      138 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/README.md
+-rw-r--r--   0     1001      123     2383 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/avro/mod.rs
+-rw-r--r--   0     1001      123     3608 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/avro/read.rs
+-rw-r--r--   0     1001      123     2622 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/avro/write.rs
+-rw-r--r--   0     1001      123     4505 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/cloud/adaptors.rs
+-rw-r--r--   0     1001      123     9506 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/cloud/glob.rs
+-rw-r--r--   0     1001      123     3089 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/cloud/mod.rs
+-rw-r--r--   0     1001      123    28829 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/buffer.rs
+-rw-r--r--   0     1001      123     1815 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/mod.rs
+-rw-r--r--   0     1001      123    19446 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/parser.rs
+-rw-r--r--   0     1001      123    22228 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/read.rs
+-rw-r--r--   0     1001      123    10847 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs
+-rw-r--r--   0     1001      123    13939 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs
+-rw-r--r--   0     1001      123    30724 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/read_impl/mod.rs
+-rw-r--r--   0     1001      123    11466 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/splitfields.rs
+-rw-r--r--   0     1001      123    24531 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/utils.rs
+-rw-r--r--   0     1001      123     2796 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/write.rs
+-rw-r--r--   0     1001      123    14759 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/write_impl.rs
+-rw-r--r--   0     1001      123      184 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/export.rs
+-rw-r--r--   0     1001      123     7586 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/ipc_file.rs
+-rw-r--r--   0     1001      123     9227 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/ipc_stream.rs
+-rw-r--r--   0     1001      123     3253 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/mmap.rs
+-rw-r--r--   0     1001      123      401 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/mod.rs
+-rw-r--r--   0     1001      123     8287 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/write.rs
+-rw-r--r--   0     1001      123     1471 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/write_async.rs
+-rw-r--r--   0     1001      123    11044 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/json/mod.rs
+-rw-r--r--   0     1001      123     4771 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/lib.rs
+-rw-r--r--   0     1001      123     1969 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/mmap.rs
+-rw-r--r--   0     1001      123     7228 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ndjson/buffer.rs
+-rw-r--r--   0     1001      123    11979 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ndjson/core.rs
+-rw-r--r--   0     1001      123       37 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ndjson/mod.rs
+-rw-r--r--   0     1001      123      273 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/options.rs
+-rw-r--r--   0     1001      123     7360 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/async_impl.rs
+-rw-r--r--   0     1001      123     3093 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/mmap.rs
+-rw-r--r--   0     1001      123     3132 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/mod.rs
+-rw-r--r--   0     1001      123     4784 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/predicates.rs
+-rw-r--r--   0     1001      123     9623 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/read.rs
+-rw-r--r--   0     1001      123    17321 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/read_impl.rs
+-rw-r--r--   0     1001      123    10129 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/write.rs
+-rw-r--r--   0     1001      123     5334 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/partition.rs
+-rw-r--r--   0     1001      123     1455 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/predicates.rs
+-rw-r--r--   0     1001      123      621 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/prelude.rs
+-rw-r--r--   0     1001      123      417 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/tests.rs
+-rw-r--r--   0     1001      123     4374 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/utils.rs
+-rw-r--r--   0        0        0     5484 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/LICENSE
+-rw-r--r--   0     1001      123      144 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/README.md
+-rw-r--r--   0     1001      123     5158 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/arithmetic/decimal.rs
+-rw-r--r--   0     1001      123     8275 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/arithmetic/mod.rs
+-rw-r--r--   0     1001      123     9417 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/arithmetic/numeric.rs
+-rw-r--r--   0     1001      123     3588 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/array/iterator.rs
+-rw-r--r--   0     1001      123     2551 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/array/mod.rs
+-rw-r--r--   0     1001      123     6448 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/bitwise.rs
+-rw-r--r--   0     1001      123     2298 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/binary.rs
+-rw-r--r--   0     1001      123     1207 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs
+-rw-r--r--   0     1001      123     4311 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/fixed_size_list.rs
+-rw-r--r--   0     1001      123     1556 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/from.rs
+-rw-r--r--   0     1001      123    20366 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/list.rs
+-rw-r--r--   0     1001      123     8969 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/mod.rs
+-rw-r--r--   0     1001      123     1410 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs
+-rw-r--r--   0     1001      123     2291 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs
+-rw-r--r--   0     1001      123    17014 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/cast.rs
+-rw-r--r--   0     1001      123    50501 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs
+-rw-r--r--   0     1001      123    10060 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs
+-rw-r--r--   0     1001      123      551 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/drop.rs
+-rw-r--r--   0     1001      123      963 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/float.rs
+-rw-r--r--   0     1001      123     7945 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/from.rs
+-rw-r--r--   0     1001      123    42339 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs
+-rw-r--r--   0     1001      123     1453 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs
+-rw-r--r--   0     1001      123       28 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/iterator/par/mod.rs
+-rw-r--r--   0     1001      123     1129 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs
+-rw-r--r--   0     1001      123       21 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/kernels/mod.rs
+-rw-r--r--   0     1001      123     2347 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/kernels/take.rs
+-rw-r--r--   0     1001      123     7963 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/list/iterator.rs
+-rw-r--r--   0     1001      123     3242 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/list/mod.rs
+-rw-r--r--   0     1001      123    19831 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs
+-rw-r--r--   0     1001      123     3688 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs
+-rw-r--r--   0     1001      123     4270 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs
+-rw-r--r--   0     1001      123    10219 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs
+-rw-r--r--   0     1001      123     1263 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs
+-rw-r--r--   0     1001      123      358 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/full.rs
+-rw-r--r--   0     1001      123      192 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/mod.rs
+-rw-r--r--   0     1001      123     2731 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs
+-rw-r--r--   0     1001      123     2172 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs
+-rw-r--r--   0     1001      123      925 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs
+-rw-r--r--   0     1001      123     6805 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs
+-rw-r--r--   0     1001      123     1604 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/date.rs
+-rw-r--r--   0     1001      123     4105 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs
+-rw-r--r--   0     1001      123     4443 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs
+-rw-r--r--   0     1001      123     2434 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/duration.rs
+-rw-r--r--   0     1001      123     2556 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/mod.rs
+-rw-r--r--   0     1001      123      476 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/struct_/from.rs
+-rw-r--r--   0     1001      123    15983 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs
+-rw-r--r--   0     1001      123     1182 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/time.rs
+-rw-r--r--   0     1001      123    23273 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/mod.rs
+-rw-r--r--   0     1001      123     9064 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ndarray.rs
+-rw-r--r--   0     1001      123     4484 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/builder.rs
+-rw-r--r--   0     1001      123     1547 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs
+-rw-r--r--   0     1001      123     3124 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs
+-rw-r--r--   0     1001      123     7054 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs
+-rw-r--r--   0     1001      123     3410 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs
+-rw-r--r--   0     1001      123      137 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/is_valid.rs
+-rw-r--r--   0     1001      123     4419 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/iterator.rs
+-rw-r--r--   0     1001      123     4806 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/mod.rs
+-rw-r--r--   0     1001      123     2956 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/registry.rs
+-rw-r--r--   0     1001      123      272 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/abs.rs
+-rw-r--r--   0     1001      123    32662 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs
+-rw-r--r--   0     1001      123    10025 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs
+-rw-r--r--   0     1001      123     2880 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs
+-rw-r--r--   0     1001      123    10551 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs
+-rw-r--r--   0     1001      123     4526 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/append.rs
+-rw-r--r--   0     1001      123    28257 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/apply.rs
+-rw-r--r--   0     1001      123    12799 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs
+-rw-r--r--   0     1001      123     6236 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs
+-rw-r--r--   0     1001      123    11537 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs
+-rw-r--r--   0     1001      123     1737 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs
+-rw-r--r--   0     1001      123     4801 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs
+-rw-r--r--   0     1001      123      908 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/decimal.rs
+-rw-r--r--   0     1001      123     7056 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs
+-rw-r--r--   0     1001      123    19462 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/explode.rs
+-rw-r--r--   0     1001      123     8691 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/explode_and_offsets.rs
+-rw-r--r--   0     1001      123     9103 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/extend.rs
+-rw-r--r--   0     1001      123    13777 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs
+-rw-r--r--   0     1001      123     6356 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/filter.rs
+-rw-r--r--   0     1001      123     5876 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/full.rs
+-rw-r--r--   0     1001      123        1 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/interpolate.rs
+-rw-r--r--   0     1001      123    16797 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs
+-rw-r--r--   0     1001      123        1 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/len.rs
+-rw-r--r--   0     1001      123     2658 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/min_max_binary.rs
+-rw-r--r--   0     1001      123    23299 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/mod.rs
+-rw-r--r--   0     1001      123     2414 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs
+-rw-r--r--   0     1001      123      593 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs
+-rw-r--r--   0     1001      123     4375 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs
+-rw-r--r--   0     1001      123     2771 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs
+-rw-r--r--   0     1001      123    10267 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs
+-rw-r--r--   0     1001      123    12518 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/set.rs
+-rw-r--r--   0     1001      123     7391 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/shift.rs
+-rw-r--r--   0     1001      123     2299 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs
+-rw-r--r--   0     1001      123     5522 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs
+-rw-r--r--   0     1001      123     7543 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs
+-rw-r--r--   0     1001      123    28138 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs
+-rw-r--r--   0     1001      123      380 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/slice.rs
+-rw-r--r--   0     1001      123    22089 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs
+-rw-r--r--   0     1001      123     7848 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs
+-rw-r--r--   0     1001      123      301 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/take_every.rs
+-rw-r--r--   0     1001      123    16256 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs
+-rw-r--r--   0     1001      123     6275 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs
+-rw-r--r--   0     1001      123     6072 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs
+-rw-r--r--   0     1001      123      459 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/tile.rs
+-rw-r--r--   0     1001      123    12251 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs
+-rw-r--r--   0     1001      123    14620 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs
+-rw-r--r--   0     1001      123     5846 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/zip.rs
+-rw-r--r--   0     1001      123     9093 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/random.rs
+-rw-r--r--   0     1001      123     1875 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs
+-rw-r--r--   0     1001      123     2826 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/date.rs
+-rw-r--r--   0     1001      123    10336 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs
+-rw-r--r--   0     1001      123     3201 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs
+-rw-r--r--   0     1001      123     1061 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/mod.rs
+-rw-r--r--   0     1001      123     3042 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/time.rs
+-rw-r--r--   0     1001      123      872 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/to_vec.rs
+-rw-r--r--   0     1001      123     8114 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/trusted_len.rs
+-rw-r--r--   0     1001      123    25939 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs
+-rw-r--r--   0     1001      123     7944 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/cloud.rs
+-rw-r--r--   0     1001      123     1549 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/config.rs
+-rw-r--r--   0     1001      123     4469 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/_serde.rs
+-rw-r--r--   0     1001      123     2509 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/aliases.rs
+-rw-r--r--   0     1001      123    42659 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/any_value.rs
+-rw-r--r--   0     1001      123    13349 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/dtype.rs
+-rw-r--r--   0     1001      123     5609 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/field.rs
+-rw-r--r--   0     1001      123     8059 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/mod.rs
+-rw-r--r--   0     1001      123     2016 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/time_unit.rs
+-rw-r--r--   0     1001      123      118 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/mod.rs
+-rw-r--r--   0     1001      123      898 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs
+-rw-r--r--   0     1001      123      481 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_3.rs
+-rw-r--r--   0     1001      123      293 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_4.rs
+-rw-r--r--   0     1001      123      499 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_5.rs
+-rw-r--r--   0     1001      123      288 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_6.rs
+-rw-r--r--   0     1001      123     1071 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_7.rs
+-rw-r--r--   0     1001      123      819 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_8.rs
+-rw-r--r--   0     1001      123      596 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_9.rs
+-rw-r--r--   0     1001      123       43 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/mod.rs
+-rw-r--r--   0     1001      123       25 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/error.rs
+-rw-r--r--   0     1001      123      263 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/export.rs
+-rw-r--r--   0     1001      123    36573 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/fmt.rs
+-rw-r--r--   0     1001      123     5177 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/arithmetic.rs
+-rw-r--r--   0     1001      123     9916 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/asof_join/asof.rs
+-rw-r--r--   0     1001      123    35743 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/asof_join/groups.rs
+-rw-r--r--   0     1001      123     7168 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/asof_join/mod.rs
+-rw-r--r--   0     1001      123      559 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/chunks.rs
+-rw-r--r--   0     1001      123     5181 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/cross_join.rs
+-rw-r--r--   0     1001      123    16760 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/explode.rs
+-rw-r--r--   0     1001      123     1019 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/from.rs
+-rw-r--r--   0     1001      123    19219 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs
+-rw-r--r--   0     1001      123     4113 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/boolean.rs
+-rw-r--r--   0     1001      123     7749 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs
+-rw-r--r--   0     1001      123    40479 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs
+-rw-r--r--   0     1001      123     5634 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/utf8.rs
+-rw-r--r--   0     1001      123      218 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/expr.rs
+-rw-r--r--   0     1001      123    22901 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/hashing.rs
+-rw-r--r--   0     1001      123    14380 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/into_groups.rs
+-rw-r--r--   0     1001      123    39623 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/mod.rs
+-rw-r--r--   0     1001      123    10637 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/perfect.rs
+-rw-r--r--   0     1001      123    19780 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/proxy.rs
+-rw-r--r--   0     1001      123     5416 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/args.rs
+-rw-r--r--   0     1001      123    13172 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/mod.rs
+-rw-r--r--   0     1001      123    22364 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs
+-rw-r--r--   0     1001      123     2400 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs
+-rw-r--r--   0     1001      123    17372 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs
+-rw-r--r--   0     1001      123     4677 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs
+-rw-r--r--   0     1001      123     6502 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs
+-rw-r--r--   0     1001      123     4665 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs
+-rw-r--r--   0     1001      123     3913 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs
+-rw-r--r--   0     1001      123    12313 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs
+-rw-r--r--   0     1001      123     3865 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/zip_outer.rs
+-rw-r--r--   0     1001      123   126294 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/mod.rs
+-rw-r--r--   0     1001      123    27652 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/row/av_buffer.rs
+-rw-r--r--   0     1001      123     5183 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/row/dataframe.rs
+-rw-r--r--   0     1001      123     5976 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/row/mod.rs
+-rw-r--r--   0     1001      123     9875 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/row/transpose.rs
+-rw-r--r--   0     1001      123     2811 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/top_k.rs
+-rw-r--r--   0     1001      123     1388 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/upstream_traits.rs
+-rw-r--r--   0     1001      123    10198 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/functions.rs
+-rw-r--r--   0     1001      123     2149 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/fx.rs
+-rw-r--r--   0     1001      123     1503 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/identity.rs
+-rw-r--r--   0     1001      123      457 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/mod.rs
+-rw-r--r--   0     1001      123     2684 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/partition.rs
+-rw-r--r--   0     1001      123    17704 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/vector_hasher.rs
+-rw-r--r--   0     1001      123     1896 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/lib.rs
+-rw-r--r--   0     1001      123    15733 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/named_from.rs
+-rw-r--r--   0     1001      123     2502 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/prelude.rs
+-rw-r--r--   0     1001      123    18242 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/schema.rs
+-rw-r--r--   0     1001      123     3995 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/serde/chunked_array.rs
+-rw-r--r--   0     1001      123     1094 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/serde/df.rs
+-rw-r--r--   0     1001      123     4734 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/serde/mod.rs
+-rw-r--r--   0     1001      123     9938 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/serde/series.rs
+-rw-r--r--   0     1001      123    18543 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/any_value.rs
+-rw-r--r--   0     1001      123    28755 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs
+-rw-r--r--   0     1001      123      222 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/arithmetic/mod.rs
+-rw-r--r--   0     1001      123     3546 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/arithmetic/owned.rs
+-rw-r--r--   0     1001      123    19293 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/comparison.rs
+-rw-r--r--   0     1001      123    29766 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/from.rs
+-rw-r--r--   0     1001      123     6080 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/array.rs
+-rw-r--r--   0     1001      123     9089 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/binary.rs
+-rw-r--r--   0     1001      123    10835 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/boolean.rs
+-rw-r--r--   0     1001      123    12800 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/categorical.rs
+-rw-r--r--   0     1001      123    18214 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/dates_time.rs
+-rw-r--r--   0     1001      123    15034 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/datetime.rs
+-rw-r--r--   0     1001      123     7981 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/decimal.rs
+-rw-r--r--   0     1001      123    14734 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/duration.rs
+-rw-r--r--   0     1001      123    14063 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/floats.rs
+-rw-r--r--   0     1001      123     6078 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/list.rs
+-rw-r--r--   0     1001      123    18396 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/mod.rs
+-rw-r--r--   0     1001      123     5522 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/null.rs
+-rw-r--r--   0     1001      123     7939 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/object.rs
+-rw-r--r--   0     1001      123    11788 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/struct_.rs
+-rw-r--r--   0     1001      123     9607 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/utf8.rs
+-rw-r--r--   0     1001      123     4471 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/into.rs
+-rw-r--r--   0     1001      123     6241 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/iterator.rs
+-rw-r--r--   0     1001      123    39074 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/mod.rs
+-rw-r--r--   0     1001      123      853 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/diff.rs
+-rw-r--r--   0     1001      123     5814 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/downcast.rs
+-rw-r--r--   0     1001      123     3601 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/ewm.rs
+-rw-r--r--   0     1001      123      413 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/extend.rs
+-rw-r--r--   0     1001      123      562 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/mod.rs
+-rw-r--r--   0     1001      123     5974 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/moment.rs
+-rw-r--r--   0     1001      123     3181 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/null.rs
+-rw-r--r--   0     1001      123     1347 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/pct_change.rs
+-rw-r--r--   0     1001      123     4620 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/round.rs
+-rw-r--r--   0     1001      123     5073 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/to_list.rs
+-rw-r--r--   0     1001      123     1476 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/unique.rs
+-rw-r--r--   0     1001      123    18408 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/series_trait.rs
+-rw-r--r--   0     1001      123     2912 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/unstable.rs
+-rw-r--r--   0     1001      123     7077 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/testing.rs
+-rw-r--r--   0     1001      123      508 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/tests.rs
+-rw-r--r--   0     1001      123     2492 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/utils/flatten.rs
+-rw-r--r--   0     1001      123    31194 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/utils/mod.rs
+-rw-r--r--   0     1001      123     1600 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/utils/series.rs
+-rw-r--r--   0     1001      123    13201 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/utils/supertype.rs
+-rw-r--r--   0        0        0     1353 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/LICENSE
+-rw-r--r--   0     1001      123    16461 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/json/deserialize.rs
+-rw-r--r--   0     1001      123     6564 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/json/infer_schema.rs
+-rw-r--r--   0     1001      123      189 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/json/mod.rs
+-rw-r--r--   0     1001      123       30 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/lib.rs
+-rw-r--r--   0     1001      123     1198 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/ndjson/deserialize.rs
+-rw-r--r--   0     1001      123     4808 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/ndjson/file.rs
+-rw-r--r--   0     1001      123      143 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/ndjson/mod.rs
+-rw-r--r--   0        0        0    10755 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/LICENSE
+-rw-r--r--   0     1001      123     3472 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/Makefile
+-rw-r--r--   0     1001      123      215 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/build.rs
+-rw-r--r--   0     1001      123       78 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/clippy.toml
+-rw-r--r--   0     1001      123    17614 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/src/docs/eager.rs
+-rw-r--r--   0     1001      123     8815 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/src/docs/lazy.rs
+-rw-r--r--   0     1001      123       50 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/src/docs/mod.rs
+-rw-r--r--   0     1001      123     3806 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/src/docs/performance.rs
+-rw-r--r--   0     1001      123       59 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/src/export.rs
+-rw-r--r--   0     1001      123    19848 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/src/lib.rs
+-rw-r--r--   0     1001      123      387 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/src/prelude.rs
+-rw-r--r--   0     1001      123       54 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/src/sql.rs
+-rw-r--r--   0     1001      123     4272 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/date_like.rs
+-rw-r--r--   0     1001      123     2401 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/groupby.rs
+-rw-r--r--   0     1001      123    17838 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/joins.rs
+-rw-r--r--   0     1001      123      545 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/list.rs
+-rw-r--r--   0     1001      123      198 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/mod.rs
+-rw-r--r--   0     1001      123       24 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/ops/mod.rs
+-rw-r--r--   0     1001      123      457 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/ops/take.rs
+-rw-r--r--   0     1001      123     6259 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/pivot.rs
+-rw-r--r--   0     1001      123     1102 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/random.rs
+-rw-r--r--   0     1001      123    11096 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/rolling_window.rs
+-rw-r--r--   0     1001      123     1093 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/series.rs
+-rw-r--r--   0     1001      123      370 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/utils.rs
+-rw-r--r--   0     1001      123    30423 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/csv.rs
+-rw-r--r--   0     1001      123     4490 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/ipc_stream.rs
+-rw-r--r--   0     1001      123     7043 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/json.rs
+-rw-r--r--   0     1001      123      378 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/mod.rs
+-rw-r--r--   0     1001      123      531 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/parquet.rs
+-rw-r--r--   0     1001      123     1530 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/joins.rs
+-rw-r--r--   0     1001      123     2452 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/aggregation.rs
+-rw-r--r--   0     1001      123      821 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/cse.rs
+-rw-r--r--   0     1001      123      500 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/explodes.rs
+-rw-r--r--   0     1001      123     2278 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/apply.rs
+-rw-r--r--   0     1001      123    10285 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/arity.rs
+-rw-r--r--   0     1001      123     1065 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/expand.rs
+-rw-r--r--   0     1001      123     1008 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/filter.rs
+-rw-r--r--   0     1001      123      428 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/is_in.rs
+-rw-r--r--   0     1001      123      121 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/mod.rs
+-rw-r--r--   0     1001      123      659 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/slice.rs
+-rw-r--r--   0     1001      123    10657 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/window.rs
+-rw-r--r--   0     1001      123      579 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/folds.rs
+-rw-r--r--   0     1001      123      557 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/functions.rs
+-rw-r--r--   0     1001      123     4482 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/groupby.rs
+-rw-r--r--   0     1001      123     1681 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs
+-rw-r--r--   0     1001      123      691 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/mod.rs
+-rw-r--r--   0     1001      123     5747 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/predicate_queries.rs
+-rw-r--r--   0     1001      123     4483 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/projection_queries.rs
+-rw-r--r--   0     1001      123     6584 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/queries.rs
+-rw-r--r--   0     1001      123      151 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/main.rs
+-rw-r--r--   0     1001      123    12591 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/schema.rs
+-rw-r--r--   0     1001      123     1899 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/time/date_range.rs
+-rw-r--r--   0     1001      123       16 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/time/mod.rs
+-rw-r--r--   0        0        0      894 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-error/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-error/LICENSE
+-rw-r--r--   0     1001      123      145 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-error/README.md
+-rw-r--r--   0     1001      123     7567 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-error/src/lib.rs
+-rw-r--r--   0        0        0      827 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-algo/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-algo/LICENSE
+-rw-r--r--   0     1001      123      142 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-algo/README.md
+-rw-r--r--   0     1001      123     7548 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-algo/src/algo.rs
+-rw-r--r--   0     1001      123       88 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-algo/src/lib.rs
+-rw-r--r--   0     1001      123       28 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-algo/src/prelude.rs
+-rw-r--r--   0        0        0      587 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/LICENSE
+-rw-r--r--   0     1001      123      141 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/README.md
+-rw-r--r--   0     1001      123      151 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/aliases.rs
+-rw-r--r--   0     1001      123     2879 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/arena.rs
+-rw-r--r--   0     1001      123     1379 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/atomic.rs
+-rw-r--r--   0     1001      123     2659 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/cell.rs
+-rw-r--r--   0     1001      123     1015 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/contention_pool.rs
+-rw-r--r--   0     1001      123      509 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/error.rs
+-rw-r--r--   0     1001      123      271 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/fmt.rs
+-rw-r--r--   0     1001      123      763 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/functions.rs
+-rw-r--r--   0     1001      123     2709 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/iter/enumerate_idx.rs
+-rw-r--r--   0     1001      123       61 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/iter/mod.rs
+-rw-r--r--   0     1001      123      503 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/lib.rs
+-rw-r--r--   0     1001      123      573 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/macros.rs
+-rw-r--r--   0     1001      123      282 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/mem.rs
+-rw-r--r--   0     1001      123     2642 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/slice.rs
+-rw-r--r--   0     1001      123     2467 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/sort.rs
+-rw-r--r--   0     1001      123     1115 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/sync.rs
+-rw-r--r--   0     1001      123      504 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/sys.rs
+-rw-r--r--   0     1001      123      697 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/unwrap.rs
+-rw-r--r--   0     1001      123     2024 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/vec.rs
+-rw-r--r--   0     1001      123      616 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/wasm.rs
+-rw-r--r--   0        0        0     1106 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/Cargo.toml
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/LICENSE
+-rw-r--r--   0     1001      123      466 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/README.md
+-rw-r--r--   0     1001      123    23373 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/context.rs
+-rw-r--r--   0     1001      123    23921 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/functions.rs
+-rw-r--r--   0     1001      123     2122 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/keywords.rs
+-rw-r--r--   0     1001      123      239 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/lib.rs
+-rw-r--r--   0     1001      123    20933 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/sql_expr.rs
+-rw-r--r--   0     1001      123     4572 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/table_functions.rs
+-rw-r--r--   0     1001      123     1682 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_cumulative.rs
+-rw-r--r--   0     1001      123     3063 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_io.rs
+-rw-r--r--   0     1001      123     1539 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_math.rs
+-rw-r--r--   0     1001      123      860 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_meta.rs
+-rw-r--r--   0     1001      123     2982 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_string.rs
+-rw-r--r--   0     1001      123     1056 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_7436.rs
+-rw-r--r--   0     1001      123      888 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_7437.rs
+-rw-r--r--   0     1001      123      652 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_7440.rs
+-rw-r--r--   0     1001      123      700 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_8395.rs
+-rw-r--r--   0     1001      123     1062 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_8419.rs
+-rw-r--r--   0     1001      123      982 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/ops_distinct_on.rs
+-rw-r--r--   0     1001      123    15811 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/simple_exprs.rs
+-rw-r--r--   0     1001      123     3976 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/statements.rs
+-rw-r--r--   0        0        0     4544 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/Cargo.toml
+-rw-r--r--   0     1001      123       76 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/.gitignore
+-rw-r--r--   0     1001      123     1055 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/LICENSE
+-rw-r--r--   0     1001      123     2414 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/Makefile
+-rw-r--r--   0     1001      123    11696 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/README.md
+-rw-r--r--   0     1001      123      651 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/build.rs
+-rw-r--r--   0     1001      123       32 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/.gitignore
+-rw-r--r--   0     1001      123      682 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/Makefile
+-rw-r--r--   0     1001      123      318 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/_templates/api_redirect.html
+-rw-r--r--   0     1001      123      151 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/_templates/autosummary/accessor.rst
+-rw-r--r--   0     1001      123      160 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/_templates/autosummary/accessor_attribute.rst
+-rw-r--r--   0     1001      123      168 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/_templates/autosummary/accessor_callable.rst
+-rw-r--r--   0     1001      123      157 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/_templates/autosummary/accessor_method.rst
+-rw-r--r--   0     1001      123      836 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/_templates/autosummary/class.rst
+-rw-r--r--   0     1001      123       94 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/_templates/autosummary/class_without_autosummary.rst
+-rw-r--r--   0     1001      123      406 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/_templates/sidebar-nav-bs.html
+-rw-r--r--   0     1001      123      559 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/requirements-docs.txt
+-rw-r--r--   0     1001      123     1164 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/run_live_docs_server.py
+-rw-r--r--   0     1001      123     1567 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/_static/css/custom.css
+-rw-r--r--   0     1001      123     7297 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/conf.py
+-rw-r--r--   0     1001      123       51 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/index.rst
+-rw-r--r--   0     1001      123     6767 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/api.rst
+-rw-r--r--   0     1001      123     2069 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/config.rst
+-rw-r--r--   0     1001      123      274 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/aggregation.rst
+-rw-r--r--   0     1001      123      221 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/attributes.rst
+-rw-r--r--   0     1001      123      142 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/computation.rst
+-rw-r--r--   0     1001      123      319 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/descriptive.rst
+-rw-r--r--   0     1001      123      319 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/export.rst
+-rw-r--r--   0     1001      123      464 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/groupby.rst
+-rw-r--r--   0     1001      123      379 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/index.rst
+-rw-r--r--   0     1001      123      189 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/miscellaneous.rst
+-rw-r--r--   0     1001      123     1538 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/dataframe/modify_select.rst
+-rw-r--r--   0     1001      123      673 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/datatypes.rst
+-rw-r--r--   0     1001      123      421 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/exceptions.rst
+-rw-r--r--   0     1001      123      391 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/aggregation.rst
+-rw-r--r--   0     1001      123      267 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/array.rst
+-rw-r--r--   0     1001      123      309 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/binary.rst
+-rw-r--r--   0     1001      123      338 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/boolean.rst
+-rw-r--r--   0     1001      123      237 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/categories.rst
+-rw-r--r--   0     1001      123      221 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/columns.rst
+-rw-r--r--   0     1001      123     1095 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/computation.rst
+-rw-r--r--   0     1001      123     1215 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/functions.rst
+-rw-r--r--   0     1001      123      470 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/index.rst
+-rw-r--r--   0     1001      123      830 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/list.rst
+-rw-r--r--   0     1001      123      458 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/meta.rst
+-rw-r--r--   0     1001      123      159 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/miscellaneous.rst
+-rw-r--r--   0     1001      123      977 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/modify_select.rst
+-rw-r--r--   0     1001      123      679 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/operators.rst
+-rw-r--r--   0     1001      123      977 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/string.rst
+-rw-r--r--   0     1001      123      254 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/struct.rst
+-rw-r--r--   0     1001      123     1087 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/temporal.rst
+-rw-r--r--   0     1001      123       98 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/expressions/window.rst
+-rw-r--r--   0     1001      123      694 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/functions.rst
+-rw-r--r--   0     1001      123      405 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/index.rst
+-rw-r--r--   0     1001      123     1294 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/io.rst
+-rw-r--r--   0     1001      123      277 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/lazyframe/aggregation.rst
+-rw-r--r--   0     1001      123      179 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/lazyframe/attributes.rst
+-rw-r--r--   0     1001      123      146 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/lazyframe/descriptive.rst
+-rw-r--r--   0     1001      123      497 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/lazyframe/groupby.rst
+-rw-r--r--   0     1001      123      354 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/lazyframe/index.rst
+-rw-r--r--   0     1001      123      455 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/lazyframe/miscellaneous.rst
+-rw-r--r--   0     1001      123     1013 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/lazyframe/modify_select.rst
+-rw-r--r--   0     1001      123     3279 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/selectors.rst
+-rw-r--r--   0     1001      123      358 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/aggregation.rst
+-rw-r--r--   0     1001      123      277 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/array.rst
+-rw-r--r--   0     1001      123      257 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/attributes.rst
+-rw-r--r--   0     1001      123      321 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/binary.rst
+-rw-r--r--   0     1001      123      117 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/boolean.rst
+-rw-r--r--   0     1001      123      241 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/categories.rst
+-rw-r--r--   0     1001      123     1103 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/computation.rst
+-rw-r--r--   0     1001      123      744 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/descriptive.rst
+-rw-r--r--   0     1001      123      240 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/export.rst
+-rw-r--r--   0     1001      123      437 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/index.rst
+-rw-r--r--   0     1001      123      894 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/list.rst
+-rw-r--r--   0     1001      123      236 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/miscellaneous.rst
+-rw-r--r--   0     1001      123     1077 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/modify_select.rst
+-rw-r--r--   0     1001      123     1049 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/string.rst
+-rw-r--r--   0     1001      123      421 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/struct.rst
+-rw-r--r--   0     1001      123     1247 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/series/temporal.rst
+-rw-r--r--   0     1001      123      503 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/sql.rst
+-rw-r--r--   0     1001      123     8067 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/testing.rst
+-rw-r--r--   0     1001      123      168 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/docs/source/reference/utils.rst
+-rw-r--r--   0     1001      123     6370 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/__init__.py
+-rw-r--r--   0     1001      123      280 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/_reexport.py
+-rw-r--r--   0     1001      123    13229 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/api.py
+-rw-r--r--   0     1001      123    29652 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/config.py
+-rw-r--r--   0     1001      123    28090 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/convert.py
+-rw-r--r--   0     1001      123       77 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/dataframe/__init__.py
+-rw-r--r--   0     1001      123     5227 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/dataframe/_html.py
+-rw-r--r--   0     1001      123   323980 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/dataframe/frame.py
+-rw-r--r--   0     1001      123    41618 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/dataframe/groupby.py
+-rw-r--r--   0     1001      123     2692 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/datatypes/__init__.py
+-rw-r--r--   0     1001      123    17874 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/datatypes/classes.py
+-rw-r--r--   0     1001      123     1690 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/datatypes/constants.py
+-rw-r--r--   0     1001      123     4701 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/datatypes/constructor.py
+-rw-r--r--   0     1001      123    15446 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/datatypes/convert.py
+-rw-r--r--   0     1001      123     7358 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/dependencies.py
+-rw-r--r--   0     1001      123     3792 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/exceptions.py
+-rw-r--r--   0     1001      123       61 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/__init__.py
+-rw-r--r--   0     1001      123     3020 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/array.py
+-rw-r--r--   0     1001      123    10330 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/binary.py
+-rw-r--r--   0     1001      123     1698 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/categorical.py
+-rw-r--r--   0     1001      123    80633 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/datetime.py
+-rw-r--r--   0     1001      123   314741 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/expr.py
+-rw-r--r--   0     1001      123    30816 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/list.py
+-rw-r--r--   0     1001      123     4683 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/meta.py
+-rw-r--r--   0     1001      123    60086 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/string.py
+-rw-r--r--   0     1001      123     5426 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/expr/struct.py
+-rw-r--r--   0     1001      123     2126 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/functions/__init__.py
+-rw-r--r--   0     1001      123    16430 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/functions/as_datatype.py
+-rw-r--r--   0     1001      123    18732 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/functions/eager.py
+-rw-r--r--   0     1001      123    72418 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/functions/lazy.py
+-rw-r--r--   0     1001      123    20012 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/functions/range.py
+-rw-r--r--   0     1001      123     6043 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/functions/repeat.py
+-rw-r--r--   0     1001      123     6051 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/functions/whenthen.py
+-rw-r--r--   0     1001      123      952 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/__init__.py
+-rw-r--r--   0     1001      123     6364 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/_utils.py
+-rw-r--r--   0     1001      123      861 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/avro.py
+-rw-r--r--   0     1001      123      144 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/csv/__init__.py
+-rw-r--r--   0     1001      123     1072 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/csv/_utils.py
+-rw-r--r--   0     1001      123     4681 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/csv/batched_reader.py
+-rw-r--r--   0     1001      123    35482 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/csv/functions.py
+-rw-r--r--   0     1001      123     6428 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/database.py
+-rw-r--r--   0     1001      123    11047 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/delta.py
+-rw-r--r--   0     1001      123       75 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/excel/__init__.py
+-rw-r--r--   0     1001      123    18338 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/excel/_write_utils.py
+-rw-r--r--   0     1001      123     6355 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/excel/functions.py
+-rw-r--r--   0     1001      123      142 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/ipc/__init__.py
+-rw-r--r--   0     1001      123     1227 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/ipc/anonymous_scan.py
+-rw-r--r--   0     1001      123     5804 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/ipc/functions.py
+-rw-r--r--   0     1001      123      510 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/json.py
+-rw-r--r--   0     1001      123     2215 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/ndjson.py
+-rw-r--r--   0     1001      123      170 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/parquet/__init__.py
+-rw-r--r--   0     1001      123     1259 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/parquet/anonymous_scan.py
+-rw-r--r--   0     1001      123     7177 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/parquet/functions.py
+-rw-r--r--   0     1001      123      136 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/pyarrow_dataset/__init__.py
+-rw-r--r--   0     1001      123     2186 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/pyarrow_dataset/anonymous_scan.py
+-rw-r--r--   0     1001      123     3601 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/io/pyarrow_dataset/functions.py
+-rw-r--r--   0     1001      123       77 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/lazyframe/__init__.py
+-rw-r--r--   0     1001      123   172003 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/lazyframe/frame.py
+-rw-r--r--   0     1001      123    25094 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/lazyframe/groupby.py
+-rw-r--r--   0     1001      123        0 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/py.typed
+-rw-r--r--   0     1001      123    38494 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/selectors.py
+-rw-r--r--   0     1001      123       69 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/__init__.py
+-rw-r--r--   0     1001      123     1572 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/_numpy.py
+-rw-r--r--   0     1001      123     2515 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/array.py
+-rw-r--r--   0     1001      123     1913 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/binary.py
+-rw-r--r--   0     1001      123     1692 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/categorical.py
+-rw-r--r--   0     1001      123    54653 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/datetime.py
+-rw-r--r--   0     1001      123    16940 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/list.py
+-rw-r--r--   0     1001      123   169195 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/series.py
+-rw-r--r--   0     1001      123    38879 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/string.py
+-rw-r--r--   0     1001      123     2542 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/struct.py
+-rw-r--r--   0     1001      123     5361 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/series/utils.py
+-rw-r--r--   0     1001      123     7559 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/slice.py
+-rw-r--r--   0     1001      123       75 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/sql/__init__.py
+-rw-r--r--   0     1001      123    17286 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/sql/context.py
+-rw-r--r--   0     1001      123     4793 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/string_cache.py
+-rw-r--r--   0     1001      123      362 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/testing/__init__.py
+-rw-r--r--   0     1001      123     1060 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/testing/_private.py
+-rw-r--r--   0     1001      123    16964 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/testing/asserts.py
+-rw-r--r--   0     1001      123      898 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/testing/parametric/__init__.py
+-rw-r--r--   0     1001      123    28187 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/testing/parametric/primitives.py
+-rw-r--r--   0     1001      123     3371 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/testing/parametric/profiles.py
+-rw-r--r--   0     1001      123    13165 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/testing/parametric/strategies.py
+-rw-r--r--   0     1001      123     6460 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/type_aliases.py
+-rw-r--r--   0     1001      123     1157 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/__init__.py
+-rw-r--r--   0     1001      123    56946 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/_construction.py
+-rw-r--r--   0     1001      123     4937 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/_parse_expr_input.py
+-rw-r--r--   0     1001      123      647 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/_scan.py
+-rw-r--r--   0     1001      123      579 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/_wrap.py
+-rw-r--r--   0     1001      123      683 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/build_info.py
+-rw-r--r--   0     1001      123     8702 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/convert.py
+-rw-r--r--   0     1001      123     7199 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/decorators.py
+-rw-r--r--   0     1001      123     1660 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/meta.py
+-rw-r--r--   0     1001      123      514 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/polars_version.py
+-rw-r--r--   0     1001      123     2509 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/show_versions.py
+-rw-r--r--   0     1001      123    13340 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/polars/utils/various.py
+-rw-r--r--   0     1001      123     5370 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/pyproject.toml
+-rw-r--r--   0     1001      123      756 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/requirements-dev.txt
+-rw-r--r--   0     1001      123       70 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/requirements-lint.txt
+-rw-r--r--   0     1001      123     1610 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/scripts/check_stacklevels.py
+-rw-r--r--   0     1001      123    10980 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/apply/dataframe.rs
+-rw-r--r--   0     1001      123     6428 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/apply/lazy.rs
+-rw-r--r--   0     1001      123     8402 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/apply/mod.rs
+-rw-r--r--   0     1001      123    90347 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/apply/series.rs
+-rw-r--r--   0     1001      123       32 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/arrow_interop/mod.rs
+-rw-r--r--   0     1001      123     1306 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/arrow_interop/to_py.rs
+-rw-r--r--   0     1001      123     3902 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/arrow_interop/to_rust.rs
+-rw-r--r--   0     1001      123     5250 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/batched_csv.rs
+-rw-r--r--   0     1001      123    49804 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/conversion.rs
+-rw-r--r--   0     1001      123    46152 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/dataframe.rs
+-rw-r--r--   0     1001      123     3950 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/datatypes.rs
+-rw-r--r--   0     1001      123     3506 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/error.rs
+-rw-r--r--   0     1001      123      570 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/array.rs
+-rw-r--r--   0     1001      123     2080 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/binary.rs
+-rw-r--r--   0     1001      123      274 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/categorical.rs
+-rw-r--r--   0     1001      123     6206 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/datetime.rs
+-rw-r--r--   0     1001      123    35096 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/general.rs
+-rw-r--r--   0     1001      123     4693 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/list.rs
+-rw-r--r--   0     1001      123     3152 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/meta.rs
+-rw-r--r--   0     1001      123      870 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/mod.rs
+-rw-r--r--   0     1001      123     8366 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/string.rs
+-rw-r--r--   0     1001      123      467 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/expr/struct.rs
+-rw-r--r--   0     1001      123     9482 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/file.rs
+-rw-r--r--   0     1001      123     2777 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/functions/eager.rs
+-rw-r--r--   0     1001      123     1657 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/functions/io.rs
+-rw-r--r--   0     1001      123    11595 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/functions/lazy.rs
+-rw-r--r--   0     1001      123     1312 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/functions/meta.rs
+-rw-r--r--   0     1001      123      217 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/functions/misc.rs
+-rw-r--r--   0     1001      123      102 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/functions/mod.rs
+-rw-r--r--   0     1001      123      689 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/functions/range.rs
+-rw-r--r--   0     1001      123     1474 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/functions/whenthen.rs
+-rw-r--r--   0     1001      123    28073 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/lazyframe.rs
+-rw-r--r--   0     1001      123     2670 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/lazygroupby.rs
+-rw-r--r--   0     1001      123     8553 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/lib.rs
+-rw-r--r--   0     1001      123       47 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/object.rs
+-rw-r--r--   0     1001      123     2989 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/on_startup.rs
+-rw-r--r--   0     1001      123      122 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/prelude.rs
+-rw-r--r--   0     1001      123      435 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/py_modules.rs
+-rw-r--r--   0     1001      123     1964 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/series/aggregation.rs
+-rw-r--r--   0     1001      123     5406 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/series/arithmetic.rs
+-rw-r--r--   0     1001      123     5138 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/series/comparison.rs
+-rw-r--r--   0     1001      123     9077 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/series/construction.rs
+-rw-r--r--   0     1001      123     8971 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/series/export.rs
+-rw-r--r--   0     1001      123    26606 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/series/mod.rs
+-rw-r--r--   0     1001      123     4569 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/series/numpy_ufunc.rs
+-rw-r--r--   0     1001      123     4046 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/series/set_at_idx.rs
+-rw-r--r--   0     1001      123     1036 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/sql.rs
+-rw-r--r--   0     1001      123     2335 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/src/utils.rs
+-rw-r--r--   0     1001      123     6165 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/README.md
+-rw-r--r--   0     1001      123     2189 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/benchmark/groupby-datagen.R
+-rw-r--r--   0     1001      123     7963 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/benchmark/run_h2oai_benchmark.py
+-rw-r--r--   0     1001      123     6530 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/benchmark/test_release.py
+-rw-r--r--   0     1001      123     4589 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/docs/run_doctest.py
+-rw-r--r--   0     1001      123        0 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/__init__.py
+-rw-r--r--   0     1001      123      179 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/conftest.py
+-rw-r--r--   0     1001      123     3856 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/test_dataframe.py
+-rw-r--r--   0     1001      123     2398 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/test_groupby_rolling.py
+-rw-r--r--   0     1001      123     1692 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/test_lazyframe.py
+-rw-r--r--   0     1001      123      976 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/test_lit.py
+-rw-r--r--   0     1001      123     6853 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/test_series.py
+-rw-r--r--   0     1001      123     8467 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/test_testing.py
+-rw-r--r--   0     1001      123     1554 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/parametric/time_series/test_to_datetime.py
+-rw-r--r--   0     1001      123        0 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/__init__.py
+-rw-r--r--   0     1001      123     3382 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/conftest.py
+-rw-r--r--   0     1001      123       86 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/__init__.py
+-rw-r--r--   0     1001      123     1285 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_array.py
+-rw-r--r--   0     1001      123      847 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_binary.py
+-rw-r--r--   0     1001      123     1420 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_bool.py
+-rw-r--r--   0     1001      123    13609 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_categorical.py
+-rw-r--r--   0     1001      123     5222 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_decimal.py
+-rw-r--r--   0     1001      123      549 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_duration.py
+-rw-r--r--   0     1001      123      423 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_integer.py
+-rw-r--r--   0     1001      123    14052 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_list.py
+-rw-r--r--   0     1001      123      284 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_null.py
+-rw-r--r--   0     1001      123     3028 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_object.py
+-rw-r--r--   0     1001      123    27697 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_struct.py
+-rw-r--r--   0     1001      123    87698 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_temporal.py
+-rw-r--r--   0     1001      123      418 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/datatypes/test_time.py
+-rw-r--r--   0     1001      123        0 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/functions/__init__.py
+-rw-r--r--   0     1001      123    13970 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/functions/test_as_datatype.py
+-rw-r--r--   0     1001      123      480 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/functions/test_concat.py
+-rw-r--r--   0     1001      123    15574 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/functions/test_functions.py
+-rw-r--r--   0     1001      123    30418 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/functions/test_range.py
+-rw-r--r--   0     1001      123     3847 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/functions/test_repeat.py
+-rw-r--r--   0     1001      123      218 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/conftest.py
+-rw-r--r--   0     1001      123       16 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/.part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet.crc
+-rw-r--r--   0     1001      123       16 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/.part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet.crc
+-rw-r--r--   0     1001      123       16 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/_delta_log/.00000000000000000000.json.crc
+-rw-r--r--   0     1001      123       16 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/_delta_log/.00000000000000000001.json.crc
+-rw-r--r--   0     1001      123      905 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json
+-rw-r--r--   0     1001      123      936 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json
+-rw-r--r--   0     1001      123      972 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet
+-rw-r--r--   0     1001      123      690 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet
+-rw-r--r--   0     1001      123        0 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/empty.csv
+-rw-r--r--   0     1001      123     5959 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/example.xlsx
+-rw-r--r--   0     1001      123      457 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods1.csv
+-rw-r--r--   0     1001      123     2351 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods1.ipc
+-rw-r--r--   0     1001      123     1713 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods1.ndjson
+-rw-r--r--   0     1001      123     1427 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods1.parquet
+-rw-r--r--   0     1001      123      455 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods2.csv
+-rw-r--r--   0     1001      123     2351 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods2.ipc
+-rw-r--r--   0     1001      123     1711 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods2.ndjson
+-rw-r--r--   0     1001      123     1916 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods2.parquet
+-rw-r--r--   0     1001      123      455 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods3.csv
+-rw-r--r--   0     1001      123      457 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods4.csv
+-rw-r--r--   0     1001      123      452 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/foods5.csv
+-rw-r--r--   0     1001      123       49 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/gzipped.csv
+-rw-r--r--   0     1001      123       57 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/small.csv
+-rw-r--r--   0     1001      123      756 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/files/small.parquet
+-rw-r--r--   0     1001      123     1884 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_avro.py
+-rw-r--r--   0     1001      123    41164 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_csv.py
+-rw-r--r--   0     1001      123     6271 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_database.py
+-rw-r--r--   0     1001      123     6172 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_delta.py
+-rw-r--r--   0     1001      123    11169 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_excel.py
+-rw-r--r--   0     1001      123     5483 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_ipc.py
+-rw-r--r--   0     1001      123     4389 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_json.py
+-rw-r--r--   0     1001      123     7379 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_lazy_csv.py
+-rw-r--r--   0     1001      123     2060 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_lazy_ipc.py
+-rw-r--r--   0     1001      123     2867 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_lazy_json.py
+-rw-r--r--   0     1001      123    11145 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_lazy_parquet.py
+-rw-r--r--   0     1001      123     2012 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_other.py
+-rw-r--r--   0     1001      123    14157 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_parquet.py
+-rw-r--r--   0     1001      123      612 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_pickle.py
+-rw-r--r--   0     1001      123     3706 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/io/test_pyarrow_dataset.py
+-rw-r--r--   0     1001      123      509 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/__init__.py
+-rw-r--r--   0     1001      123      589 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_array.py
+-rw-r--r--   0     1001      123     3218 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_binary.py
+-rw-r--r--   0     1001      123     2489 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_categorical.py
+-rw-r--r--   0     1001      123    23231 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_datetime.py
+-rw-r--r--   0     1001      123    15154 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_list.py
+-rw-r--r--   0     1001      123     2472 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_meta.py
+-rw-r--r--   0     1001      123    24050 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_string.py
+-rw-r--r--   0     1001      123    20819 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_strptime.py
+-rw-r--r--   0     1001      123      982 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/namespaces/test_struct.py
+-rw-r--r--   0     1001      123       85 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/__init__.py
+-rw-r--r--   0     1001      123     8008 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_aggregations.py
+-rw-r--r--   0     1001      123    10613 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_apply.py
+-rw-r--r--   0     1001      123     6896 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_arithmetic.py
+-rw-r--r--   0     1001      123     4940 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_comparison.py
+-rw-r--r--   0     1001      123     3275 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_drop.py
+-rw-r--r--   0     1001      123     8813 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_explode.py
+-rw-r--r--   0     1001      123     3664 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_filter.py
+-rw-r--r--   0     1001      123     1801 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_folds.py
+-rw-r--r--   0     1001      123    25037 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_groupby.py
+-rw-r--r--   0     1001      123     7649 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_groupby_rolling.py
+-rw-r--r--   0     1001      123     2983 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_is_in.py
+-rw-r--r--   0     1001      123    18993 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_join.py
+-rw-r--r--   0     1001      123    14952 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_join_asof.py
+-rw-r--r--   0     1001      123      643 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_melt.py
+-rw-r--r--   0     1001      123    10253 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_pivot.py
+-rw-r--r--   0     1001      123     3187 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_random.py
+-rw-r--r--   0     1001      123    24274 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_rolling.py
+-rw-r--r--   0     1001      123     2389 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_select.py
+-rw-r--r--   0     1001      123    20770 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_sort.py
+-rw-r--r--   0     1001      123     6121 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_statistics.py
+-rw-r--r--   0     1001      123     4130 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_transpose.py
+-rw-r--r--   0     1001      123      771 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_unique.py
+-rw-r--r--   0     1001      123    11644 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_window.py
+-rw-r--r--   0     1001      123     5480 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/operations/test_with_columns.py
+-rw-r--r--   0     1001      123        0 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/streaming/__init__.py
+-rw-r--r--   0     1001      123      196 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/streaming/conftest.py
+-rw-r--r--   0     1001      123      908 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/streaming/test_ooc.py
+-rw-r--r--   0     1001      123    19789 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/streaming/test_streaming.py
+-rw-r--r--   0     1001      123     4831 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_api.py
+-rw-r--r--   0     1001      123     1969 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_arity.py
+-rw-r--r--   0     1001      123    20397 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_cfg.py
+-rw-r--r--   0     1001      123    43560 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_constructors.py
+-rw-r--r--   0     1001      123      454 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_context.py
+-rw-r--r--   0     1001      123     2626 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_cse.py
+-rw-r--r--   0     1001      123     5191 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_datatypes.py
+-rw-r--r--   0     1001      123   120452 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_df.py
+-rw-r--r--   0     1001      123     2741 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_empty.py
+-rw-r--r--   0     1001      123    19664 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_errors.py
+-rw-r--r--   0     1001      123     2741 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_expr_multi_cols.py
+-rw-r--r--   0     1001      123    33619 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_exprs.py
+-rw-r--r--   0     1001      123     3516 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_fmt.py
+-rw-r--r--   0     1001      123     3512 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_interchange.py
+-rw-r--r--   0     1001      123    38530 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_interop.py
+-rw-r--r--   0     1001      123    49654 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_lazy.py
+-rw-r--r--   0     1001      123     2463 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_polars_import.py
+-rw-r--r--   0     1001      123     4883 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_predicates.py
+-rw-r--r--   0     1001      123     7572 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_projections.py
+-rw-r--r--   0     1001      123    11551 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_queries.py
+-rw-r--r--   0     1001      123     8100 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_rows.py
+-rw-r--r--   0     1001      123    13961 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_schema.py
+-rw-r--r--   0     1001      123    12341 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_selectors.py
+-rw-r--r--   0     1001      123     4107 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_serde.py
+-rw-r--r--   0     1001      123    82889 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_series.py
+-rw-r--r--   0     1001      123      657 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_single.py
+-rw-r--r--   0     1001      123    16616 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_sql.py
+-rw-r--r--   0     1001      123    35314 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/test_testing.py
+-rw-r--r--   0     1001      123       41 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/utils/__init__.py
+-rw-r--r--   0     1001      123      306 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/utils/test_build_info.py
+-rw-r--r--   0     1001      123     2855 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/utils/test_parse_expr_input.py
+-rw-r--r--   0     1001      123      247 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/utils/test_show_versions.py
+-rw-r--r--   0     1001      123     5026 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/tests/unit/utils/test_utils.py
+-rw-r--r--   0     1001      123    65129 2023-07-05 14:01:02.000000 polars_lts_cpu-0.18.5/Cargo.lock
+-rw-r--r--   0        0        0    14286 1970-01-01 00:00:00.000000 polars_lts_cpu-0.18.5/PKG-INFO
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-json/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-json/Cargo.toml`

 * *Files 8% similar despite different names*

```diff
@@ -9,29 +9,29 @@
 resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 ahash= "0.8"
 fallible-streaming-iterator = "0.1"
-hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
-indexmap= { version = "1", features = ["std"] }
+hashbrown= { version = "0.14.0", features = ["rayon", "ahash"] }
+indexmap= { version = "2", features = ["std"] }
 num-traits= "0.2"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", default-features = false }
 polars-error = { version = "0.30.0", path = "../polars-error" }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
 simd-json = { version = "0.10", features = ["allow-non-simd", "known-key"] }
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-json/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/json/deserialize.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/json/deserialize.rs`

 * *Files 2% similar despite different names*

```diff
@@ -374,29 +374,21 @@
         DataType::LargeList(_) => Box::new(deserialize_list(rows, data_type)),
         DataType::LargeBinary => Box::new(deserialize_binary(rows)),
         DataType::Struct(_) => Box::new(deserialize_struct(rows, data_type)),
         _ => todo!(),
     }
 }
 
-/// Deserializes a `json` [`Value`][Value] into an [`Array`] of [`DataType`]
-/// This is CPU-bounded.
-/// # Error
-/// This function errors iff either:
-/// * `json` is not an [`Array`]
-/// * `data_type` is neither [`DataType::List`] nor [`DataType::LargeList`]
-///
-/// [Value]: simd_json::value::Value
 pub fn deserialize(json: &BorrowedValue, data_type: DataType) -> Result<Box<dyn Array>, Error> {
     match json {
         BorrowedValue::Array(rows) => match data_type {
             DataType::LargeList(inner) => Ok(_deserialize(rows, inner.data_type)),
             _ => todo!("read an Array from a non-Array data type"),
         },
-        _ => todo!("read an Array from a non-Array JSON"),
+        _ => Ok(_deserialize(&[json], data_type)),
     }
 }
 
 fn allocate_array(f: &Field) -> Box<dyn MutableArray> {
     match f.data_type() {
         DataType::Int8 => Box::new(MutablePrimitiveArray::<i8>::new()),
         DataType::Int16 => Box::new(MutablePrimitiveArray::<i16>::new()),
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/json/infer_schema.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/json/infer_schema.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/ndjson/deserialize.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/ndjson/deserialize.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-json/src/ndjson/file.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-json/src/ndjson/file.rs`

 * *Files 5% similar despite different names*

```diff
@@ -140,10 +140,9 @@
         let data_type = crate::json::infer(&v)?;
         if data_type != DataType::Null {
             data_types.insert(data_type);
         }
     }
 
     let v: Vec<&DataType> = data_types.iter().collect();
-    dbg!(&v);
-    dbg!(Ok(crate::json::infer_schema::coerce_data_type(&v)))
+    Ok(crate::json::infer_schema::coerce_data_type(&v))
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/Cargo.toml`

 * *Files 4% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 atoi = { version = "2.0.0", optional = true }
 chrono = { version = "0.4", default-features = false, features = ["std"], optional = true }
 chrono-tz = { version = "0.8", optional = true }
 ethnum = { version = "1.3.2", optional = true }
-hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
+hashbrown= { version = "0.14.0", features = ["rayon", "ahash"] }
 multiversion= "0.7"
 num-traits= "0.2"
 polars-error = { version = "0.30.0", path = "../polars-error" }
 serde = { version = "1", features = ["derive"], optional = true }
 thiserror= "^1"
 
 [features]
@@ -36,15 +36,15 @@
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/default_arrays.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/default_arrays.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/fixed_size_list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/fixed_size_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/get.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/get.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/null.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/slice.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/array/utf8.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/array/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/bit_util.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/bit_util.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/bitmap/mutable.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/bitmap/mutable.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/commutative.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/commutative.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/div.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/div.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mul.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/arithmetics/decimal/mul.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/bitwise.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/bitwise.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/cast.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/cast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/decimal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/decimal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/take/boolean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/take/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/take/fixed_size_list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/take/fixed_size_list.rs`

 * *Files 11% similar despite different names*

```diff
@@ -79,15 +79,15 @@
 ) -> FixedSizeListArray {
     let values = list_values.values().as_slice();
     let mut out = Vec::with_capacity(idx.len() * width);
 
     for &i in idx {
         let start = i as usize * width;
         let end = start + width;
-        out.copy_from_slice(values.get_unchecked(start..end));
+        out.extend_from_slice(values.get_unchecked(start..end));
     }
 
     let validity = if list_values.null_count() > 0 {
         let validity = list_values.validity().unwrap();
         Some(take_bitmap_unchecked(validity, idx, width))
     } else {
         None
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/take/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/take/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/compute/tile.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/compute/tile.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/conversion.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/conversion.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/data_types.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/data_types.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/floats/ord.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/floats/ord.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/index.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/index.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/is_valid.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/is_valid.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/agg_mean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/agg_mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/comparison.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/comparison.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/concatenate.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/concatenate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/ewm/average.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/ewm/average.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/ewm/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/ewm/variance.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/float.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/float.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/list_bytes_iter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/mod.rs`

 * *Files 11% similar despite different names*

```diff
@@ -108,28 +108,27 @@
     )))
 }
 
 fn compute_var_weights<T>(vals: &[T], weights: &[T]) -> T
 where
     T: Float + std::ops::AddAssign,
 {
-    let weighted_iter = vals.iter().zip(weights).map(|(x, y)| *x * *y);
+    // Assumes the weights have already been standardized to 1
+    debug_assert!(
+        weights.iter().fold(T::zero(), |acc, x| acc + *x) == T::one(),
+        "Rolling weighted variance Weights don't sum to 1"
+    );
+    let (wssq, wmean) = vals
+        .iter()
+        .zip(weights)
+        .fold((T::zero(), T::zero()), |(wssq, wsum), (&v, &w)| {
+            (wssq + v * v * w, wsum + v * w)
+        });
 
-    let mut sum = T::zero();
-    let mut sum_of_squares = T::zero();
-
-    for val in weighted_iter {
-        sum += val;
-        sum_of_squares += val * val;
-    }
-    let count = NumCast::from(vals.len()).unwrap();
-
-    let mean = sum / count;
-    // apply Bessel's correction
-    ((sum_of_squares / count) - mean * mean) / (count - T::one()) * count
+    wssq - wmean * wmean
 }
 
 pub(crate) fn compute_sum_weights<T>(values: &[T], weights: &[T]) -> T
 where
     T: std::iter::Sum<T> + Copy + std::ops::Mul<Output = T>,
 {
     values.iter().zip(weights).map(|(v, w)| *v * *w).sum()
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/quantile.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs`

 * *Files 24% similar despite different names*

```diff
@@ -1,399 +1,276 @@
-use std::fmt::Debug;
-
-use num_traits::ToPrimitive;
+mod mean;
+mod min_max;
+mod quantile;
+mod sum;
+mod variance;
+
+pub use mean::*;
+pub use min_max::*;
+pub use quantile::*;
+pub use sum::*;
+pub use variance::*;
 
 use super::*;
-use crate::index::IdxSize;
-use crate::trusted_len::TrustedLen;
-
-// used by agg_quantile
-pub fn rolling_quantile_by_iter<T, O>(
-    values: &[T],
-    quantile: f64,
-    interpolation: QuantileInterpolOptions,
-    offsets: O,
-) -> ArrayRef
-where
-    O: Iterator<Item = (IdxSize, IdxSize)> + TrustedLen,
-    T: std::iter::Sum<T>
-        + NativeType
-        + Copy
-        + PartialOrd
-        + ToPrimitive
-        + NumCast
-        + Add<Output = T>
-        + Sub<Output = T>
-        + Div<Output = T>
-        + Mul<Output = T>
-        + IsFloat,
-{
-    if values.is_empty() {
-        let out: Vec<T> = vec![];
-        return Box::new(PrimitiveArray::new(T::PRIMITIVE.into(), out.into(), None));
-    }
-
-    let mut sorted_window = SortedBuf::new(values, 0, 1);
-
-    let out = offsets
-        .map(|(start, len)| {
-            let end = start + len;
-
-            // safety:
-            // we are in bounds
-            if start == end {
-                None
-            } else {
-                let window = unsafe { sorted_window.update(start as usize, end as usize) };
-                Some(compute_quantile2(window, quantile, interpolation))
-            }
-        })
-        .collect::<PrimitiveArray<T>>();
-
-    Box::new(out)
-}
-
-pub(crate) fn compute_quantile2<T>(
-    vals: &[T],
-    quantile: f64,
-    interpolation: QuantileInterpolOptions,
-) -> T
-where
-    T: std::iter::Sum<T>
-        + Copy
-        + PartialOrd
-        + ToPrimitive
-        + NumCast
-        + Add<Output = T>
-        + Sub<Output = T>
-        + Div<Output = T>
-        + Mul<Output = T>
-        + IsFloat,
-{
-    let length = vals.len();
 
-    let mut idx = match interpolation {
-        QuantileInterpolOptions::Nearest => ((length as f64) * quantile) as usize,
-        QuantileInterpolOptions::Lower
-        | QuantileInterpolOptions::Midpoint
-        | QuantileInterpolOptions::Linear => ((length as f64 - 1.0) * quantile).floor() as usize,
-        QuantileInterpolOptions::Higher => ((length as f64 - 1.0) * quantile).ceil() as usize,
-    };
-
-    idx = std::cmp::min(idx, length - 1);
-
-    match interpolation {
-        QuantileInterpolOptions::Midpoint => {
-            let top_idx = ((length as f64 - 1.0) * quantile).ceil() as usize;
-            if top_idx == idx {
-                // safety
-                // we are in bounds
-                unsafe { *vals.get_unchecked(idx) }
-            } else {
-                // safety
-                // we are in bounds
-                let (mid, mid_plus_1) =
-                    unsafe { (*vals.get_unchecked(idx), *vals.get_unchecked(idx + 1)) };
-
-                (mid + mid_plus_1) / T::from::<f64>(2.0f64).unwrap()
-            }
-        }
-        QuantileInterpolOptions::Linear => {
-            let float_idx = (length as f64 - 1.0) * quantile;
-            let top_idx = f64::ceil(float_idx) as usize;
-
-            if top_idx == idx {
-                // safety
-                // we are in bounds
-                unsafe { *vals.get_unchecked(idx) }
-            } else {
-                let proportion = T::from(float_idx - idx as f64).unwrap();
-                proportion * (vals[top_idx] - vals[idx]) + vals[idx]
-            }
-        }
-        _ => {
-            // safety
-            // we are in bounds
-            unsafe { *vals.get_unchecked(idx) }
-        }
-    }
-}
-
-pub fn rolling_median<T>(
-    values: &[T],
-    window_size: usize,
-    min_periods: usize,
-    center: bool,
-    weights: Option<&[f64]>,
-    _params: DynArgs,
-) -> PolarsResult<ArrayRef>
-where
-    T: NativeType
-        + std::iter::Sum<T>
-        + PartialOrd
-        + ToPrimitive
-        + NumCast
-        + Add<Output = T>
-        + Sub<Output = T>
-        + Div<Output = T>
-        + Mul<Output = T>
-        + Zero
-        + IsFloat,
-{
-    Ok(rolling_quantile(
-        values,
-        0.5,
-        QuantileInterpolOptions::Linear,
-        window_size,
-        min_periods,
-        center,
-        weights,
-    ))
-}
+pub trait RollingAggWindowNulls<'a, T: NativeType> {
+    /// # Safety
+    /// `start` and `end` must be in bounds for `slice` and `validity`
+    unsafe fn new(
+        slice: &'a [T],
+        validity: &'a Bitmap,
+        start: usize,
+        end: usize,
+        params: DynArgs,
+    ) -> Self;
+
+    /// # Safety
+    /// `start` and `end` must be in bounds of `slice` and `bitmap`
+    unsafe fn update(&mut self, start: usize, end: usize) -> Option<T>;
 
-pub fn rolling_quantile<T>(
-    values: &[T],
-    quantile: f64,
-    interpolation: QuantileInterpolOptions,
-    window_size: usize,
-    min_periods: usize,
-    center: bool,
-    weights: Option<&[f64]>,
-) -> ArrayRef
-where
-    T: NativeType
-        + std::iter::Sum<T>
-        + PartialOrd
-        + ToPrimitive
-        + NumCast
-        + Add<Output = T>
-        + Sub<Output = T>
-        + Div<Output = T>
-        + Mul<Output = T>
-        + Zero
-        + IsFloat,
-{
-    match (center, weights) {
-        (true, None) => rolling_apply_quantile(
-            values,
-            quantile,
-            interpolation,
-            window_size,
-            min_periods,
-            det_offsets_center,
-            compute_quantile2,
-        ),
-        (false, None) => rolling_apply_quantile(
-            values,
-            quantile,
-            interpolation,
-            window_size,
-            min_periods,
-            det_offsets,
-            compute_quantile2,
-        ),
-        (true, Some(weights)) => rolling_apply_convolve_quantile(
-            values,
-            quantile,
-            interpolation,
-            window_size,
-            min_periods,
-            det_offsets_center,
-            compute_quantile2,
-            weights,
-        ),
-        (false, Some(weights)) => rolling_apply_convolve_quantile(
-            values,
-            quantile,
-            interpolation,
-            window_size,
-            min_periods,
-            det_offsets,
-            compute_quantile2,
-            weights,
-        ),
-    }
+    fn is_valid(&self, min_periods: usize) -> bool;
 }
 
-fn rolling_apply_quantile<T, Fo, Fa>(
-    values: &[T],
-    quantile: f64,
-    interpolation: QuantileInterpolOptions,
+// Use an aggregation window that maintains the state
+pub(super) fn rolling_apply_agg_window<'a, Agg, T, Fo>(
+    values: &'a [T],
+    validity: &'a Bitmap,
     window_size: usize,
     min_periods: usize,
     det_offsets_fn: Fo,
-    aggregator: Fa,
+    params: DynArgs,
 ) -> ArrayRef
 where
-    Fo: Fn(Idx, WindowSize, Len) -> (Start, End),
-    Fa: Fn(&[T], f64, QuantileInterpolOptions) -> T,
-    T: Debug + NativeType + IsFloat + PartialOrd,
+    Fo: Fn(Idx, WindowSize, Len) -> (Start, End) + Copy,
+    Agg: RollingAggWindowNulls<'a, T>,
+    T: IsFloat + NativeType,
 {
     let len = values.len();
     let (start, end) = det_offsets_fn(0, window_size, len);
-    let mut sorted_window = SortedBuf::new(values, start, end);
+    // Safety; we are in bounds
+    let mut agg_window = unsafe { Agg::new(values, validity, start, end, params) };
 
-    let out = (0..len)
-        .map(|idx| {
-            let (start, end) = det_offsets_fn(idx, window_size, len);
-
-            // Safety:
-            // we are in bounds
-            let window = unsafe { sorted_window.update(start, end) };
-            aggregator(window, quantile, interpolation)
-        })
-        .collect_trusted::<Vec<T>>();
-
-    let validity = create_validity(min_periods, len, window_size, det_offsets_fn);
-    Box::new(PrimitiveArray::new(
-        T::PRIMITIVE.into(),
-        out.into(),
-        validity.map(|b| b.into()),
-    ))
-}
+    let mut validity = match create_validity(min_periods, len, window_size, det_offsets_fn) {
+        Some(v) => v,
+        None => {
+            let mut validity = MutableBitmap::with_capacity(len);
+            validity.extend_constant(len, true);
+            validity
+        }
+    };
 
-#[allow(clippy::too_many_arguments)]
-fn rolling_apply_convolve_quantile<T, Fo, Fa>(
-    values: &[T],
-    quantile: f64,
-    interpolation: QuantileInterpolOptions,
-    window_size: usize,
-    min_periods: usize,
-    det_offsets_fn: Fo,
-    aggregator: Fa,
-    weights: &[f64],
-) -> ArrayRef
-where
-    Fo: Fn(Idx, WindowSize, Len) -> (Start, End),
-    Fa: Fn(&[T], f64, QuantileInterpolOptions) -> T,
-    T: Debug + NativeType + Mul<Output = T> + NumCast + ToPrimitive + Zero + IsFloat + PartialOrd,
-{
-    assert_eq!(weights.len(), window_size);
-    let mut buf = vec![T::zero(); window_size];
-    let len = values.len();
     let out = (0..len)
         .map(|idx| {
             let (start, end) = det_offsets_fn(idx, window_size, len);
-            let vals = unsafe { values.get_unchecked(start..end) };
-            buf.iter_mut()
-                .zip(vals.iter().zip(weights))
-                .for_each(|(b, (v, w))| *b = *v * NumCast::from(*w).unwrap());
-
-            sort_buf(&mut buf);
-            aggregator(&buf, quantile, interpolation)
+            // safety:
+            // we are in bounds
+            let agg = unsafe { agg_window.update(start, end) };
+            match agg {
+                Some(val) => {
+                    if agg_window.is_valid(min_periods) {
+                        val
+                    } else {
+                        // safety: we are in bounds
+                        unsafe { validity.set_unchecked(idx, false) };
+                        T::default()
+                    }
+                }
+                None => {
+                    // safety: we are in bounds
+                    unsafe { validity.set_unchecked(idx, false) };
+                    T::default()
+                }
+            }
         })
-        .collect_trusted::<Vec<T>>();
+        .collect_trusted::<Vec<_>>();
 
-    let validity = create_validity(min_periods, len, window_size, det_offsets_fn);
     Box::new(PrimitiveArray::new(
         T::PRIMITIVE.into(),
         out.into(),
-        validity.map(|b| b.into()),
+        Some(validity.into()),
     ))
 }
 
 #[cfg(test)]
 mod test {
+    use arrow::array::{Array, Int32Array};
+    use arrow::buffer::Buffer;
+    use arrow::datatypes::DataType;
+
     use super::*;
-    use crate::kernels::rolling::no_nulls::{rolling_max, rolling_min};
+    use crate::kernels::rolling::nulls::mean::rolling_mean;
 
-    #[test]
-    fn test_rolling_median() {
-        let values = &[1.0, 2.0, 3.0, 4.0];
+    fn get_null_arr() -> PrimitiveArray<f64> {
+        // 1, None, -1, 4
+        let buf = Buffer::from(vec![1.0, 0.0, -1.0, 4.0]);
+        PrimitiveArray::new(
+            DataType::Float64,
+            buf,
+            Some(Bitmap::from(&[true, false, true, true])),
+        )
+    }
 
-        let out = rolling_quantile(
-            values,
-            0.5,
-            QuantileInterpolOptions::Linear,
-            2,
-            2,
-            false,
-            None,
+    #[test]
+    fn test_rolling_sum_nulls() {
+        let buf = Buffer::from(vec![1.0, 2.0, 3.0, 4.0]);
+        let arr = &PrimitiveArray::new(
+            DataType::Float64,
+            buf,
+            Some(Bitmap::from(&[true, false, true, true])),
         );
+
+        let out = rolling_sum(arr, 2, 2, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[None, Some(1.5), Some(2.5), Some(3.5)]);
+        assert_eq!(out, &[None, None, None, Some(7.0)]);
 
-        let out = rolling_quantile(
-            values,
-            0.5,
-            QuantileInterpolOptions::Linear,
-            2,
-            1,
-            false,
-            None,
-        );
+        let out = rolling_sum(arr, 2, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.0), Some(1.5), Some(2.5), Some(3.5)]);
+        assert_eq!(out, &[Some(1.0), Some(1.0), Some(3.0), Some(7.0)]);
 
-        let out = rolling_quantile(
-            values,
-            0.5,
-            QuantileInterpolOptions::Linear,
-            4,
-            1,
-            false,
-            None,
-        );
+        let out = rolling_sum(arr, 4, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.0), Some(1.5), Some(2.0), Some(2.5)]);
+        assert_eq!(out, &[Some(1.0), Some(1.0), Some(4.0), Some(8.0)]);
 
-        let out = rolling_quantile(
-            values,
-            0.5,
-            QuantileInterpolOptions::Linear,
-            4,
-            1,
-            true,
-            None,
+        let out = rolling_sum(arr, 4, 1, true, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[Some(1.0), Some(4.0), Some(8.0), Some(7.0)]);
+
+        let out = rolling_sum(arr, 4, 4, true, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[None, None, None, None]);
+    }
+
+    #[test]
+    fn test_rolling_mean_nulls() {
+        let arr = get_null_arr();
+        let arr = &arr;
+
+        let out = rolling_mean(arr, 2, 2, false, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[None, None, None, Some(1.5)]);
+
+        let out = rolling_mean(arr, 2, 1, false, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[Some(1.0), Some(1.0), Some(-1.0), Some(1.5)]);
+
+        let out = rolling_mean(arr, 4, 1, false, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[Some(1.0), Some(1.0), Some(0.0), Some(4.0 / 3.0)]);
+    }
+
+    #[test]
+    fn test_rolling_var_nulls() {
+        let arr = get_null_arr();
+        let arr = &arr;
+
+        let out = rolling_var(arr, 3, 1, false, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out
+            .into_iter()
+            .map(|v| v.copied().unwrap())
+            .collect::<Vec<_>>();
+
+        assert_eq!(out, &[0.0, 0.0, 2.0, 12.5]);
+
+        let testpars = Some(Arc::new(RollingVarParams { ddof: 0 }) as Arc<dyn Any + Send + Sync>);
+        let out = rolling_var(arr, 3, 1, false, None, testpars.clone());
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out
+            .into_iter()
+            .map(|v| v.copied().unwrap())
+            .collect::<Vec<_>>();
+
+        assert_eq!(out, &[0.0, 0.0, 1.0, 6.25]);
+
+        let out = rolling_var(arr, 4, 1, false, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out
+            .into_iter()
+            .map(|v| v.copied().unwrap())
+            .collect::<Vec<_>>();
+        assert_eq!(out, &[0.0, 0.0, 2.0, 6.333333333333334]);
+
+        let out = rolling_var(arr, 4, 1, false, None, testpars.clone());
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out
+            .into_iter()
+            .map(|v| v.copied().unwrap())
+            .collect::<Vec<_>>();
+        assert_eq!(out, &[0.0, 0.0, 1.0, 4.222222222222222]);
+    }
+
+    #[test]
+    fn test_rolling_max_no_nulls() {
+        let buf = Buffer::from(vec![1.0, 2.0, 3.0, 4.0]);
+        let arr = &PrimitiveArray::new(
+            DataType::Float64,
+            buf,
+            Some(Bitmap::from(&[true, true, true, true])),
         );
+        let out = rolling_max(arr, 4, 1, false, None, None);
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.5), Some(2.0), Some(2.5), Some(3.0)]);
+        assert_eq!(out, &[Some(1.0), Some(2.0), Some(3.0), Some(4.0)]);
 
-        let out = rolling_quantile(
-            values,
-            0.5,
-            QuantileInterpolOptions::Linear,
-            4,
-            4,
-            true,
-            None,
+        let out = rolling_max(arr, 2, 2, false, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[None, Some(2.0), Some(3.0), Some(4.0)]);
+
+        let out = rolling_max(arr, 4, 4, false, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[None, None, None, Some(4.0)]);
+
+        let buf = Buffer::from(vec![4.0, 3.0, 2.0, 1.0]);
+        let arr = &PrimitiveArray::new(
+            DataType::Float64,
+            buf,
+            Some(Bitmap::from(&[true, true, true, true])),
         );
+        let out = rolling_max(arr, 2, 1, false, None, None);
+        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
+        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
+        assert_eq!(out, &[Some(4.0), Some(4.0), Some(3.0), Some(2.0)]);
+
+        let out =
+            super::no_nulls::rolling_max(arr.values().as_slice(), 2, 1, false, None, None).unwrap();
         let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
         let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[None, None, Some(2.5), None]);
+        assert_eq!(out, &[Some(4.0), Some(4.0), Some(3.0), Some(2.0)]);
     }
 
     #[test]
-    fn test_rolling_quantile_limits() {
-        let values = &[1.0f64, 2.0, 3.0, 4.0];
-
-        let interpol_options = vec![
-            QuantileInterpolOptions::Lower,
-            QuantileInterpolOptions::Higher,
-            QuantileInterpolOptions::Nearest,
-            QuantileInterpolOptions::Midpoint,
-            QuantileInterpolOptions::Linear,
-        ];
-
-        for interpol in interpol_options {
-            let out1 = rolling_min(values, 2, 2, false, None, None).unwrap();
-            let out1 = out1.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-            let out1 = out1.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-            let out2 = rolling_quantile(values, 0.0, interpol, 2, 2, false, None);
-            let out2 = out2.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-            let out2 = out2.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-            assert_eq!(out1, out2);
-
-            let out1 = rolling_max(values, 2, 2, false, None, None).unwrap();
-            let out1 = out1.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-            let out1 = out1.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-            let out2 = rolling_quantile(values, 1.0, interpol, 2, 2, false, None);
-            let out2 = out2.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-            let out2 = out2.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-            assert_eq!(out1, out2);
-        }
+    fn test_rolling_extrema_nulls() {
+        let vals = vec![3, 3, 3, 10, 10, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1];
+        let mut validity = MutableBitmap::new();
+        validity.extend_constant(vals.len(), true);
+
+        let window_size = 3;
+        let min_periods = 3;
+
+        let arr = Int32Array::new(DataType::Int32, vals.into(), Some(validity.into()));
+
+        let out = rolling_apply_agg_window::<MaxWindow<_>, _, _>(
+            arr.values().as_slice(),
+            arr.validity().as_ref().unwrap(),
+            window_size,
+            min_periods,
+            det_offsets,
+            None,
+        );
+        let arr = out.as_any().downcast_ref::<Int32Array>().unwrap();
+        assert_eq!(arr.null_count(), 2);
+        assert_eq!(
+            &arr.values().as_slice()[2..],
+            &[3, 10, 10, 10, 10, 10, 9, 8, 7, 6, 5, 4, 3]
+        );
     }
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/sum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/no_nulls/variance.rs`

 * *Files 9% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 use no_nulls::{rolling_apply_agg_window, RollingAggWindowNoNulls};
+use polars_error::polars_ensure;
 
 use super::mean::MeanWindow;
 use super::*;
 
 pub(super) struct SumSquaredWindow<'a, T> {
     slice: &'a [T],
     sum_of_squares: T,
@@ -150,49 +151,43 @@
         + SubAssign
         + Div<Output = T>
         + NumCast
         + One
         + Zero
         + Sub<Output = T>,
 {
-    match (center, weights) {
-        (true, None) => rolling_apply_agg_window::<VarWindow<_>, _, _>(
+    let offset_fn = match center {
+        true => det_offsets_center,
+        false => det_offsets,
+    };
+    match weights {
+        None => rolling_apply_agg_window::<VarWindow<_>, _, _>(
             values,
             window_size,
             min_periods,
-            det_offsets_center,
+            offset_fn,
             params,
         ),
-        (false, None) => rolling_apply_agg_window::<VarWindow<_>, _, _>(
-            values,
-            window_size,
-            min_periods,
-            det_offsets,
-            params,
-        ),
-        (true, Some(weights)) => {
-            let weights = coerce_weights(weights);
-            super::rolling_apply_weights(
-                values,
-                window_size,
-                min_periods,
-                det_offsets_center,
-                compute_var_weights,
-                &weights,
-            )
-        }
-        (false, Some(weights)) => {
-            let weights = coerce_weights(weights);
+        Some(weights) => {
+            // Validate and standardize the weights like we do for the mean. This definition is fine
+            // because frequency weights and unbiasing don't make sense for rolling operations.
+            let mut wts = no_nulls::coerce_weights(weights);
+            let wsum = wts.iter().fold(T::zero(), |acc, x| acc + *x);
+            polars_ensure!(
+                wsum != T::zero(),
+                ComputeError: "Weighted variance is undefined if weights sum to 0"
+            );
+            wts.iter_mut().for_each(|w| *w = *w / wsum);
             super::rolling_apply_weights(
                 values,
                 window_size,
                 min_periods,
-                det_offsets,
+                offset_fn,
                 compute_var_weights,
-                &weights,
+                &wts,
             )
         }
     }
 }
 
 #[cfg(test)]
 mod test {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/functions.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,276 +1,337 @@
-mod mean;
-mod min_max;
-mod quantile;
-mod sum;
-mod variance;
-
-pub use mean::*;
-pub use min_max::*;
-pub use quantile::*;
-pub use sum::*;
-pub use variance::*;
-
-use super::*;
-
-pub trait RollingAggWindowNulls<'a, T: NativeType> {
-    /// # Safety
-    /// `start` and `end` must be in bounds for `slice` and `validity`
-    unsafe fn new(
-        slice: &'a [T],
-        validity: &'a Bitmap,
-        start: usize,
-        end: usize,
-        params: DynArgs,
-    ) -> Self;
-
-    /// # Safety
-    /// `start` and `end` must be in bounds of `slice` and `bitmap`
-    unsafe fn update(&mut self, start: usize, end: usize) -> Option<T>;
+//! # Functions
+//!
+//! Functions that might be useful.
+//!
+use std::ops::Add;
+
+#[cfg(feature = "diagonal_concat")]
+use ahash::AHashSet;
+use arrow::compute;
+use arrow::types::simd::Simd;
+use num_traits::{Float, NumCast, ToPrimitive};
+#[cfg(feature = "concat_str")]
+use polars_arrow::prelude::ValueSize;
+
+use crate::prelude::*;
+use crate::utils::coalesce_nulls;
+#[cfg(feature = "diagonal_concat")]
+use crate::utils::concat_df;
 
-    fn is_valid(&self, min_periods: usize) -> bool;
+/// Compute the covariance between two columns.
+pub fn cov_f<T>(a: &ChunkedArray<T>, b: &ChunkedArray<T>) -> Option<T::Native>
+where
+    T: PolarsFloatType,
+    T::Native: Float,
+    <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
+        + compute::aggregate::Sum<T::Native>
+        + compute::aggregate::SimdOrd<T::Native>,
+{
+    if a.len() != b.len() {
+        None
+    } else {
+        let tmp = (a - a.mean()?) * (b - b.mean()?);
+        let n = tmp.len() - tmp.null_count();
+        Some(tmp.sum()? / NumCast::from(n - 1).unwrap())
+    }
+}
+
+/// Compute the covariance between two columns.
+pub fn cov_i<T>(a: &ChunkedArray<T>, b: &ChunkedArray<T>) -> Option<f64>
+where
+    T: PolarsIntegerType,
+    T::Native: ToPrimitive,
+    <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
+        + compute::aggregate::Sum<T::Native>
+        + compute::aggregate::SimdOrd<T::Native>,
+{
+    if a.len() != b.len() {
+        None
+    } else {
+        let a_mean = a.mean()?;
+        let b_mean = b.mean()?;
+        let a = a.apply_cast_numeric::<_, Float64Type>(|a| a.to_f64().unwrap() - a_mean);
+        let b = b.apply_cast_numeric(|b| b.to_f64().unwrap() - b_mean);
+
+        let tmp = a * b;
+        let n = tmp.len() - tmp.null_count();
+        Some(tmp.sum()? / (n - 1) as f64)
+    }
 }
 
-// Use an aggregation window that maintains the state
-pub(super) fn rolling_apply_agg_window<'a, Agg, T, Fo>(
-    values: &'a [T],
-    validity: &'a Bitmap,
-    window_size: usize,
-    min_periods: usize,
-    det_offsets_fn: Fo,
-    params: DynArgs,
-) -> ArrayRef
+/// Compute the pearson correlation between two columns.
+pub fn pearson_corr_i<T>(a: &ChunkedArray<T>, b: &ChunkedArray<T>, ddof: u8) -> Option<f64>
 where
-    Fo: Fn(Idx, WindowSize, Len) -> (Start, End) + Copy,
-    Agg: RollingAggWindowNulls<'a, T>,
-    T: IsFloat + NativeType,
+    T: PolarsIntegerType,
+    T::Native: ToPrimitive,
+    <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
+        + compute::aggregate::Sum<T::Native>
+        + compute::aggregate::SimdOrd<T::Native>,
+    ChunkedArray<T>: ChunkVar<f64>,
 {
-    let len = values.len();
-    let (start, end) = det_offsets_fn(0, window_size, len);
-    // Safety; we are in bounds
-    let mut agg_window = unsafe { Agg::new(values, validity, start, end, params) };
-
-    let mut validity = match create_validity(min_periods, len, window_size, det_offsets_fn) {
-        Some(v) => v,
-        None => {
-            let mut validity = MutableBitmap::with_capacity(len);
-            validity.extend_constant(len, true);
-            validity
+    let (a, b) = coalesce_nulls(a, b);
+    let a = a.as_ref();
+    let b = b.as_ref();
+
+    Some(cov_i(a, b)? / (a.std(ddof)? * b.std(ddof)?))
+}
+
+/// Compute the pearson correlation between two columns.
+pub fn pearson_corr_f<T>(a: &ChunkedArray<T>, b: &ChunkedArray<T>, ddof: u8) -> Option<T::Native>
+where
+    T: PolarsFloatType,
+    T::Native: Float,
+    <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
+        + compute::aggregate::Sum<T::Native>
+        + compute::aggregate::SimdOrd<T::Native>,
+    ChunkedArray<T>: ChunkVar<T::Native>,
+{
+    let (a, b) = coalesce_nulls(a, b);
+    let a = a.as_ref();
+    let b = b.as_ref();
+
+    Some(cov_f(a, b)? / (a.std(ddof)? * b.std(ddof)?))
+}
+
+// utility to be able to also add literals to concat_str function
+#[cfg(feature = "concat_str")]
+enum IterBroadCast<'a> {
+    Column(Box<dyn PolarsIterator<Item = Option<&'a str>> + 'a>),
+    Value(Option<&'a str>),
+}
+
+#[cfg(feature = "concat_str")]
+impl<'a> IterBroadCast<'a> {
+    fn next(&mut self) -> Option<Option<&'a str>> {
+        use IterBroadCast::*;
+        match self {
+            Column(iter) => iter.next(),
+            Value(val) => Some(*val),
         }
-    };
+    }
+}
 
-    let out = (0..len)
-        .map(|idx| {
-            let (start, end) = det_offsets_fn(idx, window_size, len);
-            // safety:
-            // we are in bounds
-            let agg = unsafe { agg_window.update(start, end) };
-            match agg {
-                Some(val) => {
-                    if agg_window.is_valid(min_periods) {
-                        val
-                    } else {
-                        // safety: we are in bounds
-                        unsafe { validity.set_unchecked(idx, false) };
-                        T::default()
-                    }
-                }
-                None => {
-                    // safety: we are in bounds
-                    unsafe { validity.set_unchecked(idx, false) };
-                    T::default()
-                }
+/// Casts all series to string data and will concat them in linear time.
+/// The concatenated strings are separated by a `delimiter`.
+/// If no `delimiter` is needed, an empty &str should be passed as argument.
+#[cfg(feature = "concat_str")]
+pub fn concat_str(s: &[Series], delimiter: &str) -> PolarsResult<Utf8Chunked> {
+    polars_ensure!(!s.is_empty(), NoData: "expected multiple series in `concat_str`");
+    if s.iter().any(|s| s.is_empty()) {
+        return Ok(Utf8Chunked::full_null(s[0].name(), 0));
+    }
+
+    let len = s.iter().map(|s| s.len()).max().unwrap();
+
+    let cas = s
+        .iter()
+        .map(|s| {
+            let s = s.cast(&DataType::Utf8)?;
+            let mut ca = s.utf8()?.clone();
+            // broadcast
+            if ca.len() == 1 && len > 1 {
+                ca = ca.new_from_index(0, len)
             }
+
+            Ok(ca)
         })
-        .collect_trusted::<Vec<_>>();
+        .collect::<PolarsResult<Vec<_>>>()?;
 
-    Box::new(PrimitiveArray::new(
-        T::PRIMITIVE.into(),
-        out.into(),
-        Some(validity.into()),
-    ))
-}
+    polars_ensure!(
+        s.iter().all(|s| s.len() == 1 || s.len() == len),
+        ComputeError: "all series in `concat_str` should have equal or unit length"
+    );
+    let mut iters = cas
+        .iter()
+        .map(|ca| match ca.len() {
+            1 => IterBroadCast::Value(ca.get(0)),
+            _ => IterBroadCast::Column(ca.into_iter()),
+        })
+        .collect::<Vec<_>>();
 
-#[cfg(test)]
-mod test {
-    use arrow::array::{Array, Int32Array};
-    use arrow::buffer::Buffer;
-    use arrow::datatypes::DataType;
+    let bytes_cap = cas.iter().map(|ca| ca.get_values_size()).sum();
+    let mut builder = Utf8ChunkedBuilder::new(s[0].name(), len, bytes_cap);
 
-    use super::*;
-    use crate::kernels::rolling::nulls::mean::rolling_mean;
+    // use a string buffer, to amortize alloc
+    let mut buf = String::with_capacity(128);
 
-    fn get_null_arr() -> PrimitiveArray<f64> {
-        // 1, None, -1, 4
-        let buf = Buffer::from(vec![1.0, 0.0, -1.0, 4.0]);
-        PrimitiveArray::new(
-            DataType::Float64,
-            buf,
-            Some(Bitmap::from(&[true, false, true, true])),
-        )
-    }
+    for _ in 0..len {
+        let mut has_null = false;
 
-    #[test]
-    fn test_rolling_sum_nulls() {
-        let buf = Buffer::from(vec![1.0, 2.0, 3.0, 4.0]);
-        let arr = &PrimitiveArray::new(
-            DataType::Float64,
-            buf,
-            Some(Bitmap::from(&[true, false, true, true])),
-        );
+        iters.iter_mut().enumerate().for_each(|(i, it)| {
+            if i > 0 {
+                buf.push_str(delimiter);
+            }
 
-        let out = rolling_sum(arr, 2, 2, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[None, None, None, Some(7.0)]);
-
-        let out = rolling_sum(arr, 2, 1, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.0), Some(1.0), Some(3.0), Some(7.0)]);
-
-        let out = rolling_sum(arr, 4, 1, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.0), Some(1.0), Some(4.0), Some(8.0)]);
-
-        let out = rolling_sum(arr, 4, 1, true, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.0), Some(4.0), Some(8.0), Some(7.0)]);
-
-        let out = rolling_sum(arr, 4, 4, true, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[None, None, None, None]);
-    }
+            match it.next() {
+                Some(Some(s)) => buf.push_str(s),
+                Some(None) => has_null = true,
+                None => {
+                    // should not happen as the out loop counts to length
+                    unreachable!()
+                }
+            }
+        });
 
-    #[test]
-    fn test_rolling_mean_nulls() {
-        let arr = get_null_arr();
-        let arr = &arr;
-
-        let out = rolling_mean(arr, 2, 2, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[None, None, None, Some(1.5)]);
-
-        let out = rolling_mean(arr, 2, 1, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.0), Some(1.0), Some(-1.0), Some(1.5)]);
-
-        let out = rolling_mean(arr, 4, 1, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.0), Some(1.0), Some(0.0), Some(4.0 / 3.0)]);
+        if has_null {
+            builder.append_null();
+        } else {
+            builder.append_value(&buf)
+        }
+        buf.truncate(0)
     }
+    Ok(builder.finish())
+}
 
-    #[test]
-    fn test_rolling_var_nulls() {
-        let arr = get_null_arr();
-        let arr = &arr;
-
-        let out = rolling_var(arr, 3, 1, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out
-            .into_iter()
-            .map(|v| v.copied().unwrap())
+/// Concat `[DataFrame]`s horizontally.
+#[cfg(feature = "horizontal_concat")]
+/// Concat horizontally and extend with null values if lengths don't match
+pub fn hor_concat_df(dfs: &[DataFrame]) -> PolarsResult<DataFrame> {
+    let max_len = dfs
+        .iter()
+        .map(|df| df.height())
+        .max()
+        .ok_or_else(|| polars_err!(ComputeError: "cannot concat empty dataframes"))?;
+
+    let owned_df;
+
+    // if not all equal length, extend the DataFrame with nulls
+    let dfs = if !dfs.iter().all(|df| df.height() == max_len) {
+        owned_df = dfs
+            .iter()
+            .cloned()
+            .map(|mut df| {
+                if df.height() != max_len {
+                    let diff = max_len - df.height();
+                    df.columns
+                        .iter_mut()
+                        .for_each(|s| *s = s.extend_constant(AnyValue::Null, diff).unwrap());
+                }
+                df
+            })
             .collect::<Vec<_>>();
+        owned_df.as_slice()
+    } else {
+        dfs
+    };
 
-        assert_eq!(out, &[0.0, 0.0, 2.0, 12.5]);
+    let mut first_df = dfs[0].clone();
 
-        let testpars = Some(Arc::new(RollingVarParams { ddof: 0 }) as Arc<dyn Any + Send + Sync>);
-        let out = rolling_var(arr, 3, 1, false, None, testpars.clone());
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out
-            .into_iter()
-            .map(|v| v.copied().unwrap())
-            .collect::<Vec<_>>();
+    for df in &dfs[1..] {
+        first_df.hstack_mut(df.get_columns())?;
+    }
+    Ok(first_df)
+}
 
-        assert_eq!(out, &[0.0, 0.0, 1.0, 6.25]);
+/// Concat `[DataFrame]`s diagonally.
+#[cfg(feature = "diagonal_concat")]
+/// Concat diagonally thereby combining different schemas.
+pub fn diag_concat_df(dfs: &[DataFrame]) -> PolarsResult<DataFrame> {
+    // TODO! replace with lazy only?
+    let upper_bound_width = dfs.iter().map(|df| df.width()).sum();
+    let mut column_names = AHashSet::with_capacity(upper_bound_width);
+    let mut schema = Vec::with_capacity(upper_bound_width);
+
+    for df in dfs {
+        df.get_columns().iter().for_each(|s| {
+            let name = s.name();
+            if column_names.insert(name) {
+                schema.push((name, s.dtype()))
+            }
+        });
+    }
 
-        let out = rolling_var(arr, 4, 1, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out
-            .into_iter()
-            .map(|v| v.copied().unwrap())
-            .collect::<Vec<_>>();
-        assert_eq!(out, &[0.0, 0.0, 2.0, 6.333333333333334]);
+    let dfs = dfs
+        .iter()
+        .map(|df| {
+            let height = df.height();
+            let mut columns = Vec::with_capacity(schema.len());
+
+            for (name, dtype) in &schema {
+                match df.column(name).ok() {
+                    Some(s) => columns.push(s.clone()),
+                    None => columns.push(Series::full_null(name, height, dtype)),
+                }
+            }
+            DataFrame::new_no_checks(columns)
+        })
+        .collect::<Vec<_>>();
 
-        let out = rolling_var(arr, 4, 1, false, None, testpars.clone());
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out
-            .into_iter()
-            .map(|v| v.copied().unwrap())
-            .collect::<Vec<_>>();
-        assert_eq!(out, &[0.0, 0.0, 1.0, 4.222222222222222]);
+    concat_df(&dfs)
+}
+
+#[cfg(test)]
+mod test {
+    use super::*;
+
+    #[test]
+    fn test_cov() {
+        let a = Series::new("a", &[1.0f32, 2.0, 5.0]);
+        let b = Series::new("b", &[1.0f32, 2.0, -3.0]);
+        let out = cov_f(a.f32().unwrap(), b.f32().unwrap());
+        assert_eq!(out, Some(-5.0));
+        let a = a.cast(&DataType::Int32).unwrap();
+        let b = b.cast(&DataType::Int32).unwrap();
+        let out = cov_i(a.i32().unwrap(), b.i32().unwrap());
+        assert_eq!(out, Some(-5.0));
     }
 
     #[test]
-    fn test_rolling_max_no_nulls() {
-        let buf = Buffer::from(vec![1.0, 2.0, 3.0, 4.0]);
-        let arr = &PrimitiveArray::new(
-            DataType::Float64,
-            buf,
-            Some(Bitmap::from(&[true, true, true, true])),
+    fn test_pearson_corr() {
+        let a = Series::new("a", &[1.0f32, 2.0]);
+        let b = Series::new("b", &[1.0f32, 2.0]);
+        assert!((cov_f(a.f32().unwrap(), b.f32().unwrap()).unwrap() - 0.5).abs() < 0.001);
+        assert!(
+            (pearson_corr_f(a.f32().unwrap(), b.f32().unwrap(), 1).unwrap() - 1.0).abs() < 0.001
         );
-        let out = rolling_max(arr, 4, 1, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(1.0), Some(2.0), Some(3.0), Some(4.0)]);
-
-        let out = rolling_max(arr, 2, 2, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[None, Some(2.0), Some(3.0), Some(4.0)]);
-
-        let out = rolling_max(arr, 4, 4, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[None, None, None, Some(4.0)]);
-
-        let buf = Buffer::from(vec![4.0, 3.0, 2.0, 1.0]);
-        let arr = &PrimitiveArray::new(
-            DataType::Float64,
-            buf,
-            Some(Bitmap::from(&[true, true, true, true])),
-        );
-        let out = rolling_max(arr, 2, 1, false, None, None);
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(4.0), Some(4.0), Some(3.0), Some(2.0)]);
-
-        let out =
-            super::no_nulls::rolling_max(arr.values().as_slice(), 2, 1, false, None, None).unwrap();
-        let out = out.as_any().downcast_ref::<PrimitiveArray<f64>>().unwrap();
-        let out = out.into_iter().map(|v| v.copied()).collect::<Vec<_>>();
-        assert_eq!(out, &[Some(4.0), Some(4.0), Some(3.0), Some(2.0)]);
     }
 
     #[test]
-    fn test_rolling_extrema_nulls() {
-        let vals = vec![3, 3, 3, 10, 10, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1];
-        let mut validity = MutableBitmap::new();
-        validity.extend_constant(vals.len(), true);
-
-        let window_size = 3;
-        let min_periods = 3;
-
-        let arr = Int32Array::new(DataType::Int32, vals.into(), Some(validity.into()));
-
-        let out = rolling_apply_agg_window::<MaxWindow<_>, _, _>(
-            arr.values().as_slice(),
-            arr.validity().as_ref().unwrap(),
-            window_size,
-            min_periods,
-            det_offsets,
-            None,
-        );
-        let arr = out.as_any().downcast_ref::<Int32Array>().unwrap();
-        assert_eq!(arr.null_count(), 2);
+    #[cfg(feature = "concat_str")]
+    fn test_concat_str() {
+        let a = Series::new("a", &["foo", "bar"]);
+        let b = Series::new("b", &["spam", "ham"]);
+
+        let out = concat_str(&[a.clone(), b.clone()], "_").unwrap();
+        assert_eq!(Vec::from(&out), &[Some("foo_spam"), Some("bar_ham")]);
+
+        let c = Series::new("b", &["literal"]);
+        let out = concat_str(&[a, b, c], "_").unwrap();
         assert_eq!(
-            &arr.values().as_slice()[2..],
-            &[3, 10, 10, 10, 10, 10, 9, 8, 7, 6, 5, 4, 3]
+            Vec::from(&out),
+            &[Some("foo_spam_literal"), Some("bar_ham_literal")]
         );
     }
+
+    #[test]
+    #[cfg(feature = "diagonal_concat")]
+    fn test_diag_concat() -> PolarsResult<()> {
+        let a = df![
+            "a" => [1, 2],
+            "b" => ["a", "b"]
+        ]?;
+
+        let b = df![
+            "b" => ["a", "b"],
+            "c" => [1, 2]
+        ]?;
+
+        let c = df![
+            "a" => [5, 7],
+            "c" => [1, 2],
+            "d" => [1, 2]
+        ]?;
+
+        let out = diag_concat_df(&[a, b, c])?;
+
+        let expected = df![
+            "a" => [Some(1), Some(2), None, None, Some(5), Some(7)],
+            "b" => [Some("a"), Some("b"), Some("a"), Some("b"), None, None],
+            "c" => [None, None, Some(1), Some(2), Some(1), Some(2)],
+            "d" => [None, None, None, None, Some(1), Some(2)]
+        ]?;
+
+        assert!(out.frame_equal_missing(&expected));
+
+        Ok(())
+    }
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/quantile.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/sum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/nulls/variance.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/rolling/window.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/rolling/window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/set.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/sort_partition.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/sort_partition.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/sorted_join/inner.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/sorted_join/left.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/string.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/take_agg/boolean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/take_agg/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/take_agg/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/take_agg/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/take_agg/var.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/take_agg/var.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/kernels/time.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/kernels/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/slice.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/trusted_len/boolean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/trusted_len/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/trusted_len/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/trusted_len/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/trusted_len/push_unchecked.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-arrow/src/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-arrow/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -43,15 +43,15 @@
 # extra utilities for Utf8Chunked
 strings = ["polars-core/strings", "polars-lazy/strings", "polars-ops/strings"]
 
 # support for ObjectChunked<T> (downcastable Series of any type)
 object = ["polars-core/object", "polars-lazy/object", "polars-io/object"]
 
 # support for arrows json parsing
-json = ["polars-io", "polars-io/json", "polars-lazy/json", "polars-sql/json"]
+json = ["polars-io", "polars-io/json", "polars-lazy/json", "polars-sql/json", "dtype-struct"]
 
 # support for arrows ipc file parsing
 ipc = ["polars-io", "polars-io/ipc", "polars-lazy/ipc", "polars-sql/ipc"]
 
 # support for arrows streaming ipc file parsing
 ipc_streaming = ["polars-io", "polars-io/ipc_streaming", "polars-lazy/ipc"]
 
@@ -114,15 +114,15 @@
 cum_agg = ["polars-core/cum_agg", "polars-core/cum_agg"]
 rolling_window = ["polars-core/rolling_window", "polars-lazy/rolling_window", "polars-time/rolling_window"]
 interpolate = ["polars-ops/interpolate", "polars-lazy/interpolate"]
 rank = ["polars-core/rank", "polars-lazy/rank"]
 diff = ["polars-core/diff", "polars-lazy/diff", "polars-ops/diff"]
 pct_change = ["polars-core/pct_change", "polars-lazy/pct_change"]
 moment = ["polars-core/moment", "polars-lazy/moment", "polars-ops/moment"]
-arange = ["polars-lazy/arange"]
+range = ["polars-lazy/range"]
 true_div = ["polars-lazy/true_div"]
 diagonal_concat = ["polars-core/diagonal_concat", "polars-lazy/diagonal_concat"]
 horizontal_concat = ["polars-core/horizontal_concat"]
 abs = ["polars-core/abs", "polars-lazy/abs"]
 dynamic_groupby = ["polars-core/dynamic_groupby", "polars-lazy/dynamic_groupby"]
 ewma = ["polars-core/ewma", "polars-lazy/ewma"]
 dot_diagram = ["polars-lazy/dot_diagram"]
@@ -155,14 +155,17 @@
 top_k = ["polars-lazy/top_k"]
 algo = ["polars-algo"]
 cse = ["polars-lazy/cse"]
 propagate_nans = ["polars-lazy/propagate_nans"]
 coalesce = ["polars-lazy/coalesce"]
 streaming = ["polars-lazy/streaming"]
 fused = ["polars-ops/fused", "polars-lazy/fused"]
+list_sets = ["polars-lazy/list_sets"]
+list_any_all = ["polars-lazy/list_any_all"]
+cutqcut = ["polars-lazy/cutqcut"]
 
 test = [
   "lazy",
   "rolling_window",
   "rank",
   "round_series",
   "csv",
@@ -282,15 +285,15 @@
   "mode",
   "take_opt_iter",
   "cum_agg",
   "rolling_window",
   "interpolate",
   "diff",
   "rank",
-  "arange",
+  "range",
   "diagonal_concat",
   "horizontal_concat",
   "abs",
   "dot_diagram",
   "string_encoding",
   "product",
   "to_dummies",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/Makefile` & `polars_lts_cpu-0.18.5/local_dependencies/polars/Makefile`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/src/docs/eager.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/src/docs/eager.rs`

 * *Files 0% similar despite different names*

```diff
@@ -388,15 +388,15 @@
 //!
 //! // join on a single column
 //! temp.left_join(&rain, ["days"], ["days"]);
 //! temp.inner_join(&rain, ["days"], ["days"]);
 //! temp.outer_join(&rain, ["days"], ["days"]);
 //!
 //! // join on multiple columns
-//! temp.join(&rain, vec!["days", "other"], vec!["days", "other"], JoinType::Left, None);
+//! temp.join(&rain, vec!["days", "other"], vec!["days", "other"], JoinArgs::new(JoinType::Left));
 //!
 //! # Ok(())
 //! # }
 //! ```
 //!
 //! ## Groupby
 //!
@@ -431,17 +431,15 @@
 //! # fn example(df: &DataFrame) -> PolarsResult<()> {
 //!  let df = df!("foo" => ["A", "A", "B", "B", "C"],
 //!      "N" => [1, 2, 2, 4, 2],
 //!      "bar" => ["k", "l", "m", "n", "0"]
 //!      )?;
 //!
 //! // groupby "foo" | pivot "bar" column | aggregate "N"
-//!  let pivoted = df.groupby(["foo"])?
-//!     .pivot(["bar"], ["N"])
-//!     .first();
+//!  let pivoted = pivot::pivot(&df, ["foo"], ["bar"], ["N"], false, Some(first()), None);
 //!
 //! // pivoted:
 //! // +-----+------+------+------+------+------+
 //! // | foo | o    | n    | m    | l    | k    |
 //! // | --- | ---  | ---  | ---  | ---  | ---  |
 //! // | str | i32  | i32  | i32  | i32  | i32  |
 //! // +=====+======+======+======+======+======+
@@ -627,15 +625,15 @@
 //! ```
 //!
 //! ### Write Parquet
 //! ```
 //! use polars::prelude::*;
 //! use std::fs::File;
 //!
-//! # fn example(df: &mut DataFrame) -> PolarsResult<()> {
+//! # fn example(df: &mut DataFrame) -> PolarsResult<u64> {
 //! // create a file
 //! let file = File::create("example.parquet").expect("could not create file");
 //!
 //! ParquetWriter::new(file)
 //!     .finish(df)
 //! # }
 //! ```
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/src/docs/lazy.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/src/docs/lazy.rs`

 * *Files 1% similar despite different names*

```diff
@@ -141,15 +141,15 @@
 //!     "bar" => ["a", "c", "c"],
 //!     "ham" => ["let", "var", "const"]
 //! ]?;
 //!
 //! let lf_a = df_a.clone().lazy();
 //! let lf_b = df_b.clone().lazy();
 //!
-//! let joined = lf_a.join(lf_b, vec![col("a")], vec![col("foo")], JoinType::Outer).collect()?;
+//! let joined = lf_a.join(lf_b, vec![col("a")], vec![col("foo")], JoinArgs::new(JoinType::Outer)).collect()?;
 //! // joined:
 //!
 //! // 
 //! //  b    c    a    bar   ham     
 //! //  ---  ---  ---  ---   ---     
 //! //  str  i64  i64  str   str     
 //! // 
@@ -237,15 +237,15 @@
 //!
 //! # Black box function
 //!
 //! The expression API should be expressive enough for most of what you want to achieve, but it can happen
 //! that you need to pass the values to an external function you do not control. The snippet below
 //! shows how we use the `Struct` datatype to be able to apply a function over multiple inputs.
 //!
-//! ```
+//! ```ignore
 //! use polars::prelude::*;
 //! fn my_black_box_function(a: f32, b: f32) -> f32 {
 //!     // do something
 //!     a
 //! }
 //!
 //! fn apply_multiples(lf: LazyFrame) -> PolarsResult<DataFrame> {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/src/docs/performance.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/src/docs/performance.rs`

 * *Files 0% similar despite different names*

```diff
@@ -60,15 +60,15 @@
 //!
 //! fn example(mut df_a: DataFrame, mut df_b: DataFrame) -> PolarsResult<DataFrame> {
 //!     // Set a global string cache
 //!     enable_string_cache(true);
 //!
 //!     df_a.try_apply("a", |s| s.categorical().cloned())?;
 //!     df_b.try_apply("b", |s| s.categorical().cloned())?;
-//!     df_a.join(&df_b, ["a"], ["b"], JoinType::Inner, None)
+//!     df_a.join(&df_b, ["a"], ["b"], JoinArgs::new(JoinType::Inner))
 //! }
 //! ```
 //!
 //! ### Example: Lazy join multiple DataFrames on a Categorical
 //! A lazy Query always has a global string cache (unless you opt-out) for the duration of that query (until `collect` is called).
 //! The example below shows how you could join two DataFrames with Categorical types.
 //!
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/src/lib.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/src/lib.rs`

 * *Files 6% similar despite different names*

```diff
@@ -14,28 +14,28 @@
 //! # fn example() -> PolarsResult<()> {
 //!
 //! let lf1 = LazyFrame::scan_parquet("myfile_1.parquet", Default::default())?
 //!     .groupby([col("ham")])
 //!     .agg([
 //!         // expressions can be combined into powerful aggregations
 //!         col("foo")
-//!             .sort_by([col("ham").rank(Default::default())], [false])
+//!             .sort_by([col("ham").rank(Default::default(), None)], [false])
 //!             .last()
 //!             .alias("last_foo_ranked_by_ham"),
 //!         // every expression runs in parallel
 //!         col("foo").cummin(false).alias("cumulative_min_per_group"),
 //!         // every expression runs in parallel
 //!         col("foo").reverse().implode().alias("reverse_group"),
 //!     ]);
 //!
 //! let lf2 = LazyFrame::scan_parquet("myfile_2.parquet", Default::default())?
 //!     .select([col("ham"), col("spam")]);
 //!
 //! let df = lf1
-//!     .join(lf2, [col("reverse")], [col("foo")], JoinType::Left)
+//!     .join(lf2, [col("reverse")], [col("foo")], JoinArgs::new(JoinType::Left))
 //!     // now we finally materialize the result.
 //!     .collect()?;
 //! # Ok(())
 //! # }
 //! ```
 //!
 //! This means that Polars data structures can be shared zero copy with processes in many different
@@ -243,14 +243,15 @@
 //!     - `diff` - `diff` operation.
 //!     - `pct_change` - Compute change percentages.
 //!     - `unique_counts` - Count unique values in expressions.
 //!     - `log` - Logarithms for `Series`.
 //!     - `list_to_struct` - Convert `List` to `Struct` dtypes.
 //!     - `list_count` - Count elements in lists.
 //!     - `list_eval` - Apply expressions over list elements.
+//!     - `list_sets` - Compute UNION, INTERSECTION, and DIFFERENCE on list types.
 //!     - `cumulative_eval` - Apply expressions over cumulatively increasing windows.
 //!     - `arg_where` - Get indices where condition holds.
 //!     - `search_sorted` - Find indices where elements should be inserted to maintain order.
 //!     - `date_offset` Add an offset to dates that take months and leap years into account.
 //!     - `trigonometry` Trigonometric functions.
 //!     - `sign` Compute the element-wise sign of a Series.
 //!     - `propagate_nans` NaN propagating min/max aggregations.
@@ -321,36 +322,32 @@
 //! ```toml
 //! [dependencies]
 //! mimalloc = { version = "*", default-features = false }
 //! ```
 //!
 //! ## Config with ENV vars
 //!
-//! * `POLARS_FMT_TABLE_FORMATTING` -> define styling of tables using any of the following options (default = UTF8_FULL_CONDENSED):
-//!
-//!                                    ASCII_FULL
-//!                                    ASCII_FULL_CONDENSED
-//!                                    ASCII_NO_BORDERS
-//!                                    ASCII_BORDERS_ONLY
-//!                                    ASCII_BORDERS_ONLY_CONDENSED
-//!                                    ASCII_HORIZONTAL_ONLY
-//!                                    ASCII_MARKDOWN
-//!                                    UTF8_FULL
-//!                                    UTF8_FULL_CONDENSED
-//!                                    UTF8_NO_BORDERS
-//!                                    UTF8_BORDERS_ONLY
-//!                                    UTF8_HORIZONTAL_ONLY
-//!                                    NOTHING
-//!
-//!                                    These options are defined by comfy-table which provides examples for each at:
-//!                                    https://github.com/Nukesor/comfy-table/blob/main/src/style/presets.rs
+//! * `POLARS_FMT_TABLE_FORMATTING` -> define styling of tables using any of the following options (default = UTF8_FULL_CONDENSED). These options are defined by comfy-table which provides examples for each at <https://github.com/Nukesor/comfy-table/blob/main/src/style/presets.rs>
+//!   * `ASCII_FULL`
+//!   * `ASCII_FULL_CONDENSED`
+//!   * `ASCII_NO_BORDERS`
+//!   * `ASCII_BORDERS_ONLY`
+//!   * `ASCII_BORDERS_ONLY_CONDENSED`
+//!   * `ASCII_HORIZONTAL_ONLY`
+//!   * `ASCII_MARKDOWN`
+//!   * `UTF8_FULL`
+//!   * `UTF8_FULL_CONDENSED`
+//!   * `UTF8_NO_BORDERS`
+//!   * `UTF8_BORDERS_ONLY`
+//!   * `UTF8_HORIZONTAL_ONLY`
+//!   * `NOTHING`
 //! * `POLARS_FMT_TABLE_CELL_ALIGNMENT` -> define cell alignment using any of the following options (default = LEFT):
-//!                                    LEFT
-//!                                    CENTER
-//!                                    RIGHT
+//!   * `LEFT`
+//!   * `CENTER`
+//!   * `RIGHT`
 //! * `POLARS_FMT_TABLE_DATAFRAME_SHAPE_BELOW` -> print shape information below the table.
 //! * `POLARS_FMT_TABLE_HIDE_COLUMN_NAMES` -> hide table column names.
 //! * `POLARS_FMT_TABLE_HIDE_COLUMN_DATA_TYPES` -> hide data types for columns.
 //! * `POLARS_FMT_TABLE_HIDE_COLUMN_SEPARATOR` -> hide separator that separates column names from rows.
 //! * `POLARS_FMT_TABLE_HIDE_DATAFRAME_SHAPE_INFORMATION"` -> omit table shape information.
 //! * `POLARS_FMT_TABLE_INLINE_COLUMN_DATA_TYPE` -> put column data type on the same line as the column name.
 //! * `POLARS_FMT_TABLE_ROUNDED_CORNERS` -> apply rounded corners to UTF8-styled tables.
@@ -390,7 +387,10 @@
 pub use polars_core::{enable_string_cache, using_string_cache};
 #[cfg(feature = "polars-io")]
 pub use polars_io as io;
 #[cfg(feature = "lazy")]
 pub use polars_lazy as lazy;
 #[cfg(feature = "temporal")]
 pub use polars_time as time;
+
+/// Polars crate version
+pub const VERSION: &str = env!("CARGO_PKG_VERSION");
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/date_like.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/date_like.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/groupby.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/joins.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/joins.rs`

 * *Files 0% similar despite different names*

```diff
@@ -252,15 +252,15 @@
         .series_equal_missing(joined_outer.column("ham").unwrap()));
 }
 
 #[test]
 #[cfg_attr(miri, ignore)]
 #[cfg(feature = "dtype-categorical")]
 fn test_join_categorical() {
-    let _lock = IUseStringCache::new();
+    let _lock = IUseStringCache::hold();
     let _lock = polars_core::SINGLE_LOCK.lock();
 
     let (mut df_a, mut df_b) = get_dfs();
 
     df_a.try_apply("b", |s| s.cast(&DataType::Categorical(None)))
         .unwrap();
     df_b.try_apply("bar", |s| s.cast(&DataType::Categorical(None)))
@@ -294,15 +294,15 @@
     let (mut df_a, mut df_b) = get_dfs();
     df_a.try_apply("b", |s| s.cast(&DataType::Categorical(None)))
         .unwrap();
     // create a new cache
     reset_string_cache();
 
     // _sc is needed to ensure we hold the string cache.
-    let _sc = IUseStringCache::new();
+    let _sc = IUseStringCache::hold();
 
     df_b.try_apply("bar", |s| s.cast(&DataType::Categorical(None)))
         .unwrap();
     let out = df_a.join(&df_b, ["b"], ["bar"], JoinType::Left.into());
     assert!(out.is_err());
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/pivot.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/pivot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/random.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/rolling_window.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/rolling_window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/core/series.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/core/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/csv.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/ipc_stream.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/ipc_stream.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/json.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/json.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/io/parquet.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/io/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/joins.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/joins.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/aggregation.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/aggregation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/cse.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/cse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/apply.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/apply.rs`

 * *Files 0% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 use super::*;
 
 #[test]
-#[cfg(feature = "arange")]
+#[cfg(feature = "range")]
 fn test_arange_agg() -> PolarsResult<()> {
     let df = df![
         "x" => [5, 5, 4, 4, 2, 2]
     ]?;
 
     let out = df
         .lazy()
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/arity.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/expand.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/expand.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/filter.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/slice.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/expressions/window.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/expressions/window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/folds.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/folds.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/functions.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/groupby.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/groupby_dynamic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/predicate_queries.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/predicate_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/projection_queries.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/projection_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/lazy/queries.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/lazy/queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/schema.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/schema.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars/tests/it/time/date_range.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars/tests/it/time/date_range.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,84 +1,79 @@
-use polars::time::date_range;
-use chrono::NaiveDate;
-
-use super::*;
+use polars::export::chrono::NaiveDate;
+use polars::prelude::*;
+use polars::time::{date_range, ClosedWindow, Duration};
 
 #[test]
-fn date_range() {
-
-    use super::*;
-    #[test]
-    fn test_date_range_9413() {
-        let start = NaiveDate::from_ymd_opt(2022, 1, 1)
-            .unwrap()
-            .and_hms_opt(0, 0, 0)
-            .unwrap();
-        let stop = NaiveDate::from_ymd_opt(2022, 1, 5)
-            .unwrap()
-            .and_hms_opt(0, 0, 0)
-            .unwrap();
-        let actual = date_range(
-            "date",
-            start,
-            stop,
-            Duration::parse("1d"),
-            ClosedWindow::Both,
-            TimeUnit::Milliseconds,
-            None,
-        )
-        .map(|date_range| date_range.into_series());
-        let result = format!("{:?}", actual);
-        let expected = r#"Ok(shape: (5,)
+fn test_time_units_9413() {
+    let start = NaiveDate::from_ymd_opt(2022, 1, 1)
+        .unwrap()
+        .and_hms_opt(0, 0, 0)
+        .unwrap();
+    let stop = NaiveDate::from_ymd_opt(2022, 1, 5)
+        .unwrap()
+        .and_hms_opt(0, 0, 0)
+        .unwrap();
+    let actual = date_range(
+        "date",
+        start,
+        stop,
+        Duration::parse("1d"),
+        ClosedWindow::Both,
+        TimeUnit::Milliseconds,
+        None,
+    )
+    .map(|date_range| date_range.into_series());
+    let result = format!("{:?}", actual);
+    let expected = r#"Ok(shape: (5,)
 Series: 'date' [datetime[ms]]
 [
 	2022-01-01 00:00:00
 	2022-01-02 00:00:00
 	2022-01-03 00:00:00
 	2022-01-04 00:00:00
 	2022-01-05 00:00:00
 ])"#;
-        assert_eq!(result, expected);
-        let actual = date_range(
-            "date",
-            start,
-            stop,
-            Duration::parse("1d"),
-            ClosedWindow::Both,
-            TimeUnit::Microseconds,
-            None,
-        )
-        .map(|date_range| date_range.into_series());
-        let result = format!("{:?}", actual);
-        let expected = r#"Ok(shape: (5,)
+    assert_eq!(result, expected);
+    let actual = date_range(
+        "date",
+        start,
+        stop,
+        Duration::parse("1d"),
+        ClosedWindow::Both,
+        TimeUnit::Microseconds,
+        None,
+    )
+    .map(|date_range| date_range.into_series());
+    let result = format!("{:?}", actual);
+    let expected = r#"Ok(shape: (5,)
 Series: 'date' [datetime[s]]
 [
 	2022-01-01 00:00:00
 	2022-01-02 00:00:00
 	2022-01-03 00:00:00
 	2022-01-04 00:00:00
 	2022-01-05 00:00:00
 ])"#;
-        assert_eq!(result, expected);
-        let actual = date_range(
-            "date",
-            start,
-            stop,
-            Duration::parse("1d"),
-            ClosedWindow::Both,
-            TimeUnit::Nanoseconds,
-            None,
-        )
-        .map(|date_range| date_range.into_series());
-        let result = format!("{:?}", actual);
-        let expected = r#"Ok(shape: (5,)
+    assert_eq!(result, expected);
+    let actual = date_range(
+        "date",
+        start,
+        stop,
+        Duration::parse("1d"),
+        ClosedWindow::Both,
+        TimeUnit::Nanoseconds,
+        None,
+    )
+    .map(|date_range| date_range.into_series());
+    let result = format!("{:?}", actual);
+    let expected = r#"Ok(shape: (5,)
 Series: 'date' [datetime[ns]]
 [
 	2022-01-01 00:00:00
 	2022-01-02 00:00:00
 	2022-01-03 00:00:00
 	2022-01-04 00:00:00
 	2022-01-05 00:00:00
 ])"#;
-        assert_eq!(result, expected);
-    }
+    assert_eq!(result, expected);
+    assert_eq!(result, expected);
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/Cargo.toml`

 * *Files 2% similar despite different names*

```diff
@@ -75,15 +75,15 @@
 repeat_by = ["polars-plan/repeat_by"]
 round_series = ["polars-plan/round_series", "polars-ops/round_series"]
 is_first = ["polars-plan/is_first"]
 is_unique = ["polars-plan/is_unique"]
 cross_join = ["polars-plan/cross_join", "polars-pipe/cross_join", "polars-ops/cross_join"]
 asof_join = ["polars-plan/asof_join", "polars-time"]
 concat_str = ["polars-plan/concat_str"]
-arange = ["polars-plan/arange"]
+range = ["polars-plan/range"]
 mode = ["polars-plan/mode"]
 cum_agg = ["polars-plan/cum_agg"]
 interpolate = ["polars-plan/interpolate"]
 rolling_window = [
   "polars-plan/rolling_window",
   "polars-time/rolling_window",
 ]
@@ -123,14 +123,17 @@
   "polars-arrow/serde",
   "polars-core/serde-lazy",
   "polars-time/serde",
   "polars-io/serde",
   "polars-ops/serde",
 ]
 fused = ["polars-plan/fused", "polars-ops/fused"]
+list_sets = ["polars-plan/list_sets", "polars-ops/list_sets"]
+list_any_all = ["polars-ops/list_any_all", "polars-plan/list_any_all"]
+cutqcut = ["polars-plan/cutqcut", "polars-ops/cutqcut"]
 
 binary_encoding = ["polars-plan/binary_encoding"]
 
 bigidx = ["polars-plan/bigidx"]
 
 panic_on_schema = ["polars-plan/panic_on_schema"]
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dot.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/eval.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/eval.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/functions.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/dsl/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/dsl/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/anonymous_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/csv.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/file_list_reader.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/file_list_reader.rs`

 * *Files 2% similar despite different names*

```diff
@@ -113,14 +113,14 @@
     }
 
     /// Get list of files referenced by this reader.
     ///
     /// Returns [None] if path is not a glob pattern.
     fn glob(&self) -> PolarsResult<Option<GlobIterator>> {
         let path_str = self.path().to_string_lossy();
-        if path_str.contains('*') {
+        if path_str.contains('*') || path_str.contains('?') || path_str.contains('[') {
             polars_glob(&path_str, self.cloud_options()).map(Some)
         } else {
             Ok(None)
         }
     }
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/ipc.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/ipc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1167,14 +1167,30 @@
                 schema,
                 name.unwrap_or("ANONYMOUS UDF"),
             )
             .build();
         Self::from_logical_plan(lp, opt_state)
     }
 
+    #[cfg(feature = "python")]
+    pub fn map_python(
+        self,
+        function: polars_plan::prelude::python_udf::PythonFunction,
+        optimizations: AllowedOptimizations,
+        schema: Option<SchemaRef>,
+        validate_output: bool,
+    ) -> LazyFrame {
+        let opt_state = self.get_opt_state();
+        let lp = self
+            .get_plan_builder()
+            .map_python(function, optimizations, schema, validate_output)
+            .build();
+        Self::from_logical_plan(lp, opt_state)
+    }
+
     pub(crate) fn map_private(self, function: FunctionNode) -> LazyFrame {
         let opt_state = self.get_opt_state();
         let lp = self.get_plan_builder().map_private(function).build();
         Self::from_logical_plan(lp, opt_state)
     }
 
     /// Add a new column at index 0 that counts the rows.
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/ndjson.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/ndjson.rs`

 * *Files 3% similar despite different names*

```diff
@@ -14,18 +14,17 @@
     pub(crate) schema: Option<Schema>,
     pub(crate) row_count: Option<RowCount>,
     pub(crate) infer_schema_length: Option<usize>,
     pub(crate) n_rows: Option<usize>,
 }
 
 impl LazyJsonLineReader {
-    pub fn new(path: String) -> Self {
-        // TODO: Change argument type to impl AsRef<Path>
+    pub fn new(path: impl AsRef<Path>) -> Self {
         LazyJsonLineReader {
-            path: path.into(),
+            path: path.as_ref().to_path_buf(),
             batch_size: None,
             low_memory: false,
             rechunk: true,
             schema: None,
             row_count: None,
             infer_schema_length: Some(100),
             n_rows: None,
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/parquet.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/frame/pivot.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/frame/pivot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/lib.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/cache.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/executor.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/ext_context.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_dynamic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_partitioned.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/groupby_rolling.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/join.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/python_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ipc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/ndjson.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/scan/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/stack.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/udf.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/union.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/executors/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/exotic.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/exotic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/aggregation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/alias.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/apply.rs`

 * *Files 3% similar despite different names*

```diff
@@ -22,14 +22,15 @@
     pub collect_groups: ApplyOptions,
     pub auto_explode: bool,
     pub allow_rename: bool,
     pub pass_name_to_apply: bool,
     pub input_schema: Option<SchemaRef>,
     pub allow_threading: bool,
     pub check_lengths: bool,
+    pub allow_group_aware: bool,
 }
 
 impl ApplyExpr {
     pub(crate) fn new_minimal(
         inputs: Vec<Arc<dyn PhysicalExpr>>,
         function: SpecialEq<Arc<dyn SeriesUdf>>,
         expr: Expr,
@@ -42,14 +43,15 @@
             collect_groups,
             auto_explode: false,
             allow_rename: false,
             pass_name_to_apply: false,
             input_schema: None,
             allow_threading: true,
             check_lengths: true,
+            allow_group_aware: true,
         }
     }
 
     #[allow(clippy::ptr_arg)]
     fn prepare_multiple_inputs<'a>(
         &self,
         df: &DataFrame,
@@ -276,14 +278,19 @@
     #[allow(clippy::ptr_arg)]
     fn evaluate_on_groups<'a>(
         &self,
         df: &DataFrame,
         groups: &'a GroupsProxy,
         state: &ExecutionState,
     ) -> PolarsResult<AggregationContext<'a>> {
+        polars_ensure!(
+            self.allow_group_aware,
+            expr = self.expr,
+            ComputeError: "this expression cannot run in the groupby context",
+        );
         if self.inputs.len() == 1 {
             let mut ac = self.inputs[0].evaluate_on_groups(df, groups, state)?;
 
             match self.collect_groups {
                 ApplyOptions::ApplyList => {
                     let s = self.eval_and_flatten(&mut [ac.aggregated()])?;
                     ac.with_series(s, true, Some(&self.expr))?;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/cache.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/cache.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/cast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/column.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/count.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/group_iter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/literal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/sortby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/take.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/ternary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/expressions/window.rs`

 * *Files 2% similar despite different names*

```diff
@@ -486,14 +486,20 @@
         // the groups, so that the cached groups and join keys
         // are consistent among all windows
         if sort_groups || state.cache_window() {
             groups.sort()
         }
         let gb = GroupBy::new(df, groupby_columns.clone(), groups, Some(apply_columns));
 
+        // If the aggregation creates categoricals and `MapStrategy` is `Join`,
+        // the string cache was needed. So we hold it for that case.
+        // Worst case is that a categorical is created with indexes from the string
+        // cache which is fine, as the physical representation is undefined.
+        #[cfg(feature = "dtype-categorical")]
+        let _sc = polars_core::IUseStringCache::hold();
         let mut ac = self.run_aggregation(df, state, &gb)?;
 
         use MapStrategy::*;
         match self.determine_map_strategy(ac.agg_state(), sorted_keys, &gb)? {
             Nothing => {
                 let mut out = ac.flat_naive().into_owned();
                 cache_gb(gb, state, &cache_key);
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/file_cache.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/node_timer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/planner/expr.rs`

 * *Files 2% similar despite different names*

```diff
@@ -460,14 +460,15 @@
                 collect_groups: options.collect_groups,
                 auto_explode: options.auto_explode,
                 allow_rename: options.allow_rename,
                 pass_name_to_apply: options.pass_name_to_apply,
                 input_schema: schema.cloned(),
                 allow_threading: !state.has_cache,
                 check_lengths: options.check_lengths(),
+                allow_group_aware: options.allow_group_aware,
             }))
         }
         Function {
             input,
             function,
             options,
             ..
@@ -495,14 +496,15 @@
                 collect_groups: options.collect_groups,
                 auto_explode: options.auto_explode,
                 allow_rename: options.allow_rename,
                 pass_name_to_apply: options.pass_name_to_apply,
                 input_schema: schema.cloned(),
                 allow_threading: !state.has_cache,
                 check_lengths: options.check_lengths(),
+                allow_group_aware: options.allow_group_aware,
             }))
         }
         Slice {
             input,
             offset,
             length,
         } => {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/planner/lp.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/state.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/checks.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/checks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/construct_pipeline.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/construct_pipeline.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/convert_alp.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/convert_alp.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/physical_plan/streaming/tree.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/prelude.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/aggregations.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/aggregations.rs`

 * *Files 0% similar despite different names*

```diff
@@ -232,16 +232,16 @@
     ]
     .unwrap();
 
     let out = df
         .lazy()
         .groupby_stable([col("groups")])
         .agg([when(col("vals").first().neq(lit(1)))
-            .then(repeat("a", count()))
-            .otherwise(repeat("b", count()))
+            .then(repeat(lit("a"), count()))
+            .otherwise(repeat(lit("b"), count()))
             .alias("foo")])
         .collect()
         .unwrap();
 
     let out = out.column("foo")?;
     let out = out.explode()?;
     let out = out.utf8()?;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/arity.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/cse.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/cse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/io.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/io.rs`

 * *Files 0% similar despite different names*

```diff
@@ -240,15 +240,15 @@
 #[test]
 #[cfg(not(target_os = "windows"))]
 #[cfg(feature = "json")]
 fn test_ndjson_globbing() -> PolarsResult<()> {
     // for side effects
     init_files();
     let glob = "../../examples/datasets/*.ndjson";
-    let df = LazyJsonLineReader::new(glob.into()).finish()?.collect()?;
+    let df = LazyJsonLineReader::new(glob).finish()?.collect()?;
     assert_eq!(df.shape(), (54, 4));
     let cal = df.column("calories")?;
     assert_eq!(cal.get(0)?, AnyValue::Int64(45));
     assert_eq!(cal.get(53)?, AnyValue::Int64(194));
 
     Ok(())
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/logical.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/logical.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/optimization_checks.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/optimization_checks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/predicate_queries.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/predicate_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/projection_queries.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/projection_queries.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/queries.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/queries.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 use polars_core::frame::explode::MeltArgs;
 #[cfg(feature = "diff")]
 use polars_core::series::ops::NullBehavior;
 
 use super::*;
-#[cfg(feature = "arange")]
+#[cfg(feature = "range")]
 use crate::dsl::arg_sort_by;
 
 #[test]
 fn test_lazy_with_column() {
     let df = get_df()
         .lazy()
         .with_column(lit(10).alias("foo"))
@@ -1013,15 +1013,15 @@
             .collect::<Vec<_>>()
     );
 
     Ok(())
 }
 
 #[test]
-#[cfg(feature = "arange")]
+#[cfg(feature = "range")]
 fn test_arg_sort_multiple() -> PolarsResult<()> {
     let df = df![
         "int" => [1, 2, 3, 1, 2],
         "flt" => [3.0, 2.0, 1.0, 2.0, 1.0],
         "str" => ["a", "a", "a", "b", "b"]
     ]?;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/streaming.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/streaming.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/tests/tpch.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/tests/tpch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-lazy/src/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-lazy/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/Cargo.toml`

 * *Files 6% similar despite different names*

```diff
@@ -11,14 +11,15 @@
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 argminmax = { version = "0.6.1", default-features = false, features = ["float"] }
 base64 = { version = "0.21", optional = true }
 either= "1.8"
 hex = { version = "0.4", optional = true }
+indexmap= { version = "2", features = ["std"] }
 jsonpath_lib = { version = "0.3.0", optional = true, git = "https://github.com/ritchie46/jsonpath", branch = "improve_compiled" }
 memchr= "2"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", default-features = false }
 polars-core = { version = "0.30.0", path = "../polars-core", features = [], default-features = false }
 polars-json = { version = "0.30.0", optional = true, path = "../polars-json", default-features = false }
 polars-utils = { version = "0.30.0", path = "../polars-utils", default-features = false }
 serde = { version = "1", features = ["derive"], optional = true }
@@ -45,14 +46,15 @@
 performant = ["polars-core/performant", "fused"]
 big_idx = ["polars-core/bigidx"]
 round_series = []
 is_first = []
 is_unique = []
 approx_unique = []
 fused = []
+cutqcut = ["dtype-categorical"]
 
 # extra utilities for BinaryChunked
 binary_encoding = ["base64", "hex"]
 string_encoding = ["base64", "hex"]
 
 # ops
 to_dummies = []
@@ -73,22 +75,24 @@
 top_k = []
 pivot = ["polars-core/reinterpret"]
 cross_join = ["polars-core/cross_join"]
 chunked_ids = ["polars-core/chunked_ids"]
 asof_join = ["polars-core/asof_join"]
 semi_anti_join = ["polars-core/semi_anti_join"]
 list_take = []
+list_sets = []
+list_any_all = []
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/array/min_max.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/array/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/array/namespace.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/array/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/array/sum_mean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/array/sum_mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/binary/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/interpolate.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/interpolate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/count.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/count.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/hash.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/hash.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/namespace.rs`

 * *Files 8% similar despite different names*

```diff
@@ -9,14 +9,16 @@
 #[cfg(feature = "list_take")]
 use polars_core::export::num::{NumCast, Signed, Zero};
 #[cfg(feature = "diff")]
 use polars_core::series::ops::NullBehavior;
 use polars_core::utils::{try_get_supertype, CustomIterTools};
 
 use super::*;
+#[cfg(feature = "list_any_all")]
+use crate::chunked_array::list::any_all::*;
 use crate::chunked_array::list::min_max::{list_max_function, list_min_function};
 use crate::chunked_array::list::sum_mean::sum_with_nulls;
 use crate::prelude::list::sum_mean::{mean_list_numerical, sum_list_numerical};
 use crate::series::ArgAgg;
 
 pub(super) fn has_inner_nulls(ca: &ListChunked) -> bool {
     for arr in ca.downcast_iter() {
@@ -110,14 +112,26 @@
         }
     }
 
     fn lst_max(&self) -> Series {
         list_max_function(self.as_list())
     }
 
+    #[cfg(feature = "list_any_all")]
+    fn lst_all(&self) -> PolarsResult<Series> {
+        let ca = self.as_list();
+        list_all(ca)
+    }
+
+    #[cfg(feature = "list_any_all")]
+    fn lst_any(&self) -> PolarsResult<Series> {
+        let ca = self.as_list();
+        list_any(ca)
+    }
+
     fn lst_min(&self) -> Series {
         list_min_function(self.as_list())
     }
 
     fn lst_sum(&self) -> Series {
         let ca = self.as_list();
 
@@ -141,34 +155,48 @@
 
         match ca.inner_dtype() {
             dt if dt.is_numeric() => mean_list_numerical(ca, &dt),
             _ => sum_mean::mean_with_nulls(ca),
         }
     }
 
+    fn same_type(&self, out: ListChunked) -> ListChunked {
+        let ca = self.as_list();
+        let dtype = ca.dtype();
+        if out.dtype() != dtype {
+            out.cast(ca.dtype()).unwrap().list().unwrap().clone()
+        } else {
+            out
+        }
+    }
+
     #[must_use]
     fn lst_sort(&self, options: SortOptions) -> ListChunked {
         let ca = self.as_list();
-        ca.apply_amortized(|s| s.as_ref().sort_with(options))
+        let out = ca.apply_amortized(|s| s.as_ref().sort_with(options));
+        self.same_type(out)
     }
 
     #[must_use]
     fn lst_reverse(&self) -> ListChunked {
         let ca = self.as_list();
-        ca.apply_amortized(|s| s.as_ref().reverse())
+        let out = ca.apply_amortized(|s| s.as_ref().reverse());
+        self.same_type(out)
     }
 
     fn lst_unique(&self) -> PolarsResult<ListChunked> {
         let ca = self.as_list();
-        ca.try_apply_amortized(|s| s.as_ref().unique())
+        let out = ca.try_apply_amortized(|s| s.as_ref().unique())?;
+        Ok(self.same_type(out))
     }
 
     fn lst_unique_stable(&self) -> PolarsResult<ListChunked> {
         let ca = self.as_list();
-        ca.try_apply_amortized(|s| s.as_ref().unique_stable())
+        let out = ca.try_apply_amortized(|s| s.as_ref().unique_stable())?;
+        Ok(self.same_type(out))
     }
 
     fn lst_arg_min(&self) -> IdxCa {
         let ca = self.as_list();
         let mut out: IdxCa = ca
             .amortized_iter()
             .map(|opt_s| opt_s.and_then(|s| s.as_ref().arg_min().map(|idx| idx as IdxSize)))
@@ -191,20 +219,22 @@
     fn lst_diff(&self, n: i64, null_behavior: NullBehavior) -> PolarsResult<ListChunked> {
         let ca = self.as_list();
         ca.try_apply_amortized(|s| s.as_ref().diff(n, null_behavior))
     }
 
     fn lst_shift(&self, periods: i64) -> ListChunked {
         let ca = self.as_list();
-        ca.apply_amortized(|s| s.as_ref().shift(periods))
+        let out = ca.apply_amortized(|s| s.as_ref().shift(periods));
+        self.same_type(out)
     }
 
     fn lst_slice(&self, offset: i64, length: usize) -> ListChunked {
         let ca = self.as_list();
-        ca.apply_amortized(|s| s.as_ref().slice(offset, length))
+        let out = ca.apply_amortized(|s| s.as_ref().slice(offset, length));
+        self.same_type(out)
     }
 
     fn lst_lengths(&self) -> IdxCa {
         let ca = self.as_list();
         let mut lengths = Vec::with_capacity(ca.len());
         ca.downcast_iter().for_each(|arr| {
             let offsets = arr.offsets().as_slice();
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/sum_mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/to_struct.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/nan_propagating_aggregate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/set.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/case.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/case.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/json_path.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/justify.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/namespace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/strings/replace.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/chunked_array/top_k.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/top_k.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/join/merge_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/join/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/join/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/pivot/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/pivot/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/frame/pivot/positioning.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/frame/pivot/positioning.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/approx_algo/hyperloglogplus.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/approx_unique.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/approx_unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/arg_min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/floor_divide.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/floor_divide.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/fused.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/fused.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/is_first.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/is_first.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/is_unique.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/is_unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/log.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/log.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/mod.rs`

 * *Files 7% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 mod approx_algo;
 #[cfg(feature = "approx_unique")]
 mod approx_unique;
 mod arg_min_max;
+#[cfg(feature = "cutqcut")]
+mod cut;
 #[cfg(feature = "round_series")]
 mod floor_divide;
 #[cfg(feature = "fused")]
 mod fused;
 #[cfg(feature = "is_first")]
 mod is_first;
 #[cfg(feature = "is_unique")]
@@ -20,14 +22,16 @@
 mod to_dummies;
 mod various;
 
 pub use approx_algo::*;
 #[cfg(feature = "approx_unique")]
 pub use approx_unique::*;
 pub use arg_min_max::ArgAgg;
+#[cfg(feature = "cutqcut")]
+pub use cut::*;
 #[cfg(feature = "round_series")]
 pub use floor_divide::*;
 #[cfg(feature = "fused")]
 pub use fused::*;
 #[cfg(feature = "is_first")]
 pub use is_first::*;
 #[cfg(feature = "is_unique")]
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/rolling.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/rolling.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/search_sorted.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/search_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/to_dummies.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/to_dummies.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-ops/src/series/ops/various.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/series/ops/various.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/Cargo.toml`

 * *Files 4% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 crossbeam-channel = { version = "0.5", optional = true }
 crossbeam-queue = { version = "0.3", optional = true }
 enum_dispatch = "0.3"
-hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
+hashbrown= { version = "0.14.0", features = ["rayon", "ahash"] }
 num-traits= "0.2"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", default-features = false }
 polars-core = { version = "0.30.0", path = "../polars-core", features = ["lazy", "zip_with", "random"], default-features = false }
 polars-io = { version = "0.30.0", path = "../polars-io", default-features = false, features = ["ipc", "async"] }
 polars-ops = { version = "0.30.0", path = "../polars-ops", features = ["search_sorted"] }
 polars-plan = { version = "0.30.0", path = "../polars-plan", default-features = false, features = ["compile"] }
 polars-row = { version = "0.30.0", path = "../polars-row" }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/filter.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/function.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/function.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/pass.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/pass.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/placeholder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/projection.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/operators/reproject.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/operators/reproject.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/file_sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/convert.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/count.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/first.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/interface.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/last.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/mean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/min_max.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/aggregates/sum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/eval.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/global.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/hash_table.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/ooc_state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/source.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/source.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/generic/thread_local.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/ooc_state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/primitive/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/groupby/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/io.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/io.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/joins/cross.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/joins/generic_build.rs`

 * *Files 1% similar despite different names*

```diff
@@ -138,16 +138,15 @@
     }
 
     fn set_join_series(
         &mut self,
         context: &PExecutionContext,
         chunk: &DataChunk,
     ) -> PolarsResult<&BinaryArray<i64>> {
-        self.join_columns.clear();
-
+        debug_assert!(self.join_columns.is_empty());
         for phys_e in self.join_columns_left.iter() {
             let s = phys_e.evaluate(chunk, context.execution_state.as_any())?;
             let arr = s.to_physical_repr().rechunk().array_ref(0).clone();
             self.join_columns.push(arr);
         }
         let rows_encoded = polars_row::convert_columns_no_order(&self.join_columns).into_array();
         self.materialized_join_cols.push(rows_encoded);
@@ -202,14 +201,19 @@
                 RawEntryMut::Occupied(mut entry) => {
                     entry.get_mut().push(payload);
                 }
             };
 
             current_df_idx += 1;
         }
+
+        // clear memory
+        self.hashes.clear();
+        self.join_columns.clear();
+
         self.chunks.push(chunk);
         Ok(SinkResult::CanHaveMoreInput)
     }
 
     fn combine(&mut self, other: &mut dyn Sink) {
         if self.is_empty() {
             let other = other.as_any().downcast_mut::<Self>().unwrap();
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/joins/inner_left.rs`

 * *Files 6% similar despite different names*

```diff
@@ -115,15 +115,15 @@
         }
     }
     fn set_join_series(
         &mut self,
         context: &PExecutionContext,
         chunk: &DataChunk,
     ) -> PolarsResult<BinaryArray<i64>> {
-        self.join_columns.clear();
+        debug_assert!(self.join_columns.is_empty());
 
         let determine_idx = !self.swapped_or_left && self.join_column_idx.is_none();
         let mut names = vec![];
 
         for phys_e in self.join_columns_right.iter() {
             let s = phys_e.evaluate(chunk, context.execution_state.as_any())?;
             let s = s.to_physical_repr().rechunk();
@@ -148,14 +148,44 @@
         }
         polars_row::convert_columns_amortized_no_order(&self.join_columns, &mut self.current_rows);
 
         // safety: we keep rows-encode alive
         unsafe { Ok(self.current_rows.borrow_array()) }
     }
 
+    fn finish_join(
+        &mut self,
+        mut left_df: DataFrame,
+        right_df: DataFrame,
+    ) -> PolarsResult<DataFrame> {
+        Ok(match &self.output_names {
+            None => {
+                let out = _finish_join(left_df, right_df, Some(self.suffix.as_ref()))?;
+                self.output_names = Some(out.get_column_names_owned());
+                out
+            }
+            Some(names) => unsafe {
+                // safety:
+                // if we have duplicate names, we overwrite
+                // them in the next snippet
+                left_df
+                    .get_columns_mut()
+                    .extend_from_slice(right_df.get_columns());
+                left_df
+                    .get_columns_mut()
+                    .iter_mut()
+                    .zip(names)
+                    .for_each(|(s, name)| {
+                        s.rename(name);
+                    });
+                left_df
+            },
+        })
+    }
+
     fn execute_left(
         &mut self,
         context: &PExecutionContext,
         chunk: &DataChunk,
     ) -> PolarsResult<OperatorResult> {
         // A left join holds the right table as build table
         // and streams the left table through. This allows us to maintain
@@ -192,38 +222,23 @@
                     self.join_tuples_b.push(df_idx_left);
                     self.join_tuples_a_left_join.push(None);
                 }
             }
         }
         let right_df = self.df_a.as_ref();
 
-        let mut left_df = unsafe { chunk.data._take_unchecked_slice(&self.join_tuples_b, false) };
+        let left_df = unsafe { chunk.data._take_unchecked_slice(&self.join_tuples_b, false) };
         let right_df =
             unsafe { right_df._take_opt_chunked_unchecked_seq(&self.join_tuples_a_left_join) };
 
-        let out = match &self.output_names {
-            None => {
-                let out = _finish_join(left_df, right_df, Some(self.suffix.as_ref()))?;
-                self.output_names = Some(out.get_column_names_owned());
-                out
-            }
-            Some(names) => unsafe {
-                left_df
-                    .get_columns_mut()
-                    .extend_from_slice(right_df.get_columns());
-                left_df
-                    .get_columns_mut()
-                    .iter_mut()
-                    .zip(names)
-                    .for_each(|(s, name)| {
-                        s.rename(name);
-                    });
-                left_df
-            },
-        };
+        let out = self.finish_join(left_df, right_df)?;
+
+        // clear memory
+        self.join_columns.clear();
+        self.hashes.clear();
 
         Ok(OperatorResult::Finished(chunk.with_data(out)))
     }
 
     fn execute_inner(
         &mut self,
         context: &PExecutionContext,
@@ -271,38 +286,24 @@
                     let _ = cols.remove(*idx);
                 }
                 df = Cow::Owned(tmp);
             }
             df._take_unchecked_slice(&self.join_tuples_b, false)
         };
 
-        let (mut a, b) = if self.swapped_or_left {
+        let (a, b) = if self.swapped_or_left {
             (right_df, left_df)
         } else {
             (left_df, right_df)
         };
-        let out = match &self.output_names {
-            None => {
-                let out = _finish_join(a, b, Some(self.suffix.as_ref()))?;
-                self.output_names = Some(out.get_column_names_owned());
-                out
-            }
-            Some(names) => {
-                a.hstack_mut(b.get_columns()).unwrap();
-                unsafe {
-                    a.get_columns_mut()
-                        .iter_mut()
-                        .zip(names)
-                        .for_each(|(s, name)| {
-                            s.rename(name);
-                        });
-                }
-                a
-            }
-        };
+        let out = self.finish_join(a, b)?;
+
+        // clear memory
+        self.join_columns.clear();
+        self.hashes.clear();
 
         Ok(OperatorResult::Finished(chunk.with_data(out)))
     }
 }
 
 impl Operator for GenericJoinProbe {
     fn execute(
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/memory.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/memory.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/ordered.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/reproject.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/slice.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/sort/ooc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/sort/sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/sort/source.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sinks/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sinks/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/csv.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/frame.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/frame.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/ipc_one_shot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/parquet.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/parquet.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/reproject.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/reproject.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/executors/sources/union.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/executors/sources/union.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/chunks.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/chunks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/operator.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/operator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/operators/sink.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/operators/sink.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/pipeline/convert.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/pipeline/convert.rs`

 * *Files 0% similar despite different names*

```diff
@@ -216,15 +216,15 @@
                     .iter()
                     .map(|node| {
                         let name = aexpr_to_leaf_names_iter(*node, expr_arena).next().unwrap();
                         input_schema.try_index_of(name.as_ref())
                     })
                     .collect::<PolarsResult<Vec<_>>>()?;
 
-                let sort_sink = SortSinkMultiple::new(args.clone(), &input_schema, sort_idx);
+                let sort_sink = SortSinkMultiple::new(args.clone(), input_schema, sort_idx);
                 Box::new(sort_sink) as Box<dyn Sink>
             }
         }
         Distinct { input, options } => {
             // We create a Groupby.agg_first()/agg_last (depending on the keep strategy
             let input_schema = lp_arena.get(*input).schema(lp_arena).into_owned();
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/pipeline/dispatcher.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-pipe/src/pipeline/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/src/pipeline/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/Cargo.toml`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-pipe/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/context.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/context.rs`

 * *Files 1% similar despite different names*

```diff
@@ -424,15 +424,18 @@
                 name, alias, args, ..
             } => {
                 if let Some(args) = args {
                     return self.execute_tbl_function(name, alias, args);
                 }
                 let tbl_name = name.0.get(0).unwrap().value.as_str();
                 if let Some(lf) = self.get_table_from_current_scope(tbl_name) {
-                    Ok((tbl_name.to_string(), lf))
+                    match alias {
+                        Some(alias) => Ok((alias.to_string(), lf)),
+                        None => Ok((tbl_name.to_string(), lf)),
+                    }
                 } else {
                     polars_bail!(ComputeError: "relation '{}' was not found", tbl_name);
                 }
             }
             // Support bare table, optional with alias for now
             _ => polars_bail!(ComputeError: "not implemented"),
         }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/functions.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/keywords.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/keywords.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/sql_expr.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/sql_expr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/src/table_functions.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/src/table_functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_cumulative.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_cumulative.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_io.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_io.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_math.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_math.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_meta.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_meta.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/functions_string.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/functions_string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_7436.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_7436.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_7437.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_7437.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_7440.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_7440.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_8395.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_8395.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/iss_8419.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/iss_8419.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/ops_distinct_on.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/ops_distinct_on.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/simple_exprs.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/simple_exprs.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-sql/tests/statements.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/tests/statements.rs`

 * *Files 19% similar despite different names*

```diff
@@ -155,7 +155,29 @@
     DROP TABLE df
     "#;
     let actual = ctx.execute(sql);
     assert!(actual.is_ok());
     let res = ctx.execute("SELECT * FROM df");
     assert!(res.is_err());
 }
+
+#[test]
+fn iss_9560_join_as() {
+    let df1 = df! {"id"=> [1, 2, 3, 4], "ano"=> [2, 3, 4, 5]}.unwrap();
+    let df2 = df! {"id"=> [1, 2, 3, 4], "ano"=> [2, 3, 4, 5]}.unwrap();
+    let mut ctx = SQLContext::new();
+    ctx.register("df1", df1.lazy());
+    ctx.register("df2", df2.lazy());
+    let sql = r#"
+        SELECT * FROM df1 AS t1 JOIN df2 AS t2 ON t1.id = t2.id
+    "#;
+    let actual = ctx.execute(sql).unwrap().collect().unwrap();
+
+    let expected = df! {
+        "id" => [1, 2, 3, 4],
+        "ano" => [2, 3, 4, 5],
+        "ano_right" => [2, 3, 4, 5],
+    }
+    .unwrap();
+
+    assert!(actual.frame_equal(&expected));
+}
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -38,15 +38,15 @@
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/date.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/date.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/datetime.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/duration.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/kernels.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/kernels.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/floats.rs`

 * *Files 0% similar despite different names*

```diff
@@ -115,15 +115,16 @@
                 arr.values(),
                 quantile,
                 interpolation,
                 options.window_size,
                 options.min_periods,
                 options.center,
                 options.weights.as_deref(),
-            ),
+            )
+            .unwrap(),
             _ => rolling::nulls::rolling_quantile(
                 arr,
                 quantile,
                 interpolation,
                 options.window_size,
                 options.min_periods,
                 options.center,
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/ints.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/rolling_window/rolling_kernels/no_nulls.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/time.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/utf8/infer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/utf8/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/utf8/patterns.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/chunkedarray/utf8/strptime.rs`

 * *Files 13% similar despite different names*

```diff
@@ -4,16 +4,19 @@
 use chrono::{NaiveDate, NaiveDateTime};
 use once_cell::sync::Lazy;
 use polars_utils::slice::GetSaferUnchecked;
 use regex::Regex;
 
 use crate::chunkedarray::{polars_bail, PolarsResult};
 
-static HOUR_PATTERN: Lazy<Regex> = Lazy::new(|| Regex::new(r"%[HI]").unwrap());
-static MINUTE_PATTERN: Lazy<Regex> = Lazy::new(|| Regex::new(r"%M").unwrap());
+static HOUR_PATTERN: Lazy<Regex> = Lazy::new(|| Regex::new(r"%[_-]?[HkIl]").unwrap());
+static MINUTE_PATTERN: Lazy<Regex> = Lazy::new(|| Regex::new(r"%[_-]?M").unwrap());
+static SECOND_PATTERN: Lazy<Regex> = Lazy::new(|| Regex::new(r"%[_-]?S").unwrap());
+static TWELVE_HOUR_PATTERN: Lazy<Regex> = Lazy::new(|| Regex::new(r"%[_-]?[Il]").unwrap());
+static MERIDIEM_PATTERN: Lazy<Regex> = Lazy::new(|| Regex::new(r"%[_-]?[pP]").unwrap());
 
 #[inline]
 fn update_and_parse<T: atoi::FromRadix10>(
     incr: usize,
     offset: usize,
     vals: &[u8],
 ) -> Option<(T, usize)> {
@@ -48,22 +51,31 @@
     }
 }
 
 /// Tries to convert a chrono `fmt` to a `fmt` that the polars parser consumes.
 /// E.g. chrono supports single letter date identifiers like %F, whereas polars only consumes
 /// year, day, month distinctively with %Y, %d, %m.
 pub(super) fn compile_fmt(fmt: &str) -> PolarsResult<String> {
-    if HOUR_PATTERN.is_match(fmt) & !MINUTE_PATTERN.is_match(fmt) {
-        // (hopefully) temporary hack. Ideally, chrono would return a ParseKindError indicating
-        // if `fmt` is too long for NaiveDate. If that's implemented, then this check could
-        // be removed, and that error could be matched against in `transform_datetime_*s`
-        // See https://github.com/chronotope/chrono/issues/1075.
-        polars_bail!(ComputeError: "Invalid format string: found hour, but no minute directive. \
-            Please either specify both or neither.");
+    // (hopefully) temporary hacks. Ideally, chrono would return a ParseKindError indicating
+    // if `fmt` is too long for NaiveDate. If that's implemented, then this check could
+    // be removed, and that error could be matched against in `transform_datetime_*s`
+    // See https://github.com/chronotope/chrono/issues/1075.
+    if HOUR_PATTERN.is_match(fmt) ^ MINUTE_PATTERN.is_match(fmt) {
+        polars_bail!(ComputeError: "Invalid format string: \
+            Please either specify both hour and minute, or neither.");
     }
+    if SECOND_PATTERN.is_match(fmt) && !HOUR_PATTERN.is_match(fmt) {
+        polars_bail!(ComputeError: "Invalid format string: \
+            Found seconds directive, but no hours directive.");
+    }
+    if TWELVE_HOUR_PATTERN.is_match(fmt) ^ MERIDIEM_PATTERN.is_match(fmt) {
+        polars_bail!(ComputeError: "Invalid format string: \
+            Please either specify both 12-hour directive and meridiem directive, or neither.");
+    }
+
     Ok(fmt
         .replace("%D", "%m/%d/%y")
         .replace("%R", "%H:%M")
         .replace("%T", "%H:%M:%S")
         .replace("%X", "%H:%M:%S")
         .replace("%F", "%Y-%m-%d"))
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/date_range.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/date_range.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/groupby/dynamic.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/groupby/dynamic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/lib.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/lib.rs`

 * *Files 23% similar despite different names*

```diff
@@ -1,22 +1,28 @@
 #![cfg_attr(docsrs, feature(doc_auto_cfg))]
+mod base_utc_offset;
 pub mod chunkedarray;
 mod date_range;
+mod dst_offset;
 mod groupby;
 mod month_end;
 mod month_start;
 pub mod prelude;
 mod round;
 pub mod series;
 mod truncate;
 mod upsample;
 mod utils;
 mod windows;
 
+#[cfg(feature = "timezones")]
+pub use base_utc_offset::*;
 pub use date_range::*;
+#[cfg(feature = "timezones")]
+pub use dst_offset::*;
 #[cfg(any(feature = "dtype-date", feature = "dtype-datetime"))]
 pub use groupby::dynamic::*;
 pub use month_end::*;
 pub use month_start::*;
 pub use round::*;
 pub use truncate::*;
 pub use upsample::*;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/month_end.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/month_end.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/month_start.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/month_start.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/round.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/round.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/_trait.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/_trait.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/floats.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/floats.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/implementations/integers.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/implementations/integers.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/series/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/series/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/truncate.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/truncate.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/upsample.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/upsample.rs`

 * *Files 10% similar despite different names*

```diff
@@ -23,24 +23,29 @@
     /// the following string language:
     /// - 1ns   (1 nanosecond)
     /// - 1us   (1 microsecond)
     /// - 1ms   (1 millisecond)
     /// - 1s    (1 second)
     /// - 1m    (1 minute)
     /// - 1h    (1 hour)
-    /// - 1d    (1 day)
-    /// - 1w    (1 week)
+    /// - 1d    (1 calendar day)
+    /// - 1w    (1 calendar week)
     /// - 1mo   (1 calendar month)
+    /// - 1q    (1 calendar quarter)
     /// - 1y    (1 calendar year)
     /// - 1i    (1 index count)
     /// Or combine them:
     /// "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
     /// Suffix with `"_saturating"` to saturate dates with days too
     /// large for their month to the last day of the month (e.g.
     /// 2022-02-29 to 2022-02-28).
+    /// By "calendar day", we mean the corresponding time on the next
+    /// day (which may not be 24 hours, depending on daylight savings).
+    /// Similarly for "calendar week", "calendar month", "calendar quarter",
+    /// and "calendar year".
     fn upsample<I: IntoVec<String>>(
         &self,
         by: I,
         time_column: &str,
         every: Duration,
         offset: Duration,
     ) -> PolarsResult<DataFrame>;
@@ -58,21 +63,29 @@
     /// the following string language:
     /// - 1ns   (1 nanosecond)
     /// - 1us   (1 microsecond)
     /// - 1ms   (1 millisecond)
     /// - 1s    (1 second)
     /// - 1m    (1 minute)
     /// - 1h    (1 hour)
-    /// - 1d    (1 day)
-    /// - 1w    (1 week)
+    /// - 1d    (1 calendar day)
+    /// - 1w    (1 calendar week)
     /// - 1mo   (1 calendar month)
+    /// - 1q    (1 calendar quarter)
     /// - 1y    (1 calendar year)
     /// - 1i    (1 index count)
     /// Or combine them:
     /// "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
+    /// Suffix with `"_saturating"` to saturate dates with days too
+    /// large for their month to the last day of the month (e.g.
+    /// 2022-02-29 to 2022-02-28).
+    /// By "calendar day", we mean the corresponding time on the next
+    /// day (which may not be 24 hours, depending on daylight savings).
+    /// Similarly for "calendar week", "calendar month", "calendar quarter",
+    /// and "calendar year".
     fn upsample_stable<I: IntoVec<String>>(
         &self,
         by: I,
         time_column: &str,
         every: Duration,
         offset: Duration,
     ) -> PolarsResult<DataFrame>;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/bounds.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/bounds.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/calendar.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/calendar.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/duration.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/duration.rs`

 * *Files 2% similar despite different names*

```diff
@@ -88,21 +88,27 @@
     /// * `ms`: millisecond
     /// * `s`:  second
     /// * `m`:  minute
     /// * `h`:  hour
     /// * `d`:  day
     /// * `w`:  week
     /// * `mo`: calendar month
+    /// * `q`: calendar quarter
     /// * `y`:  calendar year
     /// * `i`:  index value (only for {Int32, Int64} dtypes)
     ///
     /// Suffix with `"_saturating"` to indicate that dates too large for
     /// their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
     /// instead of erroring.
     ///
+    /// By "calendar day", we mean the corresponding time on the next
+    /// day (which may not be 24 hours, depending on daylight savings).
+    /// Similarly for "calendar week", "calendar month", "calendar quarter",
+    /// and "calendar year".
+    ///
     /// # Panics
     /// If the given str is invalid for any reason.
     pub fn parse(duration: &str) -> Self {
         let num_minus_signs = duration.matches('-').count();
         if num_minus_signs > 1 {
             panic!("a Duration string can only have a single minus sign")
         }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/groupby.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/test.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/test.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-time/src/windows/window.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-time/src/windows/window.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/Cargo.toml`

 * *Files 4% similar despite different names*

```diff
@@ -23,14 +23,15 @@
 polars-time = { version = "0.30.0", path = "../polars-time", optional = true }
 polars-utils = { version = "0.30.0", path = "../polars-utils" }
 pyo3 = { version = "0.19", optional = true }
 rayon= "1.6"
 regex = { version = "1.6", optional = true }
 serde = { version = "1", features = ["derive", "rc"], optional = true }
 smartstring= { version = "1" }
+strum_macros= "0.25"
 
 [features]
 # debugging utility
 debugging = []
 python = ["pyo3", "ciborium"]
 # make sure we don't compile unneeded things even though
 # this dependency gets activated
@@ -77,15 +78,15 @@
 repeat_by = ["polars-core/repeat_by"]
 round_series = ["polars-core/round_series"]
 is_first = ["polars-core/is_first", "polars-ops/is_first"]
 is_unique = ["polars-ops/is_unique"]
 cross_join = ["polars-core/cross_join"]
 asof_join = ["polars-core/asof_join", "polars-time", "polars-ops/asof_join"]
 concat_str = ["polars-core/concat_str"]
-arange = []
+range = []
 mode = ["polars-core/mode"]
 cum_agg = ["polars-core/cum_agg"]
 interpolate = ["polars-ops/interpolate"]
 rolling_window = [
   "polars-core/rolling_window",
   "polars-time/rolling_window",
   "polars-ops/rolling_window",
@@ -114,14 +115,17 @@
 pivot = ["polars-core/rows", "polars-ops/pivot"]
 top_k = ["polars-ops/top_k"]
 semi_anti_join = ["polars-core/semi_anti_join", "polars-ops/semi_anti_join"]
 cse = []
 propagate_nans = ["polars-ops/propagate_nans"]
 coalesce = []
 fused = []
+list_sets = ["polars-ops/list_sets"]
+list_any_all = ["polars-ops/list_any_all"]
+cutqcut = ["polars-ops/cutqcut"]
 
 bigidx = ["polars-arrow/bigidx", "polars-core/bigidx", "polars-utils/bigidx"]
 
 panic_on_schema = []
 
 [package.metadata.docs.rs]
 all-features = true
@@ -130,15 +134,15 @@
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dot.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dot.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/arithmetic.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/arity.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/array.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/array.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/binary.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/cat.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/cat.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/dt.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/dt.rs`

 * *Files 2% similar despite different names*

```diff
@@ -245,14 +245,28 @@
     // roll forward to the last day of the month
     #[cfg(feature = "date_offset")]
     pub fn month_end(self) -> Expr {
         self.0
             .map_private(FunctionExpr::TemporalExpr(TemporalFunction::MonthEnd))
     }
 
+    // Get the base offset from UTC
+    #[cfg(feature = "timezones")]
+    pub fn base_utc_offset(self) -> Expr {
+        self.0
+            .map_private(FunctionExpr::TemporalExpr(TemporalFunction::BaseUtcOffset))
+    }
+
+    // Get the additional offset from UTC currently in effect (usually due to daylight saving time)
+    #[cfg(feature = "timezones")]
+    pub fn dst_offset(self) -> Expr {
+        self.0
+            .map_private(FunctionExpr::TemporalExpr(TemporalFunction::DSTOffset))
+    }
+
     pub fn round<S: AsRef<str>>(self, every: S, offset: S) -> Expr {
         let every = every.as_ref().into();
         let offset = offset.as_ref().into();
         self.0
             .map_private(FunctionExpr::TemporalExpr(TemporalFunction::Round(
                 every, offset,
             )))
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/expr.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/expr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/expr_dyn_fn.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/expr_dyn_fn.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/from.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/arg_where.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/array.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/array.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/bounds.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/cat.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/correlation.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/correlation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/cum.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/datetime.rs`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,13 @@
 #[cfg(feature = "timezones")]
 use chrono_tz::Tz;
+#[cfg(feature = "timezones")]
+use polars_time::base_utc_offset as base_utc_offset_fn;
+#[cfg(feature = "timezones")]
+use polars_time::dst_offset as dst_offset_fn;
 #[cfg(feature = "serde")]
 use serde::{Deserialize, Serialize};
 
 use super::*;
 
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 #[derive(Clone, PartialEq, Debug, Eq, Hash)]
@@ -28,22 +32,27 @@
     Nanosecond,
     TimeStamp(TimeUnit),
     Truncate(String, String),
     #[cfg(feature = "date_offset")]
     MonthStart,
     #[cfg(feature = "date_offset")]
     MonthEnd,
+    #[cfg(feature = "timezones")]
+    BaseUtcOffset,
+    #[cfg(feature = "timezones")]
+    DSTOffset,
     Round(String, String),
     #[cfg(feature = "timezones")]
     CastTimezone(Option<TimeZone>, Option<bool>),
     #[cfg(feature = "timezones")]
     TzLocalize(TimeZone),
     DateRange {
         every: Duration,
         closed: ClosedWindow,
+        time_unit: Option<TimeUnit>,
         tz: Option<TimeZone>,
     },
     TimeRange {
         every: Duration,
         closed: ClosedWindow,
     },
     Combine(TimeUnit),
@@ -73,14 +82,18 @@
             Nanosecond => "nanosecond",
             TimeStamp(tu) => return write!(f, "dt.timestamp({tu})"),
             Truncate(..) => "truncate",
             #[cfg(feature = "date_offset")]
             MonthStart => "month_start",
             #[cfg(feature = "date_offset")]
             MonthEnd => "month_end",
+            #[cfg(feature = "timezones")]
+            BaseUtcOffset => "base_utc_offset",
+            #[cfg(feature = "timezones")]
+            DSTOffset => "dst_offset",
             Round(..) => "round",
             #[cfg(feature = "timezones")]
             CastTimezone(_, _) => "replace_timezone",
             #[cfg(feature = "timezones")]
             TzLocalize(_) => "tz_localize",
             DateRange { .. } => return write!(f, "date_range"),
             TimeRange { .. } => return write!(f, "time_range"),
@@ -250,14 +263,47 @@
             _ => s.datetime().unwrap().month_end(None)?.into_series(),
         },
         DataType::Date => s.date().unwrap().month_end(None)?.into_series(),
         dt => polars_bail!(opq = month_end, got = dt, expected = "date/datetime"),
     })
 }
 
+#[cfg(feature = "timezones")]
+pub(super) fn base_utc_offset(s: &Series) -> PolarsResult<Series> {
+    match s.dtype() {
+        DataType::Datetime(time_unit, Some(tz)) => {
+            let tz = tz
+                .parse::<Tz>()
+                .expect("Time zone has already been validated");
+            Ok(base_utc_offset_fn(s.datetime().unwrap(), time_unit, &tz).into_series())
+        }
+        dt => polars_bail!(
+            opq = base_utc_offset,
+            got = dt,
+            expected = "time-zone-aware datetime"
+        ),
+    }
+}
+#[cfg(feature = "timezones")]
+pub(super) fn dst_offset(s: &Series) -> PolarsResult<Series> {
+    match s.dtype() {
+        DataType::Datetime(time_unit, Some(tz)) => {
+            let tz = tz
+                .parse::<Tz>()
+                .expect("Time zone has already been validated");
+            Ok(dst_offset_fn(s.datetime().unwrap(), time_unit, &tz).into_series())
+        }
+        dt => polars_bail!(
+            opq = dst_offset,
+            got = dt,
+            expected = "time-zone-aware datetime"
+        ),
+    }
+}
+
 pub(super) fn round(s: &Series, every: &str, offset: &str) -> PolarsResult<Series> {
     let every = Duration::parse(every);
     let offset = Duration::parse(offset);
     Ok(match s.dtype() {
         DataType::Datetime(_, tz) => match tz {
             #[cfg(feature = "timezones")]
             Some(tz) => s
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/dispatch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/fill_null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/fused.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/fused.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/list.rs`

 * *Files 8% similar despite different names*

```diff
@@ -12,14 +12,20 @@
     Slice,
     Get,
     #[cfg(feature = "list_take")]
     Take(bool),
     #[cfg(feature = "list_count")]
     CountMatch,
     Sum,
+    #[cfg(feature = "list_sets")]
+    SetOperation(SetOperation),
+    #[cfg(feature = "list_any_all")]
+    Any,
+    #[cfg(feature = "list_any_all")]
+    All,
 }
 
 impl Display for ListFunction {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         use ListFunction::*;
 
         let name = match self {
@@ -29,14 +35,20 @@
             Slice => "slice",
             Get => "get",
             #[cfg(feature = "list_take")]
             Take(_) => "take",
             #[cfg(feature = "list_count")]
             CountMatch => "count",
             Sum => "sum",
+            #[cfg(feature = "list_sets")]
+            SetOperation(s) => return write!(f, "{s}"),
+            #[cfg(feature = "list_any_all")]
+            Any => "any",
+            #[cfg(feature = "list_any_all")]
+            All => "all",
         };
         write!(f, "{name}")
     }
 }
 
 #[cfg(feature = "is_in")]
 pub(super) fn contains(args: &mut [Series]) -> PolarsResult<Option<Series>> {
@@ -237,7 +249,24 @@
     let ca = s.list()?;
     list_count_match(ca, element.get(0).unwrap())
 }
 
 pub(super) fn sum(s: &Series) -> PolarsResult<Series> {
     Ok(s.list()?.lst_sum())
 }
+
+#[cfg(feature = "list_sets")]
+pub(super) fn set_operation(s: &[Series], set_type: SetOperation) -> PolarsResult<Series> {
+    let s0 = &s[0];
+    let s1 = &s[1];
+    Ok(list_set_operation(s0.list()?, s1.list()?, set_type).into_series())
+}
+
+#[cfg(feature = "list_any_all")]
+pub(super) fn lst_any(s: &Series) -> PolarsResult<Series> {
+    s.list()?.lst_any()
+}
+
+#[cfg(feature = "list_any_all")]
+pub(super) fn lst_all(s: &Series) -> PolarsResult<Series> {
+    s.list()?.lst_all()
+}
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/log.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/log.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/mod.rs`

 * *Files 10% similar despite different names*

```diff
@@ -21,14 +21,18 @@
 #[cfg(feature = "fused")]
 mod fused;
 mod list;
 #[cfg(feature = "log")]
 mod log;
 mod nan;
 mod pow;
+#[cfg(feature = "random")]
+mod random;
+#[cfg(feature = "range")]
+mod range;
 #[cfg(all(feature = "rolling_window", feature = "moment"))]
 mod rolling;
 #[cfg(feature = "round_series")]
 mod round;
 #[cfg(feature = "row_hash")]
 mod row_hash;
 mod schema;
@@ -45,32 +49,40 @@
 #[cfg(any(feature = "temporal", feature = "date_offset"))]
 mod temporal;
 #[cfg(feature = "trigonometry")]
 mod trigonometry;
 mod unique;
 
 use std::fmt::{Display, Formatter};
+#[cfg(feature = "random")]
+use std::sync::atomic::AtomicU64;
 
 #[cfg(feature = "dtype-array")]
 pub(super) use array::ArrayFunction;
 pub(crate) use correlation::CorrelationMethod;
 #[cfg(feature = "fused")]
 pub(crate) use fused::FusedOperator;
 pub(super) use list::ListFunction;
 use polars_core::prelude::*;
+#[cfg(feature = "cutqcut")]
+use polars_ops::prelude::{cut, qcut};
+#[cfg(feature = "random")]
+pub(crate) use random::RandomMethod;
 use schema::FieldsMapper;
 #[cfg(feature = "serde")]
 use serde::{Deserialize, Serialize};
 
 pub(crate) use self::binary::BinaryFunction;
 pub use self::boolean::BooleanFunction;
 #[cfg(feature = "dtype-categorical")]
 pub(crate) use self::cat::CategoricalFunction;
 #[cfg(feature = "temporal")]
 pub(super) use self::datetime::TemporalFunction;
+#[cfg(feature = "range")]
+pub(super) use self::range::RangeFunction;
 #[cfg(feature = "strings")]
 pub(crate) use self::strings::StringFunction;
 #[cfg(feature = "dtype-struct")]
 pub(super) use self::struct_::StructFunction;
 #[cfg(feature = "trigonometry")]
 pub(super) use self::trigonometry::TrigonometricFunction;
 use super::*;
@@ -89,14 +101,16 @@
     #[cfg(feature = "search_sorted")]
     SearchSorted(SearchSortedSide),
     #[cfg(feature = "strings")]
     StringExpr(StringFunction),
     BinaryExpr(BinaryFunction),
     #[cfg(feature = "temporal")]
     TemporalExpr(TemporalFunction),
+    #[cfg(feature = "range")]
+    Range(RangeFunction),
     #[cfg(feature = "date_offset")]
     DateOffset(polars_time::Duration),
     #[cfg(feature = "trigonometry")]
     Trigonometry(TrigonometricFunction),
     #[cfg(feature = "sign")]
     Sign,
     FillNull {
@@ -182,15 +196,36 @@
     #[cfg(feature = "fused")]
     Fused(fused::FusedOperator),
     ConcatExpr(bool),
     Correlation {
         method: correlation::CorrelationMethod,
         ddof: u8,
     },
+    #[cfg(feature = "cutqcut")]
+    Cut {
+        breaks: Vec<f64>,
+        labels: Option<Vec<String>>,
+        left_closed: bool,
+    },
+    #[cfg(feature = "cutqcut")]
+    QCut {
+        probs: Vec<f64>,
+        labels: Option<Vec<String>>,
+        left_closed: bool,
+        allow_duplicates: bool,
+    },
     ToPhysical,
+    #[cfg(feature = "random")]
+    Random {
+        method: random::RandomMethod,
+        #[cfg_attr(feature = "serde", serde(skip))]
+        atomic_seed: Option<SpecialEq<Arc<AtomicU64>>>,
+        seed: Option<u64>,
+        fixed_seed: bool,
+    },
 }
 
 impl Display for FunctionExpr {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         use FunctionExpr::*;
 
         let s = match self {
@@ -205,14 +240,16 @@
             #[cfg(feature = "search_sorted")]
             SearchSorted(_) => "search_sorted",
             #[cfg(feature = "strings")]
             StringExpr(s) => return write!(f, "{s}"),
             BinaryExpr(b) => return write!(f, "{b}"),
             #[cfg(feature = "temporal")]
             TemporalExpr(fun) => return write!(f, "{fun}"),
+            #[cfg(feature = "range")]
+            Range(func) => return write!(f, "{func}"),
             #[cfg(feature = "date_offset")]
             DateOffset(_) => "dt.offset_by",
             #[cfg(feature = "trigonometry")]
             Trigonometry(func) => return write!(f, "{func}"),
             #[cfg(feature = "sign")]
             Sign => "sign",
             FillNull { .. } => "fill_null",
@@ -275,15 +312,21 @@
             LowerBound => "lower_bound",
             #[cfg(feature = "fused")]
             Fused(fused) => return Display::fmt(fused, f),
             #[cfg(feature = "dtype-array")]
             ArrayExpr(af) => return Display::fmt(af, f),
             ConcatExpr(_) => "concat_expr",
             Correlation { method, .. } => return Display::fmt(method, f),
+            #[cfg(feature = "cutqcut")]
+            Cut { .. } => "cut",
+            #[cfg(feature = "cutqcut")]
+            QCut { .. } => "qcut",
             ToPhysical => "to_physical",
+            #[cfg(feature = "random")]
+            Random { method, .. } => method.into(),
         };
         write!(f, "{s}")
     }
 }
 
 #[macro_export]
 macro_rules! wrap {
@@ -387,14 +430,16 @@
                 map_as_slice!(search_sorted::search_sorted_impl, side)
             }
             #[cfg(feature = "strings")]
             StringExpr(s) => s.into(),
             BinaryExpr(s) => s.into(),
             #[cfg(feature = "temporal")]
             TemporalExpr(func) => func.into(),
+            #[cfg(feature = "range")]
+            Range(func) => func.into(),
 
             #[cfg(feature = "date_offset")]
             DateOffset(offset) => {
                 map_owned!(temporal::date_offset, offset)
             }
             #[cfg(feature = "trigonometry")]
             Trigonometry(trig_function) => {
@@ -429,14 +474,20 @@
                     Slice => wrap!(list::slice),
                     Get => wrap!(list::get),
                     #[cfg(feature = "list_take")]
                     Take(null_ob_oob) => map_as_slice!(list::take, null_ob_oob),
                     #[cfg(feature = "list_count")]
                     CountMatch => map_as_slice!(list::count_match),
                     Sum => map!(list::sum),
+                    #[cfg(feature = "list_sets")]
+                    SetOperation(s) => map_as_slice!(list::set_operation, s),
+                    #[cfg(feature = "list_any_all")]
+                    Any => map!(list::lst_any),
+                    #[cfg(feature = "list_any_all")]
+                    All => map!(list::lst_all),
                 }
             }
             #[cfg(feature = "dtype-array")]
             ArrayExpr(lf) => {
                 use ArrayFunction::*;
                 match lf {
                     Min => map!(array::min),
@@ -494,15 +545,47 @@
             Ceil => map!(round::ceil),
             UpperBound => map!(bounds::upper_bound),
             LowerBound => map!(bounds::lower_bound),
             #[cfg(feature = "fused")]
             Fused(op) => map_as_slice!(fused::fused, op),
             ConcatExpr(rechunk) => map_as_slice!(concat::concat_expr, rechunk),
             Correlation { method, ddof } => map_as_slice!(correlation::corr, ddof, method),
+            #[cfg(feature = "cutqcut")]
+            Cut {
+                breaks,
+                labels,
+                left_closed,
+            } => map!(cut, breaks.clone(), labels.clone(), left_closed),
+            #[cfg(feature = "cutqcut")]
+            QCut {
+                probs,
+                labels,
+                left_closed,
+                allow_duplicates,
+            } => map!(
+                qcut,
+                probs.clone(),
+                labels.clone(),
+                left_closed,
+                allow_duplicates
+            ),
             ToPhysical => map!(dispatch::to_physical),
+            #[cfg(feature = "random")]
+            Random {
+                method,
+                seed,
+                atomic_seed,
+                fixed_seed,
+            } => map!(
+                random::random,
+                method,
+                atomic_seed.as_deref(),
+                seed,
+                fixed_seed
+            ),
         }
     }
 }
 
 #[cfg(feature = "strings")]
 impl From<StringFunction> for SpecialEq<Arc<dyn SeriesUdf>> {
     fn from(func: StringFunction) -> Self {
@@ -608,36 +691,65 @@
             Nanosecond => map!(datetime::nanosecond),
             TimeStamp(tu) => map!(datetime::timestamp, tu),
             Truncate(every, offset) => map!(datetime::truncate, &every, &offset),
             #[cfg(feature = "date_offset")]
             MonthStart => map!(datetime::month_start),
             #[cfg(feature = "date_offset")]
             MonthEnd => map!(datetime::month_end),
+            #[cfg(feature = "timezones")]
+            BaseUtcOffset => map!(datetime::base_utc_offset),
+            #[cfg(feature = "timezones")]
+            DSTOffset => map!(datetime::dst_offset),
             Round(every, offset) => map!(datetime::round, &every, &offset),
             #[cfg(feature = "timezones")]
             CastTimezone(tz, use_earliest) => {
                 map!(datetime::replace_timezone, tz.as_deref(), use_earliest)
             }
             #[cfg(feature = "timezones")]
             TzLocalize(tz) => map!(datetime::tz_localize, &tz),
             Combine(tu) => map_as_slice!(temporal::combine, tu),
-            DateRange { every, closed, tz } => {
+            DateRange {
+                every,
+                closed,
+                time_unit,
+                tz,
+            } => {
                 map_as_slice!(
                     temporal::temporal_range_dispatch,
                     "date",
                     every,
                     closed,
+                    time_unit,
                     tz.clone()
                 )
             }
             TimeRange { every, closed } => {
                 map_as_slice!(
                     temporal::temporal_range_dispatch,
                     "time",
                     every,
                     closed,
+                    None,
                     None
                 )
             }
         }
     }
 }
+
+#[cfg(feature = "range")]
+impl From<RangeFunction> for SpecialEq<Arc<dyn SeriesUdf>> {
+    fn from(func: RangeFunction) -> Self {
+        use RangeFunction::*;
+        match func {
+            ARange { step } => {
+                map_as_slice!(range::arange, step)
+            }
+            IntRange { step } => {
+                map_as_slice!(range::int_range, step)
+            }
+            IntRanges { step } => {
+                map_as_slice!(range::int_ranges, step)
+            }
+        }
+    }
+}
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/pow.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/schema.rs`

 * *Files 14% similar despite different names*

```diff
@@ -48,34 +48,60 @@
                         dtype => polars_bail!(ComputeError: "expected Datetime, got {}", dtype),
                     },
                     Truncate(..) => mapper.with_same_dtype().unwrap().dtype,
                     #[cfg(feature = "date_offset")]
                     MonthStart => mapper.with_same_dtype().unwrap().dtype,
                     #[cfg(feature = "date_offset")]
                     MonthEnd => mapper.with_same_dtype().unwrap().dtype,
+                    #[cfg(feature = "timezones")]
+                    BaseUtcOffset => DataType::Duration(TimeUnit::Milliseconds),
+                    #[cfg(feature = "timezones")]
+                    DSTOffset => DataType::Duration(TimeUnit::Milliseconds),
                     Round(..) => mapper.with_same_dtype().unwrap().dtype,
                     #[cfg(feature = "timezones")]
                     CastTimezone(tz, _use_earliest) => {
                         return mapper.map_datetime_dtype_timezone(tz.as_ref())
                     }
                     #[cfg(feature = "timezones")]
                     TzLocalize(tz) => return mapper.map_datetime_dtype_timezone(Some(tz)),
-                    DateRange { .. } => return mapper.map_to_supertype(),
-                    TimeRange { .. } => DataType::Time,
+                    DateRange {
+                        every,
+                        closed: _,
+                        time_unit,
+                        tz,
+                    } => {
+                        // output dtype may change based on `every`, `tz`, and `time_unit`
+                        return mapper.map_to_date_range_dtype(every, time_unit, tz);
+                    }
+                    TimeRange { .. } => {
+                        return Ok(Field::new("time", DataType::List(Box::new(DataType::Time))));
+                    }
                     Combine(tu) => match mapper.with_same_dtype().unwrap().dtype {
                         DataType::Datetime(_, tz) => DataType::Datetime(*tu, tz),
                         DataType::Date => DataType::Datetime(*tu, None),
                         dtype => {
                             polars_bail!(ComputeError: "expected Date or Datetime, got {}", dtype)
                         }
                     },
                 };
                 mapper.with_dtype(dtype)
             }
 
+            #[cfg(feature = "range")]
+            Range(fun) => {
+                use RangeFunction::*;
+                let field = match fun {
+                    ARange { .. } => Field::new("arange", DataType::Int64), // This is not always correct
+                    IntRange { .. } => Field::new("int", DataType::Int64),
+                    IntRanges { .. } => {
+                        Field::new("int_range", DataType::List(Box::new(DataType::Int64)))
+                    }
+                };
+                Ok(field)
+            }
             #[cfg(feature = "date_offset")]
             DateOffset(_) => mapper.with_same_dtype(),
             #[cfg(feature = "trigonometry")]
             Trigonometry(_) => mapper.map_to_float_dtype(),
             #[cfg(feature = "sign")]
             Sign => mapper.with_dtype(DataType::Int64),
             FillNull { super_type, .. } => mapper.with_dtype(super_type.clone()),
@@ -94,14 +120,20 @@
                     Slice => mapper.with_same_dtype(),
                     Get => mapper.map_to_list_inner_dtype(),
                     #[cfg(feature = "list_take")]
                     Take(_) => mapper.with_same_dtype(),
                     #[cfg(feature = "list_count")]
                     CountMatch => mapper.with_dtype(IDX_DTYPE),
                     Sum => mapper.nested_sum_type(),
+                    #[cfg(feature = "list_sets")]
+                    SetOperation(_) => mapper.with_same_dtype(),
+                    #[cfg(feature = "list_any_all")]
+                    Any => mapper.with_dtype(DataType::Boolean),
+                    #[cfg(feature = "list_any_all")]
+                    All => mapper.with_dtype(DataType::Boolean),
                 }
             }
             #[cfg(feature = "dtype-array")]
             ArrayExpr(af) => {
                 use ArrayFunction::*;
                 match af {
                     Min | Max => mapper.with_same_dtype(),
@@ -198,15 +230,21 @@
             #[cfg(feature = "round_series")]
             Round { .. } | Floor | Ceil => mapper.with_same_dtype(),
             UpperBound | LowerBound => mapper.with_same_dtype(),
             #[cfg(feature = "fused")]
             Fused(_) => mapper.map_to_supertype(),
             ConcatExpr(_) => mapper.map_to_supertype(),
             Correlation { .. } => mapper.map_to_float_dtype(),
+            #[cfg(feature = "cutqcut")]
+            Cut { .. } => mapper.with_dtype(DataType::Categorical(None)),
+            #[cfg(feature = "cutqcut")]
+            QCut { .. } => mapper.with_dtype(DataType::Categorical(None)),
             ToPhysical => mapper.to_physical_type(),
+            #[cfg(feature = "random")]
+            Random { .. } => mapper.with_same_dtype(),
         }
     }
 }
 
 pub(super) struct FieldsMapper<'a> {
     fields: &'a [Field],
 }
@@ -286,14 +324,73 @@
             .inner_dtype()
             .cloned()
             .unwrap_or(DataType::Unknown);
         first.coerce(dt);
         Ok(first)
     }
 
+    #[cfg(feature = "temporal")]
+    pub(super) fn map_to_date_range_dtype(
+        &self,
+        every: &Duration,
+        time_unit: &Option<TimeUnit>,
+        tz: &Option<String>,
+    ) -> PolarsResult<Field> {
+        let inner_dtype = match (&self.map_to_supertype()?.dtype, time_unit, tz, every) {
+            #[cfg(feature = "timezones")]
+            (DataType::Datetime(tu, Some(field_tz)), time_unit, Some(tz), _) => {
+                if field_tz != tz {
+                    polars_bail!(ComputeError: format!("Given time_zone is different from that of timezone aware datetimes. \
+                    Given: '{}', got: '{}'.", tz, field_tz))
+                }
+                if let Some(time_unit) = time_unit {
+                    DataType::Datetime(*time_unit, Some(tz.to_string()))
+                } else {
+                    DataType::Datetime(*tu, Some(tz.to_string()))
+                }
+            }
+            #[cfg(feature = "timezones")]
+            (DataType::Datetime(_, Some(tz)), Some(time_unit), _, _) => {
+                DataType::Datetime(*time_unit, Some(tz.to_string()))
+            }
+            #[cfg(feature = "timezones")]
+            (DataType::Datetime(tu, Some(tz)), None, _, _) => {
+                DataType::Datetime(*tu, Some(tz.to_string()))
+            }
+            #[cfg(feature = "timezones")]
+            (DataType::Datetime(_, _), Some(time_unit), Some(tz), _) => {
+                DataType::Datetime(*time_unit, Some(tz.to_string()))
+            }
+            #[cfg(feature = "timezones")]
+            (DataType::Datetime(tu, _), None, Some(tz), _) => {
+                DataType::Datetime(*tu, Some(tz.to_string()))
+            }
+            (DataType::Datetime(_, _), Some(time_unit), _, _) => {
+                DataType::Datetime(*time_unit, None)
+            }
+            (DataType::Datetime(tu, _), None, _, _) => DataType::Datetime(*tu, None),
+            (DataType::Date, time_unit, time_zone, every) => {
+                let nsecs = every.nanoseconds();
+                if nsecs == 0 {
+                    DataType::Date
+                } else if let Some(tu) = time_unit {
+                    DataType::Datetime(*tu, time_zone.clone())
+                } else if nsecs % 1000 != 0 {
+                    DataType::Datetime(TimeUnit::Nanoseconds, time_zone.clone())
+                } else {
+                    DataType::Datetime(TimeUnit::Microseconds, time_zone.clone())
+                }
+            }
+            (dtype, _, _, _) => {
+                polars_bail!(ComputeError: "expected Date or Datetime, got {}", dtype)
+            }
+        };
+        Ok(Field::new("date", DataType::List(Box::new(inner_dtype))))
+    }
+
     /// Map the dtypes to the "supertype" of a list of lists.
     pub(super) fn map_to_list_supertype(&self) -> PolarsResult<Field> {
         self.try_map_dtypes(|dts| {
             let mut super_type_inner = None;
 
             for dt in dts {
                 match dt {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/shift_and_fill.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/shrink_type.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/sign.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/strings.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/struct_.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/temporal.rs`

 * *Files 27% similar despite different names*

```diff
@@ -78,84 +78,170 @@
 }
 
 pub(super) fn temporal_range_dispatch(
     s: &[Series],
     name: &str,
     every: Duration,
     closed: ClosedWindow,
-    _tz: Option<TimeZone>, // todo: respect _tz: https://github.com/pola-rs/polars/issues/8512
+    time_unit: Option<TimeUnit>,
+    time_zone: Option<TimeZone>,
 ) -> PolarsResult<Series> {
     let start = &s[0];
     let stop = &s[1];
 
     polars_ensure!(
         start.len() == stop.len(),
         ComputeError: "'start' and 'stop' should have the same length",
     );
     const TO_MS: i64 = SECONDS_IN_DAY * 1000;
 
-    let rng_start = start.to_physical_repr();
-    let rng_stop = stop.to_physical_repr();
-    let dtype = start.dtype();
+    // Note: `start` and `stop` have already been cast to their supertype,
+    // so only `start`'s dtype needs to be matched against.
+    #[allow(unused_mut)] // `dtype` is mutated within a "feature = timezones" block.
+    let mut dtype = match (start.dtype(), time_unit) {
+        (DataType::Date, time_unit) => {
+            let nsecs = every.nanoseconds();
+            if nsecs == 0 {
+                DataType::Date
+            } else if let Some(tu) = time_unit {
+                DataType::Datetime(tu, None)
+            } else if nsecs % 1_000 != 0 {
+                DataType::Datetime(TimeUnit::Nanoseconds, None)
+            } else {
+                DataType::Datetime(TimeUnit::Microseconds, None)
+            }
+        }
+        (DataType::Time, _) => DataType::Time,
+        // overwrite nothing, keep as-is
+        (DataType::Datetime(_, _), None) => start.dtype().clone(),
+        // overwrite time unit, keep timezone
+        (DataType::Datetime(_, tz), Some(tu)) => DataType::Datetime(tu, tz.clone()),
+        _ => unreachable!(),
+    };
 
-    let mut start = rng_start.cast(&DataType::Int64)?;
-    let mut stop = rng_stop.cast(&DataType::Int64)?;
+    let (mut start, mut stop) = match dtype {
+        #[cfg(feature = "timezones")]
+        DataType::Datetime(_, Some(_)) => (
+            start
+                .cast(&dtype)?
+                .datetime()
+                .unwrap()
+                .replace_time_zone(None, None)?
+                .into_series()
+                .to_physical_repr()
+                .cast(&DataType::Int64)?,
+            stop.cast(&dtype)?
+                .datetime()
+                .unwrap()
+                .replace_time_zone(None, None)?
+                .into_series()
+                .to_physical_repr()
+                .cast(&DataType::Int64)?,
+        ),
+        _ => (
+            start
+                .cast(&dtype)?
+                .to_physical_repr()
+                .cast(&DataType::Int64)?,
+            stop.cast(&dtype)?
+                .to_physical_repr()
+                .cast(&DataType::Int64)?,
+        ),
+    };
 
-    let (tu, tz) = match dtype {
-        DataType::Date => {
-            start = &start * TO_MS;
-            stop = &stop * TO_MS;
-            (TimeUnit::Milliseconds, None)
+    if dtype == DataType::Date {
+        start = &start * TO_MS;
+        stop = &stop * TO_MS;
+    }
+
+    // overwrite time zone, if specified
+    match (&dtype, &time_zone) {
+        #[cfg(feature = "timezones")]
+        (DataType::Datetime(tu, _), Some(tz)) => {
+            dtype = DataType::Datetime(*tu, Some(tz.clone()));
         }
-        DataType::Datetime(tu, tz) => (*tu, tz.as_ref()),
-        DataType::Time => (TimeUnit::Nanoseconds, None),
-        _ => unimplemented!(),
+        _ => {}
     };
+
     let start = start.i64().unwrap();
     let stop = stop.i64().unwrap();
 
     let list = match dtype {
         DataType::Date => {
             let mut builder = ListPrimitiveChunkedBuilder::<Int32Type>::new(
                 name,
                 start.len(),
                 start.len() * 5,
                 DataType::Int32,
             );
             for (start, stop) in start.into_iter().zip(stop.into_iter()) {
                 match (start, stop) {
                     (Some(start), Some(stop)) => {
-                        let rng = date_range_impl("", start, stop, every, closed, tu, tz)?;
+                        let rng = date_range_impl(
+                            "",
+                            start,
+                            stop,
+                            every,
+                            closed,
+                            TimeUnit::Milliseconds,
+                            None,
+                        )?;
                         let rng = rng.cast(&DataType::Date).unwrap();
                         let rng = rng.to_physical_repr();
                         let rng = rng.i32().unwrap();
                         builder.append_slice(rng.cont_slice().unwrap())
                     }
                     _ => builder.append_null(),
                 }
             }
             builder.finish().into_series()
         }
-        DataType::Datetime(_, _) | DataType::Time => {
+        DataType::Datetime(tu, ref tz) => {
+            let mut builder = ListPrimitiveChunkedBuilder::<Int64Type>::new(
+                name,
+                start.len(),
+                start.len() * 5,
+                DataType::Int64,
+            );
+            for (start, stop) in start.into_iter().zip(stop.into_iter()) {
+                match (start, stop) {
+                    (Some(start), Some(stop)) => {
+                        let rng = date_range_impl("", start, stop, every, closed, tu, tz.as_ref())?;
+                        builder.append_slice(rng.cont_slice().unwrap())
+                    }
+                    _ => builder.append_null(),
+                }
+            }
+            builder.finish().into_series()
+        }
+        DataType::Time => {
             let mut builder = ListPrimitiveChunkedBuilder::<Int64Type>::new(
                 name,
                 start.len(),
                 start.len() * 5,
                 DataType::Int64,
             );
             for (start, stop) in start.into_iter().zip(stop.into_iter()) {
                 match (start, stop) {
                     (Some(start), Some(stop)) => {
-                        let rng = date_range_impl("", start, stop, every, closed, tu, tz)?;
+                        let rng = date_range_impl(
+                            "",
+                            start,
+                            stop,
+                            every,
+                            closed,
+                            TimeUnit::Nanoseconds,
+                            None,
+                        )?;
                         builder.append_slice(rng.cont_slice().unwrap())
                     }
                     _ => builder.append_null(),
                 }
             }
             builder.finish().into_series()
         }
         _ => unimplemented!(),
     };
 
-    let to_type = DataType::List(Box::new(dtype.clone()));
+    let to_type = DataType::List(Box::new(dtype));
     list.cast(&to_type)
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/function_expr/trigonometry.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/arity.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/arity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/coerce.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/coerce.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/concat.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/concat.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/correlation.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/correlation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/horizontal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/horizontal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/index.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/index.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,15 +1,15 @@
-#[cfg(any(feature = "arange", feature = "arg_where"))]
+#[cfg(any(feature = "range", feature = "arg_where"))]
 use super::*;
 
 /// Find the indexes that would sort these series in order of appearance.
 /// That means that the first `Series` will be used to determine the ordering
 /// until duplicates are found. Once duplicates are found, the next `Series` will
 /// be used and so on.
-#[cfg(feature = "arange")]
+#[cfg(feature = "range")]
 pub fn arg_sort_by<E: AsRef<[Expr]>>(by: E, descending: &[bool]) -> Expr {
     let e = &by.as_ref()[0];
     let name = expr_output_name(e).unwrap();
     arange(lit(0 as IdxSize), count().cast(IDX_DTYPE), 1)
         .sort_by(by, descending)
         .alias(name.as_ref())
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/range.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs`

 * *Files 24% similar despite different names*

```diff
@@ -1,275 +1,257 @@
-use super::*;
+use polars_arrow::prelude::DynArgs;
 
-#[cfg(feature = "arange")]
-fn arange_impl<T>(start: T::Native, end: T::Native, step: i64) -> PolarsResult<Option<Series>>
-where
-    T: PolarsNumericType,
-    ChunkedArray<T>: IntoSeries,
-    std::ops::Range<T::Native>: Iterator<Item = T::Native>,
-    std::ops::RangeInclusive<T::Native>: DoubleEndedIterator<Item = T::Native>,
-{
-    let mut ca = match step {
-        1 => ChunkedArray::<T>::from_iter_values("arange", start..end),
-        2.. => ChunkedArray::<T>::from_iter_values("arange", (start..end).step_by(step as usize)),
-        _ => {
-            polars_ensure!(start > end, InvalidOperation: "range must be decreasing if 'step' is negative");
-            ChunkedArray::<T>::from_iter_values(
-                "arange",
-                (end..=start).rev().step_by(step.unsigned_abs() as usize),
-            )
+#[derive(Clone)]
+pub struct RollingOptionsFixedWindow {
+    /// The length of the window.
+    pub window_size: usize,
+    /// Amount of elements in the window that should be filled before computing a result.
+    pub min_periods: usize,
+    /// An optional slice with the same length as the window that will be multiplied
+    ///              elementwise with the values in the window.
+    pub weights: Option<Vec<f64>>,
+    /// Set the labels at the center of the window.
+    pub center: bool,
+    pub fn_params: DynArgs,
+}
+
+impl Default for RollingOptionsFixedWindow {
+    fn default() -> Self {
+        RollingOptionsFixedWindow {
+            window_size: 3,
+            min_periods: 1,
+            weights: None,
+            center: false,
+            fn_params: None,
         }
-    };
-    let is_sorted = if end < start {
-        IsSorted::Descending
-    } else {
-        IsSorted::Ascending
-    };
-    ca.set_sorted_flag(is_sorted);
-    Ok(Some(ca.into_series()))
+    }
 }
 
-// TODO! rewrite this with the apply_private architecture
-/// Create list entries that are range arrays
-/// - if `start` and `end` are a column, every element will expand into an array in a list column.
-/// - if `start` and `end` are literals the output will be of `Int64`.
-#[cfg(feature = "arange")]
-pub fn arange(start: Expr, end: Expr, step: i64) -> Expr {
-    let output_name = "arange";
-
-    let has_col_without_agg = |e: &Expr| {
-        has_expr(e, |ae| matches!(ae, Expr::Column(_)))
-            &&
-            // check if there is no aggregation
-            !has_expr(e, |ae| {
-                matches!(
-                    ae,
-                    Expr::Agg(_)
-                        | Expr::Count
-                        | Expr::AnonymousFunction {
-                            options: FunctionOptions {
-                                collect_groups: ApplyOptions::ApplyGroups,
-                                ..
-                            },
-                            ..
-                        }
-                        | Expr::Function {
-                            options: FunctionOptions {
-                                collect_groups: ApplyOptions::ApplyGroups,
-                                ..
-                            },
-                            ..
-                        },
-                )
-            })
-    };
-    let has_lit = |e: &Expr| {
-        (matches!(e, Expr::Literal(_)) && !matches!(e, Expr::Literal(LiteralValue::Series(_))))
-    };
-
-    let any_column_no_agg = has_col_without_agg(&start) || has_col_without_agg(&end);
-    let literal_start = has_lit(&start);
-    let literal_end = has_lit(&end);
-
-    if (literal_start || literal_end) && !any_column_no_agg {
-        let f = move |sa: Series, sb: Series| {
-            polars_ensure!(step != 0, InvalidOperation: "step must not be zero");
-
-            match sa.dtype() {
-                dt if dt == &IDX_DTYPE => {
-                    let start = sa
-                        .idx()?
-                        .get(0)
-                        .ok_or_else(|| polars_err!(NoData: "no data in `start` evaluation"))?;
-                    let sb = sb.cast(&IDX_DTYPE)?;
-                    let end = sb
-                        .idx()?
-                        .get(0)
-                        .ok_or_else(|| polars_err!(NoData: "no data in `end` evaluation"))?;
-                    #[cfg(feature = "bigidx")]
-                    {
-                        arange_impl::<UInt64Type>(start, end, step)
-                    }
-                    #[cfg(not(feature = "bigidx"))]
-                    {
-                        arange_impl::<UInt32Type>(start, end, step)
-                    }
-                }
-                _ => {
-                    let sa = sa.cast(&DataType::Int64)?;
-                    let sb = sb.cast(&DataType::Int64)?;
-                    let start = sa
-                        .i64()?
-                        .get(0)
-                        .ok_or_else(|| polars_err!(NoData: "no data in `start` evaluation"))?;
-                    let end = sb
-                        .i64()?
-                        .get(0)
-                        .ok_or_else(|| polars_err!(NoData: "no data in `end` evaluation"))?;
-                    arange_impl::<Int64Type>(start, end, step)
-                }
-            }
+#[cfg(feature = "rolling_window")]
+mod inner_mod {
+    use std::ops::SubAssign;
+
+    use arrow::array::{Array, PrimitiveArray};
+    use arrow::bitmap::MutableBitmap;
+    use num_traits::pow::Pow;
+    use num_traits::{Float, Zero};
+    use polars_arrow::bit_util::unset_bit_raw;
+    use polars_arrow::data_types::IsFloat;
+    use polars_arrow::trusted_len::TrustedLenPush;
+
+    use crate::prelude::*;
+
+    /// utility
+    fn check_input(window_size: usize, min_periods: usize) -> PolarsResult<()> {
+        polars_ensure!(
+            min_periods <= window_size,
+            ComputeError: "`window_size`: {} should be >= `min_periods`: {}",
+            window_size, min_periods
+        );
+        Ok(())
+    }
+
+    /// utility
+    fn window_edges(idx: usize, len: usize, window_size: usize, center: bool) -> (usize, usize) {
+        let (start, end) = if center {
+            let right_window = (window_size + 1) / 2;
+            (
+                idx.saturating_sub(window_size - right_window),
+                len.min(idx + right_window),
+            )
+        } else {
+            (idx.saturating_sub(window_size - 1), idx + 1)
         };
-        apply_binary(
-            start,
-            end,
-            f,
-            GetOutput::map_field(|input| {
-                let dtype = if input.data_type() == &IDX_DTYPE {
-                    IDX_DTYPE
-                } else {
-                    DataType::Int64
-                };
-                Field::new(output_name, dtype)
-            }),
-        )
-        .alias(output_name)
-    } else {
-        let f = move |sa: Series, sb: Series| {
-            polars_ensure!(step != 0, InvalidOperation: "step must not be zero");
-            let mut sa = sa.cast(&DataType::Int64)?;
-            let mut sb = sb.cast(&DataType::Int64)?;
-
-            if sa.len() != sb.len() {
-                if sa.len() == 1 {
-                    sa = sa.new_from_index(0, sb.len())
-                } else if sb.len() == 1 {
-                    sb = sb.new_from_index(0, sa.len())
-                } else {
-                    polars_bail!(
-                        ComputeError:
-                        "lengths of `start`: {} and `end`: {} arguments `\
-                        cannot be matched in the `arange` expression",
-                        sa.len(), sb.len()
-                    );
-                }
+
+        (start, end - start)
+    }
+
+    impl<T> ChunkRollApply for ChunkedArray<T>
+    where
+        T: PolarsNumericType,
+        Self: IntoSeries,
+    {
+        /// Apply a rolling custom function. This is pretty slow because of dynamic dispatch.
+        fn rolling_apply(
+            &self,
+            f: &dyn Fn(&Series) -> Series,
+            mut options: RollingOptionsFixedWindow,
+        ) -> PolarsResult<Series> {
+            check_input(options.window_size, options.min_periods)?;
+
+            let ca = self.rechunk();
+            if options.weights.is_some()
+                && !matches!(self.dtype(), DataType::Float64 | DataType::Float32)
+            {
+                let s = self.cast(&DataType::Float64)?;
+                return s.rolling_apply(f, options);
             }
 
-            let start = sa.i64()?;
-            let end = sb.i64()?;
-            let mut builder = ListPrimitiveChunkedBuilder::<Int64Type>::new(
-                output_name,
-                start.len(),
-                start.len() * 3,
-                DataType::Int64,
-            );
+            options.window_size = std::cmp::min(self.len(), options.window_size);
 
-            for (opt_start, opt_end) in start.into_iter().zip(end.into_iter()) {
-                match (opt_start, opt_end) {
-                    (Some(start_v), Some(end_v)) => match step {
-                        1 => {
-                            builder.append_iter_values(start_v..end_v);
-                        }
-                        2.. => {
-                            builder.append_iter_values((start_v..end_v).step_by(step as usize));
+            let len = self.len();
+            let arr = ca.downcast_iter().next().unwrap();
+            let mut series_container =
+                ChunkedArray::<T>::from_slice("", &[T::Native::zero()]).into_series();
+            let array_ptr = series_container.array_ref(0);
+            let ptr = array_ptr.as_ref() as *const dyn Array as *mut dyn Array
+                as *mut PrimitiveArray<T::Native>;
+            let mut builder = PrimitiveChunkedBuilder::<T>::new(self.name(), self.len());
+
+            if let Some(weights) = options.weights {
+                let weights_series = Float64Chunked::new("weights", &weights).into_series();
+
+                let weights_series = weights_series.cast(self.dtype()).unwrap();
+
+                for idx in 0..len {
+                    let (start, size) = window_edges(idx, len, options.window_size, options.center);
+
+                    if size < options.min_periods {
+                        builder.append_null();
+                    } else {
+                        // safety:
+                        // we are in bounds
+                        let arr_window = unsafe { arr.slice_typed_unchecked(start, size) };
+
+                        // Safety.
+                        // ptr is not dropped as we are in scope
+                        // We are also the only owner of the contents of the Arc
+                        // we do this to reduce heap allocs.
+                        unsafe {
+                            *ptr = arr_window;
                         }
-                        _ => {
-                            polars_ensure!(start_v > end_v, InvalidOperation: "range must be decreasing if 'step' is negative");
-                            builder.append_iter_values(
-                                (end_v..=start_v)
-                                    .rev()
-                                    .step_by(step.unsigned_abs() as usize),
-                            )
-                        }
-                    },
-                    _ => builder.append_null(),
+                        // ensure the length is correct
+                        series_container._get_inner_mut().compute_len();
+
+                        let s = if size == options.window_size {
+                            f(&series_container.multiply(&weights_series).unwrap())
+                        } else {
+                            let weights_cutoff: Series = match self.dtype() {
+                                DataType::Float64 => weights_series
+                                    .f64()
+                                    .unwrap()
+                                    .into_iter()
+                                    .take(series_container.len())
+                                    .collect(),
+                                _ => weights_series // Float32 case
+                                    .f32()
+                                    .unwrap()
+                                    .into_iter()
+                                    .take(series_container.len())
+                                    .collect(),
+                            };
+                            f(&series_container.multiply(&weights_cutoff).unwrap())
+                        };
+
+                        let out = self.unpack_series_matching_type(&s)?;
+                        builder.append_option(out.get(0));
+                    }
                 }
-            }
 
-            Ok(Some(builder.finish().into_series()))
-        };
-        apply_binary(
-            start,
-            end,
-            f,
-            GetOutput::map_field(|_| {
-                Field::new(output_name, DataType::List(DataType::Int64.into()))
-            }),
-        )
-        .alias(output_name)
-    }
-}
+                Ok(builder.finish().into_series())
+            } else {
+                for idx in 0..len {
+                    let (start, size) = window_edges(idx, len, options.window_size, options.center);
+
+                    if size < options.min_periods {
+                        builder.append_null();
+                    } else {
+                        // safety:
+                        // we are in bounds
+                        let arr_window = unsafe { arr.slice_typed_unchecked(start, size) };
+
+                        // Safety.
+                        // ptr is not dropped as we are in scope
+                        // We are also the only owner of the contents of the Arc
+                        // we do this to reduce heap allocs.
+                        unsafe {
+                            *ptr = arr_window;
+                        }
+                        // ensure the length is correct
+                        series_container._get_inner_mut().compute_len();
 
-pub trait Range<T> {
-    fn into_range(self, high: T) -> Expr;
-}
+                        let s = f(&series_container);
+                        let out = self.unpack_series_matching_type(&s)?;
+                        builder.append_option(out.get(0));
+                    }
+                }
 
-macro_rules! impl_into_range {
-    ($dt: ty) => {
-        impl Range<$dt> for $dt {
-            fn into_range(self, high: $dt) -> Expr {
-                Expr::Literal(LiteralValue::Range {
-                    low: self as i64,
-                    high: high as i64,
-                    data_type: DataType::Int32,
-                })
+                Ok(builder.finish().into_series())
             }
         }
-    };
-}
+    }
 
-impl_into_range!(i32);
-impl_into_range!(i64);
-impl_into_range!(u32);
-
-/// Create a range literal.
-pub fn range<T: Range<T>>(low: T, high: T) -> Expr {
-    low.into_range(high)
-}
+    impl<T> ChunkedArray<T>
+    where
+        ChunkedArray<T>: IntoSeries,
+        T: PolarsFloatType,
+        T::Native: Float + IsFloat + SubAssign + Pow<T::Native, Output = T::Native>,
+    {
+        /// Apply a rolling custom function. This is pretty slow because of dynamic dispatch.
+        pub fn rolling_apply_float<F>(&self, window_size: usize, mut f: F) -> PolarsResult<Self>
+        where
+            F: FnMut(&mut ChunkedArray<T>) -> Option<T::Native>,
+        {
+            if window_size > self.len() {
+                return Ok(Self::full_null(self.name(), self.len()));
+            }
+            let ca = self.rechunk();
+            let arr = ca.downcast_iter().next().unwrap();
 
-/// Create a date range from a `start` and `stop` expression.
-#[cfg(feature = "temporal")]
-pub fn date_range(
-    start: Expr,
-    end: Expr,
-    every: Duration,
-    closed: ClosedWindow,
-    tz: Option<TimeZone>,
-) -> Expr {
-    let input = vec![start, end];
-
-    Expr::Function {
-        input,
-        function: FunctionExpr::TemporalExpr(TemporalFunction::DateRange { every, closed, tz }),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            cast_to_supertypes: true,
-            allow_rename: true,
-            ..Default::default()
-        },
-    }
-}
+            // we create a temporary dummy ChunkedArray
+            // this will be a container where we swap the window contents every iteration
+            // doing so will save a lot of heap allocations.
+            let mut heap_container = ChunkedArray::<T>::from_slice("", &[T::Native::zero()]);
+            let array_ptr = &heap_container.chunks()[0];
+            let ptr = array_ptr.as_ref() as *const dyn Array as *mut dyn Array
+                as *mut PrimitiveArray<T::Native>;
+
+            let mut validity = MutableBitmap::with_capacity(ca.len());
+            validity.extend_constant(window_size - 1, false);
+            validity.extend_constant(ca.len() - (window_size - 1), true);
+            let validity_ptr = validity.as_slice().as_ptr() as *mut u8;
+
+            let mut values = Vec::with_capacity(ca.len());
+            values.extend(std::iter::repeat(T::Native::default()).take(window_size - 1));
+
+            for offset in 0..self.len() + 1 - window_size {
+                debug_assert!(offset + window_size <= arr.len());
+                let arr_window = unsafe { arr.slice_typed_unchecked(offset, window_size) };
+                // the lengths are cached, so we must update them
+                heap_container.length = arr_window.len() as IdxSize;
+
+                // Safety.
+                // ptr is not dropped as we are in scope
+                // We are also the only owner of the contents of the Arc
+                // we do this to reduce heap allocs.
+                unsafe {
+                    *ptr = arr_window;
+                }
 
-/// Create a time range from a `start` and `stop` expression.
-#[cfg(feature = "temporal")]
-pub fn time_range(start: Expr, end: Expr, every: Duration, closed: ClosedWindow) -> Expr {
-    let input = vec![start, end];
-
-    Expr::Function {
-        input,
-        function: FunctionExpr::TemporalExpr(TemporalFunction::TimeRange { every, closed }),
-        options: FunctionOptions {
-            collect_groups: ApplyOptions::ApplyGroups,
-            cast_to_supertypes: false,
-            allow_rename: true,
-            ..Default::default()
-        },
+                let out = f(&mut heap_container);
+                match out {
+                    Some(v) => {
+                        // Safety: we have pre-allocated
+                        unsafe { values.push_unchecked(v) }
+                    }
+                    None => {
+                        // safety: we allocated enough for both the `values` vec
+                        // and the `validity_ptr`
+                        unsafe {
+                            values.push_unchecked(T::Native::default());
+                            unset_bit_raw(validity_ptr, offset + window_size - 1);
+                        }
+                    }
+                }
+            }
+            let arr = PrimitiveArray::new(
+                T::get_dtype().to_arrow(),
+                values.into(),
+                Some(validity.into()),
+            );
+            unsafe { Ok(Self::from_chunks(self.name(), vec![Box::new(arr)])) }
+        }
     }
 }
 
-/// Create a column of length `n` containing `n` copies of the literal `value`. Generally you won't need this function,
-/// as `lit(value)` already represents a column containing only `value` whose length is automatically set to the correct
-/// number of rows.
-pub fn repeat<L: Literal>(value: L, n: Expr) -> Expr {
-    let function = |s: Series, n: Series| {
-        polars_ensure!(
-            n.dtype().is_integer(),
-            SchemaMismatch: "expected expression of dtype 'integer', got '{}'", n.dtype()
-        );
-        let first_value = n.get(0)?;
-        let n = first_value.extract::<usize>().ok_or_else(
-            || polars_err!(ComputeError: "could not parse value '{}' as a size.", first_value),
-        )?;
-        Ok(Some(s.new_from_index(0, n)))
-    };
-    apply_binary(lit(value), n, function, GetOutput::same_type()).alias("repeat")
-}
+#[cfg(feature = "rolling_window")]
+pub use inner_mod::*;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/selectors.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/selectors.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/syntactic_sugar.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/syntactic_sugar.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/functions/temporal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/functions/temporal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/list.rs`

 * *Files 18% similar despite different names*

```diff
@@ -10,14 +10,28 @@
 use crate::prelude::function_expr::ListFunction;
 use crate::prelude::*;
 
 /// Specialized expressions for [`Series`] of [`DataType::List`].
 pub struct ListNameSpace(pub Expr);
 
 impl ListNameSpace {
+    #[cfg(feature = "list_any_all")]
+    pub fn any(self) -> Expr {
+        self.0
+            .apply_private(FunctionExpr::ListExpr(ListFunction::Any))
+            .with_fmt("list.any")
+    }
+
+    #[cfg(feature = "list_any_all")]
+    pub fn all(self) -> Expr {
+        self.0
+            .apply_private(FunctionExpr::ListExpr(ListFunction::All))
+            .with_fmt("list.all")
+    }
+
     /// Get lengths of the arrays in the List type.
     pub fn lengths(self) -> Expr {
         let function = |s: Series| {
             let ca = s.list()?;
             Ok(Some(ca.lst_lengths().into_series()))
         };
         self.0
@@ -291,22 +305,66 @@
                 input_wildcard_expansion: true,
                 auto_explode: true,
                 ..Default::default()
             },
         }
     }
     #[cfg(feature = "list_count")]
-    pub fn count_match<E: Into<Expr>>(self, other: E) -> Expr {
-        let other = other.into();
+    /// Count how often the value produced by ``element`` occurs.
+    pub fn count_match<E: Into<Expr>>(self, element: E) -> Expr {
+        let other = element.into();
 
         Expr::Function {
             input: vec![self.0, other],
             function: FunctionExpr::ListExpr(ListFunction::CountMatch),
             options: FunctionOptions {
                 collect_groups: ApplyOptions::ApplyFlat,
                 input_wildcard_expansion: true,
                 auto_explode: true,
                 ..Default::default()
             },
         }
     }
+
+    #[cfg(feature = "list_sets")]
+    fn set_operation(self, other: Expr, set_operation: SetOperation) -> Expr {
+        Expr::Function {
+            input: vec![self.0, other],
+            function: FunctionExpr::ListExpr(ListFunction::SetOperation(set_operation)),
+            options: FunctionOptions {
+                collect_groups: ApplyOptions::ApplyFlat,
+                input_wildcard_expansion: true,
+                auto_explode: false,
+                cast_to_supertypes: true,
+                ..Default::default()
+            },
+        }
+    }
+
+    /// Return the SET UNION between both list arrays.
+    #[cfg(feature = "list_sets")]
+    pub fn union<E: Into<Expr>>(self, other: E) -> Expr {
+        let other = other.into();
+        self.set_operation(other, SetOperation::Union)
+    }
+
+    /// Return the SET DIFFERENCE between both list arrays.
+    #[cfg(feature = "list_sets")]
+    pub fn difference<E: Into<Expr>>(self, other: E) -> Expr {
+        let other = other.into();
+        self.set_operation(other, SetOperation::Difference)
+    }
+
+    /// Return the SET INTERSECTION between both list arrays.
+    #[cfg(feature = "list_sets")]
+    pub fn intersection<E: Into<Expr>>(self, other: E) -> Expr {
+        let other = other.into();
+        self.set_operation(other, SetOperation::Intersection)
+    }
+
+    /// Return the SET SYMMETRIC DIFFERENCE between both list arrays.
+    #[cfg(feature = "list_sets")]
+    pub fn symmetric_difference<E: Into<Expr>>(self, other: E) -> Expr {
+        let other = other.into();
+        self.set_operation(other, SetOperation::SymmetricDifference)
+    }
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -20,14 +20,16 @@
 mod list;
 #[cfg(feature = "meta")]
 mod meta;
 pub(crate) mod names;
 mod options;
 #[cfg(all(feature = "python", feature = "serde"))]
 pub mod python_udf;
+#[cfg(feature = "random")]
+mod random;
 mod selector;
 #[cfg(feature = "strings")]
 pub mod string;
 #[cfg(feature = "dtype-struct")]
 mod struct_;
 
 use std::fmt::Debug;
@@ -1458,14 +1460,47 @@
                 RankMethod::Average => Field::new(fld.name(), DataType::Float32),
                 _ => Field::new(fld.name(), IDX_DTYPE),
             }),
         )
         .with_fmt("rank")
     }
 
+    #[cfg(feature = "cutqcut")]
+    pub fn cut(self, breaks: Vec<f64>, labels: Option<Vec<String>>, left_closed: bool) -> Expr {
+        self.apply_private(FunctionExpr::Cut {
+            breaks,
+            labels,
+            left_closed,
+        })
+        .with_function_options(|mut opt| {
+            opt.allow_group_aware = false;
+            opt
+        })
+    }
+
+    #[cfg(feature = "cutqcut")]
+    pub fn qcut(
+        self,
+        probs: Vec<f64>,
+        labels: Option<Vec<String>>,
+        left_closed: bool,
+        allow_duplicates: bool,
+    ) -> Expr {
+        self.apply_private(FunctionExpr::QCut {
+            probs,
+            labels,
+            left_closed,
+            allow_duplicates,
+        })
+        .with_function_options(|mut opt| {
+            opt.allow_group_aware = false;
+            opt
+        })
+    }
+
     #[cfg(feature = "diff")]
     pub fn diff(self, n: i64, null_behavior: NullBehavior) -> Expr {
         self.apply_private(FunctionExpr::Diff(n, null_behavior))
     }
 
     #[cfg(feature = "pct_change")]
     pub fn pct_change(self, n: i64) -> Expr {
@@ -1555,53 +1590,14 @@
                 Field::new(fld.name(), DataType::List(Box::new(dtype)))
             })
         };
         self.apply(move |s| s.reshape(&dims).map(Some), output_type)
             .with_fmt("reshape")
     }
 
-    #[cfg(feature = "random")]
-    pub fn shuffle(self, seed: Option<u64>) -> Self {
-        self.apply(move |s| Ok(Some(s.shuffle(seed))), GetOutput::same_type())
-            .with_fmt("shuffle")
-    }
-
-    #[cfg(feature = "random")]
-    pub fn sample_n(
-        self,
-        n: usize,
-        with_replacement: bool,
-        shuffle: bool,
-        seed: Option<u64>,
-    ) -> Self {
-        self.apply(
-            move |s| s.sample_n(n, with_replacement, shuffle, seed).map(Some),
-            GetOutput::same_type(),
-        )
-        .with_fmt("sample_n")
-    }
-
-    #[cfg(feature = "random")]
-    pub fn sample_frac(
-        self,
-        frac: f64,
-        with_replacement: bool,
-        shuffle: bool,
-        seed: Option<u64>,
-    ) -> Self {
-        self.apply(
-            move |s| {
-                s.sample_frac(frac, with_replacement, shuffle, seed)
-                    .map(Some)
-            },
-            GetOutput::same_type(),
-        )
-        .with_fmt("sample_frac")
-    }
-
     #[cfg(feature = "ewma")]
     pub fn ewm_mean(self, options: EWMOptions) -> Self {
         use DataType::*;
         self.apply(
             move |s| s.ewm_mean(options).map(Some),
             GetOutput::map_dtype(|dt| match dt {
                 Float64 | Float32 => dt.clone(),
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/options.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/options.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/python_udf.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/python_udf.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,31 @@
 use std::io::Cursor;
 use std::sync::Arc;
 
 use polars_arrow::error::PolarsResult;
 use polars_core::datatypes::{DataType, Field};
 use polars_core::error::*;
+use polars_core::frame::DataFrame;
 use polars_core::prelude::Series;
 use pyo3::types::{PyBytes, PyModule};
 use pyo3::{PyErr, PyObject, Python};
 use serde::ser::Error;
 use serde::{Deserialize, Deserializer, Serialize, Serializer};
 
 use super::expr_dyn_fn::*;
 use crate::constants::MAP_LIST_NAME;
 use crate::prelude::*;
 
 // Will be overwritten on python polar start up.
-pub static mut CALL_LAMBDA: Option<fn(s: Series, lambda: &PyObject) -> PolarsResult<Series>> = None;
+pub static mut CALL_SERIES_UDF_PYTHON: Option<
+    fn(s: Series, lambda: &PyObject) -> PolarsResult<Series>,
+> = None;
+pub static mut CALL_DF_UDF_PYTHON: Option<
+    fn(s: DataFrame, lambda: &PyObject) -> PolarsResult<DataFrame>,
+> = None;
 pub(super) const MAGIC_BYTE_MARK: &[u8] = "POLARS_PYTHON_UDF".as_bytes();
 
 #[derive(Clone, Debug)]
 pub struct PythonFunction(pub PyObject);
 
 impl From<PyObject> for PythonFunction {
     fn from(value: PyObject) -> Self {
@@ -125,17 +131,24 @@
     }
 }
 
 fn from_pyerr(e: PyErr) -> PolarsError {
     PolarsError::ComputeError(format!("error raised in python: {e}").into())
 }
 
+impl DataFrameUdf for PythonFunction {
+    fn call_udf(&self, df: DataFrame) -> PolarsResult<DataFrame> {
+        let func = unsafe { CALL_DF_UDF_PYTHON.unwrap() };
+        func(df, &self.0)
+    }
+}
+
 impl SeriesUdf for PythonUdfExpression {
     fn call_udf(&self, s: &mut [Series]) -> PolarsResult<Option<Series>> {
-        let func = unsafe { CALL_LAMBDA.unwrap() };
+        let func = unsafe { CALL_SERIES_UDF_PYTHON.unwrap() };
 
         let output_type = self.output_type.clone().unwrap_or(DataType::Unknown);
         let out = func(s[0].clone(), &self.python_function)?;
 
         polars_ensure!(
             matches!(output_type, DataType::Unknown) || out.dtype() == &output_type,
             SchemaMismatch:
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/selector.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/selector.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/string.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/dsl/struct_.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/dsl/struct_.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/frame/opt_state.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/frame/opt_state.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/aexpr/mod.rs`

 * *Files 12% similar despite different names*

```diff
@@ -3,22 +3,23 @@
 use std::sync::Arc;
 
 use polars_arrow::prelude::QuantileInterpolOptions;
 use polars_core::frame::groupby::GroupByMethod;
 use polars_core::prelude::*;
 use polars_core::utils::{get_time_units, try_get_supertype};
 use polars_utils::arena::{Arena, Node};
+use strum_macros::IntoStaticStr;
 
 use crate::dsl::function_expr::FunctionExpr;
 use crate::logical_plan::Context;
 use crate::prelude::aexpr::NodeInputs::Single;
 use crate::prelude::names::COUNT;
 use crate::prelude::*;
 
-#[derive(Clone, Debug)]
+#[derive(Clone, Debug, IntoStaticStr)]
 pub enum AAggExpr {
     Min {
         input: Node,
         propagate_nans: bool,
     },
     Max {
         input: Node,
@@ -193,29 +194,67 @@
         ctxt: Context,
         arena: &Arena<AExpr>,
     ) -> PolarsResult<DataType> {
         self.to_field(schema, ctxt, arena)
             .map(|f| f.data_type().clone())
     }
 
-    pub(crate) fn replace_input(self, input: Node) -> Self {
+    pub(crate) fn replace_inputs(mut self, inputs: &[Node]) -> Self {
         use AExpr::*;
-        match self {
-            Alias(_, name) => Alias(input, name),
-            Cast {
-                expr: _,
-                data_type,
-                strict,
-            } => Cast {
-                expr: input,
-                data_type,
-                strict,
-            },
-            _ => todo!(),
-        }
+        let input = match &mut self {
+            Column(_) | Literal(_) | Wildcard | Count | Nth(_) => return self,
+            Alias(input, _) => input,
+            Cast { expr, .. } => expr,
+            Explode(input) | Slice { input, .. } | Cache { input, .. } => input,
+            BinaryExpr { left, right, .. } => {
+                *left = inputs[0];
+                *right = inputs[1];
+                return self;
+            }
+            Sort { expr, .. } | Take { expr, .. } => expr,
+            SortBy { expr, by, .. } => {
+                *expr = *inputs.last().unwrap();
+                by.clear();
+                by.extend_from_slice(&inputs[..inputs.len() - 1]);
+                return self;
+            }
+            Filter { input, .. } => input,
+            Agg(a) => {
+                a.set_input(inputs[0]);
+                return self;
+            }
+            Ternary {
+                truthy,
+                falsy,
+                predicate,
+            } => {
+                *truthy = inputs[0];
+                *falsy = inputs[1];
+                *predicate = inputs[2];
+                return self;
+            }
+            AnonymousFunction { input, .. } | Function { input, .. } => {
+                input.clear();
+                input.extend(inputs.iter().rev().copied());
+                return self;
+            }
+            Window {
+                function,
+                partition_by,
+                order_by,
+                ..
+            } => {
+                *function = inputs[0];
+                partition_by.extend_from_slice(&inputs[1..]);
+                assert!(order_by.is_none());
+                return self;
+            }
+        };
+        *input = inputs[0];
+        self
     }
 
     pub(crate) fn get_input(&self) -> NodeInputs {
         use AExpr::*;
         use NodeInputs::*;
         match self {
             Alias(input, _) => Single(*input),
@@ -234,17 +273,19 @@
             Filter { input, .. } => Single(*input),
             Agg(a) => a.get_input(),
             Ternary {
                 truthy,
                 falsy,
                 predicate,
             } => Many(vec![*truthy, *falsy, *predicate]),
+            // we iterate in reverse order, so that the lhs is popped first and will be found
+            // as the root columns/ input columns by `_suffix` and `_keep_name` etc.
             AnonymousFunction { input, .. } | Function { input, .. } => match input.len() {
                 1 => Single(input[0]),
-                _ => Many(input.clone()),
+                _ => Many(input.iter().copied().rev().collect()),
             },
             Window {
                 function,
                 order_by,
                 partition_by,
                 ..
             } => {
@@ -287,14 +328,34 @@
             Sum(input) => Single(*input),
             Count(input) => Single(*input),
             Std(input, _) => Single(*input),
             Var(input, _) => Single(*input),
             AggGroups(input) => Single(*input),
         }
     }
+    pub fn set_input(&mut self, input: Node) {
+        use AAggExpr::*;
+        let node = match self {
+            Min { input, .. } => input,
+            Max { input, .. } => input,
+            Median(input) => input,
+            NUnique(input) => input,
+            First(input) => input,
+            Last(input) => input,
+            Mean(input) => input,
+            Implode(input) => input,
+            Quantile { expr, .. } => expr,
+            Sum(input) => input,
+            Count(input) => input,
+            Std(input, _) => input,
+            Var(input, _) => input,
+            AggGroups(input) => input,
+        };
+        *node = input;
+    }
 }
 
 pub enum NodeInputs {
     Leaf,
     Single(Node),
     Many(Vec<Node>),
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/aexpr/schema.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/alp.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/alp.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/anonymous_scan.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/apply.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/builder.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/builder.rs`

 * *Files 2% similar despite different names*

```diff
@@ -20,14 +20,16 @@
     csv::CsvEncoding,
     csv::NullValues,
 };
 
 use crate::logical_plan::functions::FunctionNode;
 use crate::logical_plan::projection::{is_regex_projection, rewrite_projections};
 use crate::logical_plan::schema::{det_join_schema, FileInfo};
+#[cfg(feature = "python")]
+use crate::prelude::python_udf::PythonFunction;
 use crate::prelude::*;
 use crate::utils;
 
 pub(crate) fn prepare_projection(
     exprs: Vec<Expr>,
     schema: &Schema,
 ) -> PolarsResult<(Vec<Expr>, Schema)> {
@@ -701,14 +703,36 @@
         LogicalPlan::MapFunction {
             input: Box::new(self.0),
             function,
         }
         .into()
     }
 
+    #[cfg(feature = "python")]
+    pub fn map_python(
+        self,
+        function: PythonFunction,
+        optimizations: AllowedOptimizations,
+        schema: Option<SchemaRef>,
+        validate_output: bool,
+    ) -> Self {
+        LogicalPlan::MapFunction {
+            input: Box::new(self.0),
+            function: FunctionNode::OpaquePython {
+                function,
+                schema,
+                predicate_pd: optimizations.predicate_pushdown,
+                projection_pd: optimizations.projection_pushdown,
+                streamable: optimizations.streaming,
+                validate_output,
+            },
+        }
+        .into()
+    }
+
     pub fn map<F>(
         self,
         function: F,
         optimizations: AllowedOptimizations,
         schema: Option<Arc<dyn UdfSchema>>,
         name: &'static str,
     ) -> Self
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/conversion.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/conversion.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/format.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/format.rs`

 * *Files 2% similar despite different names*

```diff
@@ -92,18 +92,23 @@
                 let mut name = String::new();
                 let name = if let Some(slice) = options.slice {
                     write!(name, "SLICED UNION: {:?}", slice)?;
                     name.as_str()
                 } else {
                     "UNION"
                 };
+                // 3 levels of indentation
+                // - 0 => UNION ... END UNION
+                // - 1 => PLAN 0, PLAN 1, ... PLAN N
+                // - 2 => actual formatting of plans
+                let sub_sub_indent = sub_indent + 2;
                 write!(f, "{:indent$}{}", "", name)?;
                 for (i, plan) in inputs.iter().enumerate() {
-                    write!(f, "\n{:indent$}PLAN {i}:", "")?;
-                    plan._format(f, sub_indent)?;
+                    write!(f, "\n{:sub_indent$}PLAN {i}:", "")?;
+                    plan._format(f, sub_sub_indent)?;
                 }
                 write!(f, "\n{:indent$}END {}", "", name)
             }
             Cache { input, id, count } => {
                 write!(f, "{:indent$}CACHE[id: {:x}, count: {}]", "", *id, *count)?;
                 input._format(f, sub_indent)
             }
@@ -223,15 +228,15 @@
                 input._format(f, sub_indent)
             }
             Aggregate {
                 input, keys, aggs, ..
             } => {
                 write!(f, "{:indent$}AGGREGATE", "")?;
                 write!(f, "\n{:indent$}\t{aggs:?} BY {keys:?} FROM", "")?;
-                write!(f, "\n{:indent$}\t{input:?}", "")
+                input._format(f, sub_indent)
             }
             Join {
                 input_left,
                 input_right,
                 left_on,
                 right_on,
                 options,
@@ -313,29 +318,29 @@
                     _ => {
                         write!(f, "{v:?}")
                     }
                 }
             }
             BinaryExpr { left, op, right } => write!(f, "[({left:?}) {op:?} ({right:?})]"),
             Sort { expr, options } => match options.descending {
-                true => write!(f, "{expr:?} DESC"),
-                false => write!(f, "{expr:?} ASC"),
+                true => write!(f, "{expr:?}.sort(desc)"),
+                false => write!(f, "{expr:?}.sort(asc)"),
             },
             SortBy {
                 expr,
                 by,
                 descending,
             } => {
-                write!(f, "SORT {expr:?} BY {by:?} REVERSE ORDERING {descending:?}",)
+                write!(f, "{expr:?}.sort_by(by={by:?}, descending={descending:?})",)
             }
             Filter { input, by } => {
-                write!(f, "{input:?}\nFILTER WHERE {by:?}")
+                write!(f, "{input:?}.filter({by:?})")
             }
             Take { expr, idx } => {
-                write!(f, "TAKE {expr:?} AT {idx:?}")
+                write!(f, "{expr:?}.take({idx:?})")
             }
             Agg(agg) => {
                 use AggExpr::*;
                 match agg {
                     Min {
                         input,
                         propagate_nans,
@@ -383,15 +388,15 @@
             }
             Ternary {
                 predicate,
                 truthy,
                 falsy,
             } => write!(
                 f,
-                "\nWHEN {predicate:?}\nTHEN\n\t{truthy:?}\nOTHERWISE\n\t{falsy:?}",
+                ".when({predicate:?}).then({truthy:?}).otherwise({falsy:?})",
             ),
             Function {
                 input, function, ..
             } => {
                 if input.len() >= 2 {
                     write!(f, "{:?}.{}({:?})", input[0], function, &input[1..])
                 } else {
@@ -407,20 +412,20 @@
             }
             Slice {
                 input,
                 offset,
                 length,
             } => write!(f, "{input:?}.slice(offset={offset:?}, length={length:?})",),
             Wildcard => write!(f, "*"),
-            Exclude(column, names) => write!(f, "{column:?}, EXCEPT {names:?}"),
-            KeepName(e) => write!(f, "KEEP NAME {e:?}"),
-            RenameAlias { expr, .. } => write!(f, "RENAME_ALIAS {expr:?}"),
-            Columns(names) => write!(f, "COLUMNS({names:?})"),
-            DtypeColumn(dt) => write!(f, "COLUMN OF DTYPE: {dt:?}"),
-            Cache { input, .. } => write!(f, "CACHE {input:?}"),
+            Exclude(column, names) => write!(f, "{column:?}.exclude({names:?})"),
+            KeepName(e) => write!(f, "{e:?}.keep_name()"),
+            RenameAlias { expr, .. } => write!(f, ".rename_alias({expr:?})"),
+            Columns(names) => write!(f, "cols({names:?})"),
+            DtypeColumn(dt) => write!(f, "dtype_columns({dt:?})"),
+            Cache { input, .. } => write!(f, "{input:?}.cache()"),
             Selector(_) => write!(f, "SELECTOR"),
         }
     }
 }
 
 impl Debug for Operator {
     fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/merge_sorted.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/mod.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,30 +1,45 @@
 mod drop;
 #[cfg(feature = "merge_sorted")]
 mod merge_sorted;
+#[cfg(feature = "python")]
+mod python_udf;
 mod rename;
 
 use std::borrow::Cow;
 use std::fmt::{Debug, Display, Formatter};
 use std::sync::Arc;
 
 use polars_core::prelude::*;
 #[cfg(feature = "dtype-categorical")]
 use polars_core::IUseStringCache;
 #[cfg(feature = "serde")]
 use serde::{Deserialize, Serialize};
 use smartstring::alias::String as SmartString;
 
+#[cfg(feature = "python")]
+use crate::dsl::python_udf::PythonFunction;
 #[cfg(feature = "merge_sorted")]
 use crate::logical_plan::functions::merge_sorted::merge_sorted;
 use crate::prelude::*;
 
 #[derive(Clone)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub enum FunctionNode {
+    #[cfg(feature = "python")]
+    OpaquePython {
+        function: PythonFunction,
+        schema: Option<SchemaRef>,
+        ///  allow predicate pushdown optimizations
+        predicate_pd: bool,
+        ///  allow projection pushdown optimizations
+        projection_pd: bool,
+        streamable: bool,
+        validate_output: bool,
+    },
     #[cfg_attr(feature = "serde", serde(skip))]
     Opaque {
         function: Arc<dyn DataFrameUdf>,
         schema: Option<Arc<dyn UdfSchema>>,
         ///  allow predicate pushdown optimizations
         predicate_pd: bool,
         ///  allow projection pushdown optimizations
@@ -117,14 +132,16 @@
             | FastProjection { .. }
             | Unnest { .. }
             | Rename { .. }
             | Explode { .. }
             | Drop { .. } => true,
             Melt { args, .. } => args.streamable,
             Opaque { streamable, .. } => *streamable,
+            #[cfg(feature = "python")]
+            OpaquePython { streamable, .. } => *streamable,
         }
     }
 
     /// Whether this function will increase the number of rows
     pub fn expands_rows(&self) -> bool {
         use FunctionNode::*;
         match self {
@@ -144,14 +161,19 @@
             Opaque { schema, .. } => match schema {
                 None => Ok(Cow::Borrowed(input_schema)),
                 Some(schema_fn) => {
                     let output_schema = schema_fn.get_schema(input_schema)?;
                     Ok(Cow::Owned(output_schema))
                 }
             },
+            #[cfg(feature = "python")]
+            OpaquePython { schema, .. } => Ok(schema
+                .as_ref()
+                .map(|schema| Cow::Owned(schema.clone()))
+                .unwrap_or_else(|| Cow::Borrowed(input_schema))),
             Pipeline { schema, .. } => Ok(Cow::Owned(schema.clone())),
             FastProjection { columns } => {
                 let schema = columns
                     .iter()
                     .map(|name| {
                         let name = name.as_ref();
                         input_schema.try_get_field(name)
@@ -198,14 +220,16 @@
         }
     }
 
     pub(crate) fn allow_predicate_pd(&self) -> bool {
         use FunctionNode::*;
         match self {
             Opaque { predicate_pd, .. } => *predicate_pd,
+            #[cfg(feature = "python")]
+            OpaquePython { predicate_pd, .. } => *predicate_pd,
             FastProjection { .. }
             | DropNulls { .. }
             | Rechunk
             | Unnest { .. }
             | Rename { .. }
             | Explode { .. }
             | Melt { .. }
@@ -216,14 +240,16 @@
         }
     }
 
     pub(crate) fn allow_projection_pd(&self) -> bool {
         use FunctionNode::*;
         match self {
             Opaque { projection_pd, .. } => *projection_pd,
+            #[cfg(feature = "python")]
+            OpaquePython { projection_pd, .. } => *projection_pd,
             FastProjection { .. }
             | DropNulls { .. }
             | Rechunk
             | Unnest { .. }
             | Rename { .. }
             | Explode { .. }
             | Melt { .. }
@@ -245,14 +271,21 @@
         }
     }
 
     pub fn evaluate(&mut self, mut df: DataFrame) -> PolarsResult<DataFrame> {
         use FunctionNode::*;
         match self {
             Opaque { function, .. } => function.call_udf(df),
+            #[cfg(feature = "python")]
+            OpaquePython {
+                function,
+                validate_output,
+                schema,
+                ..
+            } => python_udf::call_python_udf(function, df, *validate_output, schema.as_deref()),
             FastProjection { columns } => df.select(columns.as_ref()),
             DropNulls { subset } => df.drop_nulls(Some(subset.as_ref())),
             Rechunk => {
                 df.as_single_chunk_par();
                 Ok(df)
             }
             #[cfg(feature = "merge_sorted")]
@@ -267,15 +300,15 @@
                     panic!("activate feature 'dtype-struct'")
                 }
             }
             Pipeline { function, .. } => {
                 // we use a global string cache here as streaming chunks all have different rev maps
                 #[cfg(feature = "dtype-categorical")]
                 {
-                    let _hold = IUseStringCache::new();
+                    let _hold = IUseStringCache::hold();
                     Arc::get_mut(function).unwrap().call_udf(df)
                 }
 
                 #[cfg(not(feature = "dtype-categorical"))]
                 {
                     Arc::get_mut(function).unwrap().call_udf(df)
                 }
@@ -298,14 +331,16 @@
 }
 
 impl Display for FunctionNode {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         use FunctionNode::*;
         match self {
             Opaque { fmt_str, .. } => write!(f, "{fmt_str}"),
+            #[cfg(feature = "python")]
+            OpaquePython { .. } => write!(f, "python dataframe udf"),
             FastProjection { columns } => {
                 write!(f, "FAST_PROJECT: ")?;
                 let columns = columns.as_ref();
                 fmt_column_delimited(f, columns, "[", "]")
             }
             DropNulls { subset } => {
                 write!(f, "DROP_NULLS by: ")?;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/functions/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/iterator.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/iterator.rs`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,12 @@
 use polars_arrow::error::PolarsResult;
 
 use crate::prelude::*;
+
+#[macro_export]
 macro_rules! push_expr {
     ($current_expr:expr, $push:ident, $iter:ident) => {{
         use Expr::*;
         match $current_expr {
             Nth(_) | Column(_) | Literal(_) | Wildcard | Columns(_) | DtypeColumn(_) | Count => {}
             Alias(e, _) => $push(e),
             BinaryExpr { left, op: _, right } => {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/lit.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/lit.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -26,14 +26,17 @@
 mod lit;
 pub(crate) mod optimizer;
 pub(crate) mod options;
 pub(crate) mod projection;
 #[cfg(feature = "python")]
 mod pyarrow;
 mod schema;
+#[cfg(feature = "meta")]
+pub(crate) mod tree_format;
+pub mod visitor;
 
 pub use aexpr::*;
 pub use alp::*;
 pub use anonymous_scan::*;
 pub use apply::*;
 pub use builder::*;
 pub use conversion::*;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/cache_states.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/cse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/delay_rechunk.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/drop_nulls.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/fast_projection.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/mod.rs`

 * *Files 22% similar despite different names*

```diff
@@ -1,116 +1,123 @@
-use polars_core::prelude::*;
+mod melt;
 
-use super::*;
-use crate::logical_plan::alp::ALogicalPlan;
-use crate::logical_plan::functions::FunctionNode;
+use melt::process_melt;
 
-/// Projection in the physical plan is done by selecting an expression per thread.
-/// In case of many projections and columns this can be expensive when the expressions are simple
-/// column selections. These can be selected on a single thread. The single thread is faster, because
-/// the eager selection algorithm hashes the column names, making the projection complexity linear
-/// instead of quadratic.
-///
-/// It is important that this optimization is ran after projection pushdown.
-///
-/// The schema reported after this optimization is also
-pub(super) struct FastProjectionAndCollapse {}
+use super::*;
 
-fn impl_fast_projection(
+#[allow(clippy::too_many_arguments)]
+pub(super) fn process_functions(
+    proj_pd: &mut ProjectionPushDown,
     input: Node,
-    expr: &[Node],
+    function: &FunctionNode,
+    mut acc_projections: Vec<Node>,
+    mut projected_names: PlHashSet<Arc<str>>,
+    projections_seen: usize,
+    lp_arena: &mut Arena<ALogicalPlan>,
     expr_arena: &mut Arena<AExpr>,
-) -> Option<ALogicalPlan> {
-    let mut columns = Vec::with_capacity(expr.len());
-    for node in expr.iter() {
-        if let AExpr::Column(name) = expr_arena.get(*node) {
-            columns.push(name.clone())
-        } else {
-            break;
+) -> PolarsResult<ALogicalPlan> {
+    let lp = ALogicalPlan::MapFunction {
+        input,
+        function: function.clone(),
+    };
+
+    use FunctionNode::*;
+    match function {
+        Rename {
+            existing,
+            new,
+            swapping,
+        } => {
+            process_rename(
+                &mut acc_projections,
+                &mut projected_names,
+                expr_arena,
+                existing,
+                new,
+                *swapping,
+            )?;
+            proj_pd.pushdown_and_assign(
+                input,
+                acc_projections,
+                projected_names,
+                projections_seen,
+                lp_arena,
+                expr_arena,
+            )?;
+            Ok(lp)
         }
-    }
-    if columns.len() == expr.len() {
-        let lp = ALogicalPlan::MapFunction {
+        Explode { columns, .. } => {
+            columns.iter().for_each(|name| {
+                add_str_to_accumulated(name, &mut acc_projections, &mut projected_names, expr_arena)
+            });
+            proj_pd.pushdown_and_assign(
+                input,
+                acc_projections,
+                projected_names,
+                projections_seen,
+                lp_arena,
+                expr_arena,
+            )?;
+            Ok(lp)
+        }
+        Melt { args, .. } => process_melt(
+            proj_pd,
+            lp,
+            args,
             input,
-            function: FunctionNode::FastProjection {
-                columns: Arc::from(columns),
-            },
-        };
-
-        Some(lp)
-    } else {
-        None
-    }
-}
+            acc_projections,
+            projections_seen,
+            lp_arena,
+            expr_arena,
+        ),
+        _ => {
+            if function.allow_projection_pd() && !acc_projections.is_empty() {
+                let original_acc_projection_len = acc_projections.len();
+
+                // add columns needed for the function.
+                for name in function.additional_projection_pd_columns().as_ref() {
+                    let node = expr_arena.add(AExpr::Column(name.clone()));
+                    add_expr_to_accumulated(
+                        node,
+                        &mut acc_projections,
+                        &mut projected_names,
+                        expr_arena,
+                    )
+                }
+                let expands_schema = matches!(function, FunctionNode::Unnest { .. });
 
-impl OptimizationRule for FastProjectionAndCollapse {
-    fn optimize_plan(
-        &mut self,
-        lp_arena: &mut Arena<ALogicalPlan>,
-        expr_arena: &mut Arena<AExpr>,
-        node: Node,
-    ) -> Option<ALogicalPlan> {
-        use ALogicalPlan::*;
-        let lp = lp_arena.get(node);
-
-        match lp {
-            Projection { input, expr, .. } => {
-                if !matches!(lp_arena.get(*input), ExtContext { .. }) {
-                    impl_fast_projection(*input, expr, expr_arena)
+                let local_projections = proj_pd.pushdown_and_assign_check_schema(
+                    input,
+                    acc_projections,
+                    projections_seen,
+                    lp_arena,
+                    expr_arena,
+                    expands_schema,
+                )?;
+                if local_projections.is_empty() {
+                    Ok(lp)
                 } else {
-                    None
-                }
-            }
-            LocalProjection { input, expr, .. } => impl_fast_projection(*input, expr, expr_arena),
-            MapFunction {
-                input,
-                function: FunctionNode::FastProjection { columns },
-            } => {
-                // if there are 2 subsequent fast projections, flatten them and only take the last
-                match lp_arena.get(*input) {
-                    MapFunction {
-                        function: FunctionNode::FastProjection { .. },
-                        input: prev_input,
-                    } => Some(MapFunction {
-                        input: *prev_input,
-                        function: FunctionNode::FastProjection {
-                            columns: columns.clone(),
-                        },
-                    }),
-                    // cleanup projections set in projection pushdown just above caches
-                    // they are not needed.
-                    cache_lp @ Cache { .. } => {
-                        if cache_lp.schema(lp_arena).len() == columns.len() {
-                            Some(cache_lp.clone())
-                        } else {
-                            None
-                        }
+                    // if we would project, we would remove pushed down predicates
+                    if local_projections.len() < original_acc_projection_len {
+                        Ok(ALogicalPlanBuilder::from_lp(lp, expr_arena, lp_arena)
+                            .with_columns(local_projections)
+                            .build())
+                        // all projections are local
+                    } else {
+                        Ok(ALogicalPlanBuilder::from_lp(lp, expr_arena, lp_arena)
+                            .project(local_projections)
+                            .build())
                     }
-                    _ => None,
-                }
-            }
-            // if there are 2 subsequent caches, flatten them and only take the inner
-            Cache {
-                input,
-                count: outer_count,
-                ..
-            } => {
-                if let Cache {
-                    input: prev_input,
-                    id,
-                    count,
-                } = lp_arena.get(*input)
-                {
-                    Some(Cache {
-                        input: *prev_input,
-                        id: *id,
-                        // ensure the counts are updated
-                        count: count.saturating_add(*outer_count),
-                    })
-                } else {
-                    None
                 }
+            } else {
+                // restart projection pushdown
+                proj_pd.no_pushdown_restart_opt(
+                    lp,
+                    acc_projections,
+                    projections_seen,
+                    lp_arena,
+                    expr_arena,
+                )
             }
-            _ => None,
         }
     }
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/file_caching.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/flatten_union.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/fused.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/fused.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -114,15 +114,15 @@
         let alp = lp_arena.take(lp_top);
         let alp = predicate_pushdown_opt.optimize(alp, lp_arena, expr_arena)?;
         lp_arena.replace(lp_top, alp);
     }
 
     // make sure its before slice pushdown.
     if projection_pushdown {
-        rules.push(Box::new(FastProjectionAndCollapse {}));
+        rules.push(Box::new(FastProjectionAndCollapse::new()));
     }
     rules.push(Box::new(DelayRechunk::new()));
 
     if slice_pushdown {
         let slice_pushdown_opt = SlicePushDown::new(streaming);
         let alp = lp_arena.take(lp_top);
         let alp = slice_pushdown_opt.optimize(alp, lp_arena, expr_arena)?;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/keys.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/predicate_pushdown/utils.rs`

 * *Files 2% similar despite different names*

```diff
@@ -88,14 +88,21 @@
     };
     has_aexpr(node, expr_arena, matches)
 }
 
 pub(super) fn predicate_is_sort_boundary(node: Node, expr_arena: &Arena<AExpr>) -> bool {
     let matches = |e: &AExpr| match e {
         AExpr::Window { function, .. } => shifts_elements(*function, expr_arena),
+        AExpr::Function { options, .. } | AExpr::AnonymousFunction { options, .. } => {
+            // this check for functions that are
+            // group sensitive and doesn't auto-explode (e.g. is a reduction/aggregation
+            // like sum, min, etc).
+            // function that match this are `cumsum`, `shift`, `sort`, etc.
+            options.is_groups_sensitive() && !options.auto_explode
+        }
         _ => false,
     };
     has_aexpr(node, expr_arena, matches)
 }
 
 // this checks if a predicate from a node upstream can pass
 // the predicate in this filter
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/functions/melt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/generic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/groupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/hstack.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/joins.rs`

 * *Files 2% similar despite different names*

```diff
@@ -342,24 +342,26 @@
     options: &JoinOptions,
 ) {
     // Path for renamed columns due to the join. The column name of the left table
     // stays as is, the column of the right will have the "_right" suffix.
     // Thus joining two tables with both a foo column leads to ["foo", "foo_right"]
 
     // try to push down projection in either of two tables
-    if !proj_pd.join_push_down(
+    let (pushed_at_least_once, already_projected) = proj_pd.join_push_down(
         schema_left,
         schema_right,
         proj,
         pushdown_left,
         pushdown_right,
         names_left,
         names_right,
         expr_arena,
-    )
+    );
+
+    if !(pushed_at_least_once || already_projected)
     // did not succeed push down in any tables.,
     // this might be due to the suffix in the projection name
     // this branch tries to pushdown the column without suffix
     {
         // Column name of the projection without any alias.
         let leaf_column_name = aexpr_to_leaf_names(proj, expr_arena).pop().unwrap();
 
@@ -377,15 +379,15 @@
                 pushdown_right.push(downwards_name_column);
             }
             local_projection.push(proj);
         }
     }
     // did succeed pushdown at least in any of the two tables
     // if not already added locally we ensure we project local as well
-    else if add_local {
+    else if add_local && pushed_at_least_once {
         // always also do the projection locally, because the join columns may not be
         // included in the projection.
         // for instance:
         //
         // SELECT [COLUMN temp]
         // FROM
         // JOIN (["days", "temp"]) WITH (["days", "rain"]) ON (left: days right: days)
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -208,35 +208,37 @@
         schema_right: &Schema,
         proj: Node,
         pushdown_left: &mut Vec<Node>,
         pushdown_right: &mut Vec<Node>,
         names_left: &mut PlHashSet<Arc<str>>,
         names_right: &mut PlHashSet<Arc<str>>,
         expr_arena: &mut Arena<AExpr>,
-    ) -> bool {
+    ) -> (bool, bool) {
         let mut pushed_at_least_one = false;
+        let mut already_projected = false;
         let names = aexpr_to_leaf_names(proj, expr_arena);
         let root_projections = aexpr_to_leaf_nodes(proj, expr_arena);
 
         for (name, root_projection) in names.into_iter().zip(root_projections) {
-            if check_input_node(root_projection, schema_left, expr_arena)
-                && names_left.insert(name.clone())
-            {
+            let was_not_in_left = names_left.insert(name.clone());
+            let was_not_in_right = names_right.insert(name.clone());
+            already_projected |= !was_not_in_left;
+            already_projected |= !was_not_in_right;
+
+            if check_input_node(root_projection, schema_left, expr_arena) && was_not_in_left {
                 pushdown_left.push(proj);
                 pushed_at_least_one = true;
             }
-            if check_input_node(root_projection, schema_right, expr_arena)
-                && names_right.insert(name)
-            {
+            if check_input_node(root_projection, schema_right, expr_arena) && was_not_in_right {
                 pushdown_right.push(proj);
                 pushed_at_least_one = true;
             }
         }
 
-        pushed_at_least_one
+        (pushed_at_least_one, already_projected)
     }
 
     /// This pushes down current node and assigns the result to this node.
     fn pushdown_and_assign(
         &mut self,
         input: Node,
         acc_projections: Vec<Node>,
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/projection.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/rename.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/projection_pushdown/semi_anti_join.rs`

 * *Files 2% similar despite different names*

```diff
@@ -43,15 +43,15 @@
         for e in &right_on {
             add_expr_to_accumulated(*e, &mut pushdown_right, &mut names_right, expr_arena);
         }
 
         for proj in acc_projections {
             let add_local = process_alias(proj, &mut local_projection, expr_arena, true);
 
-            proj_pd.join_push_down(
+            let _ = proj_pd.join_push_down(
                 &schema_left,
                 &schema_right,
                 proj,
                 &mut pushdown_left,
                 &mut pushdown_right,
                 &mut names_left,
                 &mut names_right,
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/simplify_expr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_expr.rs`

 * *Files 0% similar despite different names*

```diff
@@ -27,15 +27,15 @@
 
             use AExpr::*;
             let out = match expr_arena.get(*input) {
                 m @ Alias(..) | m @ Cast { .. } => {
                     let m = m.clone();
                     let input = m.get_input().first();
                     let new_input = pushdown(input, offset, length, expr_arena);
-                    Some(m.replace_input(new_input))
+                    Some(m.replace_inputs(&[new_input]))
                 }
                 Literal(lv) => {
                     match lv {
                         LiteralValue::Series(_) => None,
                         LiteralValue::Range { .. } => None,
                         // no need to slice a literal value of unit length
                         lv => Some(Literal(lv.clone())),
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/slice_pushdown_lp.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/stack_opt.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/binary.rs`

 * *Files 1% similar despite different names*

```diff
@@ -225,17 +225,19 @@
         #[cfg(feature = "dtype-categorical")]
         (Utf8 | Categorical(_), dt, op) | (dt, Utf8 | Categorical(_), op)
             if op.is_comparison() && dt.is_numeric() =>
         {
             return Ok(None)
         }
         #[cfg(feature = "dtype-date")]
-        (Date, Utf8, op) if op.is_comparison() => err_date_str_compare()?,
+        (Date, Utf8, op) | (Utf8, Date, op) if op.is_comparison() => err_date_str_compare()?,
         #[cfg(feature = "dtype-datetime")]
-        (Datetime(_, _), Utf8, op) if op.is_comparison() => err_date_str_compare()?,
+        (Datetime(_, _), Utf8, op) | (Utf8, Datetime(_, _), op) if op.is_comparison() => {
+            err_date_str_compare()?
+        }
         #[cfg(feature = "dtype-time")]
         (Time, Utf8, op) if op.is_comparison() => err_date_str_compare()?,
         // structs can be arbitrarily nested, leave the complexity to the caller for now.
         #[cfg(feature = "dtype-struct")]
         (Struct(_), Struct(_), _op) => return Ok(None),
         _ => {}
     }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/optimizer/type_coercion/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/options.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/options.rs`

 * *Files 1% similar despite different names*

```diff
@@ -186,14 +186,17 @@
 
 #[derive(Clone, Copy, PartialEq, Eq, Debug, Hash)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub struct FunctionOptions {
     /// Collect groups to a list and apply the function over the groups.
     /// This can be important in aggregation context.
     pub collect_groups: ApplyOptions,
+    // used for formatting, (only for anonymous functions)
+    #[cfg_attr(feature = "serde", serde(skip_deserializing))]
+    pub fmt_str: &'static str,
     /// There can be two ways of expanding wildcards:
     ///
     /// Say the schema is 'a', 'b' and there is a function f
     /// f('*')
     /// can expand to:
     /// 1.
     ///     f('a', 'b')
@@ -201,42 +204,38 @@
     /// 2.
     ///     f('a'), f('b')
     ///
     /// setting this to true, will lead to behavior 1.
     ///
     /// this also accounts for regex expansion
     pub input_wildcard_expansion: bool,
-
     /// automatically explode on unit length it ran as final aggregation.
     ///
     /// this is the case for aggregations like sum, min, covariance etc.
     /// We need to know this because we cannot see the difference between
     /// the following functions based on the output type and number of elements:
     ///
     /// x: {1, 2, 3}
     ///
     /// head_1(x) -> {1}
     /// sum(x) -> {4}
     pub auto_explode: bool,
-    // used for formatting, (only for anonymous functions)
-    #[cfg_attr(feature = "serde", serde(skip_deserializing))]
-    pub fmt_str: &'static str,
-
     // if the expression and its inputs should be cast to supertypes
     pub cast_to_supertypes: bool,
     // apply physical expression may rename the output of this function
     pub allow_rename: bool,
     // if set, then the `Series` passed to the function in the groupby operation
     // will ensure the name is set. This is an extra heap allocation per group.
     pub pass_name_to_apply: bool,
     // For example a `unique` or a `slice`
     pub changes_length: bool,
     // Validate the output of a `map`.
     // this should always be true or we could OOB
     pub check_lengths: UnsafeBool,
+    pub allow_group_aware: bool,
 }
 
 impl FunctionOptions {
     /// Any function that is sensitive to the number of elements in a group
     /// - Aggregations
     /// - Sorts
     /// - Counts
@@ -261,14 +260,15 @@
             auto_explode: false,
             fmt_str: "",
             cast_to_supertypes: false,
             allow_rename: false,
             pass_name_to_apply: false,
             changes_length: false,
             check_lengths: UnsafeBool(true),
+            allow_group_aware: true,
         }
     }
 }
 
 #[derive(Clone, Copy, PartialEq, Eq, Debug)]
 pub struct LogicalPlanUdfOptions {
     ///  allow predicate pushdown optimizations
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/projection.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/projection.rs`

 * *Files 2% similar despite different names*

```diff
@@ -191,28 +191,42 @@
         }
         // always keep iterating all inputs
         true
     });
     expr
 }
 
+fn dtypes_match(d1: &DataType, d2: &DataType) -> bool {
+    match (d1, d2) {
+        // note: allow Datetime "*" wildcard for timezones...
+        (DataType::Datetime(tu_l, tz_l), DataType::Datetime(tu_r, tz_r)) => {
+            tu_l == tu_r
+                && (tz_l == tz_r
+                    || tz_r.is_some() && (tz_l.as_deref().unwrap_or("") == "*")
+                    || tz_l.is_some() && (tz_r.as_deref().unwrap_or("") == "*"))
+        }
+        // ...but otherwise require exact match
+        _ => d1 == d2,
+    }
+}
+
 /// replace `DtypeColumn` with `col("foo")..col("bar")`
 fn expand_dtypes(
     expr: &Expr,
     result: &mut Vec<Expr>,
     schema: &Schema,
     dtypes: &[DataType],
     exclude: &PlHashSet<Arc<str>>,
 ) -> PolarsResult<()> {
     // note: we loop over the schema to guarantee that we return a stable
     // field-order, irrespective of which dtypes are filtered against
-    for field in schema
-        .iter_fields()
-        .filter(|f| (dtypes.contains(&f.dtype) && !exclude.contains(f.name().as_str())))
-    {
+    for field in schema.iter_fields().filter(|f| {
+        dtypes.iter().any(|dtype| dtypes_match(dtype, &f.dtype))
+            && !exclude.contains(f.name().as_str())
+    }) {
         let name = field.name();
         let new_expr = expr.clone();
         let new_expr = replace_dtype_with_column(new_expr, Arc::from(name.as_str()));
         let new_expr = rewrite_special_aliases(new_expr)?;
         result.push(new_expr)
     }
     Ok(())
@@ -226,18 +240,17 @@
     keys: &[Expr],
 ) -> PolarsResult<PlHashSet<Arc<str>>> {
     let mut exclude = PlHashSet::new();
     for e in expr {
         if let Expr::Exclude(_, to_exclude) = e {
             #[cfg(feature = "regex")]
             {
-                // instead of matching the names for regex patterns
-                // and expanding the matches in the schema we
-                // reuse the `replace_regex` function. This is a bit
-                // slower but DRY.
+                // instead of matching the names for regex patterns and
+                // expanding the matches in the schema we reuse the
+                // `replace_regex` func; this is a bit slower but DRY.
                 let mut buf = vec![];
                 for to_exclude_single in to_exclude {
                     match to_exclude_single {
                         Excluded::Name(name) => {
                             let e = Expr::Column(name.clone());
                             replace_regex(&e, &mut buf, schema)?;
                             // we cannot loop because of bchck
@@ -245,15 +258,15 @@
                                 if let Expr::Column(name) = col {
                                     exclude.insert(name);
                                 }
                             }
                         }
                         Excluded::Dtype(dt) => {
                             for fld in schema.iter_fields() {
-                                if fld.data_type() == dt {
+                                if dtypes_match(fld.data_type(), dt) {
                                     exclude.insert(Arc::from(fld.name().as_ref()));
                                 }
                             }
                         }
                     }
                 }
             }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/pyarrow.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/logical_plan/schema.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/logical_plan/schema.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/prelude.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-plan/src/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-plan/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-json/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/decode.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/decode.rs`

 * *Files 10% similar despite different names*

```diff
@@ -4,14 +4,30 @@
 use crate::fixed::{decode_bool, decode_primitive};
 use crate::variable::decode_binary;
 
 /// Decode `rows` into a arrow format
 /// # Safety
 /// This will not do any bound checks. Caller must ensure the `rows` are valid
 /// encodings.
+pub unsafe fn decode_rows_from_binary<'a>(
+    arr: &'a BinaryArray<i64>,
+    fields: &[SortField],
+    data_types: &[DataType],
+    rows: &mut Vec<&'a [u8]>,
+) -> Vec<ArrayRef> {
+    assert_eq!(arr.null_count(), 0);
+    rows.clear();
+    rows.extend(arr.values_iter());
+    decode_rows(rows, fields, data_types)
+}
+
+/// Decode `rows` into a arrow format
+/// # Safety
+/// This will not do any bound checks. Caller must ensure the `rows` are valid
+/// encodings.
 pub unsafe fn decode_rows(
     // the rows will be updated while the data is decoded
     rows: &mut [&[u8]],
     fields: &[SortField],
     data_types: &[DataType],
 ) -> Vec<ArrayRef> {
     assert_eq!(fields.len(), data_types.len());
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/encode.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/encode.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/fixed.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/fixed.rs`

 * *Files 2% similar despite different names*

```diff
@@ -212,19 +212,19 @@
     let data_type: DataType = T::PRIMITIVE.into();
     let mut has_nulls = false;
     let null_sentinel = get_null_sentinel(field);
 
     let values = rows
         .iter()
         .map(|row| {
-            has_nulls |= *row.get_unchecked(0) == null_sentinel;
+            has_nulls |= *row.get_unchecked_release(0) == null_sentinel;
             // skip null sentinel
             let start = 1;
             let end = start + T::ENCODED_LEN - 1;
-            let slice = row.get_unchecked(start..end);
+            let slice = row.get_unchecked_release(start..end);
             let bytes = T::Encoded::from_slice(slice);
             T::decode(bytes)
         })
         .collect::<Vec<_>>();
 
     let validity = if has_nulls {
         let null_sentinel = get_null_sentinel(field);
@@ -243,19 +243,19 @@
 pub(super) unsafe fn decode_bool(rows: &mut [&[u8]], field: &SortField) -> BooleanArray {
     let mut has_nulls = false;
     let null_sentinel = get_null_sentinel(field);
 
     let values = rows
         .iter()
         .map(|row| {
-            has_nulls |= *row.get_unchecked(0) == null_sentinel;
+            has_nulls |= *row.get_unchecked_release(0) == null_sentinel;
             // skip null sentinel
             let start = 1;
             let end = start + bool::ENCODED_LEN - 1;
-            let slice = row.get_unchecked(start..end);
+            let slice = row.get_unchecked_release(start..end);
             let bytes = <bool as FixedLengthEncoding>::Encoded::from_slice(slice);
             bool::decode(bytes)
         })
         .collect::<Bitmap>();
 
     let validity = if has_nulls {
         Some(decode_nulls(rows, null_sentinel))
@@ -267,16 +267,16 @@
     let increment_len = bool::ENCODED_LEN;
 
     increment_row_counter(rows, increment_len);
     BooleanArray::new(DataType::Boolean, values, validity)
 }
 unsafe fn increment_row_counter(rows: &mut [&[u8]], fixed_size: usize) {
     for row in rows {
-        *row = row.get_unchecked(fixed_size..);
+        *row = row.get_unchecked_release(fixed_size..);
     }
 }
 
 pub(super) unsafe fn decode_nulls(rows: &[&[u8]], null_sentinel: u8) -> Bitmap {
     rows.iter()
-        .map(|row| *row.get_unchecked(0) != null_sentinel)
+        .map(|row| *row.get_unchecked_release(0) != null_sentinel)
         .collect()
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/lib.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/row.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/row.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-row/src/variable.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-row/src/variable.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-error/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-error/Cargo.toml`

 * *Files 1% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-error/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-error/src/lib.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-error/src/lib.rs`

 * *Files 11% similar despite different names*

```diff
@@ -52,14 +52,16 @@
     NoData(ErrString),
     #[error("field not found: {0}")]
     SchemaFieldNotFound(ErrString),
     #[error("data types don't match: {0}")]
     SchemaMismatch(ErrString),
     #[error("lengths don't match: {0}")]
     ShapeMismatch(ErrString),
+    #[error("string caches don't match: {0}")]
+    StringCacheMismatch(ErrString),
     #[error("field not found: {0}")]
     StructFieldNotFound(ErrString),
 }
 
 impl From<ArrowError> for PolarsError {
     fn from(err: ArrowError) -> Self {
         Self::ArrowError(Box::new(err))
@@ -87,14 +89,15 @@
             Duplicate(msg) => Duplicate(func(msg).into()),
             InvalidOperation(msg) => InvalidOperation(func(msg).into()),
             Io(err) => ComputeError(func(&format!("IO: {err}")).into()),
             NoData(msg) => NoData(func(msg).into()),
             SchemaFieldNotFound(msg) => SchemaFieldNotFound(func(msg).into()),
             SchemaMismatch(msg) => SchemaMismatch(func(msg).into()),
             ShapeMismatch(msg) => ShapeMismatch(func(msg).into()),
+            StringCacheMismatch(msg) => StringCacheMismatch(func(msg).into()),
             StructFieldNotFound(msg) => StructFieldNotFound(func(msg).into()),
         }
     }
 }
 
 pub fn map_err<E: Error>(error: E) -> PolarsError {
     PolarsError::ComputeError(format!("{error}").into())
@@ -154,14 +157,34 @@
     };
     (extend) => {
         polars_err!(SchemaMismatch: "cannot extend series, data types don't match")
     };
     (unpack) => {
         polars_err!(SchemaMismatch: "cannot unpack series, data types don't match")
     };
+    (string_cache_mismatch) => {
+        polars_err!(StringCacheMismatch: r#"
+cannot compare categoricals coming from different sources, consider setting a global StringCache.
+
+Help: if you're using Python, this may look something like:
+
+    with pl.StringCache():
+        # Initialize Categoricals.
+        df1 = pl.DataFrame({'a': ['1', '2']}, schema={'a': pl.Categorical})
+        df2 = pl.DataFrame({'a': ['1', '3']}, schema={'a': pl.Categorical})
+        # Your operations go here.
+        pl.concat([df1, df2])
+
+Alternatively, if the performance cost is acceptable, you could just set:
+
+    import polars as pl
+    pl.enable_string_cache(True)
+
+on startup."#.trim_start())
+    };
     (duplicate = $name:expr) => {
         polars_err!(Duplicate: "column with name '{}' has more than one occurrences", $name)
     };
     (oob = $idx:expr, $len:expr) => {
         polars_err!(ComputeError: "index {} is out of bounds for sequence of size {}", $idx, $len)
     };
     (agg_len = $agg_len:expr, $groups_len:expr) => {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/Cargo.toml`

 * *Files 0% similar despite different names*

```diff
@@ -151,16 +151,16 @@
 [dependencies]
 ahash= "0.8"
 bitflags= "1.3"
 chrono = { version = "0.4", default-features = false, features = ["std"], optional = true }
 chrono-tz = { version = "0.8", optional = true }
 comfy-table = { version = "6.1.4", optional = true, default_features = false }
 either= "1.8"
-hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
-indexmap= { version = "1", features = ["std"] }
+hashbrown= { version = "0.14.0", features = ["rayon", "ahash"] }
+indexmap= { version = "2", features = ["std"] }
 itoap = { version = "1", optional = true, features = ["simd"] }
 ndarray = { version = "0.15", optional = true, default_features = false }
 num-traits= "0.2"
 object_store = { version = "0.6.0", default-features = false, optional = true }
 once_cell= "1"
 polars-arrow = { version = "0.30.0", path = "../polars-arrow", features = ["compute"] }
 polars-error = { version = "0.30.0", path = "../polars-error" }
@@ -180,15 +180,15 @@
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-error/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/arithmetic/decimal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/arithmetic/decimal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/arithmetic/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/arithmetic/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/arithmetic/numeric.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/arithmetic/numeric.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/array/iterator.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/array/iterator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/array/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/array/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/bitwise.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/bitwise.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/binary.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/fixed_size_list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/fixed_size_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/from.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/primitive.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/builder/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/cast.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/cast.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,14 +1,16 @@
 //! Implementations of the ChunkCast Trait.
 use std::convert::TryFrom;
 
 use arrow::compute::cast::CastOptions;
 
 #[cfg(feature = "dtype-categorical")]
 use crate::chunked_array::categorical::CategoricalChunkedBuilder;
+#[cfg(feature = "timezones")]
+use crate::chunked_array::temporal::validate_time_zone;
 use crate::prelude::*;
 
 pub(crate) fn cast_chunks(
     chunks: &[ArrayRef],
     dtype: &DataType,
     checked: bool,
 ) -> PolarsResult<Vec<ArrayRef>> {
@@ -36,15 +38,22 @@
     checked: bool,
 ) -> PolarsResult<Series> {
     let chunks = cast_chunks(chunks, &dtype.to_physical(), checked)?;
     let out = Series::try_from((name, chunks))?;
     use DataType::*;
     let out = match dtype {
         Date => out.into_date(),
-        Datetime(tu, tz) => out.into_datetime(*tu, tz.clone()),
+        Datetime(tu, tz) => match tz {
+            #[cfg(feature = "timezones")]
+            Some(tz) => {
+                validate_time_zone(tz)?;
+                out.into_datetime(*tu, Some(tz.clone()))
+            }
+            _ => out.into_datetime(*tu, None),
+        },
         Duration(tu) => out.into_duration(*tu),
         #[cfg(feature = "dtype-time")]
         Time => out.into_time(),
         _ => out,
     };
 
     Ok(out)
@@ -219,30 +228,34 @@
     /// # Safety
     /// Utf8 is not validated
     pub unsafe fn to_utf8(&self) -> Utf8Chunked {
         let chunks = self
             .downcast_iter()
             .map(|arr| Box::new(binary_to_utf8_unchecked(arr)) as ArrayRef)
             .collect();
-        Utf8Chunked::from_chunks(self.name(), chunks)
+        let field = Arc::new(Field::new(self.name(), DataType::Utf8));
+        Utf8Chunked::from_chunks_and_metadata(chunks, field, self.bit_settings, true, true)
     }
 }
 
 impl Utf8Chunked {
     pub fn as_binary(&self) -> BinaryChunked {
         let chunks = self
             .downcast_iter()
             .map(|arr| {
                 Box::new(arrow::compute::cast::utf8_to_binary(
                     arr,
                     ArrowDataType::LargeBinary,
                 )) as ArrayRef
             })
             .collect();
-        unsafe { BinaryChunked::from_chunks(self.name(), chunks) }
+        let field = Arc::new(Field::new(self.name(), DataType::Binary));
+        unsafe {
+            BinaryChunked::from_chunks_and_metadata(chunks, field, self.bit_settings, true, true)
+        }
     }
 }
 
 impl ChunkCast for BinaryChunked {
     fn cast(&self, data_type: &DataType) -> PolarsResult<Series> {
         match data_type {
             #[cfg(feature = "dtype-struct")]
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/comparison/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 mod scalar;
 
-use std::ops::Not;
+use std::ops::{BitOr, Not};
 
 use arrow::array::{BooleanArray, PrimitiveArray, Utf8Array};
 use arrow::bitmap::MutableBitmap;
 use arrow::compute;
 use arrow::compute::comparison;
 use arrow::scalar::{BinaryScalar, PrimitiveScalar, Scalar, Utf8Scalar};
 use num_traits::{NumCast, ToPrimitive};
@@ -359,19 +359,38 @@
     }
 
     fn not_equal_missing(&self, rhs: &BooleanChunked) -> BooleanChunked {
         // broadcast
         match (self.len(), rhs.len()) {
             (_, 1) => {
                 if let Some(value) = rhs.get(0) {
-                    if value {
-                        self.not()
+                    let chunks = if value {
+                        self.downcast_iter()
+                            .map(|arr| {
+                                let values = match arr.validity() {
+                                    None => arr.values().not(),
+                                    Some(validity) => validity.not().bitor(&arr.values().not()),
+                                };
+                                BooleanArray::from_data_default(values, None).boxed()
+                            })
+                            .collect()
                     } else {
-                        self.clone()
-                    }
+                        self.downcast_iter()
+                            .map(|arr| {
+                                let values = match arr.validity() {
+                                    None => arr.values().clone(),
+                                    Some(validity) => validity.not().bitor(arr.values()),
+                                };
+                                BooleanArray::from_data_default(values, None).boxed()
+                            })
+                            .collect()
+                    };
+
+                    // safety: arrays are of dtype boolean
+                    unsafe { BooleanChunked::from_chunks(self.name(), chunks) }
                 } else {
                     self.is_not_null()
                 }
             }
             (1, _) => rhs.not_equal_missing(self),
             _ => {
                 // same length
@@ -850,29 +869,27 @@
                 .map(|(l, r)| l.equal_missing(r).unwrap())
                 .reduce(|lhs, rhs| lhs.bitand(rhs))
                 .unwrap()
         }
     }
 
     fn not_equal(&self, rhs: &StructChunked) -> BooleanChunked {
-        use std::ops::BitOr;
         if self.len() != rhs.len() || self.fields().len() != rhs.fields().len() {
             BooleanChunked::full("", true, self.len())
         } else {
             self.fields()
                 .iter()
                 .zip(rhs.fields().iter())
                 .map(|(l, r)| l.not_equal(r).unwrap())
                 .reduce(|lhs, rhs| lhs.bitor(rhs))
                 .unwrap()
         }
     }
 
     fn not_equal_missing(&self, rhs: &StructChunked) -> BooleanChunked {
-        use std::ops::BitOr;
         if self.len() != rhs.len() || self.fields().len() != rhs.fields().len() {
             BooleanChunked::full("", true, self.len())
         } else {
             self.fields()
                 .iter()
                 .zip(rhs.fields().iter())
                 .map(|(l, r)| l.not_equal_missing(r).unwrap())
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/comparison/scalar.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/drop.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/float.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/float.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/from.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/from.rs`

 * *Files 13% similar despite different names*

```diff
@@ -115,14 +115,42 @@
             phantom: PhantomData,
             bit_settings: Default::default(),
             length: 0,
         };
         out.compute_len();
         out
     }
+
+    /// Create a new ChunkedArray from self, where the chunks are replaced.
+    ///
+    /// # Safety
+    /// The caller must ensure the dtypes of the chunks are correct
+    pub(crate) unsafe fn from_chunks_and_metadata(
+        chunks: Vec<ArrayRef>,
+        field: Arc<Field>,
+        bit_settings: Settings,
+        keep_sorted: bool,
+        keep_fast_explode: bool,
+    ) -> Self {
+        let mut out = ChunkedArray {
+            field,
+            chunks,
+            phantom: PhantomData,
+            bit_settings,
+            length: 0,
+        };
+        out.compute_len();
+        if !keep_sorted {
+            out.set_sorted_flag(IsSorted::Not);
+        }
+        if !keep_fast_explode {
+            out.unset_fast_explode_list()
+        }
+        out
+    }
 }
 
 impl ListChunked {
     pub(crate) unsafe fn from_chunks_and_dtype_unchecked(
         name: &str,
         chunks: Vec<ArrayRef>,
         dtype: DataType,
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/iterator/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/iterator/par/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/iterator/par/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/kernels/take.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/kernels/take.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/list/iterator.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/list/iterator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/list/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/list/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/builder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/merge.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/append.rs`

 * *Files 4% similar despite different names*

```diff
@@ -13,18 +13,15 @@
         let is_local_different_source =
             match (self.get_rev_map().as_ref(), other.get_rev_map().as_ref()) {
                 (RevMapping::Local(arr_l), RevMapping::Local(arr_r)) => !std::ptr::eq(arr_l, arr_r),
                 _ => false,
             };
 
         if is_local_different_source {
-            polars_bail!(
-                ComputeError:
-                "cannot concat categoricals coming from a different source; consider setting a global StringCache"
-            );
+            polars_bail!(string_cache_mismatch);
         } else {
             let len = self.len();
             let new_rev_map = self.merge_categorical_map(other)?;
             unsafe { self.set_rev_map(new_rev_map, false) };
 
             self.logical_mut().length += other.len() as IdxSize;
             new_chunks(&mut self.logical.chunks, &other.logical().chunks, len);
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/take_random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/ops/zip.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/categorical/stringcache.rs`

 * *Files 4% similar despite different names*

```diff
@@ -14,29 +14,38 @@
 
 /// We use atomic reference counting
 /// to determine how many threads use the string cache
 /// if the refcount is zero, we may clear the string cache.
 pub(crate) static USE_STRING_CACHE: AtomicU32 = AtomicU32::new(0);
 
 /// RAII for the string cache
+/// If an operation creates categoricals and uses them in a join
+/// or comparison that operation must hold this cache via
+/// `let handle = IUseStringCache::hold()`
+/// The cache is valid until `handle` is dropped.
+///
+/// # De-allocation
+/// Multiple threads can hold the string cache at the same time.
+/// The contents of the cache will only get dropped when no
+/// thread holds it.
 pub struct IUseStringCache {
     // only added so that it will never be constructed directly
     #[allow(dead_code)]
     private_zst: (),
 }
 
 impl Default for IUseStringCache {
     fn default() -> Self {
-        Self::new()
+        Self::hold()
     }
 }
 
 impl IUseStringCache {
     /// Hold the StringCache
-    pub fn new() -> IUseStringCache {
+    pub fn hold() -> IUseStringCache {
         enable_string_cache(true);
         IUseStringCache { private_zst: () }
     }
 }
 
 impl Drop for IUseStringCache {
     fn drop(&mut self) {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/date.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/date.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/decimal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/duration.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/struct_/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/logical/time.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/logical/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 pub mod builder;
 pub mod cast;
 pub mod comparison;
 pub mod float;
 pub mod iterator;
 pub mod kernels;
 #[cfg(feature = "ndarray")]
-mod ndarray;
+pub(crate) mod ndarray;
 
 #[cfg(feature = "dtype-array")]
 pub(crate) mod array;
 mod bitwise;
 #[cfg(feature = "object")]
 mod drop;
 mod from;
@@ -320,29 +320,21 @@
     /// The caller must ensure the dtypes of the chunks are correct
     unsafe fn copy_with_chunks(
         &self,
         chunks: Vec<ArrayRef>,
         keep_sorted: bool,
         keep_fast_explode: bool,
     ) -> Self {
-        let mut out = ChunkedArray {
-            field: self.field.clone(),
+        Self::from_chunks_and_metadata(
             chunks,
-            phantom: PhantomData,
-            bit_settings: self.bit_settings,
-            length: 0,
-        };
-        out.compute_len();
-        if !keep_sorted {
-            out.set_sorted_flag(IsSorted::Not);
-        }
-        if !keep_fast_explode {
-            out.unset_fast_explode_list()
-        }
-        out
+            self.field.clone(),
+            self.bit_settings,
+            keep_sorted,
+            keep_fast_explode,
+        )
     }
 
     /// Get data type of ChunkedArray.
     pub fn dtype(&self) -> &DataType {
         self.field.data_type()
     }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ndarray.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/asof_join/mod.rs`

 * *Files 25% similar despite different names*

```diff
@@ -1,205 +1,215 @@
-use ndarray::prelude::*;
-use rayon::prelude::*;
+mod asof;
+mod groups;
+use std::borrow::Cow;
+
+use asof::*;
+use num_traits::Bounded;
+#[cfg(feature = "serde")]
+use serde::{Deserialize, Serialize};
+use smartstring::alias::String as SmartString;
 
 use crate::prelude::*;
-use crate::POOL;
+use crate::utils::{ensure_sorted_arg, slice_slice};
+
+#[derive(Clone, Debug, PartialEq, Eq, Default)]
+#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
+pub struct AsOfOptions {
+    pub strategy: AsofStrategy,
+    /// A tolerance in the same unit as the asof column
+    pub tolerance: Option<AnyValue<'static>>,
+    /// An timedelta given as
+    /// - "5m"
+    /// - "2h15m"
+    /// - "1d6h"
+    /// etc
+    pub tolerance_str: Option<SmartString>,
+    pub left_by: Option<Vec<SmartString>>,
+    pub right_by: Option<Vec<SmartString>>,
+}
+
+fn check_asof_columns(a: &Series, b: &Series, check_sorted: bool) -> PolarsResult<()> {
+    let dtype_a = a.dtype();
+    let dtype_b = b.dtype();
+    polars_ensure!(
+        dtype_a.to_physical().is_numeric() && dtype_b.to_physical().is_numeric(),
+        InvalidOperation:
+        "asof join only supported on numeric/temporal keys"
+    );
+    polars_ensure!(
+        dtype_a == dtype_b,
+        ComputeError: "mismatching key dtypes in asof-join: `{}` and `{}`",
+        a.dtype(), b.dtype()
+    );
+    polars_ensure!(
+        a.null_count() == 0 && b.null_count() == 0,
+        ComputeError: "asof join must not have null values in 'on' arguments"
+    );
+    if check_sorted {
+        ensure_sorted_arg(a, "asof_join")?;
+        ensure_sorted_arg(b, "asof_join")?;
+    }
+    Ok(())
+}
+
+#[derive(Clone, Copy, Debug, PartialEq, Eq, Default)]
+#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
+pub enum AsofStrategy {
+    /// selects the last row in the right DataFrame whose on key is less than or equal to the lefts key
+    #[default]
+    Backward,
+    /// selects the first row in the right DataFrame whose on key is greater than or equal to the lefts key.
+    Forward,
+    /// selects the right in the right DataFrame whose 'on' key is nearest to the left's key.
+    Nearest,
+}
 
 impl<T> ChunkedArray<T>
 where
     T: PolarsNumericType,
+    T::Native: Bounded + PartialOrd,
 {
-    /// If data is aligned in a single chunk and has no Null values a zero copy view is returned
-    /// as an `ndarray`
-    pub fn to_ndarray(&self) -> PolarsResult<ArrayView1<T::Native>> {
-        let slice = self.cont_slice()?;
-        Ok(aview1(slice))
+    pub(crate) fn join_asof(
+        &self,
+        other: &Series,
+        strategy: AsofStrategy,
+        tolerance: Option<AnyValue<'static>>,
+    ) -> PolarsResult<Vec<Option<IdxSize>>> {
+        let other = self.unpack_series_matching_type(other)?;
+
+        // cont_slice requires a single chunk
+        let ca = self.rechunk();
+        let other = other.rechunk();
+
+        let out = match strategy {
+            AsofStrategy::Forward => match tolerance {
+                None => join_asof_forward(ca.cont_slice().unwrap(), other.cont_slice().unwrap()),
+                Some(tolerance) => {
+                    let tolerance = tolerance.extract::<T::Native>().unwrap();
+                    join_asof_forward_with_tolerance(
+                        ca.cont_slice().unwrap(),
+                        other.cont_slice().unwrap(),
+                        tolerance,
+                    )
+                }
+            },
+            AsofStrategy::Backward => match tolerance {
+                None => join_asof_backward(ca.cont_slice().unwrap(), other.cont_slice().unwrap()),
+                Some(tolerance) => {
+                    let tolerance = tolerance.extract::<T::Native>().unwrap();
+                    join_asof_backward_with_tolerance(
+                        self.cont_slice().unwrap(),
+                        other.cont_slice().unwrap(),
+                        tolerance,
+                    )
+                }
+            },
+            AsofStrategy::Nearest => {
+                join_asof_nearest(ca.cont_slice().unwrap(), other.cont_slice().unwrap())
+            }
+        };
+        Ok(out)
     }
 }
 
-impl ListChunked {
-    /// If all nested `Series` have the same length, a 2 dimensional `ndarray::Array` is returned.
-    pub fn to_ndarray<N>(&self) -> PolarsResult<Array2<N::Native>>
-    where
-        N: PolarsNumericType,
-    {
-        polars_ensure!(
-            self.null_count() == 0,
-            ComputeError: "creation of ndarray with null values is not supported"
-        );
-
-        // first iteration determine the size
-        let mut iter = self.into_no_null_iter();
-        let series = iter
-            .next()
-            .ok_or_else(|| polars_err!(NoData: "unable to create ndarray of empty ListChunked"))?;
-
-        let width = series.len();
-        let mut row_idx = 0;
-        let mut ndarray = ndarray::Array::uninit((self.len(), width));
-
-        let series = series.cast(&N::get_dtype())?;
-        let ca = series.unpack::<N>()?;
-        let a = ca.to_ndarray()?;
-        let mut row = ndarray.slice_mut(s![row_idx, ..]);
-        a.assign_to(&mut row);
-        row_idx += 1;
-
-        for series in iter {
-            polars_ensure!(
-                series.len() == width,
-                ShapeMismatch: "unable to create a 2-D array, series have different lengths"
-            );
-            let series = series.cast(&N::get_dtype())?;
-            let ca = series.unpack::<N>()?;
-            let a = ca.to_ndarray()?;
-            let mut row = ndarray.slice_mut(s![row_idx, ..]);
-            a.assign_to(&mut row);
-            row_idx += 1;
+impl DataFrame {
+    #[doc(hidden)]
+    #[allow(clippy::too_many_arguments)]
+    pub fn _join_asof(
+        &self,
+        other: &DataFrame,
+        left_on: &str,
+        right_on: &str,
+        strategy: AsofStrategy,
+        tolerance: Option<AnyValue<'static>>,
+        suffix: Option<String>,
+        slice: Option<(i64, usize)>,
+    ) -> PolarsResult<DataFrame> {
+        let left_key = self.column(left_on)?;
+        let right_key = other.column(right_on)?;
+
+        check_asof_columns(left_key, right_key, true)?;
+        let left_key = left_key.to_physical_repr();
+        let right_key = right_key.to_physical_repr();
+
+        let take_idx = match left_key.dtype() {
+            DataType::Int64 => left_key
+                .i64()
+                .unwrap()
+                .join_asof(&right_key, strategy, tolerance),
+            DataType::Int32 => left_key
+                .i32()
+                .unwrap()
+                .join_asof(&right_key, strategy, tolerance),
+            DataType::UInt64 => left_key
+                .u64()
+                .unwrap()
+                .join_asof(&right_key, strategy, tolerance),
+            DataType::UInt32 => left_key
+                .u32()
+                .unwrap()
+                .join_asof(&right_key, strategy, tolerance),
+            DataType::Float32 => left_key
+                .f32()
+                .unwrap()
+                .join_asof(&right_key, strategy, tolerance),
+            DataType::Float64 => left_key
+                .f64()
+                .unwrap()
+                .join_asof(&right_key, strategy, tolerance),
+            _ => {
+                let left_key = left_key.cast(&DataType::Int32).unwrap();
+                let right_key = right_key.cast(&DataType::Int32).unwrap();
+                left_key
+                    .i32()
+                    .unwrap()
+                    .join_asof(&right_key, strategy, tolerance)
+            }
+        }?;
+
+        // take_idx are sorted so this is a bound check for all
+        if let Some(Some(idx)) = take_idx.last() {
+            assert!((*idx as usize) < other.height())
         }
 
-        debug_assert_eq!(row_idx, self.len());
-        // Safety:
-        // We have assigned to every row and element of the array
-        unsafe { Ok(ndarray.assume_init()) }
-    }
-}
-
-impl DataFrame {
-    /// Create a 2D `ndarray::Array` from this `DataFrame`. This requires all columns in the
-    /// `DataFrame` to be non-null and numeric. They will be casted to the same data type
-    /// (if they aren't already).
-    ///
-    /// For floating point data we implicitly convert `None` to `NaN` without failure.
-    ///
-    /// ```rust
-    /// use polars_core::prelude::*;
-    /// let a = UInt32Chunked::new("a", &[1, 2, 3]).into_series();
-    /// let b = Float64Chunked::new("b", &[10., 8., 6.]).into_series();
-    ///
-    /// let df = DataFrame::new(vec![a, b]).unwrap();
-    /// let ndarray = df.to_ndarray::<Float64Type>().unwrap();
-    /// println!("{:?}", ndarray);
-    /// ```
-    /// Outputs:
-    /// ```text
-    /// [[1.0, 10.0],
-    ///  [2.0, 8.0],
-    ///  [3.0, 6.0]], shape=[3, 2], strides=[2, 1], layout=C (0x1), const ndim=2/
-    /// ```
-    pub fn to_ndarray<N>(&self) -> PolarsResult<Array2<N::Native>>
-    where
-        N: PolarsNumericType,
-    {
-        let columns = POOL.install(|| {
-            self.get_columns()
-                .par_iter()
-                .map(|s| {
-                    let s = s.cast(&N::get_dtype())?;
-                    let s = match s.dtype() {
-                        DataType::Float32 => {
-                            let ca = s.f32().unwrap();
-                            ca.none_to_nan().into_series()
-                        }
-                        DataType::Float64 => {
-                            let ca = s.f64().unwrap();
-                            ca.none_to_nan().into_series()
-                        }
-                        _ => s,
-                    };
-                    Ok(s.rechunk())
-                })
-                .collect::<PolarsResult<Vec<_>>>()
-        })?;
-
-        let shape = self.shape();
-        let height = self.height();
-        let mut membuf = Vec::with_capacity(shape.0 * shape.1);
-        let ptr = membuf.as_ptr() as usize;
-
-        POOL.install(|| {
-            columns
-                .par_iter()
-                .enumerate()
-                .map(|(col_idx, s)| {
-                    polars_ensure!(
-                        s.null_count() == 0,
-                        ComputeError: "creation of ndarray with null values is not supported"
-                    );
-
-                    // this is an Arc clone if already of type N
-                    let s = s.cast(&N::get_dtype())?;
-                    let ca = s.unpack::<N>()?;
-                    let vals = ca.cont_slice().unwrap();
-
-                    // Safety:
-                    // we get parallel access to the vector
-                    // but we make sure that we don't get aliased access by offsetting the column indices + length
-                    unsafe {
-                        let offset_ptr = (ptr as *mut N::Native).add(col_idx * height);
-                        // Safety:
-                        // this is uninitialized memory, so we must never read from this data
-                        // copy_from_slice does not read
-                        let buf = std::slice::from_raw_parts_mut(offset_ptr, height);
-                        buf.copy_from_slice(vals)
-                    }
-
-                    Ok(())
-                })
-                .collect::<PolarsResult<Vec<_>>>()
-        })?;
+        // drop right join column
+        let other = if left_on == right_on {
+            Cow::Owned(other.drop(right_on)?)
+        } else {
+            Cow::Borrowed(other)
+        };
+
+        let mut left = self.clone();
+        let mut take_idx = &*take_idx;
+
+        if let Some((offset, len)) = slice {
+            left = left.slice(offset, len);
+            take_idx = slice_slice(take_idx, offset, len);
+        }
 
         // Safety:
-        // we have written all data, so we can now safely set length
-        unsafe {
-            membuf.set_len(shape.0 * shape.1);
-        }
-        let ndarr = Array2::from_shape_vec((shape.1, shape.0), membuf).unwrap();
-        Ok(ndarr.reversed_axes())
-    }
-}
+        // join tuples are in bounds
+        let right_df = unsafe {
+            other.take_opt_iter_unchecked(
+                take_idx
+                    .iter()
+                    .map(|opt_idx| opt_idx.map(|idx| idx as usize)),
+            )
+        };
 
-#[cfg(test)]
-mod test {
-    use super::*;
-
-    #[test]
-    fn test_ndarray_from_ca() -> PolarsResult<()> {
-        let ca = Float64Chunked::new("", &[1.0, 2.0, 3.0]);
-        let ndarr = ca.to_ndarray()?;
-        assert_eq!(ndarr, ArrayView1::from(&[1.0, 2.0, 3.0]));
-
-        let mut builder =
-            ListPrimitiveChunkedBuilder::<Float64Type>::new("", 10, 10, DataType::Float64);
-        builder.append_opt_slice(Some(&[1.0, 2.0, 3.0]));
-        builder.append_opt_slice(Some(&[2.0, 4.0, 5.0]));
-        builder.append_opt_slice(Some(&[6.0, 7.0, 8.0]));
-        let list = builder.finish();
-
-        let ndarr = list.to_ndarray::<Float64Type>()?;
-        let expected = array![[1.0, 2.0, 3.0], [2.0, 4.0, 5.0], [6.0, 7.0, 8.0]];
-        assert_eq!(ndarr, expected);
-
-        // test list array that is not square
-        let mut builder =
-            ListPrimitiveChunkedBuilder::<Float64Type>::new("", 10, 10, DataType::Float64);
-        builder.append_opt_slice(Some(&[1.0, 2.0, 3.0]));
-        builder.append_opt_slice(Some(&[2.0]));
-        builder.append_opt_slice(Some(&[6.0, 7.0, 8.0]));
-        let list = builder.finish();
-        assert!(list.to_ndarray::<Float64Type>().is_err());
-        Ok(())
+        _finish_join(left, right_df, suffix.as_deref())
     }
 
-    #[test]
-    fn test_ndarray_from_df() -> PolarsResult<()> {
-        let df = df!["a"=> [1.0, 2.0, 3.0],
-            "b" => [2.0, 3.0, 4.0]
-        ]?;
-
-        let ndarr = df.to_ndarray::<Float64Type>()?;
-        let expected = array![[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]];
-        assert_eq!(ndarr, expected);
-
-        Ok(())
+    /// This is similar to a left-join except that we match on nearest key rather than equal keys.
+    /// The keys must be sorted to perform an asof join
+    pub fn join_asof(
+        &self,
+        other: &DataFrame,
+        left_on: &str,
+        right_on: &str,
+        strategy: AsofStrategy,
+        tolerance: Option<AnyValue<'static>>,
+        suffix: Option<String>,
+    ) -> PolarsResult<DataFrame> {
+        self._join_asof(other, left_on, right_on, strategy, tolerance, suffix, None)
     }
 }
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/builder.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/builder.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/extension/drop.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/extension/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/extension/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/extension/polars_extension.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/iterator.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/iterator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/object/registry.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/object/registry.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/aggregate/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -4,15 +4,15 @@
 
 use std::cmp::Ordering;
 use std::ops::Add;
 
 use arrow::compute;
 use arrow::types::simd::Simd;
 use arrow::types::NativeType;
-use num_traits::{Float, ToPrimitive};
+use num_traits::{Float, ToPrimitive, Zero};
 use polars_arrow::kernels::rolling::{compare_fn_nan_max, compare_fn_nan_min};
 pub use quantile::*;
 pub use var::*;
 
 use crate::chunked_array::ChunkedArray;
 use crate::datatypes::{BooleanChunked, PolarsNumericType};
 use crate::prelude::*;
@@ -35,78 +35,71 @@
     }
     /// Get the product of the ChunkedArray as a new Series of length 1.
     fn prod_as_series(&self) -> Series {
         unimplemented!()
     }
 }
 
-fn sum_float_unaligned_slice<T: NumericNative>(values: &[T]) -> Option<T> {
-    Some(values.iter().copied().sum())
+fn sum_float_unaligned_slice<T: NumericNative>(values: &[T]) -> T {
+    values.iter().copied().sum()
 }
 
-fn sum_float_unaligned<T: NumericNative>(array: &PrimitiveArray<T>) -> Option<T> {
-    if array.len() == 0 {
-        return Some(T::zero());
+fn sum_float_unaligned<T: NumericNative>(array: &PrimitiveArray<T>) -> T {
+    if array.len() == 0 || array.null_count() == array.len() {
+        return T::zero();
     }
-    if array.null_count() == array.len() {
-        return None;
-    }
-    Some(array.into_iter().flatten().copied().sum())
+    array.into_iter().flatten().copied().sum()
 }
 
 /// Floating point arithmetic is non-associative.
 /// The simd chunks are determined by memory location
 /// e.g.
 ///
 /// |HEAD|  - | SIMD | - |TAIL|
 ///
 /// The SIMD chunks have a certain alignment and depending of the start of the buffer
 /// head and tail may have different sizes, making a sum non-deterministic for the same
 /// values but different memory locations
-fn stable_sum<T: NumericNative + NativeType>(array: &PrimitiveArray<T>) -> Option<T>
+fn stable_sum<T: NumericNative + NativeType>(array: &PrimitiveArray<T>) -> T
 where
     T: NumericNative + NativeType,
     <T as Simd>::Simd: Add<Output = <T as Simd>::Simd>
         + compute::aggregate::Sum<T>
         + compute::aggregate::SimdOrd<T>,
 {
     if T::is_float() {
         use arrow::types::simd::NativeSimd;
         let values = array.values().as_slice();
         let (a, _, _) = <T as Simd>::Simd::align(values);
         // we only choose SIMD path if buffer is aligned to SIMD
         if a.is_empty() {
-            compute::aggregate::sum_primitive(array)
+            compute::aggregate::sum_primitive(array).unwrap_or(T::zero())
         } else if array.null_count() == 0 {
             sum_float_unaligned_slice(values)
         } else {
             sum_float_unaligned(array)
         }
     } else {
-        compute::aggregate::sum_primitive(array)
+        compute::aggregate::sum_primitive(array).unwrap_or(T::zero())
     }
 }
 
 impl<T> ChunkAgg<T::Native> for ChunkedArray<T>
 where
     T: PolarsNumericType,
     <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
         + compute::aggregate::Sum<T::Native>
         + compute::aggregate::SimdOrd<T::Native>,
 {
     fn sum(&self) -> Option<T::Native> {
-        self.downcast_iter()
-            .map(stable_sum)
-            .fold(None, |acc, v| match v {
-                Some(v) => match acc {
-                    None => Some(v),
-                    Some(acc) => Some(acc + v),
-                },
-                None => acc,
-            })
+        Some(
+            self.downcast_iter()
+                .map(stable_sum)
+                .fold(T::Native::zero(), |acc, v| acc + v),
+        )
     }
 
     fn min(&self) -> Option<T::Native> {
         match self.is_sorted_flag() {
             IsSorted::Ascending => {
                 self.first_non_null().and_then(|idx| {
                     // Safety:
@@ -160,14 +153,17 @@
                         v
                     }
                 }),
         }
     }
 
     fn mean(&self) -> Option<f64> {
+        if self.is_empty() || self.null_count() == self.len() {
+            return None;
+        }
         match self.dtype() {
             DataType::Float64 => {
                 let len = (self.len() - self.null_count()) as f64;
                 self.sum().map(|v| v.to_f64().unwrap() / len)
             }
             _ => {
                 let null_count = self.null_count();
@@ -219,28 +215,26 @@
     }
 }
 
 /// Booleans are casted to 1 or 0.
 impl BooleanChunked {
     /// Returns `None` if the array is empty or only contains null values.
     pub fn sum(&self) -> Option<IdxSize> {
-        if self.is_empty() {
-            None
+        Some(if self.is_empty() {
+            0
         } else {
-            Some(
-                self.downcast_iter()
-                    .map(|arr| match arr.validity() {
-                        Some(validity) => {
-                            (arr.len() - (validity & arr.values()).unset_bits()) as IdxSize
-                        }
-                        None => (arr.len() - arr.values().unset_bits()) as IdxSize,
-                    })
-                    .sum(),
-            )
-        }
+            self.downcast_iter()
+                .map(|arr| match arr.validity() {
+                    Some(validity) => {
+                        (arr.len() - (validity & arr.values()).unset_bits()) as IdxSize
+                    }
+                    None => (arr.len() - arr.values().unset_bits()) as IdxSize,
+                })
+                .sum()
+        })
     }
 
     pub fn min(&self) -> Option<bool> {
         let nc = self.null_count();
         let len = self.len();
         if self.is_empty() || nc == len {
             return None;
@@ -268,14 +262,17 @@
         if self.any() {
             Some(true)
         } else {
             Some(false)
         }
     }
     pub fn mean(&self) -> Option<f64> {
+        if self.is_empty() || self.null_count() == self.len() {
+            return None;
+        }
         self.sum()
             .map(|sum| sum as f64 / (self.len() - self.null_count()) as f64)
     }
 }
 
 // Needs the same trait bounds as the implementation of ChunkedArray<T> of dyn Series
 impl<T> ChunkAggSeries for ChunkedArray<T>
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/aggregate/quantile.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/aggregate/var.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/any_value.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/append.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/append.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/apply.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/apply.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/bit_repr.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/chunkops.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/compare_inner.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/concat_str.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/cum_agg.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/decimal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/decimal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/downcast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/explode.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/explode.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/explode_and_offsets.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/explode_and_offsets.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/extend.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/extend.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/fill_null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/filter.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/filter.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/full.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/full.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/is_in.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/min_max_binary.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/min_max_binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -350,15 +350,16 @@
     where
         F: Fn(Option<A>, &T) -> T;
 }
 
 /// Aggregation operations
 pub trait ChunkAgg<T> {
     /// Aggregate the sum of the ChunkedArray.
-    /// Returns `None` if the array is empty or only contains null values.
+    /// Returns `None` if not implemented for `T`.
+    /// If the array is empty, `0` is returned
     fn sum(&self) -> Option<T> {
         None
     }
 
     fn min(&self) -> Option<T> {
         None
     }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/nulls.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/peaks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/repeat_by.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/reverse.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/rolling_window.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-ops/src/chunked_array/list/sets.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,257 +1,344 @@
-use polars_arrow::prelude::DynArgs;
+use std::fmt::{Display, Formatter};
+use std::hash::Hash;
 
-#[derive(Clone)]
-pub struct RollingOptionsFixedWindow {
-    /// The length of the window.
-    pub window_size: usize,
-    /// Amount of elements in the window that should be filled before computing a result.
-    pub min_periods: usize,
-    /// An optional slice with the same length as the window that will be multiplied
-    ///              elementwise with the values in the window.
-    pub weights: Option<Vec<f64>>,
-    /// Set the labels at the center of the window.
-    pub center: bool,
-    pub fn_params: DynArgs,
-}
-
-impl Default for RollingOptionsFixedWindow {
-    fn default() -> Self {
-        RollingOptionsFixedWindow {
-            window_size: 3,
-            min_periods: 1,
-            weights: None,
-            center: false,
-            fn_params: None,
+use arrow::array::{
+    BinaryArray, ListArray, MutableArray, MutableBinaryArray, MutablePrimitiveArray,
+    PrimitiveArray, Utf8Array,
+};
+use arrow::bitmap::Bitmap;
+use arrow::offset::OffsetsBuffer;
+use arrow::types::NativeType;
+use polars_arrow::utils::combine_validities_and;
+use polars_core::prelude::*;
+use polars_core::utils::align_chunks_binary;
+use polars_core::with_match_physical_integer_type;
+#[cfg(feature = "serde")]
+use serde::{Deserialize, Serialize};
+
+struct Intersection<'a, T, I: Iterator<Item = T>> {
+    // iterator of the first set
+    iter: I,
+    // the second set
+    other: &'a PlIndexSet<T>,
+}
+
+impl<'a, T, I> Iterator for Intersection<'a, T, I>
+where
+    T: Eq + Hash,
+    I: Iterator<Item = T>,
+{
+    type Item = T;
+
+    fn next(&mut self) -> Option<T> {
+        loop {
+            let elt = self.iter.next()?;
+            if self.other.contains(&elt) {
+                return Some(elt);
+            }
         }
     }
-}
 
-#[cfg(feature = "rolling_window")]
-mod inner_mod {
-    use std::ops::SubAssign;
-
-    use arrow::array::{Array, PrimitiveArray};
-    use arrow::bitmap::MutableBitmap;
-    use num_traits::pow::Pow;
-    use num_traits::{Float, Zero};
-    use polars_arrow::bit_util::unset_bit_raw;
-    use polars_arrow::data_types::IsFloat;
-    use polars_arrow::trusted_len::TrustedLenPush;
-
-    use crate::prelude::*;
-
-    /// utility
-    fn check_input(window_size: usize, min_periods: usize) -> PolarsResult<()> {
-        polars_ensure!(
-            min_periods <= window_size,
-            ComputeError: "`window_size`: {} should be >= `min_periods`: {}",
-            window_size, min_periods
-        );
-        Ok(())
+    fn size_hint(&self) -> (usize, Option<usize>) {
+        let (_, upper) = self.iter.size_hint();
+        (0, upper)
     }
+}
 
-    /// utility
-    fn window_edges(idx: usize, len: usize, window_size: usize, center: bool) -> (usize, usize) {
-        let (start, end) = if center {
-            let right_window = (window_size + 1) / 2;
-            (
-                idx.saturating_sub(window_size - right_window),
-                len.min(idx + right_window),
-            )
-        } else {
-            (idx.saturating_sub(window_size - 1), idx + 1)
-        };
+trait MaterializeValues<K> {
+    // extends the iterator to the values and returns the current offset
+    fn extend_buf<I: Iterator<Item = K>>(&mut self, values: I) -> usize;
+}
 
-        (start, end - start)
+impl<T> MaterializeValues<Option<T>> for MutablePrimitiveArray<T>
+where
+    T: NativeType,
+{
+    fn extend_buf<I: Iterator<Item = Option<T>>>(&mut self, values: I) -> usize {
+        self.extend(values);
+        self.len()
     }
+}
 
-    impl<T> ChunkRollApply for ChunkedArray<T>
-    where
-        T: PolarsNumericType,
-        Self: IntoSeries,
-    {
-        /// Apply a rolling custom function. This is pretty slow because of dynamic dispatch.
-        fn rolling_apply(
-            &self,
-            f: &dyn Fn(&Series) -> Series,
-            mut options: RollingOptionsFixedWindow,
-        ) -> PolarsResult<Series> {
-            check_input(options.window_size, options.min_periods)?;
-
-            let ca = self.rechunk();
-            if options.weights.is_some()
-                && !matches!(self.dtype(), DataType::Float64 | DataType::Float32)
-            {
-                let s = self.cast(&DataType::Float64)?;
-                return s.rolling_apply(f, options);
-            }
+impl<'a> MaterializeValues<Option<&'a [u8]>> for MutableBinaryArray<i64> {
+    fn extend_buf<I: Iterator<Item = Option<&'a [u8]>>>(&mut self, values: I) -> usize {
+        self.extend(values);
+        self.len()
+    }
+}
 
-            options.window_size = std::cmp::min(self.len(), options.window_size);
+fn set_operation<K, I, R>(
+    set: &mut PlIndexSet<K>,
+    set2: &mut PlIndexSet<K>,
+    a: I,
+    b: I,
+    out: &mut R,
+    set_type: SetOperation,
+) -> usize
+where
+    K: Eq + Hash + Copy,
+    I: IntoIterator<Item = K>,
+    R: MaterializeValues<K>,
+{
+    set.clear();
+    let a = a.into_iter();
+    let b = b.into_iter();
+
+    match set_type {
+        SetOperation::Intersection => {
+            let (smaller, larger) = if a.size_hint().0 <= b.size_hint().0 {
+                (a, b)
+            } else {
+                (b, a)
+            };
+            set.extend(smaller);
+            let iter = Intersection {
+                iter: larger,
+                other: set,
+            };
+            out.extend_buf(iter)
+        }
+        SetOperation::Union => {
+            set.extend(a);
+            set.extend(b);
+            out.extend_buf(set.drain(..))
+        }
+        SetOperation::Difference => {
+            set.extend(a);
+            for v in b {
+                set.remove(&v);
+            }
+            out.extend_buf(set.drain(..))
+        }
+        SetOperation::SymmetricDifference => {
+            set2.clear();
+            // We could speed this up, but implementing ourselves, but we need to have a clonable
+            // iterator as we need 2 passes
+            set.extend(a);
+            set2.extend(b);
+            out.extend_buf(set.symmetric_difference(set2).copied())
+        }
+    }
+}
 
-            let len = self.len();
-            let arr = ca.downcast_iter().next().unwrap();
-            let mut series_container =
-                ChunkedArray::<T>::from_slice("", &[T::Native::zero()]).into_series();
-            let array_ptr = series_container.array_ref(0);
-            let ptr = array_ptr.as_ref() as *const dyn Array as *mut dyn Array
-                as *mut PrimitiveArray<T::Native>;
-            let mut builder = PrimitiveChunkedBuilder::<T>::new(self.name(), self.len());
-
-            if let Some(weights) = options.weights {
-                let weights_series = Float64Chunked::new("weights", &weights).into_series();
-
-                let weights_series = weights_series.cast(self.dtype()).unwrap();
-
-                for idx in 0..len {
-                    let (start, size) = window_edges(idx, len, options.window_size, options.center);
-
-                    if size < options.min_periods {
-                        builder.append_null();
-                    } else {
-                        // safety:
-                        // we are in bounds
-                        let arr_window = unsafe { arr.slice_typed_unchecked(start, size) };
-
-                        // Safety.
-                        // ptr is not dropped as we are in scope
-                        // We are also the only owner of the contents of the Arc
-                        // we do this to reduce heap allocs.
-                        unsafe {
-                            *ptr = arr_window;
-                        }
-                        // ensure the length is correct
-                        series_container._get_inner_mut().compute_len();
-
-                        let s = if size == options.window_size {
-                            f(&series_container.multiply(&weights_series).unwrap())
-                        } else {
-                            let weights_cutoff: Series = match self.dtype() {
-                                DataType::Float64 => weights_series
-                                    .f64()
-                                    .unwrap()
-                                    .into_iter()
-                                    .take(series_container.len())
-                                    .collect(),
-                                _ => weights_series // Float32 case
-                                    .f32()
-                                    .unwrap()
-                                    .into_iter()
-                                    .take(series_container.len())
-                                    .collect(),
-                            };
-                            f(&series_container.multiply(&weights_cutoff).unwrap())
-                        };
-
-                        let out = self.unpack_series_matching_type(&s)?;
-                        builder.append_option(out.get(0));
-                    }
-                }
+fn copied_opt<T: Copy>(v: Option<&T>) -> Option<T> {
+    v.copied()
+}
 
-                Ok(builder.finish().into_series())
-            } else {
-                for idx in 0..len {
-                    let (start, size) = window_edges(idx, len, options.window_size, options.center);
+#[derive(Copy, Clone, Debug, Eq, PartialEq, Hash)]
+#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
+pub enum SetOperation {
+    Intersection,
+    Union,
+    Difference,
+    SymmetricDifference,
+}
 
-                    if size < options.min_periods {
-                        builder.append_null();
-                    } else {
-                        // safety:
-                        // we are in bounds
-                        let arr_window = unsafe { arr.slice_typed_unchecked(start, size) };
-
-                        // Safety.
-                        // ptr is not dropped as we are in scope
-                        // We are also the only owner of the contents of the Arc
-                        // we do this to reduce heap allocs.
-                        unsafe {
-                            *ptr = arr_window;
-                        }
-                        // ensure the length is correct
-                        series_container._get_inner_mut().compute_len();
-
-                        let s = f(&series_container);
-                        let out = self.unpack_series_matching_type(&s)?;
-                        builder.append_option(out.get(0));
-                    }
-                }
+impl Display for SetOperation {
+    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
+        let s = match self {
+            SetOperation::Intersection => "intersection",
+            SetOperation::Union => "union",
+            SetOperation::Difference => "difference",
+            SetOperation::SymmetricDifference => "symmetric_difference",
+        };
+        write!(f, "{s}")
+    }
+}
 
-                Ok(builder.finish().into_series())
-            }
+fn primitive<T>(
+    a: &PrimitiveArray<T>,
+    b: &PrimitiveArray<T>,
+    offsets_a: &[i64],
+    offsets_b: &[i64],
+    set_type: SetOperation,
+    validity: Option<Bitmap>,
+) -> ListArray<i64>
+where
+    T: NativeType + Hash + Copy + Eq,
+{
+    assert_eq!(offsets_a.len(), offsets_b.len());
+
+    let mut set = Default::default();
+    let mut set2 = Default::default();
+
+    let mut values_out = MutablePrimitiveArray::with_capacity(std::cmp::max(
+        *offsets_a.last().unwrap(),
+        *offsets_b.last().unwrap(),
+    ) as usize);
+    let mut offsets = Vec::with_capacity(std::cmp::max(offsets_a.len(), offsets_b.len()));
+    offsets.push(0i64);
+
+    for i in 1..offsets_a.len() {
+        unsafe {
+            let start_a = *offsets_a.get_unchecked(i - 1) as usize;
+            let end_a = *offsets_a.get_unchecked(i) as usize;
+
+            let start_b = *offsets_b.get_unchecked(i - 1) as usize;
+            let end_b = *offsets_b.get_unchecked(i) as usize;
+
+            // going via skip iterator instead of slice doesn't heap alloc nor trigger a bitcount
+            let a_iter = a
+                .into_iter()
+                .skip(start_a)
+                .take(end_a - start_a)
+                .map(copied_opt);
+            let b_iter = b
+                .into_iter()
+                .skip(start_b)
+                .take(end_b - start_b)
+                .map(copied_opt);
+
+            let offset = set_operation(
+                &mut set,
+                &mut set2,
+                a_iter,
+                b_iter,
+                &mut values_out,
+                set_type,
+            );
+            offsets.push(offset as i64);
         }
     }
+    let offsets = unsafe { OffsetsBuffer::new_unchecked(offsets.into()) };
+    let dtype = ListArray::<i64>::default_datatype(values_out.data_type().clone());
 
-    impl<T> ChunkedArray<T>
-    where
-        ChunkedArray<T>: IntoSeries,
-        T: PolarsFloatType,
-        T::Native: Float + IsFloat + SubAssign + Pow<T::Native, Output = T::Native>,
-    {
-        /// Apply a rolling custom function. This is pretty slow because of dynamic dispatch.
-        pub fn rolling_apply_float<F>(&self, window_size: usize, mut f: F) -> PolarsResult<Self>
-        where
-            F: FnMut(&mut ChunkedArray<T>) -> Option<T::Native>,
-        {
-            if window_size > self.len() {
-                return Ok(Self::full_null(self.name(), self.len()));
-            }
-            let ca = self.rechunk();
-            let arr = ca.downcast_iter().next().unwrap();
+    let values: PrimitiveArray<T> = values_out.into();
+    ListArray::new(dtype, offsets, values.boxed(), validity)
+}
 
-            // we create a temporary dummy ChunkedArray
-            // this will be a container where we swap the window contents every iteration
-            // doing so will save a lot of heap allocations.
-            let mut heap_container = ChunkedArray::<T>::from_slice("", &[T::Native::zero()]);
-            let array_ptr = &heap_container.chunks()[0];
-            let ptr = array_ptr.as_ref() as *const dyn Array as *mut dyn Array
-                as *mut PrimitiveArray<T::Native>;
-
-            let mut validity = MutableBitmap::with_capacity(ca.len());
-            validity.extend_constant(window_size - 1, false);
-            validity.extend_constant(ca.len() - (window_size - 1), true);
-            let validity_ptr = validity.as_slice().as_ptr() as *mut u8;
-
-            let mut values = Vec::with_capacity(ca.len());
-            values.extend(std::iter::repeat(T::Native::default()).take(window_size - 1));
-
-            for offset in 0..self.len() + 1 - window_size {
-                debug_assert!(offset + window_size <= arr.len());
-                let arr_window = unsafe { arr.slice_typed_unchecked(offset, window_size) };
-                // the lengths are cached, so we must update them
-                heap_container.length = arr_window.len() as IdxSize;
-
-                // Safety.
-                // ptr is not dropped as we are in scope
-                // We are also the only owner of the contents of the Arc
-                // we do this to reduce heap allocs.
-                unsafe {
-                    *ptr = arr_window;
-                }
-
-                let out = f(&mut heap_container);
-                match out {
-                    Some(v) => {
-                        // Safety: we have pre-allocated
-                        unsafe { values.push_unchecked(v) }
-                    }
-                    None => {
-                        // safety: we allocated enough for both the `values` vec
-                        // and the `validity_ptr`
-                        unsafe {
-                            values.push_unchecked(T::Native::default());
-                            unset_bit_raw(validity_ptr, offset + window_size - 1);
-                        }
-                    }
-                }
-            }
-            let arr = PrimitiveArray::new(
-                T::get_dtype().to_arrow(),
-                values.into(),
-                Some(validity.into()),
+fn binary(
+    a: &BinaryArray<i64>,
+    b: &BinaryArray<i64>,
+    offsets_a: &[i64],
+    offsets_b: &[i64],
+    set_type: SetOperation,
+    validity: Option<Bitmap>,
+    as_utf8: bool,
+) -> ListArray<i64> {
+    assert_eq!(offsets_a.len(), offsets_b.len());
+
+    let mut set = Default::default();
+    let mut set2 = Default::default();
+
+    let mut values_out = MutableBinaryArray::with_capacity(std::cmp::max(
+        *offsets_a.last().unwrap(),
+        *offsets_b.last().unwrap(),
+    ) as usize);
+    let mut offsets = Vec::with_capacity(std::cmp::max(offsets_a.len(), offsets_b.len()));
+    offsets.push(0i64);
+
+    for i in 1..offsets_a.len() {
+        unsafe {
+            let start_a = *offsets_a.get_unchecked(i - 1) as usize;
+            let end_a = *offsets_a.get_unchecked(i) as usize;
+
+            let start_b = *offsets_b.get_unchecked(i - 1) as usize;
+            let end_b = *offsets_b.get_unchecked(i) as usize;
+
+            // going via skip iterator instead of slice doesn't heap alloc nor trigger a bitcount
+            let a_iter = a.into_iter().skip(start_a).take(end_a - start_a);
+            let b_iter = b.into_iter().skip(start_b).take(end_b - start_b);
+
+            let offset = set_operation(
+                &mut set,
+                &mut set2,
+                a_iter,
+                b_iter,
+                &mut values_out,
+                set_type,
             );
-            unsafe { Ok(Self::from_chunks(self.name(), vec![Box::new(arr)])) }
+            offsets.push(offset as i64);
+        }
+    }
+    let offsets = unsafe { OffsetsBuffer::new_unchecked(offsets.into()) };
+    let values: BinaryArray<i64> = values_out.into();
+
+    if as_utf8 {
+        let values = unsafe {
+            Utf8Array::<i64>::new_unchecked(
+                ArrowDataType::LargeUtf8,
+                values.offsets().clone(),
+                values.values().clone(),
+                values.validity().cloned(),
+            )
+        };
+        let dtype = ListArray::<i64>::default_datatype(values.data_type().clone());
+        ListArray::new(dtype, offsets, values.boxed(), validity)
+    } else {
+        let dtype = ListArray::<i64>::default_datatype(values.data_type().clone());
+        ListArray::new(dtype, offsets, values.boxed(), validity)
+    }
+}
+
+fn utf8_to_binary(arr: &Utf8Array<i64>) -> BinaryArray<i64> {
+    BinaryArray::<i64>::new(
+        ArrowDataType::LargeBinary,
+        arr.offsets().clone(),
+        arr.values().clone(),
+        arr.validity().cloned(),
+    )
+}
+
+fn array_set_operation(
+    a: &ListArray<i64>,
+    b: &ListArray<i64>,
+    set_type: SetOperation,
+) -> ListArray<i64> {
+    let offsets_a = a.offsets().as_slice();
+    let offsets_b = b.offsets().as_slice();
+
+    let values_a = a.values();
+    let values_b = b.values();
+    assert_eq!(values_a.data_type(), values_b.data_type());
+
+    let dtype = values_b.data_type();
+    let validity = combine_validities_and(a.validity(), b.validity());
+
+    match dtype {
+        ArrowDataType::LargeUtf8 => {
+            let a = values_a.as_any().downcast_ref::<Utf8Array<i64>>().unwrap();
+            let b = values_b.as_any().downcast_ref::<Utf8Array<i64>>().unwrap();
+
+            let a = utf8_to_binary(a);
+            let b = utf8_to_binary(b);
+            binary(&a, &b, offsets_a, offsets_b, set_type, validity, true)
+        }
+        ArrowDataType::LargeBinary => {
+            let a = values_a
+                .as_any()
+                .downcast_ref::<BinaryArray<i64>>()
+                .unwrap();
+            let b = values_b
+                .as_any()
+                .downcast_ref::<BinaryArray<i64>>()
+                .unwrap();
+            binary(a, b, offsets_a, offsets_b, set_type, validity, false)
+        }
+        ArrowDataType::Boolean => {
+            todo!("boolean type not yet supported in list union operations")
+        }
+        _ => {
+            with_match_physical_integer_type!(dtype.into(), |$T| {
+                let a = values_a.as_any().downcast_ref::<PrimitiveArray<$T>>().unwrap();
+                let b = values_b.as_any().downcast_ref::<PrimitiveArray<$T>>().unwrap();
+
+                primitive(&a, &b, offsets_a, offsets_b, set_type, validity)
+            })
         }
     }
 }
 
-#[cfg(feature = "rolling_window")]
-pub use inner_mod::*;
+pub fn list_set_operation(a: &ListChunked, b: &ListChunked, set_type: SetOperation) -> ListChunked {
+    let (a, b) = align_chunks_binary(a, b);
+
+    // no downcasting needed as lists
+    // already have logical types
+    let chunks = a
+        .downcast_iter()
+        .zip(b.downcast_iter())
+        .map(|(a, b)| array_set_operation(a, b, set_type).boxed())
+        .collect::<Vec<_>>();
+
+    // safety: dtypes are correct
+    unsafe { a.with_chunks(chunks) }
+}
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/set.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/set.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/shift.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/shift.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/arg_sort_multiple.rs`

 * *Files 1% similar despite different names*

```diff
@@ -61,15 +61,15 @@
     });
     let ca: NoNull<IdxCa> = vals.into_iter().map(|(idx, _v)| idx).collect_trusted();
     // Don't set to sorted. Argsort indices are not sorted.
     Ok(ca.into_inner())
 }
 
 pub fn _get_rows_encoded_compat_array(by: &Series) -> PolarsResult<ArrayRef> {
-    let by = convert_sort_column_multi_sort(by, true)?;
+    let by = convert_sort_column_multi_sort(by)?;
     let by = by.rechunk();
 
     let out = match by.dtype() {
         #[cfg(feature = "dtype-categorical")]
         DataType::Categorical(_) => {
             let ca = by.categorical().unwrap();
             if ca.use_lexical_sort() {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/categorical.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/sort/mod.rs`

 * *Files 11% similar despite different names*

```diff
@@ -9,15 +9,14 @@
 use std::hint::unreachable_unchecked;
 use std::iter::FromIterator;
 
 pub(crate) use arg_sort_multiple::argsort_multiple_row_fmt;
 use arrow::bitmap::MutableBitmap;
 use arrow::buffer::Buffer;
 use num_traits::Float;
-use polars_arrow::array::default_arrays::FromDataUtf8;
 use polars_arrow::kernels::rolling::compare_fn_nan_max;
 use polars_arrow::prelude::{FromData, ValueSize};
 use polars_arrow::trusted_len::TrustedLenPush;
 use rayon::prelude::*;
 pub use slice::*;
 
 use crate::prelude::compare_inner::PartialOrdInner;
@@ -415,104 +414,15 @@
     }
     // all arrays/columns exhausted, ordering equal it is.
     Ordering::Equal
 }
 
 impl ChunkSort<Utf8Type> for Utf8Chunked {
     fn sort_with(&self, options: SortOptions) -> ChunkedArray<Utf8Type> {
-        sort_with_fast_path!(self, options);
-        let mut v: Vec<&str> = if self.null_count() > 0 {
-            Vec::from_iter(self.into_iter().flatten())
-        } else {
-            Vec::from_iter(self.into_no_null_iter())
-        };
-
-        sort_branch(
-            v.as_mut_slice(),
-            options.descending,
-            order_ascending,
-            order_descending,
-            options.multithreaded,
-        );
-
-        let mut values = Vec::<u8>::with_capacity(self.get_values_size());
-        let mut offsets = Vec::<i64>::with_capacity(self.len() + 1);
-        let mut length_so_far = 0i64;
-        offsets.push(length_so_far);
-
-        let len = self.len();
-        let null_count = self.null_count();
-        let mut ca: Self = match (null_count, options.nulls_last) {
-            (0, _) => {
-                for val in v {
-                    values.extend_from_slice(val.as_bytes());
-                    length_so_far = values.len() as i64;
-                    offsets.push(length_so_far);
-                }
-                // Safety:
-                // we pass valid utf8
-                let ar = unsafe {
-                    Utf8Array::from_data_unchecked_default(offsets.into(), values.into(), None)
-                };
-                (self.name(), ar).into()
-            }
-            (_, true) => {
-                for val in v {
-                    values.extend_from_slice(val.as_bytes());
-                    length_so_far = values.len() as i64;
-                    offsets.push(length_so_far);
-                }
-                let mut validity = MutableBitmap::with_capacity(len);
-                validity.extend_constant(len - null_count, true);
-                validity.extend_constant(null_count, false);
-                offsets.extend(std::iter::repeat(length_so_far).take(null_count));
-
-                // Safety:
-                // we pass valid utf8
-                let ar = unsafe {
-                    Utf8Array::from_data_unchecked_default(
-                        offsets.into(),
-                        values.into(),
-                        Some(validity.into()),
-                    )
-                };
-                (self.name(), ar).into()
-            }
-            (_, false) => {
-                let mut validity = MutableBitmap::with_capacity(len);
-                validity.extend_constant(null_count, false);
-                validity.extend_constant(len - null_count, true);
-                offsets.extend(std::iter::repeat(length_so_far).take(null_count));
-
-                for val in v {
-                    values.extend_from_slice(val.as_bytes());
-                    length_so_far = values.len() as i64;
-                    offsets.push(length_so_far);
-                }
-
-                // Safety:
-                // we pass valid utf8
-                let ar = unsafe {
-                    Utf8Array::from_data_unchecked_default(
-                        offsets.into(),
-                        values.into(),
-                        Some(validity.into()),
-                    )
-                };
-                (self.name(), ar).into()
-            }
-        };
-
-        let s = if options.descending {
-            IsSorted::Descending
-        } else {
-            IsSorted::Ascending
-        };
-        ca.set_sorted_flag(s);
-        ca
+        unsafe { self.as_binary().sort_with(options).to_utf8() }
     }
 
     fn sort(&self, descending: bool) -> Utf8Chunked {
         self.sort_with(SortOptions {
             descending,
             nulls_last: false,
             multithreaded: true,
@@ -564,15 +474,15 @@
             (0, _) => {
                 for val in v {
                     values.extend_from_slice(val);
                     length_so_far = values.len() as i64;
                     offsets.push(length_so_far);
                 }
                 // Safety:
-                // we pass valid utf8
+                // offsets are correctly created
                 let ar = unsafe {
                     BinaryArray::from_data_unchecked_default(offsets.into(), values.into(), None)
                 };
                 (self.name(), ar).into()
             }
             (_, true) => {
                 for val in v {
@@ -582,15 +492,15 @@
                 }
                 let mut validity = MutableBitmap::with_capacity(len);
                 validity.extend_constant(len - null_count, true);
                 validity.extend_constant(null_count, false);
                 offsets.extend(std::iter::repeat(length_so_far).take(null_count));
 
                 // Safety:
-                // we pass valid utf8
+                // offsets are correctly created
                 let ar = unsafe {
                     BinaryArray::from_data_unchecked_default(
                         offsets.into(),
                         values.into(),
                         Some(validity.into()),
                     )
                 };
@@ -735,40 +645,42 @@
             self.name(),
             self.downcast_iter().map(|arr| arr.iter()),
             options,
             self.null_count(),
             self.len(),
         )
     }
+    fn arg_sort_multiple(&self, options: &SortMultipleOptions) -> PolarsResult<IdxCa> {
+        let mut vals = Vec::with_capacity(self.len());
+        let mut count: IdxSize = 0;
+        for arr in self.downcast_iter() {
+            vals.extend_trusted_len(arr.into_iter().map(|v| {
+                let i = count;
+                count += 1;
+                (i, v.map(|v| v as u8))
+            }));
+        }
+        arg_sort_multiple_impl(vals, options)
+    }
 }
 
-pub(crate) fn convert_sort_column_multi_sort(
-    s: &Series,
-    row_ordering: bool,
-) -> PolarsResult<Series> {
+pub(crate) fn convert_sort_column_multi_sort(s: &Series) -> PolarsResult<Series> {
     use DataType::*;
     let out = match s.dtype() {
         #[cfg(feature = "dtype-categorical")]
         Categorical(_) => s.rechunk(),
-        Binary => s.clone(),
+        Binary | Boolean => s.clone(),
         Utf8 => s.cast(&Binary).unwrap(),
-        Boolean => {
-            if row_ordering {
-                s.clone()
-            } else {
-                s.cast(&UInt8).unwrap()
-            }
-        }
         #[cfg(feature = "dtype-struct")]
         Struct(_) => {
             let ca = s.struct_().unwrap();
             let new_fields = ca
                 .fields()
                 .iter()
-                .map(|s| convert_sort_column_multi_sort(s, row_ordering))
+                .map(convert_sort_column_multi_sort)
                 .collect::<PolarsResult<Vec<_>>>()?;
             return StructChunked::new(ca.name(), &new_fields).map(|ca| ca.into_series());
         }
         _ => {
             let phys = s.to_physical_repr().into_owned();
             polars_ensure!(
                 phys.dtype().is_numeric(),
@@ -792,15 +704,15 @@
     columns: Vec<Series>,
     mut descending: Vec<bool>,
 ) -> PolarsResult<(Series, Vec<Series>, Vec<bool>)> {
     let n_cols = columns.len();
 
     let mut columns = columns
         .iter()
-        .map(|s| convert_sort_column_multi_sort(s, false))
+        .map(convert_sort_column_multi_sort)
         .collect::<PolarsResult<Vec<_>>>()?;
 
     let first = columns.remove(0);
 
     // broadcast ordering
     _broadcast_descending(n_cols, &mut descending);
     Ok((first, columns, descending))
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/take_chunked.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/take_random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/take_single.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/take/traits.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/unique/mod.rs`

 * *Files 7% similar despite different names*

```diff
@@ -128,15 +128,14 @@
     fn unique(&self) -> PolarsResult<Self> {
         // prevent stackoverflow repeated sorted.unique call
         if self.is_empty() {
             return Ok(self.clone());
         }
         match self.is_sorted_flag() {
             IsSorted::Ascending | IsSorted::Descending => {
-                // TODO! optimize this branch
                 if self.null_count() > 0 {
                     let mut arr = MutablePrimitiveArray::with_capacity(self.len());
                     let mut iter = self.into_iter();
                     let mut last = None;
 
                     if let Some(val) = iter.next() {
                         last = val;
@@ -175,26 +174,47 @@
     }
 
     fn arg_unique(&self) -> PolarsResult<IdxCa> {
         Ok(IdxCa::from_vec(self.name(), arg_unique_ca!(self)))
     }
 
     fn n_unique(&self) -> PolarsResult<usize> {
-        let mut set: PlHashSet<T::Native> = PlHashSet::new();
-        if self.null_count() > 0 {
-            for arr in self.downcast_iter() {
-                set.extend(arr.into_iter().flatten())
+        // prevent stackoverflow repeated sorted.unique call
+        if self.is_empty() {
+            return Ok(0);
+        }
+        match self.is_sorted_flag() {
+            IsSorted::Ascending | IsSorted::Descending => {
+                if self.null_count() > 0 {
+                    let mut count = 0;
+                    let mut iter = self.into_iter();
+                    let mut last = None;
+
+                    if let Some(val) = iter.next() {
+                        last = val;
+                        count += 1;
+                    };
+
+                    iter.for_each(|opt_val| {
+                        if opt_val != last {
+                            last = opt_val;
+                            count += 1;
+                        }
+                    });
+
+                    Ok(count)
+                } else {
+                    let mask = self.not_equal_and_validity(&self.shift(1));
+                    Ok(mask.sum().unwrap() as usize)
+                }
             }
-            Ok(set.len() + 1)
-        } else {
-            for arr in self.downcast_iter() {
-                let slice = arr.values().as_slice();
-                set.extend(slice.iter().copied())
+            IsSorted::Not => {
+                let sorted = self.sort(false);
+                sorted.n_unique()
             }
-            Ok(set.len())
         }
     }
 
     #[cfg(feature = "mode")]
     fn mode(&self) -> PolarsResult<Self> {
         Ok(mode(self))
     }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/unique/rank.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/ops/zip.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/ops/zip.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/random.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/random.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/conversion.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/date.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/date.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/datetime.rs`

 * *Files 2% similar despite different names*

```diff
@@ -9,25 +9,19 @@
 #[cfg(feature = "timezones")]
 use chrono_tz::Tz;
 #[cfg(feature = "timezones")]
 use polars_arrow::kernels::replace_timezone;
 
 use super::conversion::{datetime_to_timestamp_ms, datetime_to_timestamp_ns};
 use super::*;
+#[cfg(feature = "timezones")]
+use crate::chunked_array::temporal::validate_time_zone;
 use crate::prelude::DataType::Datetime;
 use crate::prelude::*;
 
-#[cfg(feature = "timezones")]
-fn validate_time_zone(tz: TimeZone) -> PolarsResult<()> {
-    match tz.parse::<Tz>() {
-        Ok(_) => Ok(()),
-        Err(_) => polars_bail!(ComputeError: "unable to parse time zone: '{}'", tz),
-    }
-}
-
 fn apply_datefmt_f<'a>(
     arr: &PrimitiveArray<i64>,
     fmted: &'a str,
     conversion_f: fn(i64) -> NaiveDateTime,
     datefmt_f: impl Fn(NaiveDateTime) -> DelayedFormat<StrftimeItems<'a>>,
 ) -> ArrayRef {
     let mut buf = String::new();
@@ -258,15 +252,15 @@
     pub fn set_time_unit(&mut self, tu: TimeUnit) {
         self.2 = Some(Datetime(tu, self.time_zone().clone()))
     }
 
     /// Change the underlying [`TimeZone`]. This does not modify the data.
     #[cfg(feature = "timezones")]
     pub fn set_time_zone(&mut self, time_zone: TimeZone) -> PolarsResult<()> {
-        validate_time_zone(time_zone.to_string())?;
+        validate_time_zone(&time_zone)?;
         self.2 = Some(Datetime(self.time_unit(), Some(time_zone)));
         Ok(())
     }
     #[cfg(feature = "timezones")]
     pub fn convert_time_zone(mut self, time_zone: TimeZone) -> PolarsResult<Self> {
         polars_ensure!(
             self.time_zone().is_some(),
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/temporal/time.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/temporal/time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/to_vec.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/to_vec.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/trusted_len.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/trusted_len.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/chunked_array/upstream_traits.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/cloud.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/cloud.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/config.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/config.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/_serde.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/_serde.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/aliases.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/aliases.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/any_value.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/any_value.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/dtype.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/dtype.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/field.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/field.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/datatypes/time_unit.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/datatypes/time_unit.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_10_0_11.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_7.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_7.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_8.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/doc/changelog/v0_9.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/doc/changelog/v0_9.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/fmt.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/fmt.rs`

 * *Files 1% similar despite different names*

```diff
@@ -457,32 +457,35 @@
                 {
                     format!("{column_name} ({column_data_type})")
                 } else {
                     format!("{column_name}{column_separator}{column_data_type}")
                 };
                 (s, lower_bounds)
             };
-            let tbl_lower_bounds =
+
+            let col_width_exact =
+                |l: usize| ColumnConstraint::Absolute(comfy_table::Width::Fixed(l as u16));
+            let col_width_lower_bound =
                 |l: usize| ColumnConstraint::LowerBoundary(comfy_table::Width::Fixed(l as u16));
 
             let mut constraints = Vec::with_capacity(n_first + n_last + reduce_columns as usize);
             let fields = self.fields();
             for field in fields[0..n_first].iter() {
                 let (s, l) = field_to_str(field);
                 names.push(s);
-                constraints.push(tbl_lower_bounds(l));
+                constraints.push(col_width_lower_bound(l));
             }
             if reduce_columns {
                 names.push("".into());
-                constraints.push(tbl_lower_bounds(3));
+                constraints.push(col_width_exact(3));
             }
             for field in fields[self.width() - n_last..].iter() {
                 let (s, l) = field_to_str(field);
                 names.push(s);
-                constraints.push(tbl_lower_bounds(l));
+                constraints.push(col_width_lower_bound(l));
             }
             let (preset, is_utf8) = match std::env::var(FMT_TABLE_FORMATTING)
                 .as_deref()
                 .unwrap_or("DEFAULT")
             {
                 "ASCII_FULL" => (ASCII_FULL, false),
                 "ASCII_FULL_CONDENSED" => (ASCII_FULL_CONDENSED, false),
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/arithmetic.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/asof_join/asof.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/asof_join/asof.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/asof_join/groups.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/asof_join/groups.rs`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 use smartstring::alias::String as SmartString;
 
 use super::*;
 use crate::frame::groupby::hashing::HASHMAP_INIT_SIZE;
 #[cfg(feature = "dtype-categorical")]
 use crate::frame::hash_join::_check_categorical_src;
 use crate::frame::hash_join::{
-    create_probe_table, get_hash_tbl_threaded_join_partitioned, multiple_keys as mk, prepare_bytes,
+    build_tables, get_hash_tbl_threaded_join_partitioned, multiple_keys as mk, prepare_bytes,
 };
 use crate::hashing::{df_rows_to_hashes_threaded_vertical, AsU64};
 use crate::utils::{split_ca, split_df};
 use crate::POOL;
 
 pub(super) unsafe fn join_asof_backward_with_indirection_and_tolerance<
     T: PartialOrd + Copy + Sub<Output = T> + Debug,
@@ -299,15 +299,15 @@
         .map(|ca| ca.cont_slice().unwrap())
         .collect::<Vec<_>>();
     let vals_right = splitted_right
         .iter()
         .map(|ca| ca.cont_slice().unwrap())
         .collect::<Vec<_>>();
 
-    let hash_tbls = create_probe_table(vals_right);
+    let hash_tbls = build_tables(vals_right);
 
     // we determine the offset so that we later know which index to store in the join tuples
     let offsets = vals_left
         .iter()
         .map(|ph| ph.len())
         .scan(0, |state, val| {
             let out = *state;
@@ -423,15 +423,15 @@
     let splitted_by_left = split_ca(by_left, n_threads).unwrap();
     let splitted_right = split_ca(by_right, n_threads).unwrap();
 
     let hb = RandomState::default();
     let vals_left = prepare_bytes(&splitted_by_left, &hb);
     let vals_right = prepare_bytes(&splitted_right, &hb);
 
-    let hash_tbls = create_probe_table(vals_right);
+    let hash_tbls = build_tables(vals_right);
 
     // we determine the offset so that we later know which index to store in the join tuples
     let offsets = vals_left
         .iter()
         .map(|ph| ph.len())
         .scan(0, |state, val| {
             let out = *state;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/chunks.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/chunks.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/cross_join.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/cross_join.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/explode.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/explode.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/from.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/agg_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/boolean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/dispatch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/aggregations/utf8.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/aggregations/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/hashing.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/hashing.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/into_groups.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/into_groups.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/perfect.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/perfect.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/groupby/proxy.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/groupby/proxy.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/args.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/args.rs`

 * *Files 2% similar despite different names*

```diff
@@ -154,21 +154,21 @@
         Ok(())
     }
 
     pub(super) fn validate_build(
         &self,
         build_size: usize,
         expected_size: usize,
-        swap: bool,
+        check_rhs: bool,
     ) -> PolarsResult<()> {
         use JoinValidation::*;
 
         // all lhs `Many`s are valid
         // lhs `One`s need to be checked
-        let valid = match self.swap(swap) {
+        let valid = match self.swap(check_rhs) {
             ManyToMany | ManyToOne => true,
             OneToMany | OneToOne => build_size == expected_size,
         };
         polars_ensure!(valid, ComputeError: "the join keys did not fulfil {} validation", self);
         Ok(())
     }
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 use hashbrown::hash_map::{Entry, RawEntryMut};
 use hashbrown::HashMap;
 use polars_arrow::utils::CustomIterTools;
 use rayon::prelude::*;
 #[cfg(feature = "serde")]
 use serde::{Deserialize, Serialize};
 #[cfg(feature = "asof_join")]
-pub(crate) use single_keys::create_probe_table;
+pub(crate) use single_keys::build_tables;
 #[cfg(feature = "asof_join")]
 pub(crate) use single_keys_dispatch::prepare_bytes;
 use single_keys_left::*;
 use single_keys_outer::*;
 #[cfg(feature = "semi_anti_join")]
 use single_keys_semi_anti::*;
 pub use sort_merge::*;
@@ -89,19 +89,15 @@
 use crate::series::IsSorted;
 
 /// If Categorical types are created without a global string cache or under
 /// a different global string cache the mapping will be incorrect.
 #[cfg(feature = "dtype-categorical")]
 pub fn _check_categorical_src(l: &DataType, r: &DataType) -> PolarsResult<()> {
     if let (DataType::Categorical(Some(l)), DataType::Categorical(Some(r))) = (l, r) {
-        polars_ensure!(
-            l.same_src(r),
-            ComputeError: "joins/or comparisons on categoricals can only happen if they were \
-            created under the same global string cache"
-        );
+        polars_ensure!(l.same_src(r), string_cache_mismatch);
     }
     Ok(())
 }
 
 pub(crate) unsafe fn get_hash_tbl_threaded_join_partitioned<Item>(
     h: u64,
     hash_tables: &[Item],
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/multiple_keys.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys.rs`

 * *Files 11% similar despite different names*

```diff
@@ -1,12 +1,10 @@
 use super::*;
 
-pub(crate) fn create_probe_table<T, IntoSlice>(
-    keys: Vec<IntoSlice>,
-) -> Vec<PlHashMap<T, Vec<IdxSize>>>
+pub(crate) fn build_tables<T, IntoSlice>(keys: Vec<IntoSlice>) -> Vec<PlHashMap<T, Vec<IdxSize>>>
 where
     T: Send + Hash + Eq + Sync + Copy + AsU64,
     IntoSlice: AsRef<[T]> + Send + Sync,
 {
     let n_partitions = _set_partition_size();
 
     // We will create a hashtable in every thread.
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_dispatch.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_inner.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 use polars_utils::iter::EnumerateIdxTrait;
 use polars_utils::sync::SyncPtr;
 
-use super::single_keys::create_probe_table;
+use super::single_keys::build_tables;
 use super::*;
 use crate::frame::hash_join::single_keys::probe_to_offsets;
 use crate::utils::flatten;
 
 /// Probe the build table and add tuples to the results (inner join)
 pub(super) fn probe_inner<T, F>(
     probe: &[T],
@@ -44,20 +44,23 @@
 where
     IntoSlice: AsRef<[T]> + Send + Sync,
     T: Send + Hash + Eq + Sync + Copy + AsU64,
 {
     // NOTE: see the left join for more elaborate comments
 
     // first we hash one relation
-    let hash_tbls = create_probe_table(build);
-    if validate.needs_checks() {
+    let hash_tbls = if validate.needs_checks() {
+        let expected_size = build.iter().map(|v| v.as_ref().len()).sum();
+        let hash_tbls = build_tables(build);
         let build_size = hash_tbls.iter().map(|m| m.len()).sum();
-        let expected_size = probe.iter().map(|v| v.as_ref().len()).sum();
-        validate.validate_build(build_size, expected_size, swap)?;
-    }
+        validate.validate_build(build_size, expected_size, !swap)?;
+        hash_tbls
+    } else {
+        build_tables(build)
+    };
 
     let n_tables = hash_tbls.len() as u64;
     debug_assert!(n_tables.is_power_of_two());
     let offsets = probe_to_offsets(&probe);
     // next we probe the other relation
     // code duplication is because we want to only do the swap check once
     let out = POOL.install(|| {
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_left.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-use super::single_keys::create_probe_table;
+use super::single_keys::build_tables;
 use super::*;
 use crate::frame::hash_join::single_keys::probe_to_offsets;
 use crate::utils::flatten::flatten_par;
 
 #[cfg(feature = "chunked_ids")]
 unsafe fn apply_mapping(idx: Vec<IdxSize>, chunk_mapping: &[ChunkId]) -> Vec<ChunkId> {
     idx.iter()
@@ -108,20 +108,23 @@
     validate: JoinValidation,
 ) -> PolarsResult<LeftJoinIds>
 where
     IntoSlice: AsRef<[T]> + Send + Sync,
     T: Send + Hash + Eq + Sync + Copy + AsU64,
 {
     // first we hash one relation
-    let hash_tbls = create_probe_table(build);
-    if validate.needs_checks() {
+    let hash_tbls = if validate.needs_checks() {
+        let expected_size = build.iter().map(|v| v.as_ref().len()).sum();
+        let hash_tbls = build_tables(build);
         let build_size = hash_tbls.iter().map(|m| m.len()).sum();
-        let expected_size = probe.iter().map(|v| v.as_ref().len()).sum();
         validate.validate_build(build_size, expected_size, false)?;
-    }
+        hash_tbls
+    } else {
+        build_tables(build)
+    };
 
     // we determine the offset so that we later know which index to store in the join tuples
     let offsets = probe_to_offsets(&probe);
 
     let n_tables = hash_tbls.len() as u64;
     debug_assert!(n_tables.is_power_of_two());
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_outer.rs`

 * *Files 4% similar despite different names*

```diff
@@ -80,20 +80,23 @@
     // keep it lock free.
 
     let size = probe.iter().map(|a| a.size_hint().0).sum::<usize>()
         + build.iter().map(|b| b.size_hint().0).sum::<usize>();
     let mut results = Vec::with_capacity(size);
 
     // prepare hash table
-    let mut hash_tbls = prepare_hashed_relation_threaded(build);
-    if validate.needs_checks() {
+    let mut hash_tbls = if validate.needs_checks() {
+        let expected_size = build.iter().map(|i| i.size_hint().0).sum();
+        let hash_tbls = prepare_hashed_relation_threaded(build);
         let build_size = hash_tbls.iter().map(|m| m.len()).sum();
-        let expected_size = probe.iter().map(|i| i.size_hint().0).sum();
-        validate.validate_build(build_size, expected_size, true)?;
-    }
+        validate.validate_build(build_size, expected_size, !swap)?;
+        hash_tbls
+    } else {
+        prepare_hashed_relation_threaded(build)
+    };
     let random_state = hash_tbls[0].hasher().clone();
 
     // we pre hash the probing values
     let (probe_hashes, _) = create_hash_and_keys_threaded_vectorized(probe, Some(random_state));
 
     let n_tables = hash_tbls.len() as u64;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/single_keys_semi_anti.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/sort_merge.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/hash_join/zip_outer.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/hash_join/zip_outer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/mod.rs`

 * *Files 0% similar despite different names*

```diff
@@ -732,18 +732,22 @@
     /// assert!(!df2.is_empty());
     /// # Ok::<(), PolarsError>(())
     /// ```
     pub fn is_empty(&self) -> bool {
         self.columns.is_empty()
     }
 
-    pub(crate) fn hstack_mut_no_checks(&mut self, columns: &[Series]) -> &mut Self {
-        for col in columns {
-            self.columns.push(col.clone());
-        }
+    /// Add columns horizontally.
+    ///
+    /// # Safety
+    /// The caller must ensure:
+    /// - the length of all [`Series`] is equal to the height of this [`DataFrame`]
+    /// - the columns names are unique
+    pub unsafe fn hstack_mut_unchecked(&mut self, columns: &[Series]) -> &mut Self {
+        self.columns.extend_from_slice(columns);
         self
     }
 
     /// Add multiple `Series` to a `DataFrame`.
     /// The added `Series` are required to have the same length.
     ///
     /// # Example
@@ -770,15 +774,15 @@
             );
             polars_ensure!(
                 names.insert(col.name()),
                 Duplicate: "unable to hstack, column with name {:?} already exists", col.name(),
             );
         }
         drop(names);
-        Ok(self.hstack_mut_no_checks(columns))
+        Ok(unsafe { self.hstack_mut_unchecked(columns) })
     }
 
     /// Add multiple `Series` to a `DataFrame`.
     /// The added `Series` are required to have the same length.
     ///
     /// # Example
     ///
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/row/av_buffer.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/row/av_buffer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/row/dataframe.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/row/dataframe.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/row/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/row/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/row/transpose.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/row/transpose.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/top_k.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/top_k.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/frame/upstream_traits.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/frame/upstream_traits.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/functions.rs` & `polars_lts_cpu-0.18.5/src/apply/dataframe.rs`

 * *Files 24% similar despite different names*

```diff
@@ -1,337 +1,318 @@
-//! # Functions
-//!
-//! Functions that might be useful.
-//!
-use std::ops::Add;
-
-#[cfg(feature = "diagonal_concat")]
-use ahash::AHashSet;
-use arrow::compute;
-use arrow::types::simd::Simd;
-use num_traits::{Float, NumCast, ToPrimitive};
-#[cfg(feature = "concat_str")]
-use polars_arrow::prelude::ValueSize;
-
-use crate::prelude::*;
-use crate::utils::coalesce_nulls;
-#[cfg(feature = "diagonal_concat")]
-use crate::utils::concat_df;
+use polars::prelude::*;
+use polars_core::frame::row::{rows_to_schema_first_non_null, Row};
+use polars_core::series::SeriesIter;
+use pyo3::conversion::{FromPyObject, IntoPy};
+use pyo3::prelude::*;
+use pyo3::types::{PyBool, PyFloat, PyInt, PyList, PyString, PyTuple};
+
+use super::*;
+use crate::conversion::Wrap;
+use crate::error::PyPolarsErr;
+use crate::series::PySeries;
+use crate::PyDataFrame;
 
-/// Compute the covariance between two columns.
-pub fn cov_f<T>(a: &ChunkedArray<T>, b: &ChunkedArray<T>) -> Option<T::Native>
-where
-    T: PolarsFloatType,
-    T::Native: Float,
-    <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
-        + compute::aggregate::Sum<T::Native>
-        + compute::aggregate::SimdOrd<T::Native>,
-{
-    if a.len() != b.len() {
-        None
-    } else {
-        let tmp = (a - a.mean()?) * (b - b.mean()?);
-        let n = tmp.len() - tmp.null_count();
-        Some(tmp.sum()? / NumCast::from(n - 1).unwrap())
-    }
+fn get_iters(df: &DataFrame) -> Vec<SeriesIter> {
+    df.get_columns().iter().map(|s| s.iter()).collect()
 }
 
-/// Compute the covariance between two columns.
-pub fn cov_i<T>(a: &ChunkedArray<T>, b: &ChunkedArray<T>) -> Option<f64>
-where
-    T: PolarsIntegerType,
-    T::Native: ToPrimitive,
-    <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
-        + compute::aggregate::Sum<T::Native>
-        + compute::aggregate::SimdOrd<T::Native>,
-{
-    if a.len() != b.len() {
-        None
-    } else {
-        let a_mean = a.mean()?;
-        let b_mean = b.mean()?;
-        let a = a.apply_cast_numeric::<_, Float64Type>(|a| a.to_f64().unwrap() - a_mean);
-        let b = b.apply_cast_numeric(|b| b.to_f64().unwrap() - b_mean);
-
-        let tmp = a * b;
-        let n = tmp.len() - tmp.null_count();
-        Some(tmp.sum()? / (n - 1) as f64)
+fn get_iters_skip(df: &DataFrame, skip: usize) -> Vec<std::iter::Skip<SeriesIter>> {
+    df.get_columns()
+        .iter()
+        .map(|s| s.iter().skip(skip))
+        .collect()
+}
+
+// the return type is Union[PySeries, PyDataFrame] and a boolean indicating if it is a dataframe or not
+pub fn apply_lambda_unknown<'a>(
+    df: &'a DataFrame,
+    py: Python,
+    lambda: &'a PyAny,
+    inference_size: usize,
+) -> PyResult<(PyObject, bool)> {
+    let mut null_count = 0;
+    let mut iters = get_iters(df);
+
+    for _ in 0..df.height() {
+        let iter = iters.iter_mut().map(|it| Wrap(it.next().unwrap()));
+        let arg = (PyTuple::new(py, iter),);
+        let out = lambda.call1(arg)?;
+
+        if out.is_none() {
+            null_count += 1;
+            continue;
+        } else if out.is_instance_of::<PyBool>() {
+            let first_value = out.extract::<bool>().ok();
+            return Ok((
+                PySeries::new(
+                    apply_lambda_with_bool_out_type(df, py, lambda, null_count, first_value)
+                        .into_series(),
+                )
+                .into_py(py),
+                false,
+            ));
+        } else if out.is_instance_of::<PyFloat>() {
+            let first_value = out.extract::<f64>().ok();
+
+            return Ok((
+                PySeries::new(
+                    apply_lambda_with_primitive_out_type::<Float64Type>(
+                        df,
+                        py,
+                        lambda,
+                        null_count,
+                        first_value,
+                    )
+                    .into_series(),
+                )
+                .into_py(py),
+                false,
+            ));
+        } else if out.is_instance_of::<PyInt>() {
+            let first_value = out.extract::<i64>().ok();
+            return Ok((
+                PySeries::new(
+                    apply_lambda_with_primitive_out_type::<Int64Type>(
+                        df,
+                        py,
+                        lambda,
+                        null_count,
+                        first_value,
+                    )
+                    .into_series(),
+                )
+                .into_py(py),
+                false,
+            ));
+        } else if out.is_instance_of::<PyString>() {
+            let first_value = out.extract::<&str>().ok();
+            return Ok((
+                PySeries::new(
+                    apply_lambda_with_utf8_out_type(df, py, lambda, null_count, first_value)
+                        .into_series(),
+                )
+                .into_py(py),
+                false,
+            ));
+        } else if out.hasattr("_s")? {
+            let py_pyseries = out.getattr("_s").unwrap();
+            let series = py_pyseries.extract::<PySeries>().unwrap().series;
+            let dt = series.dtype();
+            return Ok((
+                PySeries::new(
+                    apply_lambda_with_list_out_type(df, py, lambda, null_count, Some(&series), dt)?
+                        .into_series(),
+                )
+                .into_py(py),
+                false,
+            ));
+        } else if out.extract::<Wrap<Row<'a>>>().is_ok() {
+            let first_value = out.extract::<Wrap<Row<'a>>>().unwrap().0;
+            return Ok((
+                PyDataFrame::from(
+                    apply_lambda_with_rows_output(
+                        df,
+                        py,
+                        lambda,
+                        null_count,
+                        first_value,
+                        inference_size,
+                    )
+                    .map_err(PyPolarsErr::from)?,
+                )
+                .into_py(py),
+                true,
+            ));
+        } else if out.is_instance_of::<PyList>() || out.is_instance_of::<PyTuple>() {
+            return Err(PyPolarsErr::Other(
+                "A list output type is invalid. Do you mean to create polars List Series?\
+Then return a Series object."
+                    .into(),
+            )
+            .into());
+        } else {
+            return Err(PyPolarsErr::Other("Could not determine output type".into()).into());
+        }
     }
+    Err(PyPolarsErr::Other("Could not determine output type".into()).into())
 }
 
-/// Compute the pearson correlation between two columns.
-pub fn pearson_corr_i<T>(a: &ChunkedArray<T>, b: &ChunkedArray<T>, ddof: u8) -> Option<f64>
+fn apply_iter<'a, T>(
+    df: &'a DataFrame,
+    py: Python<'a>,
+    lambda: &'a PyAny,
+    init_null_count: usize,
+    skip: usize,
+) -> impl Iterator<Item = Option<T>> + 'a
 where
-    T: PolarsIntegerType,
-    T::Native: ToPrimitive,
-    <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
-        + compute::aggregate::Sum<T::Native>
-        + compute::aggregate::SimdOrd<T::Native>,
-    ChunkedArray<T>: ChunkVar<f64>,
+    T: FromPyObject<'a>,
 {
-    let (a, b) = coalesce_nulls(a, b);
-    let a = a.as_ref();
-    let b = b.as_ref();
-
-    Some(cov_i(a, b)? / (a.std(ddof)? * b.std(ddof)?))
+    let mut iters = get_iters_skip(df, init_null_count + skip);
+    ((init_null_count + skip)..df.height()).map(move |_| {
+        let iter = iters.iter_mut().map(|it| Wrap(it.next().unwrap()));
+        let tpl = (PyTuple::new(py, iter),);
+        match lambda.call1(tpl) {
+            Ok(val) => val.extract::<T>().ok(),
+            Err(e) => panic!("python function failed {e}"),
+        }
+    })
 }
 
-/// Compute the pearson correlation between two columns.
-pub fn pearson_corr_f<T>(a: &ChunkedArray<T>, b: &ChunkedArray<T>, ddof: u8) -> Option<T::Native>
+/// Apply a lambda with a primitive output type
+pub fn apply_lambda_with_primitive_out_type<'a, D>(
+    df: &'a DataFrame,
+    py: Python<'a>,
+    lambda: &'a PyAny,
+    init_null_count: usize,
+    first_value: Option<D::Native>,
+) -> ChunkedArray<D>
 where
-    T: PolarsFloatType,
-    T::Native: Float,
-    <T::Native as Simd>::Simd: Add<Output = <T::Native as Simd>::Simd>
-        + compute::aggregate::Sum<T::Native>
-        + compute::aggregate::SimdOrd<T::Native>,
-    ChunkedArray<T>: ChunkVar<T::Native>,
+    D: PyArrowPrimitiveType,
+    D::Native: ToPyObject + FromPyObject<'a>,
 {
-    let (a, b) = coalesce_nulls(a, b);
-    let a = a.as_ref();
-    let b = b.as_ref();
-
-    Some(cov_f(a, b)? / (a.std(ddof)? * b.std(ddof)?))
-}
-
-// utility to be able to also add literals to concat_str function
-#[cfg(feature = "concat_str")]
-enum IterBroadCast<'a> {
-    Column(Box<dyn PolarsIterator<Item = Option<&'a str>> + 'a>),
-    Value(Option<&'a str>),
-}
-
-#[cfg(feature = "concat_str")]
-impl<'a> IterBroadCast<'a> {
-    fn next(&mut self) -> Option<Option<&'a str>> {
-        use IterBroadCast::*;
-        match self {
-            Column(iter) => iter.next(),
-            Value(val) => Some(*val),
-        }
+    let skip = usize::from(first_value.is_some());
+    if init_null_count == df.height() {
+        ChunkedArray::full_null("apply", df.height())
+    } else {
+        let iter = apply_iter(df, py, lambda, init_null_count, skip);
+        iterator_to_primitive(iter, init_null_count, first_value, "apply", df.height())
     }
 }
 
-/// Casts all series to string data and will concat them in linear time.
-/// The concatenated strings are separated by a `delimiter`.
-/// If no `delimiter` is needed, an empty &str should be passed as argument.
-#[cfg(feature = "concat_str")]
-pub fn concat_str(s: &[Series], delimiter: &str) -> PolarsResult<Utf8Chunked> {
-    polars_ensure!(!s.is_empty(), NoData: "expected multiple series in `concat_str`");
-    if s.iter().any(|s| s.is_empty()) {
-        return Ok(Utf8Chunked::full_null(s[0].name(), 0));
-    }
-
-    let len = s.iter().map(|s| s.len()).max().unwrap();
-
-    let cas = s
-        .iter()
-        .map(|s| {
-            let s = s.cast(&DataType::Utf8)?;
-            let mut ca = s.utf8()?.clone();
-            // broadcast
-            if ca.len() == 1 && len > 1 {
-                ca = ca.new_from_index(0, len)
-            }
-
-            Ok(ca)
-        })
-        .collect::<PolarsResult<Vec<_>>>()?;
-
-    polars_ensure!(
-        s.iter().all(|s| s.len() == 1 || s.len() == len),
-        ComputeError: "all series in `concat_str` should have equal or unit length"
-    );
-    let mut iters = cas
-        .iter()
-        .map(|ca| match ca.len() {
-            1 => IterBroadCast::Value(ca.get(0)),
-            _ => IterBroadCast::Column(ca.into_iter()),
-        })
-        .collect::<Vec<_>>();
-
-    let bytes_cap = cas.iter().map(|ca| ca.get_values_size()).sum();
-    let mut builder = Utf8ChunkedBuilder::new(s[0].name(), len, bytes_cap);
-
-    // use a string buffer, to amortize alloc
-    let mut buf = String::with_capacity(128);
-
-    for _ in 0..len {
-        let mut has_null = false;
-
-        iters.iter_mut().enumerate().for_each(|(i, it)| {
-            if i > 0 {
-                buf.push_str(delimiter);
-            }
-
-            match it.next() {
-                Some(Some(s)) => buf.push_str(s),
-                Some(None) => has_null = true,
-                None => {
-                    // should not happen as the out loop counts to length
-                    unreachable!()
-                }
-            }
-        });
-
-        if has_null {
-            builder.append_null();
-        } else {
-            builder.append_value(&buf)
-        }
-        buf.truncate(0)
+/// Apply a lambda with a boolean output type
+pub fn apply_lambda_with_bool_out_type<'a>(
+    df: &'a DataFrame,
+    py: Python,
+    lambda: &'a PyAny,
+    init_null_count: usize,
+    first_value: Option<bool>,
+) -> ChunkedArray<BooleanType> {
+    let skip = usize::from(first_value.is_some());
+    if init_null_count == df.height() {
+        ChunkedArray::full_null("apply", df.height())
+    } else {
+        let iter = apply_iter(df, py, lambda, init_null_count, skip);
+        iterator_to_bool(iter, init_null_count, first_value, "apply", df.height())
     }
-    Ok(builder.finish())
 }
 
-/// Concat `[DataFrame]`s horizontally.
-#[cfg(feature = "horizontal_concat")]
-/// Concat horizontally and extend with null values if lengths don't match
-pub fn hor_concat_df(dfs: &[DataFrame]) -> PolarsResult<DataFrame> {
-    let max_len = dfs
-        .iter()
-        .map(|df| df.height())
-        .max()
-        .ok_or_else(|| polars_err!(ComputeError: "cannot concat empty dataframes"))?;
-
-    let owned_df;
-
-    // if not all equal length, extend the DataFrame with nulls
-    let dfs = if !dfs.iter().all(|df| df.height() == max_len) {
-        owned_df = dfs
-            .iter()
-            .cloned()
-            .map(|mut df| {
-                if df.height() != max_len {
-                    let diff = max_len - df.height();
-                    df.columns
-                        .iter_mut()
-                        .for_each(|s| *s = s.extend_constant(AnyValue::Null, diff).unwrap());
-                }
-                df
-            })
-            .collect::<Vec<_>>();
-        owned_df.as_slice()
+/// Apply a lambda with utf8 output type
+pub fn apply_lambda_with_utf8_out_type<'a>(
+    df: &'a DataFrame,
+    py: Python,
+    lambda: &'a PyAny,
+    init_null_count: usize,
+    first_value: Option<&str>,
+) -> Utf8Chunked {
+    let skip = usize::from(first_value.is_some());
+    if init_null_count == df.height() {
+        ChunkedArray::full_null("apply", df.height())
     } else {
-        dfs
-    };
-
-    let mut first_df = dfs[0].clone();
-
-    for df in &dfs[1..] {
-        first_df.hstack_mut(df.get_columns())?;
+        let iter = apply_iter::<&str>(df, py, lambda, init_null_count, skip);
+        iterator_to_utf8(iter, init_null_count, first_value, "apply", df.height())
     }
-    Ok(first_df)
 }
 
-/// Concat `[DataFrame]`s diagonally.
-#[cfg(feature = "diagonal_concat")]
-/// Concat diagonally thereby combining different schemas.
-pub fn diag_concat_df(dfs: &[DataFrame]) -> PolarsResult<DataFrame> {
-    // TODO! replace with lazy only?
-    let upper_bound_width = dfs.iter().map(|df| df.width()).sum();
-    let mut column_names = AHashSet::with_capacity(upper_bound_width);
-    let mut schema = Vec::with_capacity(upper_bound_width);
-
-    for df in dfs {
-        df.get_columns().iter().for_each(|s| {
-            let name = s.name();
-            if column_names.insert(name) {
-                schema.push((name, s.dtype()))
+/// Apply a lambda with list output type
+pub fn apply_lambda_with_list_out_type<'a>(
+    df: &'a DataFrame,
+    py: Python,
+    lambda: &'a PyAny,
+    init_null_count: usize,
+    first_value: Option<&Series>,
+    dt: &DataType,
+) -> PyResult<ListChunked> {
+    let skip = usize::from(first_value.is_some());
+    if init_null_count == df.height() {
+        Ok(ChunkedArray::full_null("apply", df.height()))
+    } else {
+        let mut iters = get_iters_skip(df, init_null_count + skip);
+        let iter = ((init_null_count + skip)..df.height()).map(|_| {
+            let iter = iters.iter_mut().map(|it| Wrap(it.next().unwrap()));
+            let tpl = (PyTuple::new(py, iter),);
+            match lambda.call1(tpl) {
+                Ok(val) => match val.getattr("_s") {
+                    Ok(val) => val.extract::<PySeries>().ok().map(|ps| ps.series),
+                    Err(_) => {
+                        if val.is_none() {
+                            None
+                        } else {
+                            panic!("should return a Series, got a {val:?}")
+                        }
+                    }
+                },
+                Err(e) => panic!("python function failed {e}"),
             }
         });
+        iterator_to_list(dt, iter, init_null_count, first_value, "apply", df.height())
     }
-
-    let dfs = dfs
-        .iter()
-        .map(|df| {
-            let height = df.height();
-            let mut columns = Vec::with_capacity(schema.len());
-
-            for (name, dtype) in &schema {
-                match df.column(name).ok() {
-                    Some(s) => columns.push(s.clone()),
-                    None => columns.push(Series::full_null(name, height, dtype)),
-                }
-            }
-            DataFrame::new_no_checks(columns)
-        })
-        .collect::<Vec<_>>();
-
-    concat_df(&dfs)
 }
 
-#[cfg(test)]
-mod test {
-    use super::*;
-
-    #[test]
-    fn test_cov() {
-        let a = Series::new("a", &[1.0f32, 2.0, 5.0]);
-        let b = Series::new("b", &[1.0f32, 2.0, -3.0]);
-        let out = cov_f(a.f32().unwrap(), b.f32().unwrap());
-        assert_eq!(out, Some(-5.0));
-        let a = a.cast(&DataType::Int32).unwrap();
-        let b = b.cast(&DataType::Int32).unwrap();
-        let out = cov_i(a.i32().unwrap(), b.i32().unwrap());
-        assert_eq!(out, Some(-5.0));
-    }
-
-    #[test]
-    fn test_pearson_corr() {
-        let a = Series::new("a", &[1.0f32, 2.0]);
-        let b = Series::new("b", &[1.0f32, 2.0]);
-        assert!((cov_f(a.f32().unwrap(), b.f32().unwrap()).unwrap() - 0.5).abs() < 0.001);
-        assert!(
-            (pearson_corr_f(a.f32().unwrap(), b.f32().unwrap(), 1).unwrap() - 1.0).abs() < 0.001
-        );
-    }
-
-    #[test]
-    #[cfg(feature = "concat_str")]
-    fn test_concat_str() {
-        let a = Series::new("a", &["foo", "bar"]);
-        let b = Series::new("b", &["spam", "ham"]);
-
-        let out = concat_str(&[a.clone(), b.clone()], "_").unwrap();
-        assert_eq!(Vec::from(&out), &[Some("foo_spam"), Some("bar_ham")]);
-
-        let c = Series::new("b", &["literal"]);
-        let out = concat_str(&[a, b, c], "_").unwrap();
-        assert_eq!(
-            Vec::from(&out),
-            &[Some("foo_spam_literal"), Some("bar_ham_literal")]
-        );
-    }
-
-    #[test]
-    #[cfg(feature = "diagonal_concat")]
-    fn test_diag_concat() -> PolarsResult<()> {
-        let a = df![
-            "a" => [1, 2],
-            "b" => ["a", "b"]
-        ]?;
-
-        let b = df![
-            "b" => ["a", "b"],
-            "c" => [1, 2]
-        ]?;
-
-        let c = df![
-            "a" => [5, 7],
-            "c" => [1, 2],
-            "d" => [1, 2]
-        ]?;
-
-        let out = diag_concat_df(&[a, b, c])?;
-
-        let expected = df![
-            "a" => [Some(1), Some(2), None, None, Some(5), Some(7)],
-            "b" => [Some("a"), Some("b"), Some("a"), Some("b"), None, None],
-            "c" => [None, None, Some(1), Some(2), Some(1), Some(2)],
-            "d" => [None, None, None, None, Some(1), Some(2)]
-        ]?;
-
-        assert!(out.frame_equal_missing(&expected));
+pub fn apply_lambda_with_rows_output<'a>(
+    df: &'a DataFrame,
+    py: Python,
+    lambda: &'a PyAny,
+    init_null_count: usize,
+    first_value: Row<'a>,
+    inference_size: usize,
+) -> PolarsResult<DataFrame> {
+    let width = first_value.0.len();
+    let null_row = Row::new(vec![AnyValue::Null; width]);
+
+    let mut row_buf = Row::default();
+
+    let skip = 1;
+    let mut iters = get_iters_skip(df, init_null_count + skip);
+    let mut row_iter = ((init_null_count + skip)..df.height()).map(|_| {
+        let iter = iters.iter_mut().map(|it| Wrap(it.next().unwrap()));
+        let tpl = (PyTuple::new(py, iter),);
+
+        let return_val = lambda.call1(tpl).map_err(|e| polars_err!(ComputeError: format!("{e}")))?;
+        if return_val.is_none() {
+            Ok(&null_row)
+        } else {
+            let tuple = return_val.downcast::<PyTuple>().map_err(|_| polars_err!(ComputeError: format!("expected tuple, got {}", return_val.get_type().name().unwrap())))?;
+            row_buf.0.clear();
+            for v in tuple {
+                let v = v.extract::<Wrap<AnyValue>>().unwrap().0;
+                row_buf.0.push(v);
+            }
+            let ptr = &row_buf as *const Row;
+            // Safety:
+            // we know that row constructor of polars dataframe does not keep a reference
+            // to the row. Before we mutate the row buf again, the reference is dropped.
+            // we only cannot prove it to the compiler.
+            // we still to this because it save a Vec allocation in a hot loop.
+            Ok(unsafe { &*ptr })
+        }
+    });
 
-        Ok(())
+    // first rows for schema inference
+    let mut buf = Vec::with_capacity(inference_size);
+    buf.push(first_value);
+    for v in (&mut row_iter).take(inference_size) {
+        buf.push(v?.clone());
+    }
+
+    let schema = rows_to_schema_first_non_null(&buf, Some(50));
+
+    if init_null_count > 0 {
+        // Safety: we know the iterators size
+        let iter = unsafe {
+            (0..init_null_count)
+                .map(|_| Ok(&null_row))
+                .chain(buf.iter().map(Ok))
+                .chain(row_iter)
+                .trust_my_length(df.height())
+        };
+        DataFrame::try_from_rows_iter_and_schema(iter, &schema)
+    } else {
+        // Safety: we know the iterators size
+        let iter = unsafe {
+            buf.iter()
+                .map(Ok)
+                .chain(row_iter)
+                .trust_my_length(df.height())
+        };
+        DataFrame::try_from_rows_iter_and_schema(iter, &schema)
     }
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/fx.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/fx.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/identity.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/identity.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/partition.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/partition.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/hashing/vector_hasher.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/hashing/vector_hasher.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/lib.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/named_from.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/named_from.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/prelude.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/prelude.rs`

 * *Files 3% similar despite different names*

```diff
@@ -13,14 +13,16 @@
     BinaryChunkedBuilder, BooleanChunkedBuilder, ChunkedBuilder, ListBinaryChunkedBuilder,
     ListBooleanChunkedBuilder, ListBuilderTrait, ListPrimitiveChunkedBuilder,
     ListUtf8ChunkedBuilder, NewChunkedArray, PrimitiveChunkedBuilder, Utf8ChunkedBuilder,
 };
 pub use crate::chunked_array::iterator::PolarsIterator;
 #[cfg(feature = "dtype-categorical")]
 pub use crate::chunked_array::logical::categorical::*;
+#[cfg(feature = "ndarray")]
+pub use crate::chunked_array::ndarray::IndexOrder;
 #[cfg(feature = "object")]
 pub use crate::chunked_array::object::PolarsObject;
 pub use crate::chunked_array::ops::aggregate::*;
 #[cfg(feature = "rolling_window")]
 pub use crate::chunked_array::ops::rolling_window::RollingOptionsFixedWindow;
 #[cfg(feature = "rank")]
 pub use crate::chunked_array::ops::unique::rank::{RankMethod, RankOptions};
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/schema.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/schema.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,10 @@
 use std::fmt::{Debug, Formatter};
 
+use indexmap::map::MutableKeys;
 use indexmap::IndexMap;
 #[cfg(feature = "serde-lazy")]
 use serde::{Deserialize, Serialize};
 use smartstring::alias::String as SmartString;
 
 use crate::prelude::*;
 use crate::utils::try_get_supertype;
@@ -248,15 +249,15 @@
     }
 
     /// Get mutable references to the name and dtype of the field at `index`
     ///
     /// If `index` is inbounds, returns `Some((&mut name, &mut dtype))`, else `None`. See
     /// [`get_at_index`][Self::get_at_index] for an immutable version.
     pub fn get_at_index_mut(&mut self, index: usize) -> Option<(&mut SmartString, &mut DataType)> {
-        self.inner.get_index_mut(index)
+        self.inner.get_index_mut2(index)
     }
 
     /// Swap-remove a field by name and, if the field existed, return its dtype
     ///
     /// If the field does not exist, the schema is not modified and `None` is returned.
     ///
     /// This method does a `swap_remove`, which is O(1) but **changes the order of the schema**: the field named `name`
@@ -272,14 +273,24 @@
     ///
     /// This method does a `shift_remove`, which preserves the order of the fields in the schema but **is O(n)**. For a
     /// faster, but not order-preserving, method, use [`remove`][Self::remove].
     pub fn shift_remove(&mut self, name: &str) -> Option<DataType> {
         self.inner.shift_remove(name)
     }
 
+    /// Remove a field by name, preserving order, and, if the field existed, return its dtype
+    ///
+    /// If the field does not exist, the schema is not modified and `None` is returned.
+    ///
+    /// This method does a `shift_remove`, which preserves the order of the fields in the schema but **is O(n)**. For a
+    /// faster, but not order-preserving, method, use [`remove`][Self::remove].
+    pub fn shift_remove_index(&mut self, index: usize) -> Option<(SmartString, DataType)> {
+        self.inner.shift_remove_index(index)
+    }
+
     /// Whether the schema contains a field named `name`
     pub fn contains(&self, name: &str) -> bool {
         self.get(name).is_some()
     }
 
     /// Change the field named `name` to the given `dtype` and return the previous dtype
     ///
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/serde/chunked_array.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/serde/chunked_array.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/serde/df.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/serde/df.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/serde/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/serde/mod.rs`

 * *Files 1% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 pub mod chunked_array;
 mod df;
 pub mod series;
 
 #[cfg(test)]
 mod test {
-    use super::*;
     use crate::prelude::*;
 
     #[test]
     fn test_serde() -> PolarsResult<()> {
         let ca = UInt32Chunked::new("foo", &[Some(1), None, Some(2)]);
 
         let json = serde_json::to_string(&ca).unwrap();
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/serde/series.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/serde/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/any_value.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/any_value.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/arithmetic/borrowed.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/arithmetic/owned.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/arithmetic/owned.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/comparison.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/comparison.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/from.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/from.rs`

 * *Files 1% similar despite different names*

```diff
@@ -13,14 +13,16 @@
 use polars_error::feature_gated;
 
 use crate::chunked_array::cast::cast_chunks;
 #[cfg(feature = "object")]
 use crate::chunked_array::object::extension::polars_extension::PolarsExtension;
 #[cfg(feature = "object")]
 use crate::chunked_array::object::extension::EXTENSION_NAME;
+#[cfg(feature = "timezones")]
+use crate::chunked_array::temporal::validate_time_zone;
 #[cfg(all(feature = "dtype-decimal", feature = "python"))]
 use crate::config::decimal_is_active;
 use crate::config::verbose;
 use crate::prelude::*;
 
 impl Series {
     /// Takes chunks and a polars datatype and constructs the Series
@@ -195,15 +197,18 @@
             }
             #[cfg(feature = "dtype-datetime")]
             ArrowDataType::Timestamp(tu, tz) => {
                 let mut tz = tz.clone();
                 if tz.as_deref() == Some("") {
                     tz = None;
                 }
-                // we still drop timezone for now
+                if let Some(_tz) = &tz {
+                    #[cfg(feature = "timezones")]
+                    validate_time_zone(_tz)?;
+                }
                 let chunks = cast_chunks(&chunks, &DataType::Int64, false).unwrap();
                 let s = Int64Chunked::from_chunks(name, chunks)
                     .into_datetime(tu.into(), tz)
                     .into_series();
                 Ok(match tu {
                     ArrowTimeUnit::Second => &s * MILLISECONDS,
                     ArrowTimeUnit::Millisecond => s,
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/array.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/array.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/binary.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/boolean.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/boolean.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/categorical.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/categorical.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/dates_time.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/dates_time.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/datetime.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/datetime.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/decimal.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/decimal.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/duration.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/duration.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/floats.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/floats.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/null.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/null.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/object.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/object.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/struct_.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/struct_.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/implementations/utf8.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/implementations/utf8.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/into.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/into.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/iterator.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/iterator.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/diff.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/diff.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/downcast.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/downcast.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/ewm.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/ewm.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/moment.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/moment.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/null.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/null.rs`

 * *Files 20% similar despite different names*

```diff
@@ -4,15 +4,22 @@
     pub fn full_null(name: &str, size: usize, dtype: &DataType) -> Self {
         // match the logical types and create them
         match dtype {
             DataType::List(inner_dtype) => {
                 ListChunked::full_null_with_dtype(name, size, inner_dtype).into_series()
             }
             #[cfg(feature = "dtype-categorical")]
-            DataType::Categorical(_) => CategoricalChunked::full_null(name, size).into_series(),
+            DataType::Categorical(rev_map) => {
+                let mut ca = CategoricalChunked::full_null(name, size);
+                // ensure we keep the rev-map of a cleared series
+                if let Some(rev_map) = rev_map {
+                    unsafe { ca.set_rev_map(rev_map.clone(), false) }
+                }
+                ca.into_series()
+            }
             #[cfg(feature = "dtype-date")]
             DataType::Date => Int32Chunked::full_null(name, size)
                 .into_date()
                 .into_series(),
             #[cfg(feature = "dtype-datetime")]
             DataType::Datetime(tu, tz) => Int64Chunked::full_null(name, size)
                 .into_datetime(*tu, tz.clone())
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/pct_change.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/pct_change.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/round.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/round.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/to_list.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/to_list.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/ops/unique.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/ops/unique.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/series_trait.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/series_trait.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/series/unstable.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/series/unstable.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/testing.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/testing.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/utils/flatten.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/utils/flatten.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/utils/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/utils/mod.rs`

 * *Files 2% similar despite different names*

```diff
@@ -313,14 +313,33 @@
         Float32 => __with_ty__! { f32 },
         Float64 => __with_ty__! { f64 },
         _ => unimplemented!()
     }
 })}
 
 #[macro_export]
+macro_rules! with_match_physical_integer_type {(
+    $dtype:expr, | $_:tt $T:ident | $($body:tt)*
+) => ({
+    macro_rules! __with_ty__ {( $_ $T:ident ) => ( $($body)* )}
+    use $crate::datatypes::DataType::*;
+    match $dtype {
+        Int8 => __with_ty__! { i8 },
+        Int16 => __with_ty__! { i16 },
+        Int32 => __with_ty__! { i32 },
+        Int64 => __with_ty__! { i64 },
+        UInt8 => __with_ty__! { u8 },
+        UInt16 => __with_ty__! { u16 },
+        UInt32 => __with_ty__! { u32 },
+        UInt64 => __with_ty__! { u64 },
+        _ => unimplemented!()
+    }
+})}
+
+#[macro_export]
 macro_rules! with_match_physical_numeric_polars_type {(
     $key_type:expr, | $_:tt $T:ident | $($body:tt)*
 ) => ({
     macro_rules! __with_ty__ {( $_ $T:ident ) => ( $($body)* )}
     use $crate::datatypes::DataType::*;
     match $key_type {
             #[cfg(feature = "dtype-i8")]
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/utils/series.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/utils/series.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-core/src/utils/supertype.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-core/src/utils/supertype.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-algo/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-algo/Cargo.toml`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-algo/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-algo/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-algo/src/algo.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-algo/src/algo.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/Cargo.toml`

 * *Files 0% similar despite different names*

```diff
@@ -84,15 +84,15 @@
 
 [dependencies.arrow]
 package = "arrow2"
 # git = "https://github.com/jorgecarleitao/arrow2"
 git = "https://github.com/ritchie46/arrow2"
 # rev = "2d2e7053f9a50810bfe9cecff25ab39089aef98e"
 # path = "../arrow2"
-branch = "polars_2023-06-23"
+branch = "polars_2023-06-26"
 version = "0.17"
 default-features = false
 features = [
   "compute_aggregate",
   "compute_arithmetics",
   "compute_boolean",
   "compute_boolean_kleene",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/avro/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/avro/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/avro/read.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/avro/read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/avro/write.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/avro/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/cloud/adaptors.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/cloud/adaptors.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/cloud/glob.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/cloud/glob.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/cloud/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/cloud/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/buffer.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/buffer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/parser.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/parser.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/read.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/read.rs`

 * *Files 0% similar despite different names*

```diff
@@ -560,15 +560,15 @@
         let mut _cat_lock = None;
 
         let mut df = if let Some(schema) = schema_overwrite.as_deref() {
             let (schema, to_cast, _has_cat) = self.prepare_schema_overwrite(schema)?;
 
             #[cfg(feature = "dtype-categorical")]
             if _has_cat {
-                _cat_lock = Some(polars_core::IUseStringCache::new())
+                _cat_lock = Some(polars_core::IUseStringCache::hold())
             }
 
             let mut csv_reader = self.core_reader(Some(Arc::new(schema)), to_cast)?;
             csv_reader.as_df()?
         } else {
             #[cfg(feature = "dtype-categorical")]
             {
@@ -578,15 +578,15 @@
                     .map(|schema| {
                         schema
                             .iter_dtypes()
                             .any(|dtype| matches!(dtype, DataType::Categorical(_)))
                     })
                     .unwrap_or(false);
                 if has_cat {
-                    _cat_lock = Some(polars_core::IUseStringCache::new())
+                    _cat_lock = Some(polars_core::IUseStringCache::hold())
                 }
             }
             let mut csv_reader = self.core_reader(self.schema.clone(), vec![])?;
             csv_reader.as_df()?
         };
 
         // Important that this rechunk is never done in parallel.
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/read_impl/batched_mmap.rs`

 * *Files 1% similar despite different names*

```diff
@@ -132,15 +132,15 @@
         let projection = self.get_projection();
 
         let str_columns = self.get_string_columns(&projection)?;
 
         // RAII structure that will ensure we maintain a global stringcache
         #[cfg(feature = "dtype-categorical")]
         let _cat_lock = if _has_cat {
-            Some(polars_core::IUseStringCache::new())
+            Some(polars_core::IUseStringCache::hold())
         } else {
             None
         };
 
         #[cfg(not(feature = "dtype-categorical"))]
         let _cat_lock = None;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/read_impl/batched_read.rs`

 * *Files 0% similar despite different names*

```diff
@@ -213,15 +213,15 @@
         let projection = self.get_projection();
 
         let str_columns = self.get_string_columns(&projection)?;
 
         // RAII structure that will ensure we maintain a global stringcache
         #[cfg(feature = "dtype-categorical")]
         let _cat_lock = if _has_cat {
-            Some(polars_core::IUseStringCache::new())
+            Some(polars_core::IUseStringCache::hold())
         } else {
             None
         };
 
         #[cfg(not(feature = "dtype-categorical"))]
         let _cat_lock = None;
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/read_impl/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/read_impl/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/splitfields.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/splitfields.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/write.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/csv/write_impl.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/csv/write_impl.rs`

 * *Files 0% similar despite different names*

```diff
@@ -197,15 +197,15 @@
         let nested = match s.dtype() {
             DataType::List(_) => true,
             #[cfg(feature = "dtype-struct")]
             DataType::Struct(_) => true,
             #[cfg(feature = "object")]
             DataType::Object(_) => {
                 return Err(PolarsError::ComputeError(
-                    "csv writer does not suppert object dtype".into(),
+                    "csv writer does not support object dtype".into(),
                 ))
             }
             _ => false,
         };
         polars_ensure!(
             !nested,
             ComputeError: "CSV format does not support nested data",
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/ipc_file.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/ipc_file.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/ipc_stream.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/ipc_stream.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/mmap.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/write.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/write.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ipc/write_async.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ipc/write_async.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/json/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/json/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/lib.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/lib.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/mmap.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ndjson/buffer.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ndjson/buffer.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/ndjson/core.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/ndjson/core.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/async_impl.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/async_impl.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/mmap.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/mmap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/mod.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/predicates.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/predicates.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/read.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/read.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/read_impl.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/read_impl.rs`

 * *Files 0% similar despite different names*

```diff
@@ -251,15 +251,15 @@
 
     // if there are multiple row groups and categorical data
     // we need a string cache
     // we keep it alive until the end of the function
     let _string_cache = if n_row_groups > 1 {
         #[cfg(feature = "dtype-categorical")]
         {
-            Some(polars_core::IUseStringCache::new())
+            Some(polars_core::IUseStringCache::hold())
         }
         #[cfg(not(feature = "dtype-categorical"))]
         {
             Some(0u8)
         }
     } else {
         None
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/parquet/write.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/parquet/write.rs`

 * *Files 2% similar despite different names*

```diff
@@ -47,27 +47,32 @@
 impl GzipLevel {
     pub fn try_new(level: u8) -> PolarsResult<Self> {
         GzipLevelParquet::try_new(level).map_err(ArrowError::from)?;
         Ok(GzipLevel(level))
     }
 }
 
-#[derive(Debug, Eq, PartialEq, Hash, Clone, Copy, Default)]
+#[derive(Debug, Eq, PartialEq, Hash, Clone, Copy)]
 #[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
 pub enum ParquetCompression {
     Uncompressed,
     Snappy,
     Gzip(Option<GzipLevel>),
     Lzo,
     Brotli(Option<BrotliLevel>),
     Zstd(Option<ZstdLevel>),
-    #[default]
     Lz4Raw,
 }
 
+impl Default for ParquetCompression {
+    fn default() -> Self {
+        Self::Zstd(None)
+    }
+}
+
 impl From<ParquetCompression> for CompressionOptions {
     fn from(value: ParquetCompression) -> Self {
         use ParquetCompression::*;
         match value {
             Uncompressed => CompressionOptions::Uncompressed,
             Snappy => CompressionOptions::Snappy,
             Gzip(level) => {
@@ -109,25 +114,25 @@
     /// Create a new writer
     pub fn new(writer: W) -> Self
     where
         W: Write,
     {
         ParquetWriter {
             writer,
-            compression: CompressionOptions::Zstd(None),
+            compression: ParquetCompression::default().into(),
             statistics: false,
             row_group_size: None,
             data_pagesize_limit: None,
             parallel: true,
         }
     }
 
-    /// Set the compression used. Defaults to `Lz4Raw`.
+    /// Set the compression used. Defaults to `Zstd`.
     ///
-    /// The default compression `Lz4Raw` has very good performance, but may not yet been supported
+    /// The default compression `Zstd` has very good performance, but may not yet been supported
     /// by older readers. If you want more compatibility guarantees, consider using `Snappy`.
     pub fn with_compression(mut self, compression: ParquetCompression) -> Self {
         self.compression = compression.into();
         self
     }
 
     /// Compute and write statistic
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/partition.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/partition.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/predicates.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/predicates.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/prelude.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/prelude.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-io/src/utils.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-io/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/Cargo.toml` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/Cargo.toml`

 * *Files 3% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 description = "private utils for the polars dataframe library"
 resolver = "2"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 ahash= "0.8"
-hashbrown= { version = "0.13.1", features = ["rayon", "ahash"] }
+hashbrown= { version = "0.14.0", features = ["rayon", "ahash"] }
 num-traits= "0.2"
 once_cell= "1"
 rayon= "1.6"
 smartstring= { version = "1" }
 sysinfo = { version = "0.29", default-features = false, optional = true }
 
 [features]
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/LICENSE` & `polars_lts_cpu-0.18.5/local_dependencies/polars-sql/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/arena.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/arena.rs`

 * *Files 2% similar despite different names*

```diff
@@ -13,15 +13,15 @@
             Some(index_of_unchecked(slice, item))
         } else {
             None
         }
     }
 }
 
-#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash)]
+#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, Ord, PartialOrd)]
 pub struct Node(pub usize);
 
 impl Default for Node {
     fn default() -> Self {
         Node(usize::MAX)
     }
 }
```

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/atomic.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/atomic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/cell.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/cell.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/contention_pool.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/contention_pool.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/functions.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/functions.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/iter/enumerate_idx.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/iter/enumerate_idx.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/macros.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/macros.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/slice.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/slice.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/sort.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/sort.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/sync.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/sync.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/unwrap.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/unwrap.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/vec.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/vec.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/local_dependencies/polars-utils/src/wasm.rs` & `polars_lts_cpu-0.18.5/local_dependencies/polars-utils/src/wasm.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/Cargo.toml` & `polars_lts_cpu-0.18.5/Cargo.toml`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [package]
 name = "py-polars"
-version = "0.18.4"
+version = "0.18.5"
 edition = "2021"
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [workspace]
 # prevents package from thinking it's in the workspace
 [target.'cfg(any(not(target_os = "linux"), use_mimalloc))'.dependencies]
@@ -21,15 +21,15 @@
 libc = "0.2"
 ndarray = "0.15"
 numpy = "0.19"
 once_cell = "1"
 polars-algo = { path = "local_dependencies/polars-algo", default-features = false }
 polars-core = { path = "local_dependencies/polars-core", features = ["python"], default-features = false }
 polars-lazy = { path = "local_dependencies/polars-lazy", features = ["python"], default-features = false }
-pyo3 = { version = "0.19", features = ["abi3-py37", "extension-module", "multiple-pymethods"] }
+pyo3 = { version = "0.19", features = ["abi3-py38", "extension-module", "multiple-pymethods"] }
 pyo3-built = { version = "0.4", optional = true }
 serde_json = { version = "1", optional = true }
 smartstring = "1"
 thiserror = "^1.0"
 
 # features are only there to enable building a slim binary for the benchmark in CI
 [features]
@@ -62,14 +62,17 @@
 performant = ["polars/performant"]
 timezones = ["polars/timezones"]
 cse = ["polars/cse"]
 merge_sorted = ["polars/merge_sorted"]
 list_take = ["polars/list_take"]
 list_count = ["polars/list_count"]
 binary_encoding = ["polars/binary_encoding"]
+list_sets = ["polars-lazy/list_sets"]
+list_any_all = ["polars/list_any_all"]
+cutqcut = ["polars/cutqcut"]
 
 all = [
   "json",
   "parquet",
   "ipc",
   "avro",
   "is_in",
@@ -97,14 +100,17 @@
   "polars/fused",
   "sql",
   "binary_encoding",
   "streaming",
   "performant",
   "list_take",
   "list_count",
+  "list_sets",
+  "list_any_all",
+  "cutqcut",
 ]
 
 # we cannot conditionally activate simd
 # https://github.com/rust-lang/cargo/issues/1197
 # so we have an indirection and compile
 # with --no-default-features --features=all for targets without simd
 default = [
@@ -135,15 +141,15 @@
   "mode",
   "cum_agg",
   "rolling_window",
   "interpolate",
   "rank",
   "diff",
   "moment",
-  "arange",
+  "range",
   "true_div",
   "dtype-categorical",
   "diagonal_concat",
   "horizontal_concat",
   "abs",
   "ewma",
   "dot_diagram",
```

### Comparing `polars_lts_cpu-0.18.4/LICENSE` & `polars_lts_cpu-0.18.5/LICENSE`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/Makefile` & `polars_lts_cpu-0.18.5/Makefile`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -27,17 +27,17 @@
 
 .PHONY: build-release
 build-release: .venv  ## Compile and install a faster Polars binary
 	@unset CONDA_PREFIX && source $(VENV_BIN)/activate && maturin develop --release
 
 .PHONY: fmt
 fmt: .venv  ## Run autoformatting and linting
+	$(VENV_BIN)/ruff .
 	$(VENV_BIN)/black .
 	$(VENV_BIN)/blackdoc .
-	$(VENV_BIN)/ruff .
 	$(VENV_BIN)/typos ..
 	$(VENV_BIN)/python scripts/check_stacklevels.py
 	cargo fmt --all
 	-dprint fmt
 	-$(VENV_BIN)/mypy
 
 .PHONY: clippy
```

### Comparing `polars_lts_cpu-0.18.4/README.md` & `polars_lts_cpu-0.18.5/README.md`

 * *Files 4% similar despite different names*

```diff
@@ -1,19 +1,13 @@
 <h1 align="center">
   <img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg">
   <br>
 </h1>
 
 <div align="center">
-  <a href="https://docs.rs/polars/latest/polars/">
-    <img src="https://docs.rs/polars/badge.svg" alt="rust docs"/>
-  </a>
-  <a href="https://github.com/pola-rs/polars/actions">
-    <img src="https://github.com/pola-rs/polars/workflows/Build%20and%20test/badge.svg" alt="Build and test"/>
-  </a>
   <a href="https://crates.io/crates/polars">
     <img src="https://img.shields.io/crates/v/polars.svg"/>
   </a>
   <a href="https://pypi.org/project/polars/">
     <img src="https://img.shields.io/pypi/v/polars.svg" alt="PyPi Latest Release"/>
   </a>
   <a href="https://www.npmjs.com/package/nodejs-polars">
@@ -27,15 +21,15 @@
   </a>
 </div>
 
 <p align="center">
   <b>Documentation</b>:
   <a href="https://pola-rs.github.io/polars/py-polars/html/reference/index.html">Python</a>
   -
-  <a href="https://pola-rs.github.io/polars/polars/index.html">Rust</a>
+  <a href="https://docs.rs/polars/latest/polars/">Rust</a>
   -
   <a href="https://pola-rs.github.io/nodejs-polars/index.html">Node.js</a>
   -
   <a href="https://rpolars.github.io/index.html">R</a>
   |
   <b>StackOverflow</b>:
   <a href="https://stackoverflow.com/questions/tagged/python-polars">Python</a>
```

#### html2text {}

```diff
@@ -1,13 +1,12 @@
  ****** [https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/
                     polars_github_logo_rect_dark_name.svg]
                                      ******
-[rust_docs] [Build_and_test] [https://img.shields.io/crates/v/polars.svg] [PyPi
- Latest_Release] [NPM_Latest_Release] [R-universe_Latest_Release] [DOI_Latest
-                                   Release]
+[https://img.shields.io/crates/v/polars.svg] [PyPi_Latest_Release] [NPM_Latest
+           Release] [R-universe_Latest_Release] [DOI_Latest_Release]
   Documentation: Python - Rust - Node.js - R | StackOverflow: Python - Rust -
                       Node.js - R | User_Guide | Discord
 ## Polars: Blazingly fast DataFrames in Rust, Python, Node.js, R and SQL Polars
 is a DataFrame interface on top of an OLAP Query Engine implemented in Rust
 using [Apache Arrow Columnar Format](https://arrow.apache.org/docs/format/
 Columnar.html) as the memory model. - Lazy | eager execution - Multi-threaded -
 SIMD - Query optimization - Powerful expression API - Hybrid Streaming (larger
```

### Comparing `polars_lts_cpu-0.18.4/build.rs` & `polars_lts_cpu-0.18.5/build.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/Makefile` & `polars_lts_cpu-0.18.5/docs/Makefile`

 * *Files 2% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 # Minimal makefile for Sphinx documentation
 #
 
 export BUILDING_SPHINX_DOCS = 1
 
 # You can set these variables from the command line, and also
 # from the environment for the first two.
-SPHINXOPTS    ?= -j auto
+SPHINXOPTS    ?= -j auto -W
 SPHINXBUILD   ?= sphinx-build
 SOURCEDIR     = source
 BUILDDIR      = build
 
 # Put it first so that "make" without argument is like "make help".
 help:
 	@$(SPHINXBUILD) -M help "$(SOURCEDIR)" "$(BUILDDIR)" $(SPHINXOPTS) $(O)
```

### Comparing `polars_lts_cpu-0.18.4/docs/_templates/autosummary/class.rst` & `polars_lts_cpu-0.18.5/docs/_templates/autosummary/class.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/run_live_docs_server.py` & `polars_lts_cpu-0.18.5/docs/run_live_docs_server.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/_static/css/custom.css` & `polars_lts_cpu-0.18.5/docs/source/_static/css/custom.css`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/conf.py` & `polars_lts_cpu-0.18.5/docs/source/conf.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/api.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/api.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/config.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/config.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/dataframe/modify_select.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/dataframe/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/datatypes.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/datatypes.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/expressions/computation.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/expressions/computation.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/expressions/functions.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/expressions/functions.rst`

 * *Files 6% similar despite different names*

```diff
@@ -14,57 +14,64 @@
 
    all
    any
    apply
    approx_unique
    arange
    arg_sort_by
+   arg_where
    avg
    coalesce
    concat_list
    concat_str
    corr
    count
    cov
    cumfold
    cumreduce
    cumsum
    date
    datetime
+   date_range
    duration
    element
    exclude
    first
    fold
    format
    from_epoch
    groups
    head
    implode
+   int_range
+   int_ranges
    lit
    map
    max
    mean
    median
    min
    n_unique
+   ones
    quantile
    reduce
    repeat
    rolling_corr
    rolling_cov
    select
    std
    struct
    sum
    sql_expr
    tail
    time
+   time_range
    var
    when
+   zeros
 
 
 **Available in expression namespace:**
 
 .. autosummary::
    :toctree: api/
```

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/expressions/modify_select.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/expressions/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/expressions/operators.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/expressions/operators.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/expressions/string.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/expressions/string.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/expressions/temporal.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/expressions/temporal.rst`

 * *Files 6% similar despite different names*

```diff
@@ -5,21 +5,23 @@
 The following methods are available under the `expr.dt` attribute.
 
 .. currentmodule:: polars
 .. autosummary::
    :toctree: api/
    :template: autosummary/accessor_method.rst
 
+    Expr.dt.base_utc_offset
     Expr.dt.cast_time_unit
     Expr.dt.replace_time_zone
     Expr.dt.combine
     Expr.dt.date
     Expr.dt.datetime
     Expr.dt.day
     Expr.dt.days
+    Expr.dt.dst_offset
     Expr.dt.epoch
     Expr.dt.hour
     Expr.dt.hours
     Expr.dt.is_leap_year
     Expr.dt.iso_year
     Expr.dt.microsecond
     Expr.dt.microseconds
```

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/functions.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/functions.rst`

 * *Files 24% similar despite different names*

```diff
@@ -13,32 +13,21 @@
     from_dict
     from_dicts
     from_numpy
     from_pandas
     from_records
     from_repr
 
-Eager/Lazy functions
-~~~~~~~~~~~~~~~~~~~~
-.. autosummary::
-   :toctree: api/
-
-    arg_where
-    concat
-    date_range
-    ones
-    time_range
-    zeros
-
 Miscellaneous
 ~~~~~~~~~~~~~~~~~~~~
 .. autosummary::
    :toctree: api/
 
     align_frames
+    concat
 
 Parallelization
 ~~~~~~~~~~~~~~~
 .. autosummary::
    :toctree: api/
 
    collect_all
```

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/io.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/io.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/lazyframe/modify_select.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/lazyframe/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/selectors.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/selectors.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/series/computation.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/series/computation.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/series/descriptive.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/series/descriptive.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/series/list.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/series/list.rst`

 * *Files 5% similar despite different names*

```diff
@@ -5,33 +5,38 @@
 The following methods are available under the `Series.list` attribute.
 
 .. currentmodule:: polars
 .. autosummary::
    :toctree: api/
    :template: autosummary/accessor_method.rst
 
+    Series.list.all
+    Series.list.any
     Series.list.arg_max
     Series.list.arg_min
     Series.list.concat
     Series.list.contains
     Series.list.count_match
     Series.list.diff
+    Series.list.difference
     Series.list.eval
     Series.list.explode
     Series.list.first
     Series.list.get
     Series.list.head
+    Series.list.intersection
     Series.list.join
     Series.list.last
     Series.list.lengths
     Series.list.max
     Series.list.mean
     Series.list.min
     Series.list.reverse
     Series.list.shift
     Series.list.slice
     Series.list.sort
     Series.list.sum
     Series.list.tail
     Series.list.take
     Series.list.to_struct
+    Series.list.union
     Series.list.unique
```

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/series/modify_select.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/series/modify_select.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/series/string.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/series/string.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/series/temporal.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/series/temporal.rst`

 * *Files 2% similar despite different names*

```diff
@@ -5,21 +5,23 @@
 The following methods are available under the `Series.dt` attribute.
 
 .. currentmodule:: polars
 .. autosummary::
    :toctree: api/
    :template: autosummary/accessor_method.rst
 
+    Series.dt.base_utc_offset
     Series.dt.cast_time_unit
     Series.dt.replace_time_zone
     Series.dt.combine
     Series.dt.date
     Series.dt.datetime
     Series.dt.day
     Series.dt.days
+    Series.dt.dst_offset
     Series.dt.epoch
     Series.dt.hour
     Series.dt.hours
     Series.dt.is_leap_year
     Series.dt.iso_year
     Series.dt.max
     Series.dt.mean
```

### Comparing `polars_lts_cpu-0.18.4/docs/source/reference/testing.rst` & `polars_lts_cpu-0.18.5/docs/source/reference/testing.rst`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/__init__.py` & `polars_lts_cpu-0.18.5/polars/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -106,14 +106,16 @@
     first,
     fold,
     format,
     from_epoch,
     groups,
     head,
     implode,
+    int_range,
+    int_ranges,
     last,
     lit,
     map,
     max,
     mean,
     median,
     min,
@@ -304,14 +306,16 @@
     "first",
     "fold",
     "format",
     "from_epoch",
     "groups",
     "head",
     "implode",
+    "int_range",
+    "int_ranges",
     "last",
     "lit",
     "map",
     "max",
     "mean",
     "median",
     "min",
```

### Comparing `polars_lts_cpu-0.18.4/polars/api.py` & `polars_lts_cpu-0.18.5/polars/api.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/config.py` & `polars_lts_cpu-0.18.5/polars/config.py`

 * *Files 1% similar despite different names*

```diff
@@ -16,24 +16,19 @@
 
 # note: module not available when building docs
 with contextlib.suppress(ImportError):
     from polars.polars import get_float_fmt as _get_float_fmt  # type: ignore[no-redef]
     from polars.polars import set_float_fmt as _set_float_fmt
 
 if TYPE_CHECKING:
-    import sys
     from types import TracebackType
+    from typing import Literal
 
     from polars.type_aliases import FloatFmt
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
-
 
 # note: register all Config-specific environment variable names here; need to constrain
 # which 'POLARS_' environment variables are recognised, as there are other lower-level
 # and/or experimental settings that should not be saved or reset with the Config vars.
 _POLARS_CFG_ENV_VARS = {
     "POLARS_ACTIVATE_DECIMAL",
     "POLARS_AUTO_STRUCTIFY",
```

### Comparing `polars_lts_cpu-0.18.4/polars/convert.py` & `polars_lts_cpu-0.18.5/polars/convert.py`

 * *Files 1% similar despite different names*

```diff
@@ -106,16 +106,16 @@
         If a list of column names is supplied that does NOT match the names in the
         underlying data, the names given here will overwrite the actual fields in
         the order that they appear - however, in this case it is typically clearer
         to rename after loading the frame.
 
         If you want to drop some of the fields found in the input dictionaries, a
         _partial_ schema can be declared, in which case omitted fields will not be
-        loaded. Similarly you can extend the loaded frame with empty columns by adding
-        them to the schema.
+        loaded. Similarly, you can extend the loaded frame with empty columns by
+        adding them to the schema.
     schema_overrides : dict, default None
         Support override of inferred types for one or more columns.
     infer_schema_length
         How many dictionaries/rows to scan to determine the data types
         if set to `None` then ALL dicts are scanned; this will be slow.
 
     Returns
@@ -181,15 +181,15 @@
         schema=schema,
         schema_overrides=schema_overrides,
         infer_schema_length=infer_schema_length,
     )
 
 
 def from_records(
-    data: Sequence[Sequence[Any]],
+    data: Sequence[Any],
     schema: SchemaDefinition | None = None,
     *,
     schema_overrides: SchemaDict | None = None,
     orient: Orientation | None = None,
     infer_schema_length: int | None = N_INFER_DEFAULT,
 ) -> DataFrame:
     """
@@ -635,26 +635,26 @@
     include_index: bool = ...,
 ) -> DataFrame:
     ...
 
 
 @overload
 def from_pandas(
-    data: pd.Series | pd.DatetimeIndex,
+    data: pd.Series[Any] | pd.Index,
     *,
     schema_overrides: SchemaDict | None = ...,
     rechunk: bool = ...,
     nan_to_null: bool = ...,
     include_index: bool = ...,
 ) -> Series:
     ...
 
 
 def from_pandas(
-    data: pd.DataFrame | pd.Series | pd.DatetimeIndex,
+    data: pd.DataFrame | pd.Series[Any] | pd.Index,
     *,
     schema_overrides: SchemaDict | None = None,
     rechunk: bool = True,
     nan_to_null: bool = True,
     include_index: bool = False,
 ) -> DataFrame | Series:
     """
```

### Comparing `polars_lts_cpu-0.18.4/polars/dataframe/_html.py` & `polars_lts_cpu-0.18.5/polars/dataframe/_html.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/dataframe/frame.py` & `polars_lts_cpu-0.18.5/polars/dataframe/frame.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,31 +1,34 @@
 """Module containing logic related to eager DataFrames."""
 from __future__ import annotations
 
 import contextlib
 import os
 import random
-import typing
 import warnings
+from collections import defaultdict
 from collections.abc import Sized
-from io import BytesIO, StringIO
+from io import BytesIO, StringIO, TextIOWrapper
+from operator import itemgetter
 from pathlib import Path
 from typing import (
     TYPE_CHECKING,
     Any,
     BinaryIO,
     Callable,
+    ClassVar,
     Collection,
     Generator,
     Iterable,
     Iterator,
     Mapping,
     NoReturn,
     Sequence,
     TypeVar,
+    cast,
     overload,
 )
 
 import polars._reexport as pl
 from polars import functions as F
 from polars.dataframe._html import NotebookFormatter
 from polars.dataframe.groupby import DynamicGroupBy, GroupBy, RollingGroupBy
@@ -41,28 +44,27 @@
     List,
     Null,
     Object,
     Struct,
     Time,
     Utf8,
     py_type_to_dtype,
-    unpack_dtypes,
 )
 from polars.dependencies import (
     _PYARROW_AVAILABLE,
     _check_for_numpy,
     _check_for_pandas,
     _check_for_pyarrow,
 )
 from polars.dependencies import numpy as np
 from polars.dependencies import pandas as pd
 from polars.dependencies import pyarrow as pa
 from polars.exceptions import NoRowsReturnedError, TooManyRowsReturnedError
 from polars.functions.lazy import col, lit
-from polars.io._utils import _is_local_file
+from polars.io._utils import _is_glob_pattern, _is_local_file
 from polars.io.excel._write_utils import (
     _unpack_multi_column_dict,
     _xl_apply_conditional_formats,
     _xl_inject_sparklines,
     _xl_setup_table_columns,
     _xl_setup_table_options,
     _xl_setup_workbook,
@@ -85,14 +87,15 @@
 from polars.utils._parse_expr_input import parse_as_expression
 from polars.utils._wrap import wrap_expr, wrap_ldf, wrap_s
 from polars.utils.convert import _timedelta_to_pl_duration
 from polars.utils.decorators import deprecated_alias
 from polars.utils.various import (
     _prepare_row_count_args,
     _process_null_values,
+    can_create_dicts_with_pyarrow,
     find_stacklevel,
     handle_projection_columns,
     is_bool_sequence,
     is_int_sequence,
     is_str_sequence,
     normalise_filepath,
     parse_version,
@@ -104,14 +107,15 @@
     from polars.polars import PyDataFrame
 
 
 if TYPE_CHECKING:
     import sys
     from datetime import timedelta
     from io import IOBase
+    from typing import Literal
 
     import deltalake
     from pyarrow.interchange.dataframe import _PyArrowDataFrame
     from xlsxwriter import Workbook
 
     from polars import Expr, LazyFrame, Series
     from polars.type_aliases import (
@@ -122,14 +126,15 @@
         ComparisonOperator,
         ConditionalFormatDict,
         CsvEncoding,
         DbWriteEngine,
         DbWriteMode,
         FillNullStrategy,
         FrameInitTypes,
+        IndexOrder,
         IntoExpr,
         IpcCompression,
         JoinStrategy,
         JoinValidation,
         NullStrategy,
         OneOrMoreDataTypes,
         Orientation,
@@ -137,26 +142,22 @@
         ParquetCompression,
         PivotAgg,
         PolarsDataType,
         RollingInterpolationMethod,
         RowTotalsDefinition,
         SchemaDefinition,
         SchemaDict,
+        SelectorType,
         SizeUnit,
         StartBy,
         UniqueKeepStrategy,
         UnstackDirection,
     )
     from polars.utils import NoDefault
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
-
     if sys.version_info >= (3, 10):
         from typing import Concatenate, ParamSpec, TypeAlias
     else:
         from typing_extensions import Concatenate, ParamSpec, TypeAlias
 
     if sys.version_info >= (3, 11):
         from typing import Self
@@ -327,15 +328,15 @@
     ...     pass
     ...
     >>> isinstance(MyDataFrame().lazy().collect(), MyDataFrame)
     False
 
     """
 
-    _accessors: set[str] = set()
+    _accessors: ClassVar[set[str]] = set()
 
     def __init__(
         self,
         data: FrameInitTypes | None = None,
         schema: SchemaDefinition | None = None,
         *,
         schema_overrides: SchemaDict | None = None,
@@ -462,15 +463,15 @@
         return cls._from_pydf(
             dict_to_pydf(data, schema=schema, schema_overrides=schema_overrides)
         )
 
     @classmethod
     def _from_records(
         cls,
-        data: Sequence[Sequence[Any]],
+        data: Sequence[Any],
         schema: SchemaDefinition | None = None,
         *,
         schema_overrides: SchemaDict | None = None,
         orient: Orientation | None = None,
         infer_schema_length: int | None = N_INFER_DEFAULT,
     ) -> Self:
         """
@@ -726,15 +727,15 @@
             else:
                 raise ValueError("dtype arg should be list or dict")
 
         processed_null_values = _process_null_values(null_values)
 
         if isinstance(columns, str):
             columns = [columns]
-        if isinstance(source, str) and "*" in source:
+        if isinstance(source, str) and _is_glob_pattern(source):
             dtypes_dict = None
             if dtype_list is not None:
                 dtypes_dict = dict(dtype_list)
             if dtype_slice is not None:
                 raise ValueError(
                     "cannot use glob patterns and unnamed dtypes as `dtypes` argument;"
                     " Use dtypes: Mapping[str, Type[DataType]"
@@ -802,15 +803,15 @@
             eol_char=eol_char,
         )
         return self
 
     @classmethod
     def _read_parquet(
         cls,
-        source: str | Path | BinaryIO,
+        source: str | Path | BinaryIO | bytes,
         *,
         columns: Sequence[int] | Sequence[str] | None = None,
         n_rows: int | None = None,
         parallel: ParallelStrategy = "auto",
         row_count_name: str | None = None,
         row_count_offset: int = 0,
         low_memory: bool = False,
@@ -828,15 +829,19 @@
 
         """
         if isinstance(source, (str, Path)):
             source = normalise_filepath(source)
         if isinstance(columns, str):
             columns = [columns]
 
-        if isinstance(source, str) and "*" in source and _is_local_file(source):
+        if (
+            isinstance(source, str)
+            and _is_glob_pattern(source)
+            and _is_local_file(source)
+        ):
             from polars import scan_parquet
 
             scan = scan_parquet(
                 source,
                 n_rows=n_rows,
                 rechunk=True,
                 parallel=parallel,
@@ -869,15 +874,15 @@
             rechunk=rechunk,
         )
         return self
 
     @classmethod
     def _read_avro(
         cls,
-        source: str | Path | BinaryIO,
+        source: str | Path | BinaryIO | bytes,
         *,
         columns: Sequence[int] | Sequence[str] | None = None,
         n_rows: int | None = None,
     ) -> Self:
         """
         Read into a DataFrame from Apache Avro format.
 
@@ -901,15 +906,15 @@
         self = cls.__new__(cls)
         self._df = PyDataFrame.read_avro(source, columns, projection, n_rows)
         return self
 
     @classmethod
     def _read_ipc(
         cls,
-        source: str | Path | BinaryIO,
+        source: str | Path | BinaryIO | bytes,
         *,
         columns: Sequence[int] | Sequence[str] | None = None,
         n_rows: int | None = None,
         row_count_name: str | None = None,
         row_count_offset: int = 0,
         rechunk: bool = True,
         memory_map: bool = True,
@@ -943,15 +948,19 @@
 
         """
         if isinstance(source, (str, Path)):
             source = normalise_filepath(source)
         if isinstance(columns, str):
             columns = [columns]
 
-        if isinstance(source, str) and "*" in source and _is_local_file(source):
+        if (
+            isinstance(source, str)
+            and _is_glob_pattern(source)
+            and _is_local_file(source)
+        ):
             from polars import scan_ipc
 
             scan = scan_ipc(
                 source,
                 n_rows=n_rows,
                 rechunk=rechunk,
                 row_count_name=row_count_name,
@@ -978,15 +987,15 @@
             n_rows,
             _prepare_row_count_args(row_count_name, row_count_offset),
             memory_map=memory_map,
         )
         return self
 
     @classmethod
-    def _read_json(cls, source: str | Path | IOBase) -> Self:
+    def _read_json(cls, source: str | Path | IOBase | bytes) -> Self:
         """
         Read into a DataFrame from a JSON file.
 
         Use ``pl.read_json`` to dispatch to this method.
 
         See Also
         --------
@@ -999,15 +1008,15 @@
             source = normalise_filepath(source)
 
         self = cls.__new__(cls)
         self._df = PyDataFrame.read_json(source, False)
         return self
 
     @classmethod
-    def _read_ndjson(cls, source: str | Path | IOBase) -> Self:
+    def _read_ndjson(cls, source: str | Path | IOBase | bytes) -> Self:
         """
         Read into a DataFrame from a newline delimited JSON file.
 
         Use ``pl.read_ndjson`` to dispatch to this method.
 
         See Also
         --------
@@ -1900,25 +1909,35 @@
         >>> df = pl.DataFrame({"foo": [1, 2, 3], "bar": [4, 5, 6]})
         >>> df.to_dicts()
         [{'foo': 1, 'bar': 4}, {'foo': 2, 'bar': 5}, {'foo': 3, 'bar': 6}]
 
         """
         return list(self.iter_rows(named=True))
 
-    def to_numpy(self, structured: bool = False) -> np.ndarray[Any, Any]:
+    def to_numpy(
+        self, structured: bool = False, *, order: IndexOrder = "fortran"
+    ) -> np.ndarray[Any, Any]:
         """
         Convert DataFrame to a 2D NumPy array.
 
         This operation clones data.
 
         Parameters
         ----------
         structured
             Optionally return a structured array, with field names and
             dtypes that correspond to the DataFrame schema.
+        order
+            The index order of the returned NumPy array, either C-like or
+            Fortran-like. In general, using the Fortran-like index order is faster.
+            However, the C-like order might be more appropriate to use for downstream
+            applications to prevent cloning data, e.g. when reshaping into a
+            one-dimensional array. Note that this option only takes effect if
+            ``structured`` is set to ``False`` and the DataFrame dtypes allow for a
+            global dtype for all columns.
 
         Notes
         -----
         If you're attempting to convert Utf8 to an array you'll need to install
         ``pyarrow``.
 
         Examples
@@ -1968,15 +1987,15 @@
 
             out = np.empty(
                 len(self), dtype=list(zip(self.columns, (a.dtype for a in arrays)))
             )
             for idx, c in enumerate(self.columns):
                 out[c] = arrays[idx]
         else:
-            out = self._df.to_numpy()
+            out = self._df.to_numpy(order)
             if out is None:
                 return np.vstack(
                     [self.to_series(i).to_numpy() for i in range(self.width)]
                 ).T
 
         return out
 
@@ -2323,15 +2342,15 @@
         null_value: str | None = ...,
     ) -> str:
         ...
 
     @overload
     def write_csv(
         self,
-        file: BytesIO | str | Path,
+        file: BytesIO | TextIOWrapper | str | Path,
         *,
         has_header: bool = ...,
         separator: str = ...,
         quote: str = ...,
         batch_size: int = ...,
         datetime_format: str | None = ...,
         date_format: str | None = ...,
@@ -2339,15 +2358,15 @@
         float_precision: int | None = ...,
         null_value: str | None = ...,
     ) -> None:
         ...
 
     def write_csv(
         self,
-        file: BytesIO | str | Path | None = None,
+        file: BytesIO | TextIOWrapper | str | Path | None = None,
         *,
         has_header: bool = True,
         separator: str = ",",
         quote: str = '"',
         batch_size: int = 1024,
         datetime_format: str | None = None,
         date_format: str | None = None,
@@ -2427,14 +2446,16 @@
                 float_precision,
                 null_value,
             )
             return str(buffer.getvalue(), encoding="utf-8")
 
         if isinstance(file, (str, Path)):
             file = normalise_filepath(file)
+        elif isinstance(file, TextIOWrapper):
+            file = cast(TextIOWrapper, file.buffer)
 
         self._df.write_csv(
             file,
             has_header,
             ord(separator),
             ord(quote),
             batch_size,
@@ -3072,15 +3093,14 @@
 
                 data[name] = column
 
             tbl = pa.table(data)
 
             # do not remove this
             # needed below
-            import pyarrow.parquet  # noqa: F401
 
             pa.parquet.write_table(
                 table=tbl,
                 where=file,
                 row_group_size=row_group_size,
                 compression=None if compression == "uncompressed" else compression,
                 compression_level=compression_level,
@@ -3146,20 +3166,20 @@
             try:
                 from sqlalchemy import create_engine
             except ImportError as exc:
                 raise ImportError(
                     "'sqlalchemy' not found. Install polars with 'pip install polars[sqlalchemy]'."
                 ) from exc
 
-            engine = create_engine(connection_uri)
+            engine_sa = create_engine(connection_uri)
 
             # this conversion to pandas as zero-copy
             # so we can utilize their sql utils for free
             self.to_pandas(use_pyarrow_extension_array=True).to_sql(
-                name=table_name, con=engine, if_exists=if_exists, index=False
+                name=table_name, con=engine_sa, if_exists=if_exists, index=False
             )
 
         else:
             raise ValueError(f"'engine' {engine} is not supported.")
 
     def write_delta(
         self,
@@ -4717,40 +4737,44 @@
 
         - 1ns   (1 nanosecond)
         - 1us   (1 microsecond)
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
-        - 1d    (1 day)
-        - 1w    (1 week)
+        - 1d    (1 calendar day)
+        - 1w    (1 calendar week)
         - 1mo   (1 calendar month)
         - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         In case of a groupby_rolling on an integer column, the windows are defined by:
 
         - **"1i"      # length 1**
         - **"10i"     # length 10**
 
         Parameters
         ----------
         index_column
             Column used to group based on the time window.
-            Often to type Date/Datetime
-            This column must be sorted in ascending order. If not the output will not
-            make sense.
+            Often of type Date/Datetime.
+            This column must be sorted in ascending order (or, if `by` is specified,
+            then it must be sorted in ascending order within each group).
 
             In case of a rolling groupby on indices, dtype needs to be one of
             {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if
             performance matters use an Int64 column.
         period
             length of the window - must be non-negative
         offset
@@ -4853,43 +4877,48 @@
 
         - 1ns   (1 nanosecond)
         - 1us   (1 microsecond)
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
-        - 1d    (1 day)
-        - 1w    (1 week)
+        - 1d    (1 calendar day)
+        - 1w    (1 calendar week)
         - 1mo   (1 calendar month)
-        - 1q    (1 quarter)
+        - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         In case of a groupby_dynamic on an integer column, the windows are defined by:
 
         - "1i"      # length 1
         - "10i"     # length 10
 
         .. warning::
-            The index column must be sorted in ascending order.
+            The index column must be sorted in ascending order. If `by` is passed, then
+            the index column must be sorted in ascending order within each group.
 
         Parameters
         ----------
         index_column
             Column used to group based on the time window.
-            Often to type Date/Datetime
-            This column must be sorted in ascending order. If not the output will not
-            make sense.
+            Often of type Date/Datetime.
+            This column must be sorted in ascending order (or, if `by` is specified,
+            then it must be sorted in ascending order within each group).
 
             In case of a dynamic groupby on indices, dtype needs to be one of
             {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if
             performance matters use an Int64 column.
         every
             interval of the window
         period
@@ -5170,29 +5199,33 @@
 
         - 1ns   (1 nanosecond)
         - 1us   (1 microsecond)
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
-        - 1d    (1 day)
-        - 1w    (1 week)
+        - 1d    (1 calendar day)
+        - 1w    (1 calendar week)
         - 1mo   (1 calendar month)
         - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
 
         - "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         Parameters
         ----------
         time_column
             time column will be used to determine a date_range.
             Note that this column has to be sorted for the output to make sense.
         every
             interval will start 'every' duration
@@ -5325,28 +5358,33 @@
 
                 - 1ns   (1 nanosecond)
                 - 1us   (1 microsecond)
                 - 1ms   (1 millisecond)
                 - 1s    (1 second)
                 - 1m    (1 minute)
                 - 1h    (1 hour)
-                - 1d    (1 day)
-                - 1w    (1 week)
+                - 1d    (1 calendar day)
+                - 1w    (1 calendar week)
                 - 1mo   (1 calendar month)
                 - 1q    (1 calendar quarter)
                 - 1y    (1 calendar year)
                 - 1i    (1 index count)
 
                 Or combine them:
                 "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
                 Suffix with `"_saturating"` to indicate that dates too large for
                 their month should saturate at the largest date
                 (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+                By "calendar day", we mean the corresponding time on the next day
+                (which may not be 24 hours, due to daylight savings). Similarly for
+                "calendar week", "calendar month", "calendar quarter", and
+                "calendar year".
+
         allow_parallel
             Allow the physical plan to optionally evaluate the computation of both
             DataFrames up to the join in parallel.
         force_parallel
             Force the physical plan to evaluate the computation of both DataFrames up to
             the join in parallel.
 
@@ -6674,23 +6712,25 @@
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          a    1    5   
          a    1    3   
-        , shape: (2, 3)
+        ,
+        shape: (2, 3)
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          b    2    4   
          b    3    2   
-        , shape: (1, 3)
+        ,
+        shape: (1, 3)
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          c    3    1   
         ]
@@ -6703,29 +6743,32 @@
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          a    1    5   
          a    1    3   
-        , shape: (1, 3)
+        ,
+        shape: (1, 3)
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          b    2    4   
-        , shape: (1, 3)
+        ,
+        shape: (1, 3)
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          b    3    2   
-        , shape: (1, 3)
+        ,
+        shape: (1, 3)
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          c    3    1   
         ]
@@ -6737,23 +6780,25 @@
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          a    1    5   
          a    1    3   
-        , 'b': shape: (2, 3)
+        ,
+        'b': shape: (2, 3)
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          b    2    4   
          b    3    2   
-        , 'c': shape: (1, 3)
+        ,
+        'c': shape: (1, 3)
         
          a    b    c   
          ---  ---  --- 
          str  i64  i64 
         
          c    3    1   
         }
@@ -7880,19 +7925,18 @@
         ...         (pl.col("c") | (pl.col("b") >= 2)),
         ...     ],
         ... )
         3
 
         """
         if isinstance(subset, str):
-            subset = [F.col(subset)]
+            expr = F.col(subset)
         elif isinstance(subset, pl.Expr):
-            subset = [subset]
-
-        if isinstance(subset, Sequence) and len(subset) == 1:
+            expr = subset
+        elif isinstance(subset, Sequence) and len(subset) == 1:
             expr = wrap_expr(parse_as_expression(subset[0]))
         else:
             struct_fields = F.all() if (subset is None) else subset
             expr = F.struct(struct_fields)  # type: ignore[call-overload]
 
         df = self.lazy().select(expr.n_unique()).collect()
         return 0 if df.is_empty() else df.row(0)[0]
@@ -8175,15 +8219,15 @@
 
         >>> df.row(by_predicate=(pl.col("ham") == "b"))
         (2, 7, 'b')
 
         See Also
         --------
         iter_rows : Row iterator over frame data (does not materialise all rows).
-        rows : Materialises all frame data as a list of rows.
+        rows : Materialise all frame data as a list of rows (potentially expensive).
         item: Return dataframe element as a scalar.
 
         """
         if index is not None and by_predicate is not None:
             raise ValueError(
                 "Cannot set both 'index' and 'by_predicate'; mutually exclusive"
             )
@@ -8243,50 +8287,219 @@
             column name to row value. This is more expensive than returning a regular
             tuple, but allows for accessing values by column name.
 
         Notes
         -----
         If you have ``ns``-precision temporal values you should be aware that python
         natively only supports up to ``us``-precision; if this matters you should export
-        to a different format.
+        to a different format, as this method returns only python-native values.
 
         Warnings
         --------
         Row-iteration is not optimal as the underlying data is stored in columnar form;
         where possible, prefer export via one of the dedicated export/output methods.
+        Where possible you should also consider using ``iter_rows`` instead to avoid
+        materialising all the data at once.
 
         Returns
         -------
         A list of tuples (default) or dictionaries of row values.
 
         Examples
         --------
         >>> df = pl.DataFrame(
         ...     {
-        ...         "a": [1, 3, 5],
-        ...         "b": [2, 4, 6],
+        ...         "x": ["a", "b", "b", "a"],
+        ...         "y": [1, 2, 3, 4],
+        ...         "z": [0, 3, 6, 9],
         ...     }
         ... )
         >>> df.rows()
-        [(1, 2), (3, 4), (5, 6)]
+        [('a', 1, 0), ('b', 2, 3), ('b', 3, 6), ('a', 4, 9)]
         >>> df.rows(named=True)
-        [{'a': 1, 'b': 2}, {'a': 3, 'b': 4}, {'a': 5, 'b': 6}]
+        [{'x': 'a', 'y': 1, 'z': 0},
+         {'x': 'b', 'y': 2, 'z': 3},
+         {'x': 'b', 'y': 3, 'z': 6},
+         {'x': 'a', 'y': 4, 'z': 9}]
 
         See Also
         --------
         iter_rows : Row iterator over frame data (does not materialise all rows).
+        rows_by_key : Materialises frame data as a key-indexed dictionary.
 
         """
         if named:
             # Load these into the local namespace for a minor performance boost
             dict_, zip_, columns = dict, zip, self.columns
             return [dict_(zip_(columns, row)) for row in self._df.row_tuples()]
         else:
             return self._df.row_tuples()
 
+    def rows_by_key(
+        self,
+        key: str | Sequence[str] | SelectorType,
+        *,
+        named: bool = False,
+        include_key: bool = False,
+        unique: bool = False,
+    ) -> dict[Any, Iterable[Any]]:
+        """
+        Returns DataFrame data as a keyed dictionary of python-native values.
+
+        Note that this method should not be used in place of native operations, due to
+        the high cost of materialising all frame data out into a dictionary; it should
+        be used only when you need to move the values out into a Python data structure
+        or other object that cannot operate directly with Polars/Arrow.
+
+        Parameters
+        ----------
+        key
+            The column(s) to use as the key for the returned dictionary. If multiple
+            columns are specified, the key will be a tuple of those values, otherwise
+            it will be a string.
+        named
+            Return dictionary rows instead of tuples, mapping column name to row value.
+        include_key
+            Include key values inline with the associated data (by default the key
+            values are omitted as a memory/performance optimisation, as they can be
+            reoconstructed from the key).
+        unique
+            Indicate that the key is unique; this will result in a 1:1 mapping from
+            key to a single associated row. Note that if the key is *not* actually
+            unique the last row with the given key will be returned.
+
+        Notes
+        -----
+        If you have ``ns``-precision temporal values you should be aware that python
+        natively only supports up to ``us``-precision; if this matters you should export
+        to a different format, as this method returns only python-native values.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "w": ["a", "b", "b", "a"],
+        ...         "x": ["q", "q", "q", "k"],
+        ...         "y": [1.0, 2.5, 3.0, 4.5],
+        ...         "z": [9, 8, 7, 6],
+        ...     }
+        ... )
+
+        Group rows by the given key column(s):
+
+        >>> df.rows_by_key(key=["w"])
+        defaultdict(<class 'list'>,
+            {'a': [('q', 1.0, 9), ('k', 4.5, 6)],
+             'b': [('q', 2.5, 8), ('q', 3.0, 7)]})
+
+        Return the same row groupings as dictionaries:
+
+        >>> df.rows_by_key(key=["w"], named=True)
+        defaultdict(<class 'list'>,
+            {'a': [{'x': 'q', 'y': 1.0, 'z': 9},
+                   {'x': 'k', 'y': 4.5, 'z': 6}],
+             'b': [{'x': 'q', 'y': 2.5, 'z': 8},
+                   {'x': 'q', 'y': 3.0, 'z': 7}]})
+
+        Return row groupings, assuming keys are unique:
+
+        >>> df.rows_by_key(key=["z"], unique=True)
+        {9: ('a', 'q', 1.0),
+         8: ('b', 'q', 2.5),
+         7: ('b', 'q', 3.0),
+         6: ('a', 'k', 4.5)}
+
+        Return row groupings as dictionaries, assuming keys are unique:
+
+        >>> df.rows_by_key(key=["z"], named=True, unique=True)
+        {9: {'w': 'a', 'x': 'q', 'y': 1.0},
+         8: {'w': 'b', 'x': 'q', 'y': 2.5},
+         7: {'w': 'b', 'x': 'q', 'y': 3.0},
+         6: {'w': 'a', 'x': 'k', 'y': 4.5}}
+
+        Return dictionary rows grouped by a compound key, including key values:
+
+        >>> df.rows_by_key(key=["w", "x"], named=True, include_key=True)
+        defaultdict(<class 'list'>,
+            {('a', 'q'): [{'w': 'a', 'x': 'q', 'y': 1.0, 'z': 9}],
+             ('b', 'q'): [{'w': 'b', 'x': 'q', 'y': 2.5, 'z': 8},
+                          {'w': 'b', 'x': 'q', 'y': 3.0, 'z': 7}],
+             ('a', 'k'): [{'w': 'a', 'x': 'k', 'y': 4.5, 'z': 6}]})
+
+        See Also
+        --------
+        rows : Materialise all frame data as a list of rows (potentially expensive).
+        iter_rows : Row iterator over frame data (does not materialise all rows).
+
+        """
+        from polars.selectors import is_selector, selector_column_names
+
+        if is_selector(key):
+            key = selector_column_names(frame=self, selector=key)  # type: ignore[type-var]
+        elif not isinstance(key, str):
+            key = tuple(key)  # type: ignore[arg-type]
+        else:
+            key = (key,)
+
+        # establish index or name-based getters for the key and data values
+        data_cols = [k for k in self.schema if k not in key]
+        if named:
+            get_data = itemgetter(*data_cols)
+            get_key = itemgetter(*key)
+        else:
+            data_idxs, index_idxs = [], []
+            for idx, c in enumerate(self.columns):
+                if c in key:
+                    index_idxs.append(idx)
+                else:
+                    data_idxs.append(idx)
+            if not index_idxs:
+                raise ValueError(f"No columns found for key: {key!r}")
+            get_data = itemgetter(*data_idxs)  # type: ignore[assignment]
+            get_key = itemgetter(*index_idxs)  # type: ignore[assignment]
+
+        # if unique, we expect to write just one entry per key; otherwise, we're
+        # returning a list of rows for each key, so append into a defaultdict.
+        rows: dict[Any, Any] = {} if unique else defaultdict(list)
+
+        # return named values (key -> dict | list of dicts), eg:
+        # "{(key,): [{col:val, col:val, ...}],
+        #   (key,): [{col:val, col:val, ...}],}"
+        if named:
+            if unique and include_key:
+                rows = {get_key(row): row for row in self.iter_rows(named=True)}
+            else:
+                for d in self.iter_rows(named=True):
+                    k = get_key(d)
+                    if not include_key:
+                        for ix in key:
+                            del d[ix]
+                    if unique:
+                        rows[k] = d
+                    else:
+                        rows[k].append(d)
+
+        # return values (key -> tuple | list of tuples), eg:
+        # "{(key,): [(val, val, ...)],
+        #   (key,): [(val, val, ...)], ...}"
+        elif unique:
+            rows = (
+                {get_key(row): row for row in self.iter_rows()}
+                if include_key
+                else {get_key(row): get_data(row) for row in self.iter_rows()}
+            )
+        elif include_key:
+            for row in self.iter_rows(named=False):
+                rows[get_key(row)].append(row)
+        else:
+            for row in self.iter_rows(named=False):
+                rows[get_key(row)].append(get_data(row))
+
+        return rows
+
     @overload
     def iter_rows(
         self, *, named: Literal[False] = ..., buffer_size: int = ...
     ) -> Iterator[tuple[Any, ...]]:
         ...
 
     @overload
@@ -8341,36 +8554,28 @@
         >>> [row[0] for row in df.iter_rows()]
         [1, 3, 5]
         >>> [row["b"] for row in df.iter_rows(named=True)]
         [2, 4, 6]
 
         See Also
         --------
-        rows : Materialises all frame data as a list of rows.
+        rows : Materialises all frame data as a list of rows (potentially expensive).
+        rows_by_key : Materialises frame data as a key-indexed dictionary.
 
         """
-        # load into the local namespace for a modest performance boost in the hot loops
+        # load into the local namespace for a (minor) performance boost in the hot loops
         columns, get_row, dict_, zip_ = self.columns, self.row, dict, zip
         has_object = Object in self.dtypes
 
         # note: buffering rows results in a 2-4x speedup over individual calls
         # to ".row(i)", so it should only be disabled in extremely specific cases.
         if buffer_size and not has_object:
-            load_pyarrow_dicts = (
-                named
-                and _PYARROW_AVAILABLE
-                # note: 'ns' precision instantiates values as pandas types - avoid
-                and not any(
-                    (getattr(tp, "time_unit", None) == "ns")
-                    for tp in unpack_dtypes(*self.dtypes)
-                )
-            )
             for offset in range(0, self.height, buffer_size):
                 zerocopy_slice = self.slice(offset, buffer_size)
-                if load_pyarrow_dicts:
+                if named and can_create_dicts_with_pyarrow(self.dtypes):
                     yield from zerocopy_slice.to_arrow().to_pylist()
                 else:
                     rows_chunk = zerocopy_slice.rows(named=False)
                     if named:
                         for row in rows_chunk:
                             yield dict_(zip_(columns, row))
                     else:
@@ -8645,30 +8850,29 @@
         if isinstance(columns, str):
             columns = [columns]
         if more_columns:
             columns = list(columns)
             columns.extend(more_columns)
         return self._from_pydf(self._df.unnest(columns))
 
-    @typing.no_type_check
     def corr(self, **kwargs: Any) -> DataFrame:
         """
-        Return Pearson product-moment correlation coefficients.
+        Return pairwise Pearson product-moment correlation coefficients between columns.
 
         See numpy ``corrcoef`` for more information:
         https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html
 
         Notes
         -----
         This functionality requires numpy to be installed.
 
         Parameters
         ----------
         **kwargs
-            keyword arguments are passed to numpy corrcoef
+            Keyword arguments are passed to numpy ``corrcoef``.
 
         Examples
         --------
         >>> df = pl.DataFrame({"foo": [1, 2, 3], "bar": [3, 2, 1], "ham": [7, 8, 9]})
         >>> df.corr()
         shape: (3, 3)
         
@@ -8697,14 +8901,60 @@
         Parameters
         ----------
         other
             Other DataFrame that must be merged
         key
             Key that is sorted.
 
+        Examples
+        --------
+        >>> df0 = pl.DataFrame(
+        ...     {"name": ["steve", "elise", "bob"], "age": [42, 44, 18]}
+        ... ).sort("age")
+        >>> df0
+        shape: (3, 2)
+        
+         name   age 
+         ---    --- 
+         str    i64 
+        
+         bob    18  
+         steve  42  
+         elise  44  
+        
+        >>> df1 = pl.DataFrame(
+        ...     {"name": ["anna", "megan", "steve", "thomas"], "age": [21, 33, 42, 20]}
+        ... ).sort("age")
+        >>> df1
+        shape: (4, 2)
+        
+         name    age 
+         ---     --- 
+         str     i64 
+        
+         thomas  20  
+         anna    21  
+         megan   33  
+         steve   42  
+        
+        >>> df0.merge_sorted(df1, key="age")
+        shape: (7, 2)
+        
+         name    age 
+         ---     --- 
+         str     i64 
+        
+         bob     18  
+         thomas  20  
+         anna    21  
+         megan   33  
+         steve   42  
+         steve   42  
+         elise   44  
+        
         """
         return self.lazy().merge_sorted(other.lazy(), key).collect(no_optimization=True)
 
     def set_sorted(
         self,
         column: str | Iterable[str],
         *more_columns: str,
```

### Comparing `polars_lts_cpu-0.18.4/polars/dataframe/groupby.py` & `polars_lts_cpu-0.18.5/polars/dataframe/groupby.py`

 * *Files 5% similar despite different names*

```diff
@@ -151,23 +151,39 @@
             Accepts expression input. Strings are parsed as column names.
         **named_aggs
             Additional aggregations, specified as keyword arguments.
             The resulting columns will be renamed to the keyword used.
 
         Examples
         --------
-        Compute the sum of a column for each group.
+        Compute the aggregation of the columns for each group.
 
         >>> df = pl.DataFrame(
         ...     {
         ...         "a": ["a", "b", "a", "b", "c"],
         ...         "b": [1, 2, 1, 3, 3],
         ...         "c": [5, 4, 3, 2, 1],
         ...     }
         ... )
+        >>> df.groupby("a").agg([pl.col("b"), pl.col("c")])  # doctest: +IGNORE_RESULT
+        shape: (3, 3)
+        
+         a    b          c         
+         ---  ---        ---       
+         str  list[i64]  list[i64] 
+        
+         a    [1, 1]     [5, 3]    
+        
+         b    [2, 3]     [4, 2]    
+        
+         c    [3]        [1]       
+        
+
+        Compute the sum of a column for each group.
+
         >>> df.groupby("a").agg(pl.col("b").sum())  # doctest: +IGNORE_RESULT
         shape: (3, 2)
         
          a    b   
          ---  --- 
          str  i64 
         
@@ -296,15 +312,15 @@
          4    red    square   
          3    red    triangle 
         
 
         It is better to implement this with an expression:
 
         >>> df.filter(
-        ...     pl.arange(0, pl.count()).shuffle().over("color") < 2
+        ...     pl.int_range(0, pl.count()).shuffle().over("color") < 2
         ... )  # doctest: +IGNORE_RESULT
 
         """
         by: list[str]
 
         if isinstance(self.by, str):
             by = [self.by]
@@ -911,15 +927,15 @@
          3    red    triangle 
         
 
         It is better to implement this with an expression:
 
         >>> (
         ...     df.lazy()
-        ...     .filter(pl.arange(0, pl.count()).shuffle().over("color") < 2)
+        ...     .filter(pl.int_range(0, pl.count()).shuffle().over("color") < 2)
         ...     .collect()
         ... )  # doctest: +IGNORE_RESULT
 
         """
         return (
             self.df.lazy()
             .groupby_rolling(
@@ -1116,15 +1132,15 @@
          3    red    triangle 
         
 
         It is better to implement this with an expression:
 
         >>> (
         ...     df.lazy()
-        ...     .filter(pl.arange(0, pl.count()).shuffle().over("color") < 2)
+        ...     .filter(pl.int_range(0, pl.count()).shuffle().over("color") < 2)
         ...     .collect()
         ... )  # doctest: +IGNORE_RESULT
 
         """
         return (
             self.df.lazy()
             .groupby_dynamic(
```

### Comparing `polars_lts_cpu-0.18.4/polars/datatypes/__init__.py` & `polars_lts_cpu-0.18.5/polars/datatypes/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/datatypes/classes.py` & `polars_lts_cpu-0.18.5/polars/datatypes/classes.py`

 * *Files 1% similar despite different names*

```diff
@@ -307,18 +307,20 @@
     ):
         """
         Calendar date and time type.
 
         Parameters
         ----------
         time_unit : {'us', 'ns', 'ms'}
-            Unit of time.
+            Unit of time / precision.
         time_zone
-            Time zone string as defined in zoneinfo (run
+            Time zone string, as defined in zoneinfo (to see valid strings run
             ``import zoneinfo; zoneinfo.available_timezones()`` for a full list).
+            When using to match dtypes, can use "*" to check for Datetime columns
+            that have any timezone.
 
         """
         if isinstance(time_zone, timezone):
             time_zone = str(time_zone)
 
         self.time_unit = time_unit or "us"
         self.time_zone = time_zone
```

### Comparing `polars_lts_cpu-0.18.4/polars/datatypes/constants.py` & `polars_lts_cpu-0.18.5/polars/datatypes/constants.py`

 * *Files 15% similar despite different names*

```diff
@@ -29,14 +29,17 @@
 DTYPE_TEMPORAL_UNITS: frozenset[TimeUnit] = frozenset(["ns", "us", "ms"])
 DATETIME_DTYPES: frozenset[PolarsDataType] = DataTypeGroup(
     [
         Datetime,
         Datetime("ms"),
         Datetime("us"),
         Datetime("ns"),
+        Datetime("ms", "*"),
+        Datetime("us", "*"),
+        Datetime("ns", "*"),
     ]
 )
 DURATION_DTYPES: frozenset[PolarsDataType] = DataTypeGroup(
     [
         Duration,
         Duration("ms"),
         Duration("us"),
```

### Comparing `polars_lts_cpu-0.18.4/polars/datatypes/constructor.py` & `polars_lts_cpu-0.18.5/polars/datatypes/constructor.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/datatypes/convert.py` & `polars_lts_cpu-0.18.5/polars/datatypes/convert.py`

 * *Files 8% similar despite different names*

```diff
@@ -12,14 +12,15 @@
     Any,
     Callable,
     Collection,
     ForwardRef,
     Optional,
     TypeVar,
     Union,
+    get_args,
     overload,
 )
 
 from polars.datatypes import (
     Binary,
     Boolean,
     Categorical,
@@ -50,38 +51,27 @@
 )
 from polars.dependencies import numpy as np
 from polars.dependencies import pyarrow as pa
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     from polars.polars import dtype_str_repr as _dtype_str_repr
 
-if sys.version_info >= (3, 8):
-    from typing import get_args
-else:
-    # pass-through (only impact is that under 3.7 we'll end-up doing
-    # standard inference for dataclass fields with an option/union)
-    def get_args(tp: Any) -> Any:
-        return tp
-
 
 OptionType = type(Optional[type])
 if sys.version_info >= (3, 10):
     from types import NoneType, UnionType
 else:
     # infer equivalent class
     NoneType = type(None)
     UnionType = type(Union[int, float])
 
 if TYPE_CHECKING:
-    from polars.type_aliases import PolarsDataType, PythonDataType, SchemaDict, TimeUnit
+    from typing import Literal
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
+    from polars.type_aliases import PolarsDataType, PythonDataType, SchemaDict, TimeUnit
 
 
 T = TypeVar("T")
 
 
 def cache(function: Callable[..., T]) -> T:
     # need this to satisfy mypy issue with "@property/@cache combination"
```

### Comparing `polars_lts_cpu-0.18.4/polars/dependencies.py` & `polars_lts_cpu-0.18.5/polars/dependencies.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 
 import re
 import sys
 from functools import lru_cache
 from importlib import import_module
 from importlib.util import find_spec
 from types import ModuleType
-from typing import TYPE_CHECKING, Any, Hashable, cast
+from typing import TYPE_CHECKING, Any, ClassVar, Hashable, cast
 
 _DELTALAKE_AVAILABLE = True
 _FSSPEC_AVAILABLE = True
 _HYPOTHESIS_AVAILABLE = True
 _NUMPY_AVAILABLE = True
 _PANDAS_AVAILABLE = True
 _PYARROW_AVAILABLE = True
@@ -28,15 +28,15 @@
     confusion in the global environment. This way we have a valid proxy
     module for our own use, but it lives _exclusively_ within polars.
 
     """
 
     __lazy__ = True
 
-    _mod_pfx: dict[str, str] = {
+    _mod_pfx: ClassVar[dict[str, str]] = {
         "numpy": "np.",
         "pandas": "pd.",
         "pyarrow": "pa.",
     }
 
     def __init__(
         self,
```

### Comparing `polars_lts_cpu-0.18.4/polars/exceptions.py` & `polars_lts_cpu-0.18.5/polars/exceptions.py`

 * *Files 3% similar despite different names*

```diff
@@ -6,14 +6,15 @@
         DuplicateError,
         InvalidOperationError,
         NoDataError,
         PolarsPanicError,
         SchemaError,
         SchemaFieldNotFoundError,
         ShapeError,
+        StringCacheMismatchError,
         StructFieldNotFoundError,
     )
 except ImportError:
     # They are only redefined for documentation purposes
     # when there is no binary yet
 
     class ArrowError(Exception):  # type: ignore[no-redef]
@@ -39,14 +40,17 @@
 
     class SchemaFieldNotFoundError(Exception):  # type: ignore[no-redef]
         """Exception raised when a specified schema field is not found."""
 
     class ShapeError(Exception):  # type: ignore[no-redef]
         """Exception raised when trying to combine data structures with incompatible shapes."""  # noqa: W505
 
+    class StringCacheMismatchError(Exception):  # type: ignore[no-redef]
+        """Exception raised when string caches come from different sources."""
+
     class StructFieldNotFoundError(Exception):  # type: ignore[no-redef]
         """Exception raised when a specified schema field is not found."""
 
     class PolarsPanicError(Exception):  # type: ignore[no-redef]
         """Exception raised when an unexpected state causes a panic in the underlying Rust library."""  # noqa: W505
 
 
@@ -92,10 +96,11 @@
     "NoDataError",
     "NoRowsReturnedError",
     "PolarsPanicError",
     "RowsError",
     "SchemaError",
     "SchemaFieldNotFoundError",
     "ShapeError",
+    "StringCacheMismatchError",
     "StructFieldNotFoundError",
     "TooManyRowsReturnedError",
 ]
```

### Comparing `polars_lts_cpu-0.18.4/polars/expr/array.py` & `polars_lts_cpu-0.18.5/polars/expr/array.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/expr/binary.py` & `polars_lts_cpu-0.18.5/polars/series/binary.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,103 +1,86 @@
 from __future__ import annotations
 
 from typing import TYPE_CHECKING
 
-from polars.utils._wrap import wrap_expr
+from polars.series.utils import expr_dispatch
 
 if TYPE_CHECKING:
-    from polars import Expr
+    from polars import Series
+    from polars.polars import PySeries
     from polars.type_aliases import TransferEncoding
 
 
-class ExprBinaryNameSpace:
-    """Namespace for bin related expressions."""
+@expr_dispatch
+class BinaryNameSpace:
+    """Series.bin namespace."""
 
     _accessor = "bin"
 
-    def __init__(self, expr: Expr):
-        self._pyexpr = expr._pyexpr
+    def __init__(self, series: Series):
+        self._s: PySeries = series._s
 
-    def contains(self, literal: bytes) -> Expr:
+    def contains(self, literal: bytes) -> Series:
         """
         Check if binaries in Series contain a binary substring.
 
         Parameters
         ----------
         literal
             The binary substring to look for
 
         Returns
         -------
         Boolean mask
 
         """
-        return wrap_expr(self._pyexpr.bin_contains(literal))
 
-    def ends_with(self, suffix: bytes) -> Expr:
+    def ends_with(self, suffix: bytes) -> Series:
         """
         Check if string values end with a binary substring.
 
         Parameters
         ----------
         suffix
             Suffix substring.
 
         """
-        return wrap_expr(self._pyexpr.bin_ends_with(suffix))
 
-    def starts_with(self, prefix: bytes) -> Expr:
+    def starts_with(self, prefix: bytes) -> Series:
         """
         Check if values start with a binary substring.
 
         Parameters
         ----------
         prefix
             Prefix substring.
 
         """
-        return wrap_expr(self._pyexpr.bin_starts_with(prefix))
 
-    def decode(self, encoding: TransferEncoding, *, strict: bool = True) -> Expr:
+    def decode(self, encoding: TransferEncoding, *, strict: bool = True) -> Series:
         """
         Decode a value using the provided encoding.
 
         Parameters
         ----------
         encoding : {'hex', 'base64'}
             The encoding to use.
         strict
             Raise an error if the underlying value cannot be decoded,
             otherwise mask out with a null value.
 
         """
-        if encoding == "hex":
-            return wrap_expr(self._pyexpr.bin_hex_decode(strict))
-        elif encoding == "base64":
-            return wrap_expr(self._pyexpr.bin_base64_decode(strict))
-        else:
-            raise ValueError(
-                f"encoding must be one of {{'hex', 'base64'}}, got {encoding}"
-            )
 
-    def encode(self, encoding: TransferEncoding) -> Expr:
+    def encode(self, encoding: TransferEncoding) -> Series:
         """
         Encode a value using the provided encoding.
 
         Parameters
         ----------
         encoding : {'hex', 'base64'}
             The encoding to use.
 
         Returns
         -------
         Binary array with values encoded using provided encoding
 
         """
-        if encoding == "hex":
-            return wrap_expr(self._pyexpr.bin_hex_encode())
-        elif encoding == "base64":
-            return wrap_expr(self._pyexpr.bin_base64_encode())
-        else:
-            raise ValueError(
-                f"encoding must be one of {{'hex', 'base64'}}, got {encoding}"
-            )
```

### Comparing `polars_lts_cpu-0.18.4/polars/expr/categorical.py` & `polars_lts_cpu-0.18.5/polars/expr/categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/expr/datetime.py` & `polars_lts_cpu-0.18.5/polars/expr/datetime.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,33 +1,26 @@
 from __future__ import annotations
 
 import datetime as dt
-import warnings
 from typing import TYPE_CHECKING
 
 import polars._reexport as pl
 from polars import functions as F
 from polars.datatypes import DTYPE_TEMPORAL_UNITS, Date, Int32
 from polars.utils._parse_expr_input import parse_as_expression
 from polars.utils._wrap import wrap_expr
 from polars.utils.convert import _timedelta_to_pl_duration
 from polars.utils.decorators import deprecated_alias
-from polars.utils.various import find_stacklevel
 
 if TYPE_CHECKING:
     from datetime import timedelta
 
     from polars import Expr
     from polars.type_aliases import EpochTimeUnit, TimeUnit
 
-TIME_ZONE_DEPRECATION_MESSAGE = (
-    "In a future version of polars, time zones other than those in `zoneinfo.available_timezones()` "
-    "will no longer be supported. Please use one of them instead."
-)
-
 
 class ExprDateTimeNameSpace:
     """Namespace for datetime related expressions."""
 
     _accessor = "dt"
 
     def __init__(self, expr: Expr):
@@ -58,30 +51,32 @@
 
         - 1ns # 1 nanosecond
         - 1us # 1 microsecond
         - 1ms # 1 millisecond
         - 1s  # 1 second
         - 1m  # 1 minute
         - 1h  # 1 hour
-        - 1d  # 1 day
+        - 1d  # 1 calendar day
         - 1w  # 1 calendar week
         - 1mo # 1 calendar month
-        - 1mo_saturating # same as above, but saturates to the last day of the month
-          if the target date does not exist
         - 1q  # 1 calendar quarter
         - 1y  # 1 calendar year
 
         These strings can be combined:
 
         - 3d12h4m25s # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         Returns
         -------
         Date/Datetime series
 
         Examples
         --------
         >>> from datetime import timedelta, datetime
@@ -182,26 +177,30 @@
 
         1ns  # 1 nanosecond
         1us  # 1 microsecond
         1ms  # 1 millisecond
         1s   # 1 second
         1m   # 1 minute
         1h   # 1 hour
-        1d   # 1 day
+        1d   # 1 calendar day
         1w   # 1 calendar week
         1mo  # 1 calendar month
         1q   # 1 calendar quarter
         1y   # 1 calendar year
 
         eg: 3d12h4m25s  # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         Returns
         -------
         Date/Datetime series
 
         Warnings
         --------
         This functionality is currently experimental and may
@@ -1364,22 +1363,14 @@
          datetime[s, UTC]        datetime[s, Europe/London] 
         
          2020-03-01 00:00:00 UTC  2020-03-01 00:00:00 GMT     
          2020-04-01 00:00:00 UTC  2020-04-01 01:00:00 BST     
          2020-05-01 00:00:00 UTC  2020-05-01 01:00:00 BST     
         
         """
-        from polars.dependencies import zoneinfo
-
-        if time_zone not in zoneinfo.available_timezones():
-            warnings.warn(
-                TIME_ZONE_DEPRECATION_MESSAGE,
-                DeprecationWarning,
-                stacklevel=find_stacklevel(),
-            )
         return wrap_expr(self._pyexpr.dt_convert_time_zone(time_zone))
 
     def replace_time_zone(
         self, time_zone: str | None, *, use_earliest: bool | None = None
     ) -> Expr:
         """
         Replace time zone for a Series of type Datetime.
@@ -1469,22 +1460,14 @@
          2018-10-28 02:00:00  true   2018-10-28 02:00:00 CEST      
          2018-10-28 02:30:00  true   2018-10-28 02:30:00 CEST      
          2018-10-28 02:00:00  false  2018-10-28 02:00:00 CET       
          2018-10-28 02:30:00  false  2018-10-28 02:30:00 CET       
         
 
         """
-        from polars.dependencies import zoneinfo
-
-        if time_zone is not None and time_zone not in zoneinfo.available_timezones():
-            warnings.warn(
-                TIME_ZONE_DEPRECATION_MESSAGE,
-                DeprecationWarning,
-                stacklevel=find_stacklevel(),
-            )
         return wrap_expr(self._pyexpr.dt_replace_time_zone(time_zone, use_earliest))
 
     def days(self) -> Expr:
         """
         Extract the days from a Duration type.
 
         Returns
@@ -1798,25 +1781,29 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         Returns
         -------
         Date/Datetime expression
 
         Examples
         --------
         >>> from datetime import datetime
@@ -1958,7 +1945,79 @@
          2000-09-30 02:00:00 
          2000-10-31 02:00:00 
          2000-11-30 02:00:00 
          2000-12-31 02:00:00 
         
         """
         return wrap_expr(self._pyexpr.dt_month_end())
+
+    def base_utc_offset(self) -> Expr:
+        """
+        Base offset from UTC.
+
+        This is usually constant for all datetimes in a given time zone, but
+        may vary in the rare case that a country switches time zone, like
+        Samoa (Apia) did at the end of 2011.
+
+        Returns
+        -------
+        Duration expression
+
+        See Also
+        --------
+        Expr.dt.dst_offset : Daylight savings offset from UTC.
+
+        Examples
+        --------
+        >>> from datetime import datetime
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "ts": [datetime(2011, 12, 29), datetime(2012, 1, 1)],
+        ...     }
+        ... )
+        >>> df = df.with_columns(pl.col("ts").dt.replace_time_zone("Pacific/Apia"))
+        >>> df.with_columns(pl.col("ts").dt.base_utc_offset().alias("base_utc_offset"))
+        shape: (2, 2)
+        
+         ts                          base_utc_offset 
+         ---                         ---             
+         datetime[s, Pacific/Apia]  duration[ms]    
+        
+         2011-12-29 00:00:00 -10     -11h            
+         2012-01-01 00:00:00 +14     13h             
+        
+        """
+        return wrap_expr(self._pyexpr.dt_base_utc_offset())
+
+    def dst_offset(self) -> Expr:
+        """
+        Additional offset currently in effect (typically due to daylight saving time).
+
+        Returns
+        -------
+        Duration expression
+
+        See Also
+        --------
+        Expr.dt.base_utc_offset : Base offset from UTC.
+
+        Examples
+        --------
+        >>> from datetime import datetime
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "ts": [datetime(2020, 10, 25), datetime(2020, 10, 26)],
+        ...     }
+        ... )
+        >>> df = df.with_columns(pl.col("ts").dt.replace_time_zone("Europe/London"))
+        >>> df.with_columns(pl.col("ts").dt.dst_offset().alias("dst_offset"))
+        shape: (2, 2)
+        
+         ts                           dst_offset   
+         ---                          ---          
+         datetime[s, Europe/London]  duration[ms] 
+        
+         2020-10-25 00:00:00 BST      1h           
+         2020-10-26 00:00:00 GMT      0ms          
+        
+        """
+        return wrap_expr(self._pyexpr.dt_dst_offset())
```

### Comparing `polars_lts_cpu-0.18.4/polars/expr/expr.py` & `polars_lts_cpu-0.18.5/polars/expr/expr.py`

 * *Files 1% similar despite different names*

```diff
@@ -7,14 +7,15 @@
 import random
 from datetime import timedelta
 from functools import partial, reduce
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
+    ClassVar,
     Collection,
     FrozenSet,
     Iterable,
     NoReturn,
     Sequence,
     Set,
     TypeVar,
@@ -89,15 +90,24 @@
     property = sphinx_accessor
 
 
 class Expr:
     """Expressions that can be used in various contexts."""
 
     _pyexpr: PyExpr = None
-    _accessors: set[str] = {"arr", "cat", "dt", "list", "meta", "str", "bin", "struct"}
+    _accessors: ClassVar[set[str]] = {
+        "arr",
+        "cat",
+        "dt",
+        "list",
+        "meta",
+        "str",
+        "bin",
+        "struct",
+    }
 
     @classmethod
     def _from_pyexpr(cls, pyexpr: PyExpr) -> Self:
         expr = cls.__new__(cls)
         expr._pyexpr = pyexpr
         return expr
 
@@ -376,15 +386,15 @@
          1   
          3   
         
 
         See Also
         --------
         Series.arg_true : Return indices where Series is True
-        pl.arg_where
+        polars.arg_where
 
         """
         return self._from_pyexpr(py_arg_where(self._pyexpr))
 
     def sqrt(self) -> Self:
         """
         Compute the square root of the elements.
@@ -1224,15 +1234,15 @@
         """
         if not isinstance(offset, Expr):
             offset = F.lit(offset)
         if not isinstance(length, Expr):
             length = F.lit(length)
         return self._from_pyexpr(self._pyexpr.slice(offset._pyexpr, length._pyexpr))
 
-    def append(self, other: Expr, *, upcast: bool = True) -> Self:
+    def append(self, other: IntoExpr, *, upcast: bool = True) -> Self:
         """
         Append expressions.
 
         This is done by adding the chunks of `other` to this `Series`.
 
         Parameters
         ----------
@@ -3220,14 +3230,65 @@
          1.5 
         
 
         """
         quantile = parse_as_expression(quantile)
         return self._from_pyexpr(self._pyexpr.quantile(quantile, interpolation))
 
+    def cut(
+        self,
+        breaks: list[float],
+        labels: list[str] | None = None,
+        left_closed: bool = False,
+    ) -> Self:
+        """
+        Bin continuous values into discrete categories.
+
+        Parameters
+        ----------
+        breaks
+            A list of unique cut points.
+        labels
+            Labels to assign to bins. If given, the length must be len(probs) + 1.
+        left_closed
+            Whether intervals should be [) instead of the default of (]
+
+        """
+        return self._from_pyexpr(self._pyexpr.cut(breaks, labels, left_closed))
+
+    def qcut(
+        self,
+        probs: list[float],
+        labels: list[str] | None = None,
+        left_closed: bool = False,
+        allow_duplicates: bool = False,
+    ) -> Self:
+        """
+        Bin continuous values into discrete categories based on their quantiles.
+
+        Parameters
+        ----------
+        probs
+            Probabilities for which to find the corresponding quantiles
+            For p in probs, we assume 0 <= p <= 1
+        labels
+            Labels to assign to bins. If given, the length must be len(probs) + 1.
+            If computing over a grouping variable we recommend this be set.
+        left_closed
+            Whether intervals should be [) instead of the default of (]
+        allow_duplicates
+            If True, the resulting quantile breaks don't have to be unique. This can
+            happen even with unique probs depending on the data. Duplicates will be
+            dropped, resulting in fewer bins.
+
+        """
+        return self._from_pyexpr(
+            self._pyexpr.qcut(probs, labels, left_closed, allow_duplicates)
+        )
+
     def filter(self, predicate: Expr) -> Self:
         """
         Filter a single column.
 
         Mostly useful in an aggregation context. If you want to filter on a DataFrame
         level, use `LazyFrame.filter`.
 
@@ -3568,16 +3629,16 @@
 
         Returns
         -------
         Exploded Series of same dtype
 
         See Also
         --------
-        ExprListNameSpace.explode : Explode a list column.
-        ExprStringNameSpace.explode : Explode a string column.
+        Expr.list.explode : Explode a list column.
+        Expr.str.explode : Explode a string column.
 
         Examples
         --------
         >>> df = pl.DataFrame(
         ...     {
         ...         "group": ["a", "b"],
         ...         "values": [
@@ -4816,25 +4877,30 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
             If a timedelta or the dynamic string language is used, the `by`
             and `closed` arguments must also be set.
         weights
             An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
         min_periods
             The number of values in the window that should be non-null before computing
@@ -4943,15 +5009,15 @@
          21      2001-01-01 21:00:00 
          22      2001-01-01 22:00:00 
          23      2001-01-01 23:00:00 
          24      2001-01-02 00:00:00 
         
         >>> df_temporal.with_columns(
         ...     rolling_row_min=pl.col("row_nr").rolling_min(
-        ...         window_size="2h", by="date"
+        ...         window_size="2h", by="date", closed="left"
         ...     )
         ... )
         shape: (25, 3)
         
          row_nr  date                 rolling_row_min 
          ---     ---                  ---             
          u32     datetime[s]         u32             
@@ -5017,25 +5083,30 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
             If a timedelta or the dynamic string language is used, the `by`
             and `closed` arguments must also be set.
         weights
             An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
         min_periods
             The number of values in the window that should be non-null before computing
@@ -5147,15 +5218,15 @@
          24      2001-01-02 00:00:00 
         
 
         Compute the rolling max with the default left closure of temporal windows
 
         >>> df_temporal.with_columns(
         ...     rolling_row_max=pl.col("row_nr").rolling_max(
-        ...         window_size="2h", by="date"
+        ...         window_size="2h", by="date", closed="left"
         ...     )
         ... )
         shape: (25, 3)
         
          row_nr  date                 rolling_row_max 
          ---     ---                  ---             
          u32     datetime[s]         u32             
@@ -5217,15 +5288,15 @@
         closed: ClosedInterval = "left",
     ) -> Self:
         """
         Apply a rolling mean (moving mean) over the values in this array.
 
         A window of length `window_size` will traverse the array. The values that fill
         this window will (optionally) be multiplied with the weights given by the
-        `weight` vector. The resulting values will be aggregated to their sum.
+        `weight` vector. The resulting values will be aggregated to their mean.
 
         If ``by`` has not been specified (the default), the window at a given row will
         include the row itself, and the `window_size - 1` elements before it.
 
         If you pass a ``by`` column ``<t_0, t_1, ..., t_n>``, then `closed="left"`
         means the windows will be:
 
@@ -5245,25 +5316,30 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
             If a timedelta or the dynamic string language is used, the `by`
             and `closed` arguments must also be set.
         weights
             An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
         min_periods
             The number of values in the window that should be non-null before computing
@@ -5375,15 +5451,15 @@
          24      2001-01-02 00:00:00 
         
 
         Compute the rolling mean with the default left closure of temporal windows
 
         >>> df_temporal.with_columns(
         ...     rolling_row_mean=pl.col("row_nr").rolling_mean(
-        ...         window_size="2h", by="date"
+        ...         window_size="2h", by="date", closed="left"
         ...     )
         ... )
         shape: (25, 3)
         
          row_nr  date                 rolling_row_mean 
          ---     ---                  ---              
          u32     datetime[s]         f64              
@@ -5473,29 +5549,34 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
             If a timedelta or the dynamic string language is used, the `by`
             and `closed` arguments must also be set.
         weights
-            An optional slice with the same length of the window that will be multiplied
+            An optional slice with the same length as the window that will be multiplied
             elementwise with the values in the window.
         min_periods
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
@@ -5603,15 +5684,15 @@
          24      2001-01-02 00:00:00 
         
 
         Compute the rolling sum with the default left closure of temporal windows
 
         >>> df_temporal.with_columns(
         ...     rolling_row_sum=pl.col("row_nr").rolling_sum(
-        ...         window_size="2h", by="date"
+        ...         window_size="2h", by="date", closed="left"
         ...     )
         ... )
         shape: (25, 3)
         
          row_nr  date                 rolling_row_sum 
          ---     ---                  ---             
          u32     datetime[s]         u32             
@@ -5672,18 +5753,14 @@
         by: str | None = None,
         closed: ClosedInterval = "left",
         ddof: int = 1,
     ) -> Self:
         """
         Compute a rolling standard deviation.
 
-        A window of length `window_size` will traverse the array. The values that fill
-        this window will (optionally) be multiplied with the weights given by the
-        `weight` vector. The resulting values will be aggregated to their sum.
-
         If ``by`` has not been specified (the default), the window at a given row will
         include the row itself, and the `window_size - 1` elements before it.
 
         If you pass a ``by`` column ``<t_0, t_1, ..., t_n>``, then `closed="left"` means
         the windows will be:
 
             - [t_0 - window_size, t_0)
@@ -5702,30 +5779,35 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
             If a timedelta or the dynamic string language is used, the `by`
             and `closed` arguments must also be set.
         weights
-            An optional slice with the same length as the window that will be multiplied
-            elementwise with the values in the window.
+            An optional slice with the same length as the window that determines the
+            relative contribution of each value in a window to the output.
         min_periods
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
@@ -5778,19 +5860,19 @@
         shape: (6, 2)
         
          A    rolling_std 
          ---  ---         
          f64  f64         
         
          1.0  null        
-         2.0  0.883883    
-         3.0  1.237437    
-         4.0  1.59099     
-         5.0  1.944544    
-         6.0  2.298097    
+         2.0  0.433013    
+         3.0  0.433013    
+         4.0  0.433013    
+         5.0  0.433013    
+         6.0  0.433013    
         
 
         Center the values in the window
 
         >>> df.with_columns(
         ...     rolling_std=pl.col("A").rolling_std(window_size=3, center=True),
         ... )
@@ -5834,15 +5916,15 @@
          24      2001-01-02 00:00:00 
         
 
         Compute the rolling std with the default left closure of temporal windows
 
         >>> df_temporal.with_columns(
         ...     rolling_row_std=pl.col("row_nr").rolling_std(
-        ...         window_size="2h", by="date"
+        ...         window_size="2h", by="date", closed="left"
         ...     )
         ... )
         shape: (25, 3)
         
          row_nr  date                 rolling_row_std 
          ---     ---                  ---             
          u32     datetime[s]         f64             
@@ -5903,18 +5985,14 @@
         by: str | None = None,
         closed: ClosedInterval = "left",
         ddof: int = 1,
     ) -> Self:
         """
         Compute a rolling variance.
 
-        A window of length `window_size` will traverse the array. The values that fill
-        this window will (optionally) be multiplied with the weights given by the
-        `weight` vector. The resulting values will be aggregated to their sum.
-
         If ``by`` has not been specified (the default), the window at a given row will
         include the row itself, and the `window_size - 1` elements before it.
 
         If you pass a ``by`` column ``<t_0, t_1, ..., t_n>``, then `closed="left"`
         means the windows will be:
 
             - [t_0 - window_size, t_0)
@@ -5933,30 +6011,35 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
             If a timedelta or the dynamic string language is used, the `by`
             and `closed` arguments must also be set.
         weights
-            An optional slice with the same length as the window that will be multiplied
-            elementwise with the values in the window.
+            An optional slice with the same length as the window that determines the
+            relative contribution of each value in a window to the output.
         min_periods
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
@@ -6009,19 +6092,19 @@
         shape: (6, 2)
         
          A    rolling_var 
          ---  ---         
          f64  f64         
         
          1.0  null        
-         2.0  0.78125     
-         3.0  1.53125     
-         4.0  2.53125     
-         5.0  3.78125     
-         6.0  5.28125     
+         2.0  0.1875      
+         3.0  0.1875      
+         4.0  0.1875      
+         5.0  0.1875      
+         6.0  0.1875      
         
 
         Center the values in the window
 
         >>> df.with_columns(
         ...     rolling_var=pl.col("A").rolling_var(window_size=3, center=True),
         ... )
@@ -6065,15 +6148,15 @@
          24      2001-01-02 00:00:00 
         
 
         Compute the rolling var with the default left closure of temporal windows
 
         >>> df_temporal.with_columns(
         ...     rolling_row_var=pl.col("row_nr").rolling_var(
-        ...         window_size="2h", by="date"
+        ...         window_size="2h", by="date", closed="left"
         ...     )
         ... )
         shape: (25, 3)
         
          row_nr  date                 rolling_row_var 
          ---     ---                  ---             
          u32     datetime[s]         f64             
@@ -6165,30 +6248,35 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
             If a timedelta or the dynamic string language is used, the `by`
             and `closed` arguments must also be set.
         weights
-            An optional slice with the same length as the window that will be multiplied
-            elementwise with the values in the window.
+            An optional slice with the same length as the window that determines the
+            relative contribution of each value in a window to the output.
         min_periods
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
@@ -6225,33 +6313,33 @@
          2.0  1.5            
          3.0  2.5            
          4.0  3.5            
          5.0  4.5            
          6.0  5.5            
         
 
-        Specify weights to multiply the values in the window with:
+        Specify weights for the values in each window:
 
         >>> df.with_columns(
         ...     rolling_median=pl.col("A").rolling_median(
         ...         window_size=2, weights=[0.25, 0.75]
         ...     ),
         ... )
         shape: (6, 2)
         
          A    rolling_median 
          ---  ---            
          f64  f64            
         
          1.0  null           
-         2.0  0.875          
-         3.0  1.375          
-         4.0  1.875          
-         5.0  2.375          
-         6.0  2.875          
+         2.0  1.5            
+         3.0  2.5            
+         4.0  3.5            
+         5.0  4.5            
+         6.0  5.5            
         
 
         Center the values in the window
 
         >>> df.with_columns(
         ...     rolling_median=pl.col("A").rolling_median(window_size=3, center=True),
         ... )
@@ -6321,30 +6409,35 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
             If a timedelta or the dynamic string language is used, the `by`
             and `closed` arguments must also be set.
         weights
-            An optional slice with the same length as the window that will be
-            multiplied elementwise with the values in the window.
+            An optional slice with the same length as the window that determines the
+            relative contribution of each value in a window to the output.
         min_periods
             The number of values in the window that should be non-null before computing
             a result. If None, it will be set equal to window size.
         center
             Set the labels at the center of the window
         by
             If the `window_size` is temporal for instance `"5h"` or `"3s"`, you must
@@ -6383,15 +6476,15 @@
          2.0  null             
          3.0  null             
          4.0  2.0              
          5.0  3.0              
          6.0  4.0              
         
 
-        Specify weights to multiply the values in the window with:
+        Specify weights for the values in each window:
 
         >>> df.with_columns(
         ...     rolling_quantile=pl.col("A").rolling_quantile(
         ...         quantile=0.25, window_size=4, weights=[0.2, 0.4, 0.4, 0.2]
         ...     ),
         ... )
         shape: (6, 2)
@@ -6399,17 +6492,41 @@
          A    rolling_quantile 
          ---  ---              
          f64  f64              
         
          1.0  null             
          2.0  null             
          3.0  null             
-         4.0  0.8              
-         5.0  1.0              
-         6.0  1.2              
+         4.0  2.0              
+         5.0  3.0              
+         6.0  4.0              
+        
+
+        Specify weights and interpolation method
+
+        >>> df.with_columns(
+        ...     rolling_quantile=pl.col("A").rolling_quantile(
+        ...         quantile=0.25,
+        ...         window_size=4,
+        ...         weights=[0.2, 0.4, 0.4, 0.2],
+        ...         interpolation="linear",
+        ...     ),
+        ... )
+        shape: (6, 2)
+        
+         A    rolling_quantile 
+         ---  ---              
+         f64  f64              
+        
+         1.0  null             
+         2.0  null             
+         3.0  null             
+         4.0  1.625            
+         5.0  2.625            
+         6.0  3.625            
         
 
         Center the values in the window
 
         >>> df.with_columns(
         ...     rolling_quantile=pl.col("A").rolling_quantile(
         ...         quantile=0.2, window_size=5, center=True
@@ -7422,28 +7539,32 @@
          [1, 2, 3] 
          [4, 5, 6] 
          [7, 8, 9] 
         
 
         See Also
         --------
-        ExprListNameSpace.explode : Explode a list column.
+        Expr.list.explode : Explode a list column.
 
         """
         return self._from_pyexpr(self._pyexpr.reshape(dimensions))
 
-    def shuffle(self, seed: int | None = None) -> Self:
+    def shuffle(self, seed: int | None = None, fixed_seed: bool = False) -> Self:
         """
         Shuffle the contents of this expression.
 
         Parameters
         ----------
         seed
             Seed for the random number generator. If set to None (default), a random
             seed is generated using the ``random`` module.
+        fixed_seed
+            If True, The seed will not be incremented between draws.
+            This can make output predictable because draw ordering can
+            change due to threads being scheduled in a different order.
 
         Examples
         --------
         >>> df = pl.DataFrame({"a": [1, 2, 3]})
         >>> df.select(pl.col("a").shuffle(seed=1))
         shape: (3, 1)
         
@@ -7453,27 +7574,29 @@
         
          2   
          1   
          3   
         
 
         """
+        # we seed from python so that we respect ``random.seed``
         if seed is None:
             seed = random.randint(0, 10000)
-        return self._from_pyexpr(self._pyexpr.shuffle(seed))
+        return self._from_pyexpr(self._pyexpr.shuffle(seed, fixed_seed))
 
     @deprecated_alias(frac="fraction")
     def sample(
         self,
         n: int | None = None,
         *,
         fraction: float | None = None,
         with_replacement: bool = False,
         shuffle: bool = False,
         seed: int | None = None,
+        fixed_seed: bool = False,
     ) -> Self:
         """
         Sample from this expression.
 
         Parameters
         ----------
         n
@@ -7484,14 +7607,18 @@
         with_replacement
             Allow values to be sampled more than once.
         shuffle
             Shuffle the order of sampled data points.
         seed
             Seed for the random number generator. If set to None (default), a random
             seed is generated using the ``random`` module.
+        fixed_seed
+            If True, The seed will not be incremented between draws.
+            This can make output predictable because draw ordering can
+            change due to threads being scheduled in a different order.
 
         Examples
         --------
         >>> df = pl.DataFrame({"a": [1, 2, 3]})
         >>> df.select(pl.col("a").sample(fraction=1.0, with_replacement=True, seed=1))
         shape: (3, 1)
         
@@ -7509,21 +7636,23 @@
             raise ValueError("cannot specify both `n` and `fraction`")
 
         if seed is None:
             seed = random.randint(0, 10000)
 
         if fraction is not None:
             return self._from_pyexpr(
-                self._pyexpr.sample_frac(fraction, with_replacement, shuffle, seed)
+                self._pyexpr.sample_frac(
+                    fraction, with_replacement, shuffle, seed, fixed_seed
+                )
             )
 
         if n is None:
             n = 1
         return self._from_pyexpr(
-            self._pyexpr.sample_n(n, with_replacement, shuffle, seed)
+            self._pyexpr.sample_n(n, with_replacement, shuffle, seed, fixed_seed)
         )
 
     def ewm_mean(
         self,
         com: float | None = None,
         span: float | None = None,
         half_life: float | None = None,
```

### Comparing `polars_lts_cpu-0.18.4/polars/expr/list.py` & `polars_lts_cpu-0.18.5/polars/expr/list.py`

 * *Files 9% similar despite different names*

```diff
@@ -23,14 +23,68 @@
 
     def __init__(self, expr: Expr):
         self._pyexpr = expr._pyexpr
 
     def __getitem__(self, item: int) -> Expr:
         return self.get(item)
 
+    def all(self) -> Expr:
+        """
+        Evaluate whether all boolean values in a list are true.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {"a": [[True, True], [False, True], [False, False], [None], [], None]}
+        ... )
+        >>> df.select(pl.col("a").list.all())
+        shape: (6, 1)
+        
+         a     
+         ---   
+         bool  
+        
+         true  
+         false 
+         false 
+         false 
+         true  
+         null  
+        
+
+        """
+        return wrap_expr(self._pyexpr.list_all())
+
+    def any(self) -> Expr:
+        """
+        Evaluate whether any boolean value in a list is true.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {"a": [[True, True], [False, True], [False, False], [None], [], None]}
+        ... )
+        >>> df.select(pl.col("a").list.any())
+        shape: (6, 1)
+        
+         a     
+         ---   
+         bool  
+        
+         true  
+         true  
+         false 
+         false 
+         false 
+         null  
+        
+
+        """
+        return wrap_expr(self._pyexpr.list_any())
+
     def lengths(self) -> Expr:
         """
         Get the length of the arrays as UInt32.
 
         Examples
         --------
         >>> df = pl.DataFrame({"foo": [1, 2], "bar": [["a", "b"], ["c"]]})
@@ -815,7 +869,128 @@
          1    4    [1.0, 2.0] 
          8    5    [2.0, 1.0] 
          3    2    [2.0, 1.0] 
         
 
         """
         return wrap_expr(self._pyexpr.list_eval(expr._pyexpr, parallel))
+
+    def union(self, other: Expr | IntoExpr) -> Expr:
+        """
+        Compute the SET UNION between the elements in this list and the elements of ``other``.
+
+        Parameters
+        ----------
+        other
+            Right hand side of the set operation.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "a": [[1, 2, 3], [], [None, 3], [5, 6, 7]],
+        ...         "b": [[2, 3, 4], [3], [3, 4, None], [6, 8]],
+        ...     }
+        ... )
+        >>> df.with_columns(
+        ...     pl.col("a").list.union("b").alias("union")
+        ... )  # doctest: +IGNORE_RESULT
+        shape: (4, 3)
+        
+         a          b             union         
+         ---        ---           ---           
+         list[i64]  list[i64]     list[i64]     
+        
+         [1, 2, 3]  [2, 3, 4]     [1, 2, 3, 4]  
+         []         [3]           [3]           
+         [null, 3]  [3, 4, null]  [null, 3, 4]  
+         [5, 6, 7]  [6, 8]        [5, 6, 7, 8]  
+        
+
+        """  # noqa: W505.
+        other = parse_as_expression(other, str_as_lit=False)
+        return wrap_expr(self._pyexpr.list_set_operation(other, "union"))
+
+    def difference(self, other: Expr | IntoExpr) -> Expr:
+        """
+        Compute the SET DIFFERENCE between the elements in this list and the elements of ``other``.
+
+        Parameters
+        ----------
+        other
+            Right hand side of the set operation.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "a": [[1, 2, 3], [], [None, 3], [5, 6, 7]],
+        ...         "b": [[2, 3, 4], [3], [3, 4, None], [6, 8]],
+        ...     }
+        ... )
+        >>> df.with_columns(pl.col("a").list.difference("b").alias("difference"))
+        shape: (4, 3)
+        
+         a          b             difference 
+         ---        ---           ---        
+         list[i64]  list[i64]     list[i64]  
+        
+         [1, 2, 3]  [2, 3, 4]     [1]        
+         []         [3]           []         
+         [null, 3]  [3, 4, null]  []         
+         [5, 6, 7]  [6, 8]        [5, 7]     
+        
+
+        See Also
+        --------
+        polars.Expr.list.diff: Calculates the n-th discrete difference of every sublist.
+
+        """  # noqa: W505.
+        other = parse_as_expression(other, str_as_lit=False)
+        return wrap_expr(self._pyexpr.list_set_operation(other, "difference"))
+
+    def intersection(self, other: Expr | IntoExpr) -> Expr:
+        """
+        Compute the SET INTERSECTION between the elements in this list and the elements of ``other``.
+
+        Parameters
+        ----------
+        other
+            Right hand side of the set operation.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {
+        ...         "a": [[1, 2, 3], [], [None, 3], [5, 6, 7]],
+        ...         "b": [[2, 3, 4], [3], [3, 4, None], [6, 8]],
+        ...     }
+        ... )
+        >>> df.with_columns(pl.col("a").list.intersection("b").alias("intersection"))
+        shape: (4, 3)
+        
+         a          b             intersection 
+         ---        ---           ---          
+         list[i64]  list[i64]     list[i64]    
+        
+         [1, 2, 3]  [2, 3, 4]     [2, 3]       
+         []         [3]           []           
+         [null, 3]  [3, 4, null]  [3, null]    
+         [5, 6, 7]  [6, 8]        [6]          
+        
+
+        """  # noqa: W505.
+        other = parse_as_expression(other, str_as_lit=False)
+        return wrap_expr(self._pyexpr.list_set_operation(other, "intersection"))
+
+    def symmetric_difference(self, other: Expr | IntoExpr) -> Expr:
+        """
+        Compute the SET SYMMETRIC DIFFERENCE between the elements in this list and the elements of ``other``.
+
+        Parameters
+        ----------
+        other
+            Right hand side of the set operation.
+
+        """  # noqa: W505.
+        other = parse_as_expression(other, str_as_lit=False)
+        return wrap_expr(self._pyexpr.list_set_operation(other, "symmetric_difference"))
```

### Comparing `polars_lts_cpu-0.18.4/polars/expr/meta.py` & `polars_lts_cpu-0.18.5/polars/expr/meta.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 from __future__ import annotations
 
 from io import BytesIO, StringIO
 from pathlib import Path
-from typing import TYPE_CHECKING, overload
+from typing import TYPE_CHECKING, Literal, overload
 
 from polars.utils._wrap import wrap_expr
 from polars.utils.various import normalise_filepath
 
 if TYPE_CHECKING:
     from io import IOBase
 
@@ -112,7 +112,32 @@
             if to_string_io:
                 file.write(json_str)  # type: ignore[union-attr]
             else:
                 return json_str
         else:
             self._pyexpr.meta_write_json(file)
         return None
+
+    @overload
+    def tree_format(self, *, return_as_string: Literal[False]) -> None:
+        ...
+
+    @overload
+    def tree_format(self, *, return_as_string: Literal[True]) -> str:
+        ...
+
+    def tree_format(self, return_as_string: bool = False) -> str | None:
+        """
+        Format the expression as a tree.
+
+        Parameters
+        ----------
+        return_as_string:
+            If True, return as string rather than printing to stdout.
+
+        """
+        s = self._pyexpr.meta_tree_format()
+        if return_as_string:
+            return s
+        else:
+            print(s)
+            return None
```

### Comparing `polars_lts_cpu-0.18.4/polars/expr/string.py` & `polars_lts_cpu-0.18.5/polars/expr/string.py`

 * *Files 0% similar despite different names*

```diff
@@ -1665,15 +1665,15 @@
 
         strict
             Bool, Default=True will raise any ParseError or overflow as ComputeError.
             False silently convert to Null.
 
         Returns
         -------
-        Expr: Series of parsed integers in i32 format
+        Expr : Series of parsed integers in i32 format
 
         Examples
         --------
         >>> df = pl.DataFrame({"bin": ["110", "101", "010", "invalid"]})
         >>> df.select(pl.col("bin").str.parse_int(2, strict=False))
         shape: (4, 1)
         
```

### Comparing `polars_lts_cpu-0.18.4/polars/expr/struct.py` & `polars_lts_cpu-0.18.5/polars/expr/struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/functions/__init__.py` & `polars_lts_cpu-0.18.5/polars/functions/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -49,15 +49,15 @@
     select,
     sql_expr,
     std,
     sum,
     tail,
     var,
 )
-from polars.functions.range import arange, date_range, time_range
+from polars.functions.range import arange, date_range, int_range, int_ranges, time_range
 from polars.functions.repeat import ones, repeat, zeros
 from polars.functions.whenthen import when
 
 __all__ = [
     # polars.functions.eager
     "align_frames",
     "approx_unique",
@@ -94,14 +94,16 @@
     "first",
     "fold",
     "format",
     "from_epoch",
     "groups",
     "head",
     "implode",
+    "int_range",
+    "int_ranges",
     "last",
     "lit",
     "map",
     "max",
     "mean",
     "median",
     "min",
```

### Comparing `polars_lts_cpu-0.18.4/polars/functions/as_datatype.py` & `polars_lts_cpu-0.18.5/polars/functions/as_datatype.py`

 * *Files 1% similar despite different names*

```diff
@@ -14,24 +14,19 @@
 from polars.utils.various import find_stacklevel
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     import polars.polars as plr
 
 
 if TYPE_CHECKING:
-    import sys
+    from typing import Literal
 
     from polars import Expr, Series
     from polars.type_aliases import IntoExpr, SchemaDict
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
-
 
 def datetime_(
     year: Expr | str | int,
     month: Expr | str | int,
     day: Expr | str | int,
     hour: Expr | str | int | None = None,
     minute: Expr | str | int | None = None,
```

### Comparing `polars_lts_cpu-0.18.4/polars/functions/eager.py` & `polars_lts_cpu-0.18.5/polars/functions/eager.py`

 * *Files 0% similar despite different names*

```diff
@@ -11,27 +11,16 @@
 from polars.utils._wrap import wrap_df, wrap_expr, wrap_ldf, wrap_s
 from polars.utils.various import ordered_unique
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     import polars.polars as plr
 
 if TYPE_CHECKING:
-    import sys
-
     from polars import DataFrame, Expr, LazyFrame, Series
-    from polars.type_aliases import (
-        ConcatMethod,
-        JoinStrategy,
-        PolarsType,
-    )
-
-    if sys.version_info >= (3, 8):
-        pass
-    else:
-        pass
+    from polars.type_aliases import ConcatMethod, JoinStrategy, PolarsType
 
 
 def concat(
     items: Iterable[PolarsType],
     *,
     how: ConcatMethod = "vertical",
     rechunk: bool = True,
```

### Comparing `polars_lts_cpu-0.18.4/polars/functions/lazy.py` & `polars_lts_cpu-0.18.5/polars/functions/lazy.py`

 * *Files 0% similar despite different names*

```diff
@@ -30,32 +30,27 @@
 from polars.utils.decorators import deprecated_alias
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     import polars.polars as plr
 
 
 if TYPE_CHECKING:
-    import sys
+    from typing import Literal
 
     from polars import DataFrame, Expr, LazyFrame, Series
     from polars.type_aliases import (
         CorrelationMethod,
         EpochTimeUnit,
         IntoExpr,
         PolarsDataType,
         PythonLiteral,
         RollingInterpolationMethod,
         TimeUnit,
     )
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
-
 
 def col(
     name: str | PolarsDataType | Iterable[str] | Iterable[PolarsDataType],
     *more_names: str | PolarsDataType,
 ) -> Expr:
     """
     Return an expression representing column(s) in a dataframe.
```

### Comparing `polars_lts_cpu-0.18.4/polars/functions/range.py` & `polars_lts_cpu-0.18.5/polars/functions/range.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,42 +1,41 @@
 from __future__ import annotations
 
 import contextlib
 import warnings
-from datetime import datetime, time, timedelta
+from datetime import time, timedelta
 from typing import TYPE_CHECKING, overload
 
 import polars._reexport as pl
 from polars import functions as F
-from polars.datatypes import Date, Int64
-from polars.expr.datetime import TIME_ZONE_DEPRECATION_MESSAGE
+from polars.datatypes import Int64
 from polars.utils._parse_expr_input import parse_as_expression
 from polars.utils._wrap import wrap_expr, wrap_s
 from polars.utils.convert import (
-    _datetime_to_pl_timestamp,
     _time_to_pl_time,
     _timedelta_to_pl_duration,
 )
 from polars.utils.decorators import deprecated_alias
 from polars.utils.various import find_stacklevel
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     import polars.polars as plr
 
 if TYPE_CHECKING:
-    import sys
-    from datetime import date
+    from datetime import date, datetime
+    from typing import Literal
 
     from polars import Expr, Series
-    from polars.type_aliases import ClosedInterval, PolarsDataType, TimeUnit
-
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
+    from polars.type_aliases import (
+        ClosedInterval,
+        IntoExpr,
+        PolarsDataType,
+        PolarsIntegerType,
+        TimeUnit,
+    )
 
 
 @overload
 def arange(
     start: int | Expr | Series,
     end: int | Expr | Series,
     step: int = ...,
@@ -45,61 +44,61 @@
     eager: Literal[False] = ...,
 ) -> Expr:
     ...
 
 
 @overload
 def arange(
-    start: int | Expr | Series,
-    end: int | Expr | Series,
+    start: int | IntoExpr,
+    end: int | IntoExpr,
     step: int = ...,
     *,
     dtype: PolarsDataType | None = ...,
     eager: Literal[True],
 ) -> Series:
     ...
 
 
 @overload
 def arange(
-    start: int | Expr | Series,
-    end: int | Expr | Series,
+    start: int | IntoExpr,
+    end: int | IntoExpr,
     step: int = ...,
     *,
     dtype: PolarsDataType | None = ...,
     eager: bool,
 ) -> Expr | Series:
     ...
 
 
 @deprecated_alias(low="start", high="end")
 def arange(
-    start: int | Expr | Series,
-    end: int | Expr | Series,
+    start: int | IntoExpr,
+    end: int | IntoExpr,
     step: int = 1,
     *,
     dtype: PolarsDataType | None = None,
     eager: bool = False,
 ) -> Expr | Series:
     """
-    Create a range expression (or Series).
+    Generate a range of integers.
 
-    This can be used in a `select`, `with_column` etc. Be sure that the resulting
+    This can be used in a ``select``, ``with_columns`` etc. Be sure that the resulting
     range size is equal to the length of the DataFrame you are collecting.
 
     Parameters
     ----------
     start
-        Lower bound of range.
+        Lower bound of the range (inclusive).
     end
-        Upper bound of range.
+        Upper bound of the range (exclusive).
     step
         Step size of the range.
     dtype
-        Apply an explicit integer dtype to the resulting expression (default is Int64).
+        Data type of the resulting column. Defaults to ``Int64``.
     eager
         Evaluate immediately and return a ``Series``. If set to ``False`` (default),
         return an expression instead.
 
     Examples
     --------
     >>> pl.arange(0, 3, eager=True)
@@ -107,37 +106,208 @@
     Series: 'arange' [i64]
     [
             0
             1
             2
     ]
 
-    >>> df = pl.DataFrame({"a": [1, 2], "b": [3, 4]})
-    >>> df.select(pl.arange(pl.col("a"), pl.col("b")))
-    shape: (2, 1)
-    
-     arange    
-     ---       
-     list[i64] 
-    
-     [1, 2]    
-     [2, 3]    
-    
-
     """
+    # This check is not water-proof, but we cannot check for literal expressions here
+    if not (isinstance(start, int) and isinstance(end, int)):
+        warnings.warn(
+            " `arange` has been replaced by two new functions:"
+            " `int_range` for generating a single range,"
+            " and `int_ranges` for generating a list column with multiple ranges."
+            " `arange` will remain available as an alias for `int_range`, which means its behaviour will change."
+            " To silence this warning, use either of the new functions.",
+            DeprecationWarning,
+            stacklevel=find_stacklevel(),
+        )
+
     start = parse_as_expression(start)
     end = parse_as_expression(end)
-    range_expr = wrap_expr(plr.arange(start, end, step))
+    result = wrap_expr(plr.arange(start, end, step))
 
     if dtype is not None and dtype != Int64:
-        range_expr = range_expr.cast(dtype)
-    if not eager:
-        return range_expr
-    else:
-        return pl.DataFrame().select(range_expr.alias("arange")).to_series()
+        result = result.cast(dtype)
+    if eager:
+        return F.select(result).to_series()
+
+    return result
+
+
+@overload
+def int_range(
+    start: int | IntoExpr,
+    end: int | IntoExpr,
+    step: int = ...,
+    *,
+    eager: Literal[False] = ...,
+) -> Expr:
+    ...
+
+
+@overload
+def int_range(
+    start: int | IntoExpr,
+    end: int | IntoExpr,
+    step: int = ...,
+    *,
+    eager: Literal[True],
+) -> Series:
+    ...
+
+
+@overload
+def int_range(
+    start: int | IntoExpr,
+    end: int | IntoExpr,
+    step: int = ...,
+    *,
+    eager: bool,
+) -> Expr | Series:
+    ...
+
+
+def int_range(
+    start: int | IntoExpr,
+    end: int | IntoExpr,
+    step: int = 1,
+    *,
+    eager: bool = False,
+) -> Expr | Series:
+    """
+    Generate a range of integers.
+
+    Parameters
+    ----------
+    start
+        Lower bound of the range (inclusive).
+    end
+        Upper bound of the range (exclusive).
+    step
+        Step size of the range.
+    eager
+        Evaluate immediately and return a ``Series``. If set to ``False`` (default),
+        return an expression instead.
+
+    Returns
+    -------
+    Column of data type ``Int64``.
+
+    Examples
+    --------
+    >>> pl.int_range(0, 3, eager=True)
+    shape: (3,)
+    Series: 'int' [i64]
+    [
+            0
+            1
+            2
+    ]
+
+    """
+    start = parse_as_expression(start)
+    end = parse_as_expression(end)
+    result = wrap_expr(plr.int_range(start, end, step))
+
+    if eager:
+        return F.select(result).to_series()
+
+    return result
+
+
+@overload
+def int_ranges(
+    start: IntoExpr,
+    end: IntoExpr,
+    step: int = ...,
+    *,
+    dtype: PolarsIntegerType = ...,
+    eager: Literal[False] = ...,
+) -> Expr:
+    ...
+
+
+@overload
+def int_ranges(
+    start: IntoExpr,
+    end: IntoExpr,
+    step: int = ...,
+    *,
+    dtype: PolarsIntegerType = ...,
+    eager: Literal[True],
+) -> Series:
+    ...
+
+
+@overload
+def int_ranges(
+    start: IntoExpr,
+    end: IntoExpr,
+    step: int = ...,
+    *,
+    dtype: PolarsIntegerType = ...,
+    eager: bool,
+) -> Expr | Series:
+    ...
+
+
+def int_ranges(
+    start: IntoExpr,
+    end: IntoExpr,
+    step: int = 1,
+    *,
+    dtype: PolarsIntegerType = Int64,
+    eager: bool = False,
+) -> Expr | Series:
+    """
+    Generate a range of integers for each row of the input columns.
+
+    Parameters
+    ----------
+    start
+        Lower bound of the range (inclusive).
+    end
+        Upper bound of the range (exclusive).
+    step
+        Step size of the range.
+    dtype
+        Integer data type of the ranges. Defaults to ``Int64``.
+    eager
+        Evaluate immediately and return a ``Series``. If set to ``False`` (default),
+        return an expression instead.
+
+    Returns
+    -------
+    Column of data type ``List(dtype)``.
+
+    Examples
+    --------
+    >>> df = pl.DataFrame({"start": [1, -1], "end": [3, 2]})
+    >>> df.with_columns(pl.int_ranges("start", "end"))
+    shape: (2, 3)
+    
+     start  end  int_range  
+     ---    ---  ---        
+     i64    i64  list[i64]  
+    
+     1      3    [1, 2]     
+     -1     2    [-1, 0, 1] 
+    
+
+    """
+    start = parse_as_expression(start)
+    end = parse_as_expression(end)
+    result = wrap_expr(plr.int_ranges(start, end, step, dtype))
+
+    if eager:
+        return F.select(result).to_series()
+
+    return result
 
 
 @overload
 def date_range(
     start: date | datetime | Expr | str,
     end: date | datetime | Expr | str,
     interval: str | timedelta = ...,
@@ -211,17 +381,17 @@
 
         It is common to attempt to create a month-end date series by using the "1mo"
         offset string with a start date at the end of the month. This will not produce
         the desired results. See Note #2 below for further information.
     closed : {'both', 'left', 'right', 'none'}
         Define whether the temporal window interval is closed or not.
     time_unit : {None, 'ns', 'us', 'ms'}
-        Set the time unit.
+        Set the time unit. Only takes effect if output is of ``Datetime`` type.
     time_zone:
-        Optional timezone
+        Optional timezone. Only takes effect if output is of ``Datetime`` type.
     eager
         Evaluate immediately and return a ``Series``. If set to ``False`` (default),
         return an expression instead.
     name
         Name of the output column.
 
         .. deprecated:: 0.18.0
@@ -344,94 +514,43 @@
     if name is not None:
         warnings.warn(
             "the `name` argument is deprecated. Use the `alias` method instead.",
             DeprecationWarning,
             stacklevel=find_stacklevel(),
         )
 
-    from polars.dependencies import zoneinfo
-
-    if time_zone is not None and time_zone not in zoneinfo.available_timezones():
-        warnings.warn(
-            TIME_ZONE_DEPRECATION_MESSAGE,
-            DeprecationWarning,
-            stacklevel=find_stacklevel(),
-        )
-
     if isinstance(interval, timedelta):
         interval = _timedelta_to_pl_duration(interval)
     elif " " in interval:
         interval = interval.replace(" ", "")
 
-    if (
-        not eager
-        or isinstance(start, (str, pl.Expr))
-        or isinstance(end, (str, pl.Expr))
-    ):
-        start = parse_as_expression(start)
-        end = parse_as_expression(end)
-        expr = wrap_expr(plr.date_range_lazy(start, end, interval, closed, time_zone))
-        if name is not None:
-            expr = expr.alias(name)
-        return expr
-
-    start, start_is_date = _ensure_datetime(start)
-    end, end_is_date = _ensure_datetime(end)
-
-    if start.tzinfo is not None or time_zone is not None:
-        if start.tzinfo != end.tzinfo:
-            raise ValueError(
-                "Cannot mix different timezone aware datetimes."
-                f" Got: '{start.tzinfo}' and '{end.tzinfo}'."
-            )
-
-        if time_zone is not None and start.tzinfo is not None:
-            if str(start.tzinfo) != time_zone:
-                raise ValueError(
-                    "Given time_zone is different from that of timezone aware datetimes."
-                    f" Given: '{time_zone}', got: '{start.tzinfo}'."
-                )
-        if time_zone is None and start.tzinfo is not None:
-            time_zone = str(start.tzinfo)
-
-    time_unit_: TimeUnit
+    time_unit_: TimeUnit | None
     if time_unit is not None:
         time_unit_ = time_unit
     elif "ns" in interval:
         time_unit_ = "ns"
     else:
-        time_unit_ = "us"
+        time_unit_ = None
 
-    start_pl = _datetime_to_pl_timestamp(start, time_unit_)
-    end_pl = _datetime_to_pl_timestamp(end, time_unit_)
-    dt_range = wrap_s(
-        plr.date_range_eager(start_pl, end_pl, interval, closed, time_unit_, time_zone)
+    start_pl = parse_as_expression(start)
+    end_pl = parse_as_expression(end)
+    dt_range = wrap_expr(
+        plr.date_range_lazy(start_pl, end_pl, interval, closed, time_unit_, time_zone)
     )
-    if (
-        start_is_date
-        and end_is_date
-        and not _interval_granularity(interval).endswith(("h", "m", "s"))
-    ):
-        dt_range = dt_range.cast(Date)
-
     if name is not None:
         dt_range = dt_range.alias(name)
-    return dt_range
-
-
-def _ensure_datetime(value: date | datetime) -> tuple[datetime, bool]:
-    is_date_type = False
-    if not isinstance(value, datetime):
-        value = datetime(value.year, value.month, value.day)
-        is_date_type = True
-    return value, is_date_type
 
-
-def _interval_granularity(interval: str) -> str:
-    return interval[-2:].lstrip("0123456789")
+    if (
+        not eager
+        or isinstance(start_pl, (str, pl.Expr))
+        or isinstance(end_pl, (str, pl.Expr))
+    ):
+        return dt_range
+    res = F.select(dt_range).to_series().explode().set_sorted()
+    return res
 
 
 @overload
 def time_range(
     start: time | Expr | str | None = ...,
     end: time | Expr | str | None = ...,
     interval: str | timedelta = ...,
```

### Comparing `polars_lts_cpu-0.18.4/polars/functions/repeat.py` & `polars_lts_cpu-0.18.5/polars/functions/repeat.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,71 +2,71 @@
 
 import contextlib
 import warnings
 from typing import TYPE_CHECKING, overload
 
 from polars import functions as F
 from polars.datatypes import Float64
+from polars.utils._parse_expr_input import parse_as_expression
 from polars.utils._wrap import wrap_expr
 from polars.utils.various import find_stacklevel
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     import polars.polars as plr
 
 
 if TYPE_CHECKING:
-    import sys
+    from typing import Literal
 
     from polars import Expr, Series
-    from polars.type_aliases import PolarsDataType, PolarsExprType, PythonLiteral
-
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
+    from polars.type_aliases import (
+        IntoExpr,
+        PolarsDataType,
+        PolarsExprType,
+    )
 
 
 @overload
 def repeat(
-    value: PythonLiteral | None,
+    value: IntoExpr | None,
     n: int | PolarsExprType,
     *,
     dtype: PolarsDataType | None = ...,
     eager: Literal[False] = ...,
     name: str | None = ...,
 ) -> Expr:
     ...
 
 
 @overload
 def repeat(
-    value: PythonLiteral | None,
+    value: IntoExpr | None,
     n: int | PolarsExprType,
     *,
     dtype: PolarsDataType | None = ...,
     eager: Literal[True],
     name: str | None = ...,
 ) -> Series:
     ...
 
 
 @overload
 def repeat(
-    value: PythonLiteral | None,
+    value: IntoExpr | None,
     n: int | PolarsExprType,
     *,
     dtype: PolarsDataType | None = ...,
     eager: bool,
     name: str | None = ...,
 ) -> Expr | Series:
     ...
 
 
 def repeat(
-    value: PythonLiteral | None,
+    value: IntoExpr | None,
     n: int | PolarsExprType,
     *,
     dtype: PolarsDataType | None = None,
     eager: bool = False,
     name: str | None = None,
 ) -> Expr | Series:
     """
@@ -130,14 +130,15 @@
             "the `name` argument is deprecated. Use the `alias` method instead.",
             DeprecationWarning,
             stacklevel=find_stacklevel(),
         )
 
     if isinstance(n, int):
         n = F.lit(n)
+    value = parse_as_expression(value, str_as_lit=True)
     expr = wrap_expr(plr.repeat(value, n._pyexpr, dtype))
     if name is not None:
         expr = expr.alias(name)
     if eager:
         return F.select(expr).to_series()
     return expr
```

### Comparing `polars_lts_cpu-0.18.4/polars/functions/whenthen.py` & `polars_lts_cpu-0.18.5/polars/functions/whenthen.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from __future__ import annotations
 
 import contextlib
-import typing
 from typing import TYPE_CHECKING, Any
 
 from polars.utils._parse_expr_input import parse_as_expression
 from polars.utils._wrap import wrap_expr
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     from polars.polars import when as _when
@@ -137,18 +136,17 @@
         --------
         pl.when : Documentation for `when, then, otherwise`
 
         """
         expr = parse_as_expression(expr, str_as_lit=True)
         return wrap_expr(self._pywhenthen.otherwise(expr))
 
-    @typing.no_type_check
-    def __getattr__(self, item) -> Expr:
-        expr = self.otherwise(None)  # noqa: F841
-        return eval(f"expr.{item}")
+    def __getattr__(self, item: str) -> Any:
+        expr = self.otherwise(None)
+        return getattr(expr, item)
 
 
 class WhenThenThen:
     """Utility class. See the `when` function."""
 
     def __init__(self, pywhenthenthen: Any):
         self.pywhenthenthen = pywhenthenthen
@@ -178,11 +176,10 @@
         --------
         pl.when : Documentation for `when, then, otherwise`
 
         """
         expr = parse_as_expression(expr, str_as_lit=True)
         return wrap_expr(self.pywhenthenthen.otherwise(expr))
 
-    @typing.no_type_check
-    def __getattr__(self, item) -> Expr:
-        expr = self.otherwise(None)  # noqa: F841
-        return eval(f"expr.{item}")
+    def __getattr__(self, item: str) -> Any:
+        expr = self.otherwise(None)
+        return getattr(expr, item)
```

### Comparing `polars_lts_cpu-0.18.4/polars/io/__init__.py` & `polars_lts_cpu-0.18.5/polars/io/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/_utils.py` & `polars_lts_cpu-0.18.5/polars/io/_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,14 +14,18 @@
 )
 
 from polars.dependencies import _FSSPEC_AVAILABLE, fsspec
 from polars.exceptions import NoDataError
 from polars.utils.various import normalise_filepath
 
 
+def _is_glob_pattern(file: str) -> bool:
+    return any(char in file for char in ["*", "?", "["])
+
+
 def _is_local_file(file: str) -> bool:
     try:
         next(glob.iglob(file, recursive=True))
         return True
     except StopIteration:
         return False
```

### Comparing `polars_lts_cpu-0.18.4/polars/io/avro.py` & `polars_lts_cpu-0.18.5/polars/io/avro.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/csv/_utils.py` & `polars_lts_cpu-0.18.5/polars/io/csv/_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/csv/batched_reader.py` & `polars_lts_cpu-0.18.5/polars/io/csv/batched_reader.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/csv/functions.py` & `polars_lts_cpu-0.18.5/polars/io/csv/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/database.py` & `polars_lts_cpu-0.18.5/polars/io/database.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,9 +1,12 @@
 from __future__ import annotations
 
+import re
+import sys
+from importlib import import_module
 from typing import TYPE_CHECKING, Any
 
 from polars.convert import from_arrow
 
 if TYPE_CHECKING:
     from polars import DataFrame
     from polars.type_aliases import DbReadEngine
@@ -23,47 +26,52 @@
     Read a SQL query into a DataFrame.
 
     Parameters
     ----------
     query
         Raw SQL query (or queries).
     connection_uri
-        A connectorx compatible connection uri, for example
+        A connectorx or ADBC connection URI that starts with the backend's
+        driver name, for example:
 
-        * "postgresql://username:password@server:port/database"
+        * "postgresql://user:pass@server:port/database"
+        * "snowflake://user:pass@account/database/schema?warehouse=warehouse&role=role"
     partition_on
-        The column on which to partition the result.
+        The column on which to partition the result (connectorx).
     partition_range
-        The value range of the partition column.
+        The value range of the partition column (connectorx).
     partition_num
-        How many partitions to generate.
+        How many partitions to generate (connectorx).
     protocol
-        Backend-specific transfer protocol directive; see connectorx documentation for
-        details.
+        Backend-specific transfer protocol directive (connectorx); see connectorx
+        documentation for more details.
     engine : {'connectorx', 'adbc'}
-        Select the engine used for reading the data.
+        Selects the engine used for reading the database:
 
         * ``'connectorx'``
           Supports a range of databases, such as PostgreSQL, Redshift, MySQL, MariaDB,
           Clickhouse, Oracle, BigQuery, SQL Server, and so on. For an up-to-date list
           please see the connectorx docs:
 
           * https://github.com/sfu-db/connector-x#supported-sources--destinations
+
         * ``'adbc'``
-          Currently just PostgreSQL and SQLite are supported and these are both in
-          development. When flight_sql is further in development and widely adopted
-          this will make this significantly better. For an up-to-date list
-          please see the adbc docs:
+          Currently there is limited support for this engine, with a relatively small
+          number of drivers available, most of which are still in development. For
+          an up-to-date list of drivers please see the ADBC docs:
 
-          * https://arrow.apache.org/adbc/0.1.0/driver/cpp/index.html
+          * https://arrow.apache.org/adbc/
 
     Notes
     -----
-    Make sure to install connectorx>=0.3.1. Read the documentation
-    `here <https://sfu-db.github.io/connector-x/intro.html>`_.
+    For ``connectorx``, ensure that you have ``connectorx>=0.3.1``. The documentation
+    is available `here <https://sfu-db.github.io/connector-x/intro.html>`_.
+
+    For ``adbc`` you will need to have installed ``pyarrow`` and the ADBC driver associated
+    with the backend you are connecting to, eg: ``adbc-driver-postgresql``.
 
     Examples
     --------
     Read a DataFrame from a SQL query using a single thread:
 
     >>> uri = "postgresql://username:password@server:port/database"
     >>> query = "SELECT * FROM lineitem"
@@ -71,43 +79,55 @@
 
     Read a DataFrame in parallel using 10 threads by automatically partitioning the
     provided SQL on the partition column:
 
     >>> uri = "postgresql://username:password@server:port/database"
     >>> query = "SELECT * FROM lineitem"
     >>> pl.read_database(
-    ...     query, uri, partition_on="partition_col", partition_num=10
+    ...     query,
+    ...     uri,
+    ...     partition_on="partition_col",
+    ...     partition_num=10,
+    ...     engine="connectorx",
     ... )  # doctest: +SKIP
 
     Read a DataFrame in parallel using 2 threads by explicitly providing two SQL
     queries:
 
     >>> uri = "postgresql://username:password@server:port/database"
     >>> queries = [
     ...     "SELECT * FROM lineitem WHERE partition_col <= 10",
     ...     "SELECT * FROM lineitem WHERE partition_col > 10",
     ... ]
-    >>> pl.read_database(queries, uri)  # doctest: +SKIP
+    >>> pl.read_database(queries, uri, engine="connectorx")  # doctest: +SKIP
 
-    """
+    Read data from Snowflake using the ADBC driver:
+
+    >>> df = pl.read_database(
+    ...     "SELECT * FROM test_table",
+    ...     "snowflake://user:pass@company-org/testdb/public?warehouse=test&role=myrole",
+    ...     engine="adbc",
+    ... )  # doctest: +SKIP
+
+    """  # noqa: W505
     if engine == "connectorx":
         return _read_sql_connectorx(
             query,
             connection_uri,
             partition_on=partition_on,
             partition_range=partition_range,
             partition_num=partition_num,
             protocol=protocol,
         )
     elif engine == "adbc":
         if not isinstance(query, str):
             raise ValueError("Only a single SQL query string is accepted for adbc.")
         return _read_sql_adbc(query, connection_uri)
     else:
-        raise ValueError("Engine is not implemented, try either connectorx or adbc.")
+        raise ValueError(f"Engine {engine!r} not implemented; use connectorx or adbc.")
 
 
 def _read_sql_connectorx(
     query: str | list[str],
     connection_uri: str,
     partition_on: str | None = None,
     partition_range: tuple[int, int] | None = None,
@@ -126,41 +146,41 @@
         query=query,
         return_type="arrow2",
         partition_on=partition_on,
         partition_range=partition_range,
         partition_num=partition_num,
         protocol=protocol,
     )
-
     return from_arrow(tbl)  # type: ignore[return-value]
 
 
 def _read_sql_adbc(query: str, connection_uri: str) -> DataFrame:
     with _open_adbc_connection(connection_uri) as conn:
         cursor = conn.cursor()
         cursor.execute(query)
         tbl = cursor.fetch_arrow_table()
         cursor.close()
     return from_arrow(tbl)  # type: ignore[return-value]
 
 
 def _open_adbc_connection(connection_uri: str) -> Any:
-    if connection_uri.startswith("sqlite"):
-        try:
-            import adbc_driver_sqlite.dbapi as adbc  # type: ignore[import]
-        except ImportError:
-            raise ImportError(
-                "ADBC sqlite driver not detected. Please run `pip install "
-                "adbc_driver_sqlite pyarrow`."
-            ) from None
-        connection_uri = connection_uri.replace(r"sqlite:///", "")
-    elif connection_uri.startswith("postgres"):
-        try:
-            import adbc_driver_postgresql.dbapi as adbc  # type: ignore[import]
-        except ImportError:
-            raise ImportError(
-                "ADBC postgresql driver not detected. Please run `pip install "
-                "adbc_driver_postgresql pyarrow`."
-            ) from None
-    else:
-        raise ValueError("ADBC does not currently support this database.")
-    return adbc.connect(connection_uri)
+    driver_name = connection_uri.split(":", 1)[0].lower()
+
+    # note: existing URI driver prefixes currently map 1:1 with
+    # the adbc module suffix; update this map if that changes.
+    module_suffix_map: dict[str, str] = {}
+    try:
+        module_suffix = module_suffix_map.get(driver_name, driver_name)
+        module_name = f"adbc_driver_{module_suffix}.dbapi"
+        import_module(module_name)
+        adbc_driver = sys.modules[module_name]
+    except ImportError:
+        raise ImportError(
+            f"ADBC {driver_name} driver not detected; if ADBC supports this database, "
+            f"please run `pip install adbc-driver-{driver_name} pyarrow`"
+        ) from None
+
+    # some backends require the driver name to be stripped from the URI
+    if driver_name in ("sqlite", "snowflake"):
+        connection_uri = re.sub(f"^{driver_name}:/{{,3}}", "", connection_uri)
+
+    return adbc_driver.connect(connection_uri)
```

### Comparing `polars_lts_cpu-0.18.4/polars/io/delta.py` & `polars_lts_cpu-0.18.5/polars/io/delta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/excel/_write_utils.py` & `polars_lts_cpu-0.18.5/polars/io/excel/_write_utils.py`

 * *Files 1% similar despite different names*

```diff
@@ -17,34 +17,29 @@
     Struct,
     Time,
 )
 from polars.dependencies import json
 from polars.exceptions import DuplicateError
 
 if TYPE_CHECKING:
-    import sys
+    from typing import Literal
 
     from xlsxwriter import Workbook
     from xlsxwriter.format import Format
     from xlsxwriter.worksheet import Worksheet
 
     from polars import DataFrame, Series
     from polars.type_aliases import (
         ColumnTotalsDefinition,
         ConditionalFormatDict,
         OneOrMoreDataTypes,
         PolarsDataType,
         RowTotalsDefinition,
     )
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
-
 
 def _cluster(iterable: Iterable[Any], n: int = 2) -> Iterable[Any]:
     return zip(*[iter(iterable)] * n)
 
 
 _XL_DEFAULT_FLOAT_FORMAT_ = "#,##0.000;[Red]-#,##0.000"
 _XL_DEFAULT_INTEGER_FORMAT_ = "#,##0;[Red]-#,##0"
```

### Comparing `polars_lts_cpu-0.18.4/polars/io/excel/functions.py` & `polars_lts_cpu-0.18.5/polars/io/excel/functions.py`

 * *Files 2% similar despite different names*

```diff
@@ -4,24 +4,19 @@
 from pathlib import Path
 from typing import TYPE_CHECKING, Any, BinaryIO, NoReturn, overload
 
 from polars.io.csv.functions import read_csv
 from polars.utils.various import normalise_filepath
 
 if TYPE_CHECKING:
-    import sys
     from io import BytesIO
+    from typing import Literal
 
     from polars import DataFrame
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
-
 
 @overload
 def read_excel(
     source: str | BytesIO | Path | BinaryIO | bytes,
     *,
     sheet_id: None = ...,
     sheet_name: str,
```

### Comparing `polars_lts_cpu-0.18.4/polars/io/ipc/anonymous_scan.py` & `polars_lts_cpu-0.18.5/polars/io/ipc/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/ipc/functions.py` & `polars_lts_cpu-0.18.5/polars/io/ipc/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/ndjson.py` & `polars_lts_cpu-0.18.5/polars/io/ndjson.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 
 if TYPE_CHECKING:
     from io import IOBase
 
     from polars import DataFrame, LazyFrame
 
 
-def read_ndjson(source: str | Path | IOBase) -> DataFrame:
+def read_ndjson(source: str | Path | IOBase | bytes) -> DataFrame:
     """
     Read into a DataFrame from a newline delimited JSON file.
 
     Parameters
     ----------
     source
         Path to a file or a file-like object.
```

### Comparing `polars_lts_cpu-0.18.4/polars/io/parquet/anonymous_scan.py` & `polars_lts_cpu-0.18.5/polars/io/parquet/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/parquet/functions.py` & `polars_lts_cpu-0.18.5/polars/io/parquet/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/pyarrow_dataset/anonymous_scan.py` & `polars_lts_cpu-0.18.5/polars/io/pyarrow_dataset/anonymous_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/io/pyarrow_dataset/functions.py` & `polars_lts_cpu-0.18.5/polars/io/pyarrow_dataset/functions.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/lazyframe/frame.py` & `polars_lts_cpu-0.18.5/polars/lazyframe/frame.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 from __future__ import annotations
 
 import contextlib
 import os
-import typing
 import warnings
 from datetime import date, datetime, time, timedelta
 from io import BytesIO, StringIO
 from pathlib import Path
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
+    ClassVar,
     Collection,
     Iterable,
     NoReturn,
     Sequence,
     TypeVar,
     overload,
 )
@@ -66,18 +66,19 @@
 with contextlib.suppress(ImportError):  # Module not available when building docs
     from polars.polars import PyLazyFrame
 
 
 if TYPE_CHECKING:
     import sys
     from io import IOBase
+    from typing import Literal
 
     import pyarrow as pa
 
-    from polars import DataFrame, Expr, Series
+    from polars import DataFrame, Expr
     from polars.type_aliases import (
         AsofJoinStrategy,
         ClosedInterval,
         CsvEncoding,
         FillNullStrategy,
         FrameInitTypes,
         IntoExpr,
@@ -89,19 +90,14 @@
         RollingInterpolationMethod,
         SchemaDefinition,
         SchemaDict,
         StartBy,
         UniqueKeepStrategy,
     )
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
-
     if sys.version_info >= (3, 10):
         from typing import Concatenate, ParamSpec
     else:
         from typing_extensions import Concatenate, ParamSpec
 
     if sys.version_info >= (3, 11):
         from typing import Self
@@ -258,15 +254,15 @@
      1    2    3   
      4    5    6   
     
 
     """
 
     _ldf: PyLazyFrame
-    _accessors: set[str] = set()
+    _accessors: ClassVar[set[str]] = set()
 
     def __init__(
         self,
         data: FrameInitTypes | None = None,
         schema: SchemaDefinition | None = None,
         *,
         schema_overrides: SchemaDict | None = None,
@@ -1866,15 +1862,15 @@
         ... )
         >>> lf.clone()  # doctest: +ELLIPSIS
         <LazyFrame [3 cols, {"a": Int64  "c": Boolean}] at ...>
 
         """
         return self._from_pyldf(self._ldf.clone())
 
-    def filter(self, predicate: Expr | str | Series | list[bool]) -> Self:
+    def filter(self, predicate: IntoExpr) -> Self:
         """
         Filter the rows in the LazyFrame based on a predicate expression.
 
         Parameters
         ----------
         predicate
             Expression that evaluates to a boolean Series.
@@ -2186,40 +2182,44 @@
 
         - 1ns   (1 nanosecond)
         - 1us   (1 microsecond)
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
-        - 1d    (1 day)
-        - 1w    (1 week)
+        - 1d    (1 calendar day)
+        - 1w    (1 calendar week)
         - 1mo   (1 calendar month)
         - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         In case of a groupby_rolling on an integer column, the windows are defined by:
 
         - "1i"      # length 1
         - "10i"     # length 10
 
         Parameters
         ----------
         index_column
             Column used to group based on the time window.
-            Often to type Date/Datetime
-            This column must be sorted in ascending order. If not the output will not
-            make sense.
+            Often of type Date/Datetime.
+            This column must be sorted in ascending order (or, if `by` is specified,
+            then it must be sorted in ascending order within each group).
 
             In case of a rolling groupby on indices, dtype needs to be one of
             {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if
             performance matters use an Int64 column.
         period
             length of the window - must be non-negative
         offset
@@ -2335,43 +2335,48 @@
 
         - 1ns   (1 nanosecond)
         - 1us   (1 microsecond)
         - 1ms   (1 millisecond)
         - 1s    (1 second)
         - 1m    (1 minute)
         - 1h    (1 hour)
-        - 1d    (1 day)
-        - 1w    (1 week)
+        - 1d    (1 calendar day)
+        - 1w    (1 calendar week)
         - 1mo   (1 calendar month)
         - 1q    (1 calendar quarter)
         - 1y    (1 calendar year)
         - 1i    (1 index count)
 
         Or combine them:
         "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         In case of a groupby_dynamic on an integer column, the windows are defined by:
 
         - "1i"      # length 1
         - "10i"     # length 10
 
         .. warning::
-            The index column must be sorted in ascending order.
+            The index column must be sorted in ascending order. If `by` is passed, then
+            the index column must be sorted in ascending order within each group.
 
         Parameters
         ----------
         index_column
             Column used to group based on the time window.
-            Often to type Date/Datetime
-            This column must be sorted in ascending order. If not the output will not
-            make sense.
+            Often of type Date/Datetime.
+            This column must be sorted in ascending order (or, if `by` is specified,
+            then it must be sorted in ascending order within each group).
 
             In case of a dynamic groupby on indices, dtype needs to be one of
             {Int32, Int64}. Note that Int32 gets temporarily cast to Int64, so if
             performance matters use an Int64 column.
         every
             interval of the window
         period
@@ -2717,28 +2722,33 @@
 
                 - 1ns   (1 nanosecond)
                 - 1us   (1 microsecond)
                 - 1ms   (1 millisecond)
                 - 1s    (1 second)
                 - 1m    (1 minute)
                 - 1h    (1 hour)
-                - 1d    (1 day)
-                - 1w    (1 week)
+                - 1d    (1 calendar day)
+                - 1w    (1 calendar week)
                 - 1mo   (1 calendar month)
                 - 1q    (1 calendar quarter)
                 - 1y    (1 calendar year)
                 - 1i    (1 index count)
 
                 Or combine them:
                 "3d12h4m25s" # 3 days, 12 hours, 4 minutes, and 25 seconds
 
                 Suffix with `"_saturating"` to indicate that dates too large for
                 their month should saturate at the largest date
                 (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+                By "calendar day", we mean the corresponding time on the next day
+                (which may not be 24 hours, due to daylight savings). Similarly for
+                "calendar week", "calendar month", "calendar quarter", and
+                "calendar year".
+
         allow_parallel
             Allow the physical plan to optionally evaluate the computation of both
             DataFrames up to the join in parallel.
         force_parallel
             Force the physical plan to evaluate the computation of both DataFrames up to
             the join in parallel.
 
@@ -3166,15 +3176,14 @@
         else:
             pyexprs = parse_as_list_of_expressions(
                 *exprs, **named_exprs, __structify=structify
             )
 
         return self._from_pyldf(self._ldf.with_columns(pyexprs))
 
-    @typing.no_type_check
     def with_context(self, other: Self | list[Self]) -> Self:
         """
         Add an external context to the computation graph.
 
         This allows expressions to also access columns from DataFrames
         that are not part of this one.
 
@@ -4689,14 +4698,60 @@
         Parameters
         ----------
         other
             Other DataFrame that must be merged
         key
             Key that is sorted.
 
+        Examples
+        --------
+        >>> df0 = pl.LazyFrame(
+        ...     {"name": ["steve", "elise", "bob"], "age": [42, 44, 18]}
+        ... ).sort("age")
+        >>> df0.collect()
+        shape: (3, 2)
+        
+         name   age 
+         ---    --- 
+         str    i64 
+        
+         bob    18  
+         steve  42  
+         elise  44  
+        
+        >>> df1 = pl.LazyFrame(
+        ...     {"name": ["anna", "megan", "steve", "thomas"], "age": [21, 33, 42, 20]}
+        ... ).sort("age")
+        >>> df1.collect()
+        shape: (4, 2)
+        
+         name    age 
+         ---     --- 
+         str     i64 
+        
+         thomas  20  
+         anna    21  
+         megan   33  
+         steve   42  
+        
+        >>> df0.merge_sorted(df1, key="age").collect()
+        shape: (7, 2)
+        
+         name    age 
+         ---     --- 
+         str     i64 
+        
+         bob     18  
+         thomas  20  
+         anna    21  
+         megan   33  
+         steve   42  
+         steve   42  
+         elise   44  
+        
         """
         return self._from_pyldf(self._ldf.merge_sorted(other._ldf, key))
 
     def set_sorted(
         self,
         column: str | Iterable[str],
         *more_columns: str,
```

### Comparing `polars_lts_cpu-0.18.4/polars/lazyframe/groupby.py` & `polars_lts_cpu-0.18.5/polars/lazyframe/groupby.py`

 * *Files 1% similar despite different names*

```diff
@@ -40,23 +40,41 @@
             Accepts expression input. Strings are parsed as column names.
         **named_aggs
             Additional aggregations, specified as keyword arguments.
             The resulting columns will be renamed to the keyword used.
 
         Examples
         --------
-        Compute the sum of a column for each group.
+        Compute the aggregation of the columns for each group.
 
         >>> ldf = pl.DataFrame(
         ...     {
         ...         "a": ["a", "b", "a", "b", "c"],
         ...         "b": [1, 2, 1, 3, 3],
         ...         "c": [5, 4, 3, 2, 1],
         ...     }
         ... ).lazy()
+        >>> ldf.groupby("a").agg(
+        ...     [pl.col("b"), pl.col("c")]
+        ... ).collect()  # doctest: +IGNORE_RESULT
+        shape: (3, 3)
+        
+         a    b          c         
+         ---  ---        ---       
+         str  list[i64]  list[i64] 
+        
+         a    [1, 1]     [5, 3]    
+        
+         b    [2, 3]     [4, 2]    
+        
+         c    [3]        [1]       
+        
+
+        Compute the sum of a column for each group.
+
         >>> ldf.groupby("a").agg(pl.col("b").sum()).collect()  # doctest: +IGNORE_RESULT
         shape: (3, 2)
         
          a    b   
          ---  --- 
          str  i64 
         
@@ -209,15 +227,15 @@
          3    red    triangle 
         
 
         It is better to implement this with an expression:
 
         >>> (
         ...     df.lazy()
-        ...     .filter(pl.arange(0, pl.count()).shuffle().over("color") < 2)
+        ...     .filter(pl.int_range(0, pl.count()).shuffle().over("color") < 2)
         ...     .collect()
         ... )  # doctest: +IGNORE_RESULT
 
         """
         return wrap_ldf(self.lgb.apply(function, schema))
 
     def head(self, n: int = 5) -> LazyFrame:
```

### Comparing `polars_lts_cpu-0.18.4/polars/selectors.py` & `polars_lts_cpu-0.18.5/polars/selectors.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,112 +1,138 @@
 from __future__ import annotations
 
 import re
-from typing import TYPE_CHECKING, Any, Collection
+from datetime import timezone
+from typing import TYPE_CHECKING, Any, Collection, TypeVar
 
 from polars import Expr
 from polars import functions as F
 from polars.datatypes import (
-    DATETIME_DTYPES,
     FLOAT_DTYPES,
     INTEGER_DTYPES,
     NUMERIC_DTYPES,
     TEMPORAL_DTYPES,
     Categorical,
     Datetime,
     Utf8,
     is_polars_dtype,
 )
 
 if TYPE_CHECKING:
     import sys
 
+    from polars import DataFrame, LazyFrame
     from polars.datatypes import PolarsDataType
     from polars.type_aliases import TimeUnit
 
     if sys.version_info >= (3, 11):
         from typing import Self
     else:
         from typing_extensions import Self
 
 
+SelectorType = TypeVar("SelectorType", bound="_selector_proxy_")
+
+
+def is_selector(obj: Any) -> bool:
+    """
+    Indicate whether the given object/expression is a selector.
+
+    Examples
+    --------
+    >>> from polars.selectors import is_selector
+    >>> import polars.selectors as cs
+    >>> is_selector(pl.col("colx"))
+    False
+    >>> is_selector(cs.first() | cs.last())
+    True
+    """
+    return isinstance(obj, _selector_proxy_)
+
+
+def selector_column_names(
+    frame: DataFrame | LazyFrame, selector: SelectorType
+) -> tuple[str, ...]:
+    """
+    Return the column names that would be selected from the given frame.
+
+    Parameters
+    ----------
+    frame
+        A polars DataFrame or LazyFrame.
+    selector
+        An arbitrary polars selector (or compound selector).
+
+    Examples
+    --------
+    >>> from polars.selectors import selector_column_names
+    >>> import polars.selectors as cs
+    >>> df = pl.DataFrame(
+    ...     {
+    ...         "colx": ["x", "y"],
+    ...         "coly": [123, 456],
+    ...         "colz": [2.0, 5.5],
+    ...     }
+    ... )
+    >>> selector_column_names(df, cs.numeric())
+    ('coly', 'colz')
+    >>> selector_column_names(df, cs.first() | cs.last())
+    ('colx', 'colz')
+    >>> selector_column_names(df, ~(cs.first() | cs.last()))
+    ('coly',)
+    """
+    return tuple(frame.clear().select(selector).columns)
+
+
 class _selector_proxy_(Expr):
     """Base column selector expression/proxy."""
 
     _attrs: dict[str, Any]
-    _inverted: bool
+    _repr_override: str
 
     def __init__(
         self,
         expr: Expr,
         name: str,
         parameters: dict[str, Any] | None = None,
-        raw_parameters: list[Any] | None = None,
-        invert: bool = False,
     ):
         self._pyexpr = expr._pyexpr
-        self._inverted = invert
-
-        # note: 'params' and 'name' are primarily stored for the repr,
-        # whereas 'raw_params' is what we need to invert the expression.
         self._attrs = {
-            "raw_params": raw_parameters,
             "params": parameters,
             "name": name,
         }
 
     def __invert__(self) -> Self:
         """Invert the selector."""
-        if not hasattr(self, "_attrs"):
-            return ~self.as_expr()  # type: ignore[return-value]
-
-        name = self._attrs["name"]
-        if name in ("sub", "and", "or"):
-            raise ValueError(f"Cannot currently invert {name!r} selector")
-        elif name in ("first", "last"):
-            return all() - self  # type: ignore[return-value]
-
-        params = self._attrs["params"] or {}
-        raw_params = self._attrs["raw_params"] or []
-        if not raw_params and params:
-            raw_params = list(params.values())
-
-        if name == "all":
-            inverted_expr = F.all() if self._inverted else F.col([])
-        elif self._inverted:
-            inverted_expr = F.col(*raw_params)
+        if hasattr(self, "_attrs"):
+            inverted = all() - self
+            inverted._repr_override = f"~{self!r}"  # type: ignore[attr-defined]
         else:
-            inverted_expr = F.all().exclude(*raw_params)
-
-        return self.__class__(
-            expr=inverted_expr,
-            name=name,
-            parameters=params,
-            raw_parameters=raw_params,
-            invert=not self._inverted,
-        )
+            inverted = ~self.as_expr()
+        return inverted  # type: ignore[return-value]
 
     def __repr__(self) -> str:
         if not hasattr(self, "_attrs"):
             return re.sub(
                 r"<[\w.]+_selector_proxy_[\w ]+>", "<selector>", super().__repr__()
             )
+        elif hasattr(self, "_repr_override"):
+            return self._repr_override
         else:
             selector_name, params = self._attrs["name"], self._attrs["params"]
             set_ops = {"and": "&", "or": "|", "sub": "-"}
             if selector_name in set_ops:
                 op = set_ops[selector_name]
                 return f" {op} ".join(repr(p) for p in params.values())
             else:
-                not_ = "~" if self._inverted else ""
                 str_params = ",".join(
                     (repr(v)[1:-1] if k.startswith("*") else f"{k}={v!r}")
                     for k, v in (params or {}).items()
                 )
-                return f"{not_}cs.{selector_name}({str_params})"
+                return f"cs.{selector_name}({str_params})"
 
     def __sub__(self, other: Any) -> Expr:  # type: ignore[override]
         if isinstance(other, _selector_proxy_) and hasattr(other, "_attrs"):
             return _selector_proxy_(
                 self.meta._as_selector().meta._selector_sub(other),
                 parameters={"self": self, "other": other},
                 name="sub",
@@ -200,15 +226,15 @@
     
      1999-12-31  1234500 
      2024-01-01  5000555 
     
 
     Select all columns *except* for those matching the given dtypes:
 
-    >>> df.select(cs.all().exclude(pl.NUMERIC_DTYPES))
+    >>> df.select(cs.all() - cs.numeric())
     shape: (2, 1)
     
      dt         
      ---        
      date       
     
      1999-12-31 
@@ -447,62 +473,124 @@
     escaped_substring = _re_string(substring)
     raw_params = f"^.*{escaped_substring}.*$"
 
     return _selector_proxy_(
         F.col(raw_params),
         name="contains",
         parameters={"substring": escaped_substring},
-        raw_parameters=[raw_params],
     )
 
 
-def datetime(time_unit: TimeUnit | None = None) -> Expr:
+def datetime(
+    time_unit: TimeUnit | Collection[TimeUnit] | None = None,
+    time_zone: (str | timezone | Collection[str | timezone | None] | None) = (
+        "*",
+        None,
+    ),
+) -> Expr:
     """
-    Select all datetime columns.
+    Select all datetime columns, optionally filtering by timeunit/timezone.
+
+    Parameters
+    ----------
+    time_unit
+        One (or more) of the allowed timeunit precision strings, "ms", "us", and "ns".
+        Omit to select columns with any valid timeunit.
+    time_zone
+        * One or more timezone strings, as defined in zoneinfo (to see valid options
+          run ``import zoneinfo; zoneinfo.available_timezones()`` for a full list).
+        * Set ``None`` to select Datetime columns that do not have a timezone.
+        * Set "*" to select Datetime columns that have *any* timezone.
 
     Examples
     --------
     >>> from datetime import datetime, date
     >>> import polars.selectors as cs
     >>> df = pl.DataFrame(
     ...     {
+    ...         "tstamp_tokyo": [
+    ...             datetime(1999, 7, 20, 20, 20, 16, 987654),
+    ...             datetime(2000, 5, 15, 21, 21, 21, 123465),
+    ...         ],
+    ...         "tstamp_utc": [
+    ...             datetime(2023, 4, 10, 12, 14, 16, 999000),
+    ...             datetime(2025, 8, 25, 14, 18, 22, 666000),
+    ...         ],
     ...         "tstamp": [
     ...             datetime(2000, 11, 20, 18, 12, 16, 600000),
     ...             datetime(2020, 10, 30, 10, 20, 25, 123000),
     ...         ],
-    ...         "dtime": [
-    ...             datetime(2010, 10, 10, 10, 25, 30, 987000),
-    ...             datetime(2024, 12, 31, 20, 30, 45, 400500),
-    ...         ],
     ...         "dt": [date(1999, 12, 31), date(2010, 7, 5)],
     ...     },
-    ...     schema_overrides={"tstamp": pl.Datetime("ns"), "dtime": pl.Datetime("ms")},
+    ...     schema_overrides={
+    ...         "tstamp_tokyo": pl.Datetime("ns", "Asia/Tokyo"),
+    ...         "tstamp_utc": pl.Datetime("us", "UTC"),
+    ...     },
     ... )
 
     Select all datetime columns:
 
     >>> df.select(cs.datetime())
+    shape: (2, 3)
+    
+     tstamp_tokyo                    tstamp_utc                   tstamp                  
+     ---                             ---                          ---                     
+     datetime[ns, Asia/Tokyo]        datetime[s, UTC]            datetime[s]            
+    
+     1999-07-21 05:20:16.987654 JST  2023-04-10 12:14:16.999 UTC  2000-11-20 18:12:16.600 
+     2000-05-16 06:21:21.123465 JST  2025-08-25 14:18:22.666 UTC  2020-10-30 10:20:25.123 
+    
+
+    Select all datetime columns that have 'us' precision:
+
+    >>> df.select(cs.datetime("us"))
+    shape: (2, 2)
+    
+     tstamp_utc                   tstamp                  
+     ---                          ---                     
+     datetime[s, UTC]            datetime[s]            
+    
+     2023-04-10 12:14:16.999 UTC  2000-11-20 18:12:16.600 
+     2025-08-25 14:18:22.666 UTC  2020-10-30 10:20:25.123 
+    
+
+    Select all datetime columns that have *any* timezone:
+
+    >>> df.select(cs.datetime(time_zone="*"))
     shape: (2, 2)
-    
-     tstamp                   dtime                   
-     ---                      ---                     
-     datetime[ns]             datetime[ms]            
-    
-     2000-11-20 18:12:16.600  2010-10-10 10:25:30.987 
-     2020-10-30 10:20:25.123  2024-12-31 20:30:45.400 
-    
+    
+     tstamp_tokyo                    tstamp_utc                  
+     ---                             ---                         
+     datetime[ns, Asia/Tokyo]        datetime[s, UTC]           
+    
+     1999-07-21 05:20:16.987654 JST  2023-04-10 12:14:16.999 UTC 
+     2000-05-16 06:21:21.123465 JST  2025-08-25 14:18:22.666 UTC 
+    
+
+    Select all datetime columns that have a *specific* timezone:
+
+    >>> df.select(cs.datetime(time_zone="UTC"))
+    shape: (2, 1)
+    
+     tstamp_utc                  
+     ---                         
+     datetime[s, UTC]           
+    
+     2023-04-10 12:14:16.999 UTC 
+     2025-08-25 14:18:22.666 UTC 
+    
 
-    Select all datetime columns that have 'ns' precision:
+    Select all datetime columns that have NO timezone:
 
-    >>> df.select(cs.datetime("ns"))
+    >>> df.select(cs.datetime(time_zone=None))
     shape: (2, 1)
     
      tstamp                  
      ---                     
-     datetime[ns]            
+     datetime[s]            
     
      2000-11-20 18:12:16.600 
      2020-10-30 10:20:25.123 
     
 
     Select all columns *except* for datetime columns:
 
@@ -513,21 +601,36 @@
      ---        
      date       
     
      1999-12-31 
      2010-07-05 
     
 
-    """
-    datetime_dtypes = DATETIME_DTYPES if not time_unit else Datetime(time_unit)
+    """  # noqa: W505
+    if not time_unit or time_unit == "*":
+        time_unit = ["ms", "us", "ns"]
+    else:
+        time_unit = [time_unit] if isinstance(time_unit, str) else list(time_unit)
+
+    if time_zone is None:
+        time_zone = [None]
+    elif time_zone:
+        time_zone = (
+            [time_zone] if isinstance(time_zone, (str, timezone)) else list(time_zone)
+        )
+
+    datetime_dtypes = []
+    for tu in time_unit:
+        for tz in time_zone:  # type: ignore[union-attr]
+            datetime_dtypes.append(Datetime(tu, tz))
+
     return _selector_proxy_(
-        F.col(datetime_dtypes),  # type: ignore[arg-type]
+        F.col(datetime_dtypes),
         name="datetime",
-        parameters={"time_unit": time_unit},
-        raw_parameters=[datetime_dtypes],
+        parameters={"time_unit": time_unit, "time_zone": time_zone},
     )
 
 
 def ends_with(*suffix: str) -> Expr:
     """
     Select columns that end with the given substring(s).
 
@@ -597,15 +700,14 @@
     escaped_suffix = _re_string(suffix)
     raw_params = f"^.*{escaped_suffix}$"
 
     return _selector_proxy_(
         F.col(raw_params),
         name="ends_with",
         parameters={"*suffix": escaped_suffix},
-        raw_parameters=[raw_params],
     )
 
 
 def first() -> Expr:
     """
     Select the first column in the current scope.
 
@@ -691,15 +793,16 @@
     integer : Select all integer columns.
     numeric : Select all numeric columns.
     temporal : Select all temporal columns.
     string : Select all string columns.
 
     """
     return _selector_proxy_(
-        F.col(FLOAT_DTYPES), name="float", raw_parameters=[FLOAT_DTYPES]
+        F.col(FLOAT_DTYPES),
+        name="float",
     )
 
 
 def integer() -> Expr:
     """
     Select all integer columns.
 
@@ -747,15 +850,16 @@
     float : Select all float columns.
     numeric : Select all numeric columns.
     temporal : Select all temporal columns.
     string : Select all string columns.
 
     """
     return _selector_proxy_(
-        F.col(INTEGER_DTYPES), name="integer", raw_parameters=[INTEGER_DTYPES]
+        F.col(INTEGER_DTYPES),
+        name="integer",
     )
 
 
 def last() -> Expr:
     """
     Select the last column in the current scope.
 
@@ -860,15 +964,14 @@
         sfx = ".*$" if not pattern.endswith("$") else ""
         raw_params = f"{pfx}{pattern}{sfx}"
 
         return _selector_proxy_(
             F.col(raw_params),
             name="matches",
             parameters={"pattern": pattern},
-            raw_parameters=[raw_params],
         )
 
 
 def numeric() -> Expr:
     """
     Select all numeric columns.
 
@@ -917,15 +1020,16 @@
     float : Select all float columns.
     integer : Select all integer columns.
     temporal : Select all temporal columns.
     string : Select all string columns.
 
     """
     return _selector_proxy_(
-        F.col(NUMERIC_DTYPES), name="numeric", raw_parameters=[NUMERIC_DTYPES]
+        F.col(NUMERIC_DTYPES),
+        name="numeric",
     )
 
 
 def starts_with(*prefix: str) -> Expr:
     """
     Select columns that start with the given substring(s).
 
@@ -995,15 +1099,14 @@
     escaped_prefix = _re_string(prefix)
     raw_params = f"^{escaped_prefix}.*$"
 
     return _selector_proxy_(
         F.col(raw_params),
         name="starts_with",
         parameters={"*prefix": prefix},
-        raw_parameters=[raw_params],
     )
 
 
 def string(include_categorical: bool = False) -> Expr:
     """
     Select all Utf8 (and, optionally, Categorical) string columns.
 
@@ -1058,15 +1161,16 @@
 
     """
     string_dtypes: list[PolarsDataType] = [Utf8]
     if include_categorical:
         string_dtypes.append(Categorical)
 
     return _selector_proxy_(
-        F.col(string_dtypes), name="string", raw_parameters=[string_dtypes]
+        F.col(string_dtypes),
+        name="string",
     )
 
 
 def temporal() -> Expr:
     """
     Select all temporal columns.
 
@@ -1093,15 +1197,15 @@
     
      2021-01-01  12:00:00 
      2021-01-02  20:30:45 
     
 
     Match all temporal columns *except* for `Time` columns:
 
-    >>> df.select(cs.temporal().exclude(pl.Time))
+    >>> df.select(cs.temporal() - cs.by_dtype(pl.Time))
     shape: (2, 1)
     
      dt         
      ---        
      date       
     
      2021-01-01 
@@ -1127,15 +1231,16 @@
     float : Select all float columns.
     integer : Select all integer columns.
     numeric : Select all numeric columns.
     string : Select all string columns.
 
     """
     return _selector_proxy_(
-        F.col(TEMPORAL_DTYPES), name="temporal", raw_parameters=[TEMPORAL_DTYPES]
+        F.col(TEMPORAL_DTYPES),
+        name="temporal",
     )
 
 
 __all__ = [
     "all",
     "by_dtype",
     "by_name",
@@ -1147,8 +1252,11 @@
     "integer",
     "last",
     "matches",
     "numeric",
     "starts_with",
     "temporal",
     "string",
+    "is_selector",
+    "selector_column_names",
+    "SelectorType",
 ]
```

### Comparing `polars_lts_cpu-0.18.4/polars/series/_numpy.py` & `polars_lts_cpu-0.18.5/polars/series/_numpy.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/series/array.py` & `polars_lts_cpu-0.18.5/polars/series/array.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/series/categorical.py` & `polars_lts_cpu-0.18.5/polars/series/categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/series/datetime.py` & `polars_lts_cpu-0.18.5/polars/series/datetime.py`

 * *Files 2% similar despite different names*

```diff
@@ -1484,25 +1484,30 @@
 
             - 1ns   (1 nanosecond)
             - 1us   (1 microsecond)
             - 1ms   (1 millisecond)
             - 1s    (1 second)
             - 1m    (1 minute)
             - 1h    (1 hour)
-            - 1d    (1 day)
-            - 1w    (1 week)
+            - 1d    (1 calendar day)
+            - 1w    (1 calendar week)
             - 1mo   (1 calendar month)
             - 1q    (1 calendar quarter)
             - 1y    (1 calendar year)
             - 1i    (1 index count)
 
             Suffix with `"_saturating"` to indicate that dates too large for
             their month should saturate at the largest date
             (e.g. 2022-02-29 -> 2022-02-28) instead of erroring.
 
+            By "calendar day", we mean the corresponding time on the next day
+            (which may not be 24 hours, due to daylight savings). Similarly for
+            "calendar week", "calendar month", "calendar quarter", and
+            "calendar year".
+
         Returns
         -------
         Date/Datetime expression
 
         Examples
         --------
         >>> from datetime import datetime
@@ -1583,28 +1588,32 @@
 
         - 1ns # 1 nanosecond
         - 1us # 1 microsecond
         - 1ms # 1 millisecond
         - 1s  # 1 second
         - 1m  # 1 minute
         - 1h  # 1 hour
-        - 1d  # 1 day
+        - 1d  # 1 calendar day
         - 1w  # 1 calendar week
         - 1mo # 1 calendar month
         - 1q  # 1 calendar quarter
         - 1y  # 1 calendar year
 
         These strings can be combined:
 
         - 3d12h4m25s # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         Returns
         -------
         Date/Datetime series
 
         Examples
         --------
         >>> from datetime import timedelta, datetime
@@ -1690,28 +1699,32 @@
 
         - 1ns # 1 nanosecond
         - 1us # 1 microsecond
         - 1ms # 1 millisecond
         - 1s  # 1 second
         - 1m  # 1 minute
         - 1h  # 1 hour
-        - 1d  # 1 day
+        - 1d  # 1 calendar day
         - 1w  # 1 calendar week
         - 1mo # 1 calendar month
         - 1q  # 1 calendar quarter
         - 1y  # 1 calendar year
 
         These strings can be combined:
 
         - 3d12h4m25s # 3 days, 12 hours, 4 minutes, and 25 seconds
 
         Suffix with `"_saturating"` to indicate that dates too large for
         their month should saturate at the largest date (e.g. 2022-02-29 -> 2022-02-28)
         instead of erroring.
 
+        By "calendar day", we mean the corresponding time on the next day (which may
+        not be 24 hours, due to daylight savings). Similarly for "calendar week",
+        "calendar month", "calendar quarter", and "calendar year".
+
         Parameters
         ----------
         every
             Every interval start and period length
         offset
             Offset the window
 
@@ -1812,15 +1825,15 @@
 
     def month_start(self) -> Series:
         """
         Roll backward to the first day of the month.
 
         Returns
         -------
-        Date/Datetime expression
+        Date/Datetime series
 
         Notes
         -----
         If you're coming from pandas, you can think of this as a vectorised version
         of ``pandas.tseries.offsets.MonthBegin().rollback(datetime)``.
 
         Examples
@@ -1842,15 +1855,15 @@
 
     def month_end(self) -> Series:
         """
         Roll forward to the last day of the month.
 
         Returns
         -------
-        Date/Datetime expression
+        Date/Datetime series.
 
         Notes
         -----
         If you're coming from pandas, you can think of this as a vectorised version
         of ``pandas.tseries.offsets.MonthEnd().rollforward(datetime)``.
 
         Examples
@@ -1865,7 +1878,86 @@
         [
                 2000-01-31 02:00:00
                 2000-02-29 02:00:00
                 2000-03-31 02:00:00
                 2000-04-30 02:00:00
         ]
         """
+
+    def base_utc_offset(self) -> Series:
+        """
+        Base offset from UTC.
+
+        This is usually constant for all datetimes in a given time zone, but
+        may vary in the rare case that a country switches time zone, like
+        Samoa (Apia) did at the end of 2011.
+
+        Returns
+        -------
+        Duration Series
+
+        See Also
+        --------
+        Series.dt.dst_offset : Additional offset currently in effect.
+
+        Examples
+        --------
+        >>> from datetime import datetime
+        >>> ser = pl.date_range(
+        ...     datetime(2011, 12, 29),
+        ...     datetime(2012, 1, 1),
+        ...     "2d",
+        ...     time_zone="Pacific/Apia",
+        ...     eager=True,
+        ... )
+        >>> ser
+        shape: (2,)
+        Series: 'date' [datetime[s, Pacific/Apia]]
+        [
+                2011-12-29 00:00:00 -10
+                2011-12-31 00:00:00 +14
+        ]
+        >>> ser.dt.base_utc_offset().rename("base_utc_offset")
+        shape: (2,)
+        Series: 'base_utc_offset' [duration[ms]]
+        [
+                -11h
+                13h
+        ]
+        """
+
+    def dst_offset(self) -> Series:
+        """
+        Additional offset currently in effect (typically due to daylight saving time).
+
+        Returns
+        -------
+        Duration Series
+
+        See Also
+        --------
+        Series.dt.base_utc_offset : Base offset from UTC.
+
+        Examples
+        --------
+        >>> from datetime import datetime
+        >>> ser = pl.date_range(
+        ...     datetime(2020, 10, 25),
+        ...     datetime(2020, 10, 26),
+        ...     time_zone="Europe/London",
+        ...     eager=True,
+        ... )
+        >>> ser
+        shape: (2,)
+        Series: 'date' [datetime[s, Europe/London]]
+        [
+                2020-10-25 00:00:00 BST
+                2020-10-26 00:00:00 GMT
+        ]
+        >>> ser.dt.dst_offset().rename("dst_offset")
+        shape: (2,)
+        Series: 'dst_offset' [duration[ms]]
+        [
+                1h
+                0ms
+        ]
+        """
```

### Comparing `polars_lts_cpu-0.18.4/polars/series/list.py` & `polars_lts_cpu-0.18.5/polars/series/list.py`

 * *Files 20% similar despite different names*

```diff
@@ -20,14 +20,66 @@
     """Namespace for list related methods."""
 
     _accessor = "list"
 
     def __init__(self, series: Series):
         self._s: PySeries = series._s
 
+    def all(self) -> Expr:
+        """
+        Evaluate whether all boolean values in a list are true.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {"a": [[True, True], [False, True], [False, False], [None], [], None]}
+        ... )
+        >>> df.select(pl.col("a").list.all())
+        shape: (6, 1)
+        
+         a     
+         ---   
+         bool  
+        
+         true  
+         false 
+         false 
+         false 
+         true  
+         null  
+        
+
+        """
+
+    def any(self) -> Expr:
+        """
+        Evaluate whether any boolean value in a list is true.
+
+        Examples
+        --------
+        >>> df = pl.DataFrame(
+        ...     {"a": [[True, True], [False, True], [False, False], [None], [], None]}
+        ... )
+        >>> df.select(pl.col("a").list.any())
+        shape: (6, 1)
+        
+         a     
+         ---   
+         bool  
+        
+         true  
+         true  
+         false 
+         false 
+         false 
+         null  
+        
+
+        """
+
     def lengths(self) -> Series:
         """
         Get the length of the arrays as UInt32.
 
         Examples
         --------
         >>> s = pl.Series([[1, 2, 3], [5]])
@@ -493,7 +545,97 @@
         
          1    4    [1.0, 2.0] 
          8    5    [2.0, 1.0] 
          3    2    [2.0, 1.0] 
         
 
         """
+
+    def union(self, other: Series) -> Series:
+        """
+        Compute the SET UNION between the elements in this list and the elements of ``other``.
+
+        Parameters
+        ----------
+        other
+            Right hand side of the set operation.
+
+        Examples
+        --------
+        >>> a = pl.Series([[1, 2, 3], [], [None, 3], [5, 6, 7]])
+        >>> b = pl.Series([[2, 3, 4], [3], [3, 4, None], [6, 8]])
+        >>> a.list.union(b)  # doctest: +IGNORE_RESULT
+        shape: (4,)
+        Series: '' [list[i64]]
+        [
+                [1, 2, 3, 4]
+                [3]
+                [null, 3, 4]
+                [5, 6, 7, 8]
+        ]
+
+        """  # noqa: W505.
+
+    def difference(self, other: Series) -> Series:
+        """
+        Compute the SET DIFFERENCE between the elements in this list and the elements of ``other``.
+
+        Parameters
+        ----------
+        other
+            Right hand side of the set operation.
+
+        Examples
+        --------
+        >>> a = pl.Series([[1, 2, 3], [], [None, 3], [5, 6, 7]])
+        >>> b = pl.Series([[2, 3, 4], [3], [3, 4, None], [6, 8]])
+        >>> a.list.difference(b)
+        shape: (4,)
+        Series: '' [list[i64]]
+        [
+                [1]
+                []
+                []
+                [5, 7]
+        ]
+
+        See Also
+        --------
+        polars.Series.list.diff: Calculates the n-th discrete difference of every sublist.
+
+        """  # noqa: W505.
+
+    def intersection(self, other: Series) -> Series:
+        """
+        Compute the SET INTERSECTION between the elements in this list and the elements of ``other``.
+
+        Parameters
+        ----------
+        other
+            Right hand side of the set operation.
+
+        Examples
+        --------
+        >>> a = pl.Series([[1, 2, 3], [], [None, 3], [5, 6, 7]])
+        >>> b = pl.Series([[2, 3, 4], [3], [3, 4, None], [6, 8]])
+        >>> a.list.intersection(b)
+        shape: (4,)
+        Series: '' [list[i64]]
+        [
+                [2, 3]
+                []
+                [3, null]
+                [6]
+        ]
+
+        """  # noqa: W505.
+
+    def symmetric_difference(self, other: Series) -> Series:
+        """
+        Compute the SET SYMMETRIC DIFFERENCE between the elements in this list and the elements of ``other``.
+
+        Parameters
+        ----------
+        other
+            Right hand side of the set operation.
+
+        """  # noqa: W505.
```

### Comparing `polars_lts_cpu-0.18.4/polars/series/series.py` & `polars_lts_cpu-0.18.5/polars/series/series.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 from __future__ import annotations
 
 import contextlib
 import math
 import os
-import typing
 import warnings
 from datetime import date, datetime, time, timedelta
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
+    ClassVar,
     Collection,
     Generator,
     Iterable,
     NoReturn,
     Sequence,
     Union,
     overload,
@@ -214,15 +214,23 @@
             2
             3
     ]
 
     """
 
     _s: PySeries = None
-    _accessors: set[str] = {"arr", "cat", "dt", "list", "str", "bin", "struct"}
+    _accessors: ClassVar[set[str]] = {
+        "arr",
+        "cat",
+        "dt",
+        "list",
+        "str",
+        "bin",
+        "struct",
+    }
 
     def __init__(
         self,
         name: str | ArrayLike | None = None,
         values: ArrayLike | None = None,
         dtype: PolarsDataType | None = None,
         *,
@@ -323,15 +331,15 @@
         """Construct a Series from an Arrow Array."""
         return cls._from_pyseries(arrow_to_pyseries(name, values, rechunk))
 
     @classmethod
     def _from_pandas(
         cls,
         name: str,
-        values: pd.Series | pd.DatetimeIndex,
+        values: pd.Series[Any] | pd.DatetimeIndex,
         *,
         nan_to_null: bool = True,
     ) -> Self:
         """Construct a Series from a pandas Series or DatetimeIndex."""
         return cls._from_pyseries(
             pandas_to_pyseries(name, values, nan_to_null=nan_to_null)
         )
@@ -719,21 +727,28 @@
 
         # this branch is exactly the floordiv function without rounding the floats
         if self.is_float() or self.dtype == Decimal:
             return self._arithmetic(other, "div", "div_<>")
 
         return self.cast(Float64) / other
 
-    # python 3.7 is not happy. Remove this when we finally ditch that
-    @typing.no_type_check
+    @overload
+    def __floordiv__(self, other: Expr) -> Expr:  # type: ignore[misc]
+        ...
+
+    @overload
     def __floordiv__(self, other: Any) -> Series:
+        ...
+
+    def __floordiv__(self, other: Any) -> Series | Expr:
         if isinstance(other, pl.Expr):
-            return F.lit(self).__floordiv__(other)
+            return F.lit(self) // other
         if self.is_temporal():
             raise ValueError("first cast to integer before dividing datelike dtypes")
+
         if not isinstance(other, pl.Expr):
             other = F.lit(other)
         return self.to_frame().select(F.col(self.name) // other).to_series()
 
     def __invert__(self) -> Self:
         if self.dtype == Boolean:
             return self._from_pyseries(self._s._not())
@@ -1586,35 +1601,41 @@
         self,
         bins: list[float],
         labels: list[str] | None = None,
         break_point_label: str = "break_point",
         category_label: str = "category",
         *,
         maintain_order: bool = False,
-    ) -> DataFrame:
+        series: bool = False,
+        left_closed: bool = False,
+    ) -> DataFrame | Series:
         """
-        Bin values into discrete values.
+        Bin continuous values into discrete categories.
 
         Parameters
         ----------
         bins
             Bins to create.
         labels
             Labels to assign to the bins. If given the length of labels must be
             len(bins) + 1.
         break_point_label
-            Name given to the breakpoint column.
+            Name given to the breakpoint column. Only used if series == False
         category_label
-            Name given to the category column.
+            Name given to the category column. Only used if series == False
         maintain_order
-            Keep the order of the original `Series`.
+            Keep the order of the original `Series`. Only used if series == False
+        series
+            If True, return the a categorical series in the data's original order
+        left_closed
+            Whether intervals should be [) instead of (]
 
         Returns
         -------
-        DataFrame
+        DataFrame or Series
 
         Examples
         --------
         >>> a = pl.Series("a", [v / 10 for v in range(-30, 30, 5)])
         >>> a.cut([-1, 1])
         shape: (12, 3)
         
@@ -1630,14 +1651,20 @@
          1.0   1.0          (-1.0, 1.0]  
          1.5   inf          (1.0, inf]   
          2.0   inf          (1.0, inf]   
          2.5   inf          (1.0, inf]   
         
 
         """
+        if series:
+            return (
+                self.to_frame()
+                .select(F.col(self._s.name()).cut(bins, labels, left_closed))
+                .to_series()
+            )
         return wrap_df(
             self._s.cut(
                 Series(break_point_label, bins, dtype=Float64)._s,
                 labels,
                 break_point_label,
                 category_label,
                 maintain_order,
@@ -1648,17 +1675,20 @@
         self,
         quantiles: list[float],
         *,
         labels: list[str] | None = None,
         break_point_label: str = "break_point",
         category_label: str = "category",
         maintain_order: bool = False,
-    ) -> DataFrame:
+        series: bool = False,
+        left_closed: bool = False,
+        allow_duplicates: bool = False,
+    ) -> DataFrame | Series:
         """
-        Bin values into discrete values based on their quantiles.
+        Bin continuous values into discrete categories based on their quantiles.
 
         Parameters
         ----------
         quantiles
             List of quantiles to create.
             We expect quantiles ``0.0 <= quantile <= 1``
         labels
@@ -1666,18 +1696,26 @@
             len(bins) + 1.
         break_point_label
             Name given to the breakpoint column.
         category_label
             Name given to the category column.
         maintain_order
             Keep the order of the original `Series`.
+        series
+            If True, return the a categorical series in the data's original order
+        left_closed
+            Whether intervals should be [) instead of (]
+        allow_duplicates
+            If True, the resulting quantile breaks don't have to be unique. This can
+            happen even with unique probs depending on the data. Duplicates will be
+            dropped, resulting in fewer bins.
 
         Returns
         -------
-        DataFrame
+        DataFrame or Series
 
         Warnings
         --------
         This functionality is experimental and may change without it being considered a
         breaking change.
 
         Examples
@@ -1697,14 +1735,24 @@
          -1.0  0.25         (-3.25, 0.25] 
          0.0   0.25         (-3.25, 0.25] 
          1.0   inf          (0.25, inf]   
          2.0   inf          (0.25, inf]   
         
 
         """
+        if series:
+            return (
+                self.to_frame()
+                .select(
+                    F.col(self._s.name()).qcut(
+                        quantiles, labels, left_closed, allow_duplicates
+                    )
+                )
+                .to_series()
+            )
         return wrap_df(
             self._s.qcut(
                 Series(quantiles, dtype=Float64)._s,
                 labels,
                 break_point_label,
                 category_label,
                 maintain_order,
@@ -2898,16 +2946,16 @@
 
         Returns
         -------
         Exploded Series of same dtype
 
         See Also
         --------
-        ListNameSpace.explode : Explode a list column.
-        StringNameSpace.explode : Explode a string column.
+        Series.list.explode : Explode a list column.
+        Series.str.explode : Explode a string column.
 
         """
 
     def series_equal(
         self, other: Series, *, null_equal: bool = True, strict: bool = False
     ) -> bool:
         """
@@ -3408,15 +3456,15 @@
         ]
 
         """
         return self._s.to_arrow()
 
     def to_pandas(  # noqa: D417
         self, *args: Any, use_pyarrow_extension_array: bool = False, **kwargs: Any
-    ) -> pd.Series:
+    ) -> pd.Series[Any]:
         """
         Convert this Series to a pandas Series.
 
         This requires that :mod:`pandas` and :mod:`pyarrow` are installed.
         This operation clones data, unless `use_pyarrow_extension_array=True`.
 
         Parameters
@@ -5551,15 +5599,15 @@
         Series
             If a single dimension is given, results in a flat Series of shape (len,).
             If a multiple dimensions are given, results in a Series of Lists with shape
             (rows, cols).
 
         See Also
         --------
-        ListNameSpace.explode : Explode a list column.
+        Series.list.explode : Explode a list column.
 
         Examples
         --------
         >>> s = pl.Series("foo", [1, 2, 3, 4, 5, 6, 7, 8, 9])
         >>> s.reshape((3, 3))
         shape: (3,)
         Series: 'foo' [list[i64]]
@@ -5590,14 +5638,23 @@
         [
                 2
                 1
                 3
         ]
 
         """
+        return (
+            self.to_frame()
+            .select(
+                F.col(self.name).shuffle(
+                    seed=seed,
+                )
+            )
+            .to_series()
+        )
 
     def ewm_mean(
         self,
         com: float | None = None,
         span: float | None = None,
         half_life: float | None = None,
         alpha: float | None = None,
```

### Comparing `polars_lts_cpu-0.18.4/polars/series/string.py` & `polars_lts_cpu-0.18.5/polars/series/string.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/series/struct.py` & `polars_lts_cpu-0.18.5/polars/series/struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/series/utils.py` & `polars_lts_cpu-0.18.5/polars/series/utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/slice.py` & `polars_lts_cpu-0.18.5/polars/slice.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/sql/context.py` & `polars_lts_cpu-0.18.5/polars/sql/context.py`

 * *Files 1% similar despite different names*

```diff
@@ -18,19 +18,15 @@
 
 with contextlib.suppress(ImportError):  # Module not available when building docs
     from polars.polars import PySQLContext
 
 if TYPE_CHECKING:
     import sys
     from types import TracebackType
-
-    if sys.version_info >= (3, 8):
-        from typing import Final, Literal
-    else:
-        from typing_extensions import Final, Literal
+    from typing import Final, Literal
 
     if sys.version_info >= (3, 11):
         from typing import Self
     else:
         from typing_extensions import Self
 
 
@@ -167,15 +163,15 @@
         return f"<SQLContext [tables:{n_tables}] at 0x{id(self):x}>"
 
     # these overloads are necessary to cover the possible permutations
     # of the init-time "eager_execution" param, and the "eager" param.
 
     @overload
     def execute(
-        self: SQLContext[DataFrame], query: str, eager: Literal[None] = None
+        self: SQLContext[DataFrame], query: str, eager: None = ...
     ) -> DataFrame:
         ...
 
     @overload
     def execute(
         self: SQLContext[DataFrame], query: str, eager: Literal[False]
     ) -> LazyFrame:
@@ -185,15 +181,15 @@
     def execute(
         self: SQLContext[DataFrame], query: str, eager: Literal[True]
     ) -> DataFrame:
         ...
 
     @overload
     def execute(
-        self: SQLContext[LazyFrame], query: str, eager: Literal[None] = None
+        self: SQLContext[LazyFrame], query: str, eager: None = ...
     ) -> LazyFrame:
         ...
 
     @overload
     def execute(
         self: SQLContext[LazyFrame], query: str, eager: Literal[False]
     ) -> LazyFrame:
```

### Comparing `polars_lts_cpu-0.18.4/polars/string_cache.py` & `polars_lts_cpu-0.18.5/polars/string_cache.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/testing/_private.py` & `polars_lts_cpu-0.18.5/polars/testing/_private.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/testing/asserts.py` & `polars_lts_cpu-0.18.5/polars/testing/asserts.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/testing/parametric/__init__.py` & `polars_lts_cpu-0.18.5/polars/testing/parametric/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/testing/parametric/primitives.py` & `polars_lts_cpu-0.18.5/polars/testing/parametric/primitives.py`

 * *Files 1% similar despite different names*

```diff
@@ -37,26 +37,21 @@
     all_strategies,
     between,
     create_list_strategy,
     scalar_strategies,
 )
 
 if TYPE_CHECKING:
-    import sys
+    from typing import Literal
 
     from hypothesis.strategies import DrawFn, SearchStrategy
 
     from polars import LazyFrame
     from polars.type_aliases import OneOrMoreDataTypes, PolarsDataType
 
-    if sys.version_info >= (3, 8):
-        from typing import Literal
-    else:
-        from typing_extensions import Literal
-
 
 _time_units = list(DTYPE_TEMPORAL_UNITS)
 
 
 def empty_list(value: Any, nested: bool) -> bool:
     """Check if value is an empty list, or a list that contains only empty lists."""
     if isinstance(value, list):
@@ -168,14 +163,15 @@
                                 if e is not None and not empty_list(e, nested=True)
                             )
                         )
                     except StopIteration:
                         raise InvalidArgument(
                             "Unable to determine dtype for strategy"
                         ) from None
+
                 if sample_value_type is not None:
                     value_dtype = py_type_to_dtype(sample_value_type)
                     if value_dtype is not List:
                         self.dtype = value_dtype
 
 
 def columns(
@@ -647,15 +643,15 @@
                 coldefs = columns(cols=n, dtype=dtypes_)
             elif isinstance(cols, column):
                 coldefs = [cols]
             else:
                 coldefs = list(cols)
 
             # append any explicitly provided cols
-            coldefs.extend(include_cols or ())  # type: ignore[arg-type]
+            coldefs.extend(include_cols or ())
 
             # assign dataframe/series size
             series_size = (
                 between(
                     draw, int, min_=(min_size or 0), max_=(max_size or MAX_DATA_SIZE)
                 )
                 if size is None
```

### Comparing `polars_lts_cpu-0.18.4/polars/testing/parametric/profiles.py` & `polars_lts_cpu-0.18.5/polars/testing/parametric/profiles.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from __future__ import annotations
 
 import os
 import re
-import sys
 
 from hypothesis import settings
 
 from polars.type_aliases import ParametricProfileNames
 
 
 def load_profile(
@@ -87,15 +86,15 @@
     >>> set_profile("balanced")
 
     """
     profile_name = str(profile).split(".")[-1]
     if profile_name.replace("_", "").isdigit():
         profile_name = str(int(profile_name))
 
-    elif sys.version_info >= (3, 8):
+    else:
         from typing import get_args
 
         valid_profile_names = get_args(ParametricProfileNames)
         if profile_name not in valid_profile_names:
             raise ValueError(
                 f"Invalid profile name {profile_name!r}; expected one of {valid_profile_names}!r"
             )
```

### Comparing `polars_lts_cpu-0.18.4/polars/testing/parametric/strategies.py` & `polars_lts_cpu-0.18.5/polars/testing/parametric/strategies.py`

 * *Files 3% similar despite different names*

```diff
@@ -24,14 +24,15 @@
     datetimes,
     decimals,
     floats,
     from_type,
     integers,
     lists,
     sampled_from,
+    sets,
     text,
     timedeltas,
     times,
 )
 
 from polars.datatypes import (
     Boolean,
@@ -126,14 +127,48 @@
             min_value=-(2**66),
             max_value=(2**66) - 1,
             places=places,
         )
     )
 
 
+@composite
+def strategy_datetime_format(draw: DrawFn) -> str:
+    """Draw a random datetime format string."""
+    fmt = draw(
+        sets(
+            sampled_from(
+                [
+                    "%m",
+                    "%b",
+                    "%B",
+                    "%d",
+                    "%j",
+                    "%a",
+                    "%A",
+                    "%w",
+                    "%H",
+                    "%I",
+                    "%p",
+                    "%M",
+                    "%S",
+                    "%U",
+                    "%W",
+                    "%%",
+                ]
+            ),
+        )
+    )
+
+    # Make sure year is always present
+    fmt.add("%Y")
+
+    return " ".join(fmt)
+
+
 class StrategyLookup(MutableMapping[PolarsDataType, SearchStrategy[Any]]):
     """
     Mapping from polars DataTypes to hypothesis Strategies.
 
     We customise this so that retrieval of nested strategies respects the inner dtype
     of List/Struct types; nested strategies are stored as callables that create the
     given strategy on demand (there are infinitely many possible nested dtypes).
@@ -222,14 +257,17 @@
         UInt32: strategy_u32,
         UInt64: strategy_u64,
         Time: strategy_time,
         Date: strategy_date,
         Datetime("ns"): strategy_datetime_ns,
         Datetime("us"): strategy_datetime_us,
         Datetime("ms"): strategy_datetime_ms,
+        # Datetime("ns", "*"): strategy_datetime_ns_tz,
+        # Datetime("us", "*"): strategy_datetime_us_tz,
+        # Datetime("ms", "*"): strategy_datetime_ms_tz,
         Datetime: strategy_datetime_us,
         Duration("ns"): strategy_duration,
         Duration("us"): strategy_duration,
         Duration("ms"): strategy_duration,
         Duration: strategy_duration,
         Categorical: strategy_categorical,
         Utf8: strategy_utf8,
```

### Comparing `polars_lts_cpu-0.18.4/polars/type_aliases.py` & `polars_lts_cpu-0.18.5/polars/type_aliases.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,47 +1,46 @@
 from __future__ import annotations
 
-import sys
 from datetime import date, datetime, time, timedelta
 from decimal import Decimal
 from typing import (
     TYPE_CHECKING,
     Any,
     Collection,
     Iterable,
     List,
+    Literal,
     Mapping,
     Sequence,
     Tuple,
     Type,
     TypeVar,
     Union,
 )
 
-if sys.version_info >= (3, 8):
-    from typing import Literal
-else:
-    from typing_extensions import Literal
-
 if TYPE_CHECKING:
+    import sys
+
     from polars import DataFrame, Expr, LazyFrame, Series
-    from polars.datatypes import DataType, DataTypeClass, TemporalType
+    from polars.datatypes import DataType, DataTypeClass, IntegralType, TemporalType
     from polars.dependencies import numpy as np
     from polars.dependencies import pandas as pd
     from polars.dependencies import pyarrow as pa
     from polars.functions.whenthen import WhenThen, WhenThenThen
+    from polars.selectors import _selector_proxy_
 
     if sys.version_info >= (3, 10):
         from typing import TypeAlias
     else:
         from typing_extensions import TypeAlias
 
 # Data types
 PolarsDataType: TypeAlias = Union["DataTypeClass", "DataType"]
 PolarsTemporalType: TypeAlias = Union[Type["TemporalType"], "TemporalType"]
+PolarsIntegerType: TypeAlias = Union[Type["IntegralType"], "IntegralType"]
 OneOrMoreDataTypes: TypeAlias = Union[PolarsDataType, Iterable[PolarsDataType]]
 PythonDataType: TypeAlias = Union[
     Type[int],
     Type[float],
     Type[bool],
     Type[str],
     Type[date],
@@ -69,23 +68,27 @@
 PythonLiteral: TypeAlias = Union[
     str, int, float, bool, date, time, datetime, timedelta, bytes, Decimal, List[Any]
 ]
 
 IntoExpr: TypeAlias = Union[PolarsExprType, PythonLiteral, "Series", None]
 ComparisonOperator: TypeAlias = Literal["eq", "neq", "gt", "lt", "gt_eq", "lt_eq"]
 
+# selector type
+SelectorType: TypeAlias = "_selector_proxy_"
+
 # User-facing string literal types
 # The following all have an equivalent Rust enum with the same name
 AvroCompression: TypeAlias = Literal["uncompressed", "snappy", "deflate"]
 CategoricalOrdering: TypeAlias = Literal["physical", "lexical"]
 CsvEncoding: TypeAlias = Literal["utf8", "utf8-lossy"]
 FillNullStrategy: TypeAlias = Literal[
     "forward", "backward", "min", "max", "mean", "zero", "one"
 ]
 FloatFmt: TypeAlias = Literal["full", "mixed"]
+IndexOrder: TypeAlias = Literal["c", "fortran"]
 IpcCompression: TypeAlias = Literal["uncompressed", "lz4", "zstd"]
 JoinValidation: TypeAlias = Literal["m:m", "m:1", "1:m", "1:1"]
 NullBehavior: TypeAlias = Literal["ignore", "drop"]
 NullStrategy: TypeAlias = Literal["ignore", "propagate"]
 ParallelStrategy: TypeAlias = Literal["auto", "columns", "row_groups", "none"]
 ParquetCompression: TypeAlias = Literal[
     "lz4", "uncompressed", "snappy", "gzip", "lzo", "brotli", "zstd"
```

### Comparing `polars_lts_cpu-0.18.4/polars/utils/__init__.py` & `polars_lts_cpu-0.18.5/polars/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/utils/_construction.py` & `polars_lts_cpu-0.18.5/polars/utils/_construction.py`

 * *Files 2% similar despite different names*

```diff
@@ -9,14 +9,15 @@
 from sys import version_info
 from typing import (
     TYPE_CHECKING,
     Any,
     Callable,
     Generator,
     Iterable,
+    Iterator,
     Mapping,
     MutableMapping,
     Sequence,
     get_type_hints,
 )
 
 import polars._reexport as pl
@@ -260,15 +261,15 @@
     values: Iterable[Any],
     dtype: PolarsDataType | None = None,
     strict: bool = True,
     dtype_if_empty: PolarsDataType | None = None,
     chunk_size: int = 1_000_000,
 ) -> PySeries:
     """Construct a PySeries from an iterable/generator."""
-    if not isinstance(values, Generator):
+    if not isinstance(values, (Generator, Iterator)):
         values = iter(values)
 
     def to_series_chunk(values: list[Any], dtype: PolarsDataType | None) -> Series:
         return pl.Series(
             name=name,
             values=values,
             dtype=dtype,
@@ -515,24 +516,24 @@
 
             return _construct_series_with_fallbacks(
                 constructor, name, values, dtype, strict
             )
 
 
 def _pandas_series_to_arrow(
-    values: pd.Series | pd.DatetimeIndex,
+    values: pd.Series[Any] | pd.Index,
     nan_to_null: bool = True,
     length: int | None = None,
 ) -> pa.Array:
     """
     Convert a pandas Series to an Arrow Array.
 
     Parameters
     ----------
-    values : :class:`pandas.Series` or :class:`pandas.DatetimeIndex`.
+    values : :class:`pandas.Series` or :class:`pandas.Index`.
         Series to convert to arrow
     nan_to_null : bool, default = True
         Interpret `NaN` as missing values.
     length : int, optional
         in case all values are null, create a null array of this length.
         if unset, length is inferred from values.
 
@@ -557,15 +558,15 @@
         raise ValueError(
             "Duplicate column names found: "
             + f"{values.columns.tolist()!s}"  # type: ignore[union-attr]
         )
 
 
 def pandas_to_pyseries(
-    name: str, values: pd.Series | pd.DatetimeIndex, nan_to_null: bool = True
+    name: str, values: pd.Series[Any] | pd.DatetimeIndex, nan_to_null: bool = True
 ) -> PySeries:
     """Construct a PySeries from a pandas Series or DatetimeIndex."""
     # TODO: Change `if not name` to `if name is not None` once name is Optional[str]
     if not name and values.name is not None:
         name = str(values.name)
     return arrow_to_pyseries(
         name, _pandas_series_to_arrow(values, nan_to_null=nan_to_null)
@@ -679,24 +680,42 @@
 
     return (
         column_names,  # type: ignore[return-value]
         column_dtypes,
     )
 
 
+def _expand_dict_data(
+    data: Mapping[str, Sequence[object] | Mapping[str, Sequence[object]] | Series],
+    dtypes: SchemaDict,
+) -> Mapping[str, Sequence[object] | Mapping[str, Sequence[object]] | Series]:
+    """
+    Expand any unsized generators/iterators.
+
+    (Note that `range` is sized, and will take a fast-path on Series init).
+    """
+    expanded_data = {}
+    for name, val in data.items():
+        expanded_data[name] = (
+            pl.Series(name, val, dtypes.get(name)) if _is_generator(val) else val
+        )
+    return expanded_data
+
+
 def _expand_dict_scalars(
     data: Mapping[str, Sequence[object] | Mapping[str, Sequence[object]] | Series],
     schema_overrides: SchemaDict | None = None,
     order: Sequence[str] | None = None,
     nan_to_null: bool = False,
 ) -> dict[str, Series]:
     """Expand any scalar values in dict data (propagate literal as array)."""
     updated_data = {}
     if data:
         dtypes = schema_overrides or {}
+        data = _expand_dict_data(data, dtypes)
         array_len = max((arrlen(val) or 0) for val in data.values())
         if array_len > 0:
             for name, val in data.items():
                 dtype = dtypes.get(name)
                 if isinstance(val, dict) and dtype != Struct:
                     updated_data[name] = pl.DataFrame(val).to_struct(name)
 
@@ -800,15 +819,21 @@
             s._s
             for s in _expand_dict_scalars(
                 data, schema_overrides, nan_to_null=nan_to_null
             ).values()
         ]
 
     data_series = _handle_columns_arg(data_series, columns=column_names, from_dict=True)
-    return PyDataFrame(data_series)
+    pydf = PyDataFrame(data_series)
+
+    if schema_overrides and pydf.dtypes() != list(schema_overrides.values()):
+        pydf = _post_apply_columns(
+            pydf, column_names, schema_overrides=schema_overrides
+        )
+    return pydf
 
 
 def sequence_to_pydf(
     data: Sequence[Any],
     schema: SchemaDefinition | None = None,
     schema_overrides: SchemaDict | None = None,
     orient: Orientation | None = None,
@@ -1032,17 +1057,17 @@
     dicts_schema = (
         include_unknowns(schema_overrides, column_names or list(schema_overrides))
         if schema_overrides and column_names
         else None
     )
     pydf = PyDataFrame.read_dicts(data, infer_schema_length, dicts_schema)
 
-    if column_names and set(column_names).intersection(pydf.columns()):
-        column_names = []
-    if column_names or schema_overrides:
+    if not schema_overrides and set(pydf.columns()) == set(column_names):
+        pass
+    elif column_names or schema_overrides:
         pydf = _post_apply_columns(
             pydf,
             columns=column_names,
             schema_overrides=schema_overrides,
         )
     return pydf
 
@@ -1074,15 +1099,15 @@
         if first_element.ndim == 1
         else _sequence_of_elements_to_pydf
     )
     return to_pydf(first_element, **kwargs)  # type: ignore[operator]
 
 
 def _sequence_of_pandas_to_pydf(
-    first_element: pd.Series | pd.DatetimeIndex,
+    first_element: pd.Series[Any] | pd.DatetimeIndex,
     data: Sequence[Any],
     schema: SchemaDefinition | None,
     schema_overrides: SchemaDict | None,
     **kwargs: Any,
 ) -> PyDataFrame:
     if schema is None:
         column_names: list[str] = []
```

### Comparing `polars_lts_cpu-0.18.4/polars/utils/_parse_expr_input.py` & `polars_lts_cpu-0.18.5/polars/utils/_parse_expr_input.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/utils/_scan.py` & `polars_lts_cpu-0.18.5/polars/utils/_scan.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/utils/_wrap.py` & `polars_lts_cpu-0.18.5/polars/utils/_wrap.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/utils/build_info.py` & `polars_lts_cpu-0.18.5/polars/utils/build_info.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/utils/convert.py` & `polars_lts_cpu-0.18.5/polars/utils/convert.py`

 * *Files 3% similar despite different names*

```diff
@@ -42,14 +42,25 @@
 
 # note: reversed views don't match as instances of MappingView
 if sys.version_info >= (3, 11):
     _views: list[Reversible[Any]] = [{}.keys(), {}.values(), {}.items()]
     _reverse_mapping_views = tuple(type(reversed(view)) for view in _views)
 
 
+EPOCH = datetime(1970, 1, 1).replace(tzinfo=None)
+EPOCH_UTC = datetime(1970, 1, 1, tzinfo=timezone.utc)
+
+_fromtimestamp = datetime.fromtimestamp
+
+
+def _timestamp_in_seconds(dt: datetime) -> int:
+    du = dt - EPOCH_UTC
+    return du.days * 86400 + du.seconds
+
+
 @overload
 def _timedelta_to_pl_duration(td: None) -> None:
     ...
 
 
 @overload
 def _timedelta_to_pl_duration(td: timedelta | str) -> str:
@@ -78,24 +89,24 @@
                 us = td.microseconds and f"{10**6 - td.microseconds}us" or ""
 
         return f"{d}{s}{us}"
 
 
 def _datetime_to_pl_timestamp(dt: datetime, time_unit: TimeUnit | None) -> int:
     """Convert a python datetime to a timestamp in nanoseconds."""
-    dt = dt.replace(tzinfo=timezone.utc)
+    dt = dt.replace(tzinfo=timezone.utc) if dt.tzinfo != timezone.utc else dt
     if time_unit == "ns":
         micros = dt.microsecond
-        return 1_000 * (int(dt.replace(microsecond=0).timestamp() * 1_000_000) + micros)
+        return 1_000 * (_timestamp_in_seconds(dt) * 1_000_000 + micros)
     elif time_unit == "us" or time_unit is None:
         micros = dt.microsecond
-        return int(dt.replace(microsecond=0).timestamp() * 1_000_000) + micros
+        return _timestamp_in_seconds(dt) * 1_000_000 + micros
     elif time_unit == "ms":
         millis = dt.microsecond // 1000
-        return int(dt.replace(microsecond=0).timestamp() * 1_000) + millis
+        return _timestamp_in_seconds(dt) * 1_000 + millis
     else:
         raise ValueError(
             f"time_unit must be one of {{'ns', 'us', 'ms'}}, got {time_unit}"
         )
 
 
 def _time_to_pl_time(t: time) -> int:
@@ -146,20 +157,14 @@
         return timedelta(milliseconds=value)
     else:
         raise ValueError(
             f"time_unit must be one of {{'ns', 'us', 'ms'}}, got {time_unit}"
         )
 
 
-EPOCH = datetime(1970, 1, 1).replace(tzinfo=None)
-EPOCH_UTC = datetime(1970, 1, 1, tzinfo=timezone.utc)
-
-_fromtimestamp = datetime.fromtimestamp
-
-
 @lru_cache(256)
 def _to_python_date(value: int | float) -> date:
     """Convert polars int64 timestamp to Python date."""
     return (EPOCH_UTC + timedelta(seconds=value * 86400)).date()
 
 
 def _to_python_datetime(
@@ -205,19 +210,14 @@
     except zoneinfo.ZoneInfoNotFoundError:
         # try fixed offset, which is not supported by ZoneInfo
         _tzinfo = _parse_fixed_tz_offset(time_zone)
 
     return dt.astimezone(_tzinfo)
 
 
-def _timestamp_in_seconds(dt: datetime) -> int:
-    du = dt - EPOCH_UTC
-    return du.days * 86400 + du.seconds
-
-
 def _datetime_for_anyvalue(dt: datetime) -> tuple[int, int]:
     """Used in pyo3 anyvalue conversion."""
     # returns (s, ms)
     if dt.tzinfo is None:
         return (
             _timestamp_in_seconds(dt.replace(tzinfo=timezone.utc)),
             dt.microsecond,
```

### Comparing `polars_lts_cpu-0.18.4/polars/utils/decorators.py` & `polars_lts_cpu-0.18.5/polars/utils/decorators.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/utils/meta.py` & `polars_lts_cpu-0.18.5/polars/utils/meta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/utils/polars_version.py` & `polars_lts_cpu-0.18.5/polars/utils/polars_version.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/polars/utils/show_versions.py` & `polars_lts_cpu-0.18.5/polars/utils/show_versions.py`

 * *Files 12% similar despite different names*

```diff
@@ -54,41 +54,39 @@
     for name, v in deps.items():
         print(f"{name:{keylen}s} {v}")
 
 
 def _get_dependency_info() -> dict[str, str]:
     # see the list of dependencies in pyproject.toml
     opt_deps = [
-        "numpy",
-        "pandas",
-        "pyarrow",
+        "adbc_driver_sqlite",
         "connectorx",
         "deltalake",
         "fsspec",
         "matplotlib",
+        "numpy",
+        "pandas",
+        "pyarrow",
+        "pydantic",
+        "sqlalchemy",
         "xlsx2csv",
         "xlsxwriter",
     ]
     return {f"{name}:": _get_dependency_version(name) for name in opt_deps}
 
 
 def _get_dependency_version(dep_name: str) -> str:
     # note: we import 'importlib' here as a significiant optimisation for initial import
     import importlib
+    import importlib.metadata
 
-    if sys.version_info >= (3, 8):
-        # importlib.metadata was introduced in Python 3.8;
-        # metadata submodule must be imported explicitly
-        import importlib.metadata
     try:
         module = importlib.import_module(dep_name)
     except ImportError:
         return "<not installed>"
 
     if hasattr(module, "__version__"):
         module_version = module.__version__
-    elif sys.version_info >= (3, 8):
-        module_version = importlib.metadata.version(dep_name)
     else:
-        module_version = "<version not detected>"
+        module_version = importlib.metadata.version(dep_name)
 
     return module_version
```

### Comparing `polars_lts_cpu-0.18.4/polars/utils/various.py` & `polars_lts_cpu-0.18.5/polars/utils/various.py`

 * *Files 3% similar despite different names*

```diff
@@ -2,33 +2,30 @@
 
 import inspect
 import os
 import re
 import sys
 from collections.abc import MappingView, Sized
 from enum import Enum
-from typing import TYPE_CHECKING, Any, Generator, Iterable, Sequence, TypeVar
+from typing import TYPE_CHECKING, Any, Generator, Iterable, Literal, Sequence, TypeVar
 
 import polars as pl
 from polars import functions as F
 from polars.datatypes import (
     Boolean,
     Date,
     Datetime,
     Duration,
     Int64,
     Time,
     Utf8,
     is_polars_dtype,
+    unpack_dtypes,
 )
-
-if sys.version_info >= (3, 8):
-    from typing import Literal
-else:
-    from typing_extensions import Literal
+from polars.dependencies import _PYARROW_AVAILABLE
 
 if TYPE_CHECKING:
     from collections.abc import Reversible
     from pathlib import Path
 
     from polars import DataFrame, Series
     from polars.type_aliases import PolarsDataType, SizeUnit
@@ -172,14 +169,26 @@
     """Return length of (non-string) sequence object; returns None for non-sequences."""
     try:
         return None if isinstance(obj, str) else len(obj)
     except TypeError:
         return None
 
 
+def can_create_dicts_with_pyarrow(dtypes: Sequence[PolarsDataType]) -> bool:
+    """Check if the given dtypes can be used to create dicts with pyarrow fast path."""
+    # TODO: have our own fast-path for dict iteration in Rust
+    return (
+        _PYARROW_AVAILABLE
+        # note: 'ns' precision instantiates values as pandas types - avoid
+        and not any(
+            (getattr(tp, "time_unit", None) == "ns") for tp in unpack_dtypes(*dtypes)
+        )
+    )
+
+
 def normalise_filepath(path: str | Path, check_not_directory: bool = True) -> str:
     """Create a string path, expanding the home directory if present."""
     path = os.path.expanduser(path)
     if check_not_directory and os.path.exists(path) and os.path.isdir(path):
         raise IsADirectoryError(f"Expected a file path; {path!r} is a directory")
     return path
```

### Comparing `polars_lts_cpu-0.18.4/pyproject.toml` & `polars_lts_cpu-0.18.5/pyproject.toml`

 * *Files 6% similar despite different names*

```diff
@@ -1,34 +1,31 @@
 [build-system]
-requires = ["maturin>=1.0,<1.1"]
+requires = ["maturin>=1.1,<1.2"]
 build-backend = "maturin"
 
 [project]
 name = "polars-lts-cpu"
 description = "Blazingly fast DataFrame library"
 readme = "README.md"
 authors = [
   { name = "Ritchie Vink", email = "ritchie46@gmail.com" },
 ]
 license = { file = "LICENSE" }
-requires-python = ">=3.7"
-dependencies = [
-  "typing_extensions >= 4.0.1; python_version < '3.8'",
-]
+requires-python = ">=3.8"
+
 keywords = ["dataframe", "arrow", "out-of-core"]
 classifiers = [
   "Development Status :: 5 - Production/Stable",
   "Environment :: Console",
   "Intended Audience :: Science/Research",
   "License :: OSI Approved :: MIT License",
   "Operating System :: OS Independent",
   "Programming Language :: Python",
   "Programming Language :: Python :: 3",
   "Programming Language :: Python :: 3 :: Only",
-  "Programming Language :: Python :: 3.7",
   "Programming Language :: Python :: 3.8",
   "Programming Language :: Python :: 3.9",
   "Programming Language :: Python :: 3.10",
   "Programming Language :: Python :: 3.11",
   "Programming Language :: Rust",
   "Topic :: Scientific/Engineering",
 ]
@@ -36,28 +33,30 @@
 [project.urls]
 Homepage = "https://www.pola.rs/"
 Documentation = "https://pola-rs.github.io/polars/py-polars/html/reference/index.html"
 Repository = "https://github.com/pola-rs/polars"
 Changelog = "https://github.com/pola-rs/polars/releases"
 
 [project.optional-dependencies]
-# NOTE: keep this list in sync with show_versions()
+# NOTE: keep this list in sync with show_versions() and requirements-dev.txt
 pyarrow = ["pyarrow>=7.0.0"]
 pandas = ["pyarrow>=7.0.0", "pandas"]
 numpy = ["numpy >= 1.16.0"]
 fsspec = ["fsspec"]
 connectorx = ["connectorx"]
 xlsx2csv = ["xlsx2csv >= 0.8.0"]
-deltalake = ["deltalake >= 0.8.0"]
+deltalake = ["deltalake >= 0.10.0"]
 timezone = ["backports.zoneinfo; python_version < '3.9'", "tzdata; platform_system == 'Windows'"]
 matplotlib = ["matplotlib"]
+pydantic = ["pydantic"]
 sqlalchemy = ["sqlalchemy", "pandas"]
 xlsxwriter = ["xlsxwriter"]
+adbc = ["adbc_driver_sqlite"]
 all = [
-  "polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter]",
+  "polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,pydantic,sqlalchemy,xlsxwriter,adbc]",
 ]
 
 [tool.mypy]
 files = ["polars", "tests"]
 strict = true
 enable_error_code = [
   "redundant-expr",
@@ -67,14 +66,16 @@
 disable_error_code = [
   "empty-body",
 ]
 
 [[tool.mypy.overrides]]
 module = [
   "IPython.*",
+  "adbc_driver_postgresql.*",
+  "adbc_driver_sqlite.*",
   "backports",
   "connectorx",
   "deltalake.*",
   "fsspec.*",
   "matplotlib.*",
   "polars.polars",
   "pyarrow.*",
```

### Comparing `polars_lts_cpu-0.18.4/requirements-dev.txt` & `polars_lts_cpu-0.18.5/requirements-dev.txt`

 * *Files 14% similar despite different names*

```diff
@@ -14,15 +14,16 @@
 tzdata; platform_system == 'Windows'
 xlsx2csv
 XlsxWriter
 adbc_driver_sqlite; python_version >= '3.9' and platform_system != 'Windows'
 connectorx==0.3.2a5; python_version >= '3.8'  # Latest full release is broken - unpin when 0.3.2 released
 
 # Tooling
-hypothesis==6.75.1
-maturin==1.0.1
-pytest==7.3.0
+hypothesis==6.79.4; python_version < '3.8'
+hypothesis==6.80.0; python_version >= '3.8'
+maturin==1.1.0
+pytest==7.4.0
 pytest-cov==4.1.0
 pytest-xdist==3.3.1
 
 # Stub files
-pandas-stubs==1.2.0.62
+pandas-stubs
```

### Comparing `polars_lts_cpu-0.18.4/scripts/check_stacklevels.py` & `polars_lts_cpu-0.18.5/scripts/check_stacklevels.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/apply/lazy.rs` & `polars_lts_cpu-0.18.5/src/apply/lazy.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/apply/mod.rs` & `polars_lts_cpu-0.18.5/src/apply/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/apply/series.rs` & `polars_lts_cpu-0.18.5/src/apply/series.rs`

 * *Files 1% similar despite different names*

```diff
@@ -2154,19 +2154,27 @@
             todo!()
         }
     }
 
     fn apply_to_struct(
         &'a self,
         _py: Python,
-        _lambda: &'a PyAny,
-        _init_null_count: usize,
-        _first_value: AnyValue<'a>,
+        lambda: &'a PyAny,
+        init_null_count: usize,
+        first_value: AnyValue<'a>,
     ) -> PyResult<PySeries> {
-        todo!()
+        let skip = 1;
+        let it = self
+            .into_iter()
+            .skip(init_null_count + skip)
+            .map(|object_value| {
+                let out = lambda.call1((object_value.map(|v| &v.inner),)).unwrap();
+                Some(out)
+            });
+        iterator_to_struct(it, init_null_count, first_value, self.name(), self.len())
     }
 
     fn apply_lambda_with_primitive_out_type<D>(
         &'a self,
         py: Python,
         lambda: &'a PyAny,
         init_null_count: usize,
```

### Comparing `polars_lts_cpu-0.18.4/src/arrow_interop/to_py.rs` & `polars_lts_cpu-0.18.5/src/arrow_interop/to_py.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/arrow_interop/to_rust.rs` & `polars_lts_cpu-0.18.5/src/arrow_interop/to_rust.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/batched_csv.rs` & `polars_lts_cpu-0.18.5/src/batched_csv.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/conversion.rs` & `polars_lts_cpu-0.18.5/src/conversion.rs`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 use polars::io::avro::AvroCompression;
 #[cfg(feature = "ipc")]
 use polars::io::ipc::IpcCompression;
 use polars::prelude::AnyValue;
 use polars::series::ops::NullBehavior;
 use polars_core::frame::hash_join::JoinValidation;
 use polars_core::frame::row::any_values_to_dtype;
-use polars_core::prelude::QuantileInterpolOptions;
+use polars_core::prelude::{IndexOrder, QuantileInterpolOptions};
 use polars_core::utils::arrow::types::NativeType;
 use polars_lazy::prelude::*;
 use pyo3::basic::CompareOp;
 use pyo3::conversion::{FromPyObject, IntoPy};
 use pyo3::exceptions::{PyTypeError, PyValueError};
 use pyo3::prelude::*;
 use pyo3::types::{PyBool, PyBytes, PyDict, PyFloat, PyList, PySequence, PyString, PyTuple};
@@ -1147,14 +1147,29 @@
                 )))
             }
         };
         Ok(Wrap(parsed))
     }
 }
 
+impl FromPyObject<'_> for Wrap<IndexOrder> {
+    fn extract(ob: &PyAny) -> PyResult<Self> {
+        let parsed = match ob.extract::<&str>()? {
+            "fortran" => IndexOrder::Fortran,
+            "c" => IndexOrder::C,
+            v => {
+                return Err(PyValueError::new_err(format!(
+                    "order must be one of {{'fortran', 'c'}}, got {v}",
+                )))
+            }
+        };
+        Ok(Wrap(parsed))
+    }
+}
+
 impl FromPyObject<'_> for Wrap<QuantileInterpolOptions> {
     fn extract(ob: &PyAny) -> PyResult<Self> {
         let parsed = match ob.extract::<&str>()? {
             "lower" => QuantileInterpolOptions::Lower,
             "higher" => QuantileInterpolOptions::Higher,
             "nearest" => QuantileInterpolOptions::Nearest,
             "linear" => QuantileInterpolOptions::Linear,
@@ -1281,14 +1296,32 @@
                 )))
             }
         };
         Ok(Wrap(parsed))
     }
 }
 
+#[cfg(feature = "list_sets")]
+impl FromPyObject<'_> for Wrap<SetOperation> {
+    fn extract(ob: &PyAny) -> PyResult<Self> {
+        let parsed = match ob.extract::<&str>()? {
+            "union" => SetOperation::Union,
+            "difference" => SetOperation::Difference,
+            "intersection" => SetOperation::Intersection,
+            "symmetric_difference" => SetOperation::Difference,
+            v => {
+                return Err(PyValueError::new_err(format!(
+                    "validate must be one of {{'union', 'difference', 'intersection', 'symmetric_difference'}}, got {v}",
+                )))
+            }
+        };
+        Ok(Wrap(parsed))
+    }
+}
+
 pub(crate) fn parse_fill_null_strategy(
     strategy: &str,
     limit: FillNullLimit,
 ) -> PyResult<FillNullStrategy> {
     let parsed = match strategy {
         "forward" => FillNullStrategy::Forward(limit),
         "backward" => FillNullStrategy::Backward(limit),
```

### Comparing `polars_lts_cpu-0.18.4/src/dataframe.rs` & `polars_lts_cpu-0.18.5/src/dataframe.rs`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 use polars::io::ipc::IpcCompression;
 use polars::io::mmap::ReaderBytes;
 use polars::io::RowCount;
 use polars::prelude::*;
 use polars_core::export::arrow::datatypes::IntegerType;
 use polars_core::frame::explode::MeltArgs;
 use polars_core::frame::*;
-use polars_core::prelude::QuantileInterpolOptions;
+use polars_core::prelude::{IndexOrder, QuantileInterpolOptions};
 use polars_core::utils::arrow::compute::cast::CastOptions;
 use polars_core::utils::try_get_supertype;
 #[cfg(feature = "pivot")]
 use polars_lazy::frame::pivot::{pivot, pivot_stable};
 use pyo3::prelude::*;
 use pyo3::types::{PyDict, PyList, PyTuple};
 
@@ -644,15 +644,15 @@
                     )
                 }),
             )
             .into_py(py)
         })
     }
 
-    pub fn to_numpy(&self, py: Python) -> Option<PyObject> {
+    pub fn to_numpy(&self, py: Python, order: Wrap<IndexOrder>) -> Option<PyObject> {
         let mut st = None;
         for s in self.df.iter() {
             let dt_i = s.dtype();
             match st {
                 None => st = Some(dt_i.clone()),
                 Some(ref mut st) => {
                     *st = try_get_supertype(st, dt_i).ok()?;
@@ -660,40 +660,40 @@
             }
         }
         let st = st?;
 
         match st {
             DataType::UInt32 => self
                 .df
-                .to_ndarray::<UInt32Type>()
+                .to_ndarray::<UInt32Type>(order.0)
                 .ok()
                 .map(|arr| arr.into_pyarray(py).into_py(py)),
             DataType::UInt64 => self
                 .df
-                .to_ndarray::<UInt64Type>()
+                .to_ndarray::<UInt64Type>(order.0)
                 .ok()
                 .map(|arr| arr.into_pyarray(py).into_py(py)),
             DataType::Int32 => self
                 .df
-                .to_ndarray::<Int32Type>()
+                .to_ndarray::<Int32Type>(order.0)
                 .ok()
                 .map(|arr| arr.into_pyarray(py).into_py(py)),
             DataType::Int64 => self
                 .df
-                .to_ndarray::<Int64Type>()
+                .to_ndarray::<Int64Type>(order.0)
                 .ok()
                 .map(|arr| arr.into_pyarray(py).into_py(py)),
             DataType::Float32 => self
                 .df
-                .to_ndarray::<Float32Type>()
+                .to_ndarray::<Float32Type>(order.0)
                 .ok()
                 .map(|arr| arr.into_pyarray(py).into_py(py)),
             DataType::Float64 => self
                 .df
-                .to_ndarray::<Float64Type>()
+                .to_ndarray::<Float64Type>(order.0)
                 .ok()
                 .map(|arr| arr.into_pyarray(py).into_py(py)),
             _ => None,
         }
     }
 
     #[cfg(feature = "parquet")]
```

### Comparing `polars_lts_cpu-0.18.4/src/datatypes.rs` & `polars_lts_cpu-0.18.5/src/datatypes.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/error.rs` & `polars_lts_cpu-0.18.5/src/error.rs`

 * *Files 8% similar despite different names*

```diff
@@ -41,14 +41,17 @@
                 PolarsError::Io(err) => PyIOError::new_err(err.to_string()),
                 PolarsError::NoData(err) => NoDataError::new_err(err.to_string()),
                 PolarsError::SchemaFieldNotFound(name) => {
                     SchemaFieldNotFoundError::new_err(name.to_string())
                 }
                 PolarsError::SchemaMismatch(err) => SchemaError::new_err(err.to_string()),
                 PolarsError::ShapeMismatch(err) => ShapeError::new_err(err.to_string()),
+                PolarsError::StringCacheMismatch(err) => {
+                    StringCacheMismatchError::new_err(err.to_string())
+                }
                 PolarsError::StructFieldNotFound(name) => {
                     StructFieldNotFoundError::new_err(name.to_string())
                 }
             },
             Arrow(err) => ArrowErrorException::new_err(format!("{err:?}")),
             _ => default(),
         }
@@ -71,14 +74,15 @@
 create_exception!(exceptions, ComputeError, PyException);
 create_exception!(exceptions, DuplicateError, PyException);
 create_exception!(exceptions, InvalidOperationError, PyException);
 create_exception!(exceptions, NoDataError, PyException);
 create_exception!(exceptions, SchemaError, PyException);
 create_exception!(exceptions, SchemaFieldNotFoundError, PyException);
 create_exception!(exceptions, ShapeError, PyException);
+create_exception!(exceptions, StringCacheMismatchError, PyException);
 create_exception!(exceptions, StructFieldNotFoundError, PyException);
 
 #[macro_export]
 macro_rules! raise_err(
     ($msg:expr, $err:ident) => {{
         Err(PolarsError::$err($msg.into())).map_err(PyPolarsErr::from)?;
         unreachable!()
```

### Comparing `polars_lts_cpu-0.18.4/src/expr/array.rs` & `polars_lts_cpu-0.18.5/src/expr/array.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/expr/binary.rs` & `polars_lts_cpu-0.18.5/src/expr/binary.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/expr/datetime.rs` & `polars_lts_cpu-0.18.5/src/expr/datetime.rs`

 * *Files 2% similar despite different names*

```diff
@@ -64,14 +64,23 @@
         self.inner.clone().dt().month_start().into()
     }
 
     fn dt_month_end(&self) -> Self {
         self.inner.clone().dt().month_end().into()
     }
 
+    #[cfg(feature = "timezones")]
+    fn dt_base_utc_offset(&self) -> Self {
+        self.inner.clone().dt().base_utc_offset().into()
+    }
+    #[cfg(feature = "timezones")]
+    fn dt_dst_offset(&self) -> Self {
+        self.inner.clone().dt().dst_offset().into()
+    }
+
     fn dt_round(&self, every: &str, offset: &str) -> Self {
         self.inner.clone().dt().round(every, offset).into()
     }
 
     fn dt_combine(&self, time: Self, time_unit: Wrap<TimeUnit>) -> Self {
         self.inner
             .clone()
```

### Comparing `polars_lts_cpu-0.18.4/src/expr/general.rs` & `polars_lts_cpu-0.18.5/src/expr/general.rs`

 * *Files 2% similar despite different names*

```diff
@@ -173,14 +173,35 @@
     }
     fn quantile(&self, quantile: Self, interpolation: Wrap<QuantileInterpolOptions>) -> Self {
         self.clone()
             .inner
             .quantile(quantile.inner, interpolation.0)
             .into()
     }
+
+    #[pyo3(signature = (breaks, labels, left_closed))]
+    #[cfg(feature = "cutqcut")]
+    fn cut(&self, breaks: Vec<f64>, labels: Option<Vec<String>>, left_closed: bool) -> Self {
+        self.inner.clone().cut(breaks, labels, left_closed).into()
+    }
+    #[pyo3(signature = (probs, labels, left_closed, allow_duplicates))]
+    #[cfg(feature = "cutqcut")]
+    fn qcut(
+        &self,
+        probs: Vec<f64>,
+        labels: Option<Vec<String>>,
+        left_closed: bool,
+        allow_duplicates: bool,
+    ) -> Self {
+        self.inner
+            .clone()
+            .qcut(probs, labels, left_closed, allow_duplicates)
+            .into()
+    }
+
     fn agg_groups(&self) -> Self {
         self.clone().inner.agg_groups().into()
     }
     fn count(&self) -> Self {
         self.clone().inner.count().into()
     }
     fn value_counts(&self, multithreaded: bool, sorted: bool) -> Self {
@@ -968,35 +989,46 @@
         self.inner.clone().cumcount(reverse).into()
     }
 
     fn to_physical(&self) -> Self {
         self.inner.clone().to_physical().into()
     }
 
-    fn shuffle(&self, seed: Option<u64>) -> Self {
-        self.inner.clone().shuffle(seed).into()
+    #[pyo3(signature = (seed, fixed_seed))]
+    fn shuffle(&self, seed: Option<u64>, fixed_seed: bool) -> Self {
+        self.inner.clone().shuffle(seed, fixed_seed).into()
     }
 
-    fn sample_n(&self, n: usize, with_replacement: bool, shuffle: bool, seed: Option<u64>) -> Self {
+    #[pyo3(signature = (n, with_replacement, shuffle, seed, fixed_seed))]
+    fn sample_n(
+        &self,
+        n: usize,
+        with_replacement: bool,
+        shuffle: bool,
+        seed: Option<u64>,
+        fixed_seed: bool,
+    ) -> Self {
         self.inner
             .clone()
-            .sample_n(n, with_replacement, shuffle, seed)
+            .sample_n(n, with_replacement, shuffle, seed, fixed_seed)
             .into()
     }
 
+    #[pyo3(signature = (frac, with_replacement, shuffle, seed, fixed_seed))]
     fn sample_frac(
         &self,
         frac: f64,
         with_replacement: bool,
         shuffle: bool,
         seed: Option<u64>,
+        fixed_seed: bool,
     ) -> Self {
         self.inner
             .clone()
-            .sample_frac(frac, with_replacement, shuffle, seed)
+            .sample_frac(frac, with_replacement, shuffle, seed, fixed_seed)
             .into()
     }
 
     fn ewm_mean(&self, alpha: f64, adjust: bool, min_periods: usize, ignore_nulls: bool) -> Self {
         let options = EWMOptions {
             alpha,
             adjust,
```

### Comparing `polars_lts_cpu-0.18.4/src/expr/list.rs` & `polars_lts_cpu-0.18.5/src/expr/list.rs`

 * *Files 23% similar despite different names*

```diff
@@ -5,14 +5,24 @@
 use smartstring::alias::String as SmartString;
 
 use crate::conversion::Wrap;
 use crate::PyExpr;
 
 #[pymethods]
 impl PyExpr {
+    #[cfg(feature = "list_any_all")]
+    fn list_all(&self) -> Self {
+        self.inner.clone().list().all().into()
+    }
+
+    #[cfg(feature = "list_any_all")]
+    fn list_any(&self) -> Self {
+        self.inner.clone().list().any().into()
+    }
+
     fn list_arg_max(&self) -> Self {
         self.inner.clone().list().arg_max().into()
     }
 
     fn list_arg_min(&self) -> Self {
         self.inner.clone().list().arg_min().into()
     }
@@ -139,8 +149,20 @@
 
         if maintain_order {
             e.list().unique_stable().into()
         } else {
             e.list().unique().into()
         }
     }
+
+    #[cfg(feature = "list_sets")]
+    fn list_set_operation(&self, other: PyExpr, operation: Wrap<SetOperation>) -> Self {
+        let e = self.inner.clone().list();
+        match operation.0 {
+            SetOperation::Intersection => e.intersection(other.inner),
+            SetOperation::Difference => e.difference(other.inner),
+            SetOperation::Union => e.union(other.inner),
+            SetOperation::SymmetricDifference => e.symmetric_difference(other.inner),
+        }
+        .into()
+    }
 }
```

### Comparing `polars_lts_cpu-0.18.4/src/expr/meta.rs` & `polars_lts_cpu-0.18.5/src/expr/meta.rs`

 * *Files 2% similar despite different names*

```diff
@@ -101,8 +101,18 @@
             Ok(PyExpr { inner })
         }
         #[cfg(not(feature = "json"))]
         {
             panic!("activate 'json' feature")
         }
     }
+
+    fn meta_tree_format(&self) -> PyResult<String> {
+        let e = self
+            .inner
+            .clone()
+            .meta()
+            .into_tree_formatter()
+            .map_err(PyPolarsErr::from)?;
+        Ok(format!("{e}"))
+    }
 }
```

### Comparing `polars_lts_cpu-0.18.4/src/expr/mod.rs` & `polars_lts_cpu-0.18.5/src/expr/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/expr/string.rs` & `polars_lts_cpu-0.18.5/src/expr/string.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/file.rs` & `polars_lts_cpu-0.18.5/src/file.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/functions/eager.rs` & `polars_lts_cpu-0.18.5/src/functions/eager.rs`

 * *Files 15% similar despite different names*

```diff
@@ -1,9 +1,8 @@
 use polars::{functions, time};
-use polars_core::datatypes::{TimeUnit, TimeZone};
 use polars_core::prelude::*;
 use pyo3::prelude::*;
 
 use crate::conversion::{get_df, get_series, Wrap};
 use crate::error::PyPolarsErr;
 use crate::prelude::{ClosedWindow, Duration};
 use crate::{PyDataFrame, PySeries};
@@ -61,36 +60,14 @@
         let item = get_series(item)?;
         s.append(&item).map_err(PyPolarsErr::from)?;
     }
     Ok(s.into())
 }
 
 #[pyfunction]
-pub fn date_range_eager(
-    start: i64,
-    stop: i64,
-    every: &str,
-    closed: Wrap<ClosedWindow>,
-    time_unit: Wrap<TimeUnit>,
-    time_zone: Option<TimeZone>,
-) -> PyResult<PySeries> {
-    let date_range = time::date_range_impl(
-        "date",
-        start,
-        stop,
-        Duration::parse(every),
-        closed.0,
-        time_unit.0,
-        time_zone.as_ref(),
-    )
-    .map_err(PyPolarsErr::from)?;
-    Ok(date_range.into_series().into())
-}
-
-#[pyfunction]
 pub fn diag_concat_df(dfs: &PyAny) -> PyResult<PyDataFrame> {
     let iter = dfs.iter()?;
 
     let dfs = iter
         .map(|item| {
             let item = item?;
             get_df(item)
```

### Comparing `polars_lts_cpu-0.18.4/src/functions/io.rs` & `polars_lts_cpu-0.18.5/src/functions/io.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/functions/lazy.rs` & `polars_lts_cpu-0.18.5/src/functions/lazy.rs`

 * *Files 4% similar despite different names*

```diff
@@ -17,19 +17,14 @@
 macro_rules! set_unwrapped_or_0 {
     ($($var:ident),+ $(,)?) => {
         $(let $var = $var.map(|e| e.inner).unwrap_or(dsl::lit(0));)+
     };
 }
 
 #[pyfunction]
-pub fn arange(start: PyExpr, end: PyExpr, step: i64) -> PyExpr {
-    dsl::arange(start.inner, end.inner, step).into()
-}
-
-#[pyfunction]
 pub fn rolling_corr(
     x: PyExpr,
     y: PyExpr,
     window_size: IdxSize,
     min_periods: IdxSize,
     ddof: u8,
 ) -> PyExpr {
@@ -186,20 +181,29 @@
 
 #[pyfunction]
 pub fn date_range_lazy(
     start: PyExpr,
     end: PyExpr,
     every: &str,
     closed: Wrap<ClosedWindow>,
+    time_unit: Option<Wrap<TimeUnit>>,
     time_zone: Option<TimeZone>,
 ) -> PyExpr {
     let start = start.inner;
     let end = end.inner;
     let every = Duration::parse(every);
-    dsl::functions::date_range(start, end, every, closed.0, time_zone).into()
+    dsl::functions::date_range(
+        start,
+        end,
+        every,
+        closed.0,
+        time_unit.map(|x| x.0),
+        time_zone,
+    )
+    .into()
 }
 
 #[pyfunction]
 pub fn datetime(
     year: PyExpr,
     month: PyExpr,
     day: PyExpr,
@@ -397,46 +401,33 @@
     let exprs = exprs.to_exprs();
 
     let func = move |a: Series, b: Series| binary_lambda(&lambda, a, b);
     dsl::reduce_exprs(func, exprs).into()
 }
 
 #[pyfunction]
-pub fn repeat(value: Wrap<AnyValue>, n: PyExpr, dtype: Option<Wrap<DataType>>) -> PyResult<PyExpr> {
-    let value = value.0;
+pub fn repeat(value: PyExpr, n: PyExpr, dtype: Option<Wrap<DataType>>) -> PyResult<PyExpr> {
+    let mut value = value.inner;
     let n = n.inner;
-    let dtype = dtype.map(|wrap| wrap.0);
 
-    let target_dtype = match dtype {
-        Some(dtype) => dtype,
-        None => match value.dtype() {
-            // Integer inputs that fit in Int32 are parsed as such
-            DataType::Int64 => {
-                let int_value: i64 = value.try_extract().unwrap();
-                if int_value >= i32::MIN as i64 && int_value <= i32::MAX as i64 {
-                    DataType::Int32
-                } else {
-                    DataType::Int64
-                }
-            }
-            DataType::Unknown => DataType::Null,
-            _ => value.dtype(),
-        },
-    };
-
-    let lit_value = LiteralValue::try_from(value).map_err(PyPolarsErr::from)?;
-    let must_cast = lit_value.get_datatype() != target_dtype;
-
-    let mut expr = dsl::repeat(lit_value, n);
-
-    if must_cast {
-        expr = expr.cast(target_dtype);
+    if let Some(dtype) = dtype {
+        value = value.cast(dtype.0);
     }
 
-    Ok(expr.into())
+    if let Expr::Literal(lv) = &value {
+        let av = lv.to_anyvalue().unwrap();
+        // Integer inputs that fit in Int32 are parsed as such
+        if let DataType::Int64 = av.dtype() {
+            let int_value = av.try_extract::<i64>().unwrap();
+            if int_value >= i32::MIN as i64 && int_value <= i32::MAX as i64 {
+                value = value.cast(DataType::Int32);
+            }
+        }
+    }
+    Ok(dsl::repeat(value, n).into())
 }
 
 #[pyfunction]
 pub fn spearman_rank_corr(a: PyExpr, b: PyExpr, ddof: u8, propagate_nans: bool) -> PyExpr {
     #[cfg(feature = "propagate_nans")]
     {
         dsl::spearman_rank_corr(a.inner, b.inner, ddof, propagate_nans).into()
```

### Comparing `polars_lts_cpu-0.18.4/src/functions/meta.rs` & `polars_lts_cpu-0.18.5/src/functions/meta.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/functions/whenthen.rs` & `polars_lts_cpu-0.18.5/src/functions/whenthen.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/lazyframe.rs` & `polars_lts_cpu-0.18.5/src/lazyframe.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,20 +1,19 @@
-use std::borrow::Cow;
 use std::collections::HashMap;
 use std::io::BufWriter;
 use std::path::PathBuf;
 
 use polars::io::RowCount;
 #[cfg(feature = "csv")]
 use polars::lazy::frame::LazyCsvReader;
 #[cfg(feature = "json")]
 use polars::lazy::frame::LazyJsonLineReader;
 use polars::lazy::frame::{AllowedOptimizations, LazyFrame};
 use polars::lazy::prelude::col;
-use polars::prelude::{ClosedWindow, CsvEncoding, DataFrame, Field, JoinType, Schema};
+use polars::prelude::{ClosedWindow, CsvEncoding, Field, JoinType, Schema};
 use polars::time::*;
 use polars_core::cloud;
 use polars_core::frame::explode::MeltArgs;
 use polars_core::frame::hash_join::JoinValidation;
 use polars_core::frame::UniqueKeepStrategy;
 use polars_core::prelude::*;
 use pyo3::exceptions::PyValueError;
@@ -23,15 +22,14 @@
 
 use crate::arrow_interop::to_rust::pyarrow_schema_to_rust;
 use crate::conversion::Wrap;
 use crate::error::PyPolarsErr;
 use crate::expr::ToExprs;
 use crate::file::get_file_like;
 use crate::prelude::*;
-use crate::py_modules::POLARS;
 use crate::{PyDataFrame, PyExpr, PyLazyGroupBy};
 
 /// Extract CloudOptions from a Python object.
 fn extract_cloud_options(url: &str, py_object: PyObject) -> PyResult<cloud::CloudOptions> {
     let untyped_options = Python::with_gil(|py| py_object.extract::<HashMap<String, String>>(py))
         .expect("Expected a dictionary for cloud_options");
     Ok(
@@ -813,82 +811,24 @@
         let opt = AllowedOptimizations {
             predicate_pushdown,
             projection_pushdown,
             slice_pushdown,
             streaming: streamable,
             ..Default::default()
         };
-        let schema = schema.map(|schema| Arc::new(schema.0));
-        let schema2 = schema.clone();
 
-        let function = move |df: DataFrame| {
-            Python::with_gil(|py| {
-                let opt_schema = schema2.clone();
-
-                let expected_schema = if let Some(schema) = opt_schema.as_ref() {
-                    Cow::Borrowed(schema.as_ref())
-                }
-                // only materialize if we validate the output
-                else if validate_output {
-                    Cow::Owned(df.schema())
-                }
-                // do not materialize the schema, we will ignore it.
-                else {
-                    Cow::Owned(Schema::default())
-                };
-
-                // create a PyDataFrame struct/object for Python
-                let pydf = PyDataFrame::new(df);
-                // Wrap this PyDataFrame object in the python side DataFrame wrapper
-                let python_df_wrapper = POLARS
-                    .getattr(py, "wrap_df")
-                    .unwrap()
-                    .call1(py, (pydf,))
-                    .unwrap();
-                // call the lambda and get a python side Series wrapper
-
-                let result_df_wrapper = lambda.call1(py, (python_df_wrapper,)).map_err(|e| {
-                    PolarsError::ComputeError(
-                        format!("User provided python function failed: {e}").into(),
-                    )
-                })?;
-                // unpack the wrapper in a PyDataFrame
-                let py_pydf = result_df_wrapper.getattr(py, "_df").map_err(|_| {
-                    let pytype = result_df_wrapper.as_ref(py).get_type();
-                    PolarsError::ComputeError(
-                        format!(
-                            "Expected 'LazyFrame.map' to return a 'DataFrame', got a '{pytype}'",
-                        )
-                        .into(),
-                    )
-                })?;
-
-                // Downcast to Rust
-                let pydf = py_pydf.extract::<PyDataFrame>(py).unwrap();
-                // Finally get the actual DataFrame
-                let df = pydf.df;
-
-                if validate_output {
-                    let output_schema = df.schema();
-                    if expected_schema.as_ref() != &output_schema {
-                        return Err(PolarsError::ComputeError(
-                            format!("The output schema of 'LazyFrame.map' is incorrect. Expected: {expected_schema:?}\n\
-                        Got: {output_schema:?}").into()
-                        ));
-                    }
-                }
-                Ok(df)
-            })
-        };
-
-        let ldf = self.ldf.clone();
-
-        let udf_schema =
-            schema.map(move |s| Arc::new(move |_: &Schema| Ok(s.clone())) as Arc<dyn UdfSchema>);
-        ldf.map(function, opt, udf_schema, None).into()
+        self.ldf
+            .clone()
+            .map_python(
+                lambda.into(),
+                opt,
+                schema.map(|s| Arc::new(s.0)),
+                validate_output,
+            )
+            .into()
     }
 
     fn drop(&self, columns: Vec<String>) -> Self {
         let ldf = self.ldf.clone();
         ldf.drop_columns(columns).into()
     }
```

### Comparing `polars_lts_cpu-0.18.4/src/lazygroupby.rs` & `polars_lts_cpu-0.18.5/src/lazygroupby.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/lib.rs` & `polars_lts_cpu-0.18.5/src/lib.rs`

 * *Files 1% similar despite different names*

```diff
@@ -23,27 +23,29 @@
 pub mod expr;
 pub mod file;
 pub mod functions;
 pub mod lazyframe;
 pub mod lazygroupby;
 #[cfg(feature = "object")]
 mod object;
+#[cfg(feature = "object")]
+mod on_startup;
 pub mod prelude;
 pub(crate) mod py_modules;
 pub mod series;
 #[cfg(feature = "sql")]
 mod sql;
 pub mod utils;
 
 #[cfg(all(target_os = "linux", not(use_mimalloc)))]
 use jemallocator::Jemalloc;
 #[cfg(any(not(target_os = "linux"), use_mimalloc))]
 use mimalloc::MiMalloc;
 #[cfg(feature = "object")]
-pub use object::__register_startup_deps;
+pub use on_startup::__register_startup_deps;
 use pyo3::panic::PanicException;
 use pyo3::prelude::*;
 use pyo3::wrap_pyfunction;
 
 use crate::conversion::Wrap;
 use crate::dataframe::PyDataFrame;
 use crate::error::{
@@ -77,26 +79,30 @@
     m.add_class::<sql::PySQLContext>().unwrap();
 
     // Functions - eager
     m.add_wrapped(wrap_pyfunction!(functions::eager::concat_df))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::eager::concat_series))
         .unwrap();
-    m.add_wrapped(wrap_pyfunction!(functions::eager::date_range_eager))
-        .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::eager::diag_concat_df))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::eager::hor_concat_df))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::eager::time_range_eager))
         .unwrap();
 
-    // Functions - lazy
-    m.add_wrapped(wrap_pyfunction!(functions::lazy::arange))
+    // Functions - range
+    m.add_wrapped(wrap_pyfunction!(functions::range::arange))
+        .unwrap();
+    m.add_wrapped(wrap_pyfunction!(functions::range::int_range))
+        .unwrap();
+    m.add_wrapped(wrap_pyfunction!(functions::range::int_ranges))
         .unwrap();
+
+    // Functions - lazy
     m.add_wrapped(wrap_pyfunction!(functions::lazy::arg_sort_by))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::arg_where))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::as_struct))
         .unwrap();
     m.add_wrapped(wrap_pyfunction!(functions::lazy::coalesce))
@@ -223,14 +229,19 @@
         "SchemaFieldNotFoundError",
         py.get_type::<SchemaFieldNotFoundError>(),
     )
     .unwrap();
     m.add("ShapeError", py.get_type::<crate::error::ShapeError>())
         .unwrap();
     m.add(
+        "StringCacheMismatchError",
+        py.get_type::<crate::error::StringCacheMismatchError>(),
+    )
+    .unwrap();
+    m.add(
         "StructFieldNotFoundError",
         py.get_type::<StructFieldNotFoundError>(),
     )
     .unwrap();
 
     // Build info
     #[cfg(feature = "build_info")]
```

### Comparing `polars_lts_cpu-0.18.4/src/series/aggregation.rs` & `polars_lts_cpu-0.18.5/src/series/aggregation.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/series/arithmetic.rs` & `polars_lts_cpu-0.18.5/src/series/arithmetic.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/series/comparison.rs` & `polars_lts_cpu-0.18.5/src/series/comparison.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/series/construction.rs` & `polars_lts_cpu-0.18.5/src/series/construction.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/series/export.rs` & `polars_lts_cpu-0.18.5/src/series/export.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/series/mod.rs` & `polars_lts_cpu-0.18.5/src/series/mod.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/series/numpy_ufunc.rs` & `polars_lts_cpu-0.18.5/src/series/numpy_ufunc.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/series/set_at_idx.rs` & `polars_lts_cpu-0.18.5/src/series/set_at_idx.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/sql.rs` & `polars_lts_cpu-0.18.5/src/sql.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/src/utils.rs` & `polars_lts_cpu-0.18.5/src/utils.rs`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/README.md` & `polars_lts_cpu-0.18.5/tests/README.md`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/benchmark/groupby-datagen.R` & `polars_lts_cpu-0.18.5/tests/benchmark/groupby-datagen.R`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/benchmark/run_h2oai_benchmark.py` & `polars_lts_cpu-0.18.5/tests/benchmark/run_h2oai_benchmark.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/benchmark/test_release.py` & `polars_lts_cpu-0.18.5/tests/benchmark/test_release.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/docs/run_doctest.py` & `polars_lts_cpu-0.18.5/tests/docs/run_doctest.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/parametric/test_dataframe.py` & `polars_lts_cpu-0.18.5/tests/parametric/test_dataframe.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/parametric/test_groupby_rolling.py` & `polars_lts_cpu-0.18.5/tests/parametric/test_groupby_rolling.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/parametric/test_lazyframe.py` & `polars_lts_cpu-0.18.5/tests/parametric/test_lazyframe.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/parametric/test_lit.py` & `polars_lts_cpu-0.18.5/tests/parametric/test_lit.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/parametric/test_series.py` & `polars_lts_cpu-0.18.5/tests/parametric/test_series.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 # -------------------------------------------------
 # Validate Series behaviour with parametric tests
 # -------------------------------------------------
 from __future__ import annotations
 
-# from decimal import Decimal as D
-from typing import no_type_check
+from typing import Any
 
 import numpy as np
 from hypothesis import given, settings
 from hypothesis.strategies import booleans, floats, sampled_from
 from numpy.testing import assert_array_equal
 
 import polars as pl
@@ -37,37 +36,36 @@
     ),
     com=floats(min_value=0, max_value=99).filter(lambda x: alpha_guard(com=x)),
     span=floats(min_value=1, max_value=10).filter(lambda x: alpha_guard(span=x)),
     ignore_nulls=booleans(),
     adjust=booleans(),
     bias=booleans(),
 )
-@no_type_check
 def test_ewm_methods(
     s: pl.Series,
     com: float | None,
     span: float | None,
     half_life: float | None,
     ignore_nulls: bool,
     adjust: bool,
     bias: bool,
 ) -> None:
     # validate a large set of varied EWM calculations
-    for decay_param in ({"com": com}, {"span": span}, {"half_life": half_life}):
+    for decay_param in [{"com": com}, {"span": span}, {"half_life": half_life}]:
         alpha = _prepare_alpha(**decay_param)
 
         # convert parametrically-generated series to pandas, then use that as a
         # reference implementation for comparison (after normalising NaN/None)
         p = s.to_pandas()
 
         # note: skip min_periods < 2, due to pandas-side inconsistency:
         # https://github.com/pola-rs/polars/issues/5006#issuecomment-1259477178
         for mp in range(2, len(s), len(s) // 3):
             # consolidate ewm parameters
-            pl_params = {
+            pl_params: dict[str, Any] = {
                 "min_periods": mp,
                 "adjust": adjust,
                 "ignore_nulls": ignore_nulls,
             }
             pl_params.update(decay_param)
             pd_params = pl_params.copy()
             if "half_life" in pl_params:
```

### Comparing `polars_lts_cpu-0.18.4/tests/parametric/test_testing.py` & `polars_lts_cpu-0.18.5/tests/parametric/test_testing.py`

 * *Files 2% similar despite different names*

```diff
@@ -18,14 +18,19 @@
     column,
     columns,
     create_list_strategy,
     dataframes,
     series,
 )
 
+# TODO: add parametric strategy generator that supports timezones
+TEMPORAL_DTYPES_ = {
+    tp for tp in TEMPORAL_DTYPES if getattr(tp, "time_zone", None) != "*"
+}
+
 
 @given(df=dataframes(), lf=dataframes(lazy=True), srs=series())
 @settings(max_examples=5)
 def test_strategy_classes(df: pl.DataFrame, lf: pl.LazyFrame, srs: pl.Series) -> None:
     assert isinstance(df, pl.DataFrame)
     assert isinstance(lf, pl.LazyFrame)
     assert isinstance(srs, pl.Series)
@@ -93,19 +98,19 @@
 
     # string col, entries selected from custom values
     xyz = {"x", "y", "z"}
     assert all(v in xyz for v in df["d"].to_list())
 
 
 @given(
-    df=dataframes(allowed_dtypes=TEMPORAL_DTYPES, max_size=1, max_cols=5),
-    lf=dataframes(excluded_dtypes=TEMPORAL_DTYPES, max_size=1, max_cols=5, lazy=True),
+    df=dataframes(allowed_dtypes=TEMPORAL_DTYPES_, max_size=1, max_cols=5),
+    lf=dataframes(excluded_dtypes=TEMPORAL_DTYPES_, max_size=1, max_cols=5, lazy=True),
     s1=series(dtype=pl.Boolean, max_size=1),
-    s2=series(allowed_dtypes=TEMPORAL_DTYPES, max_size=1),
-    s3=series(excluded_dtypes=TEMPORAL_DTYPES, max_size=1),
+    s2=series(allowed_dtypes=TEMPORAL_DTYPES_, max_size=1),
+    s3=series(excluded_dtypes=TEMPORAL_DTYPES_, max_size=1),
 )
 @settings(max_examples=50)
 def test_strategy_dtypes(
     df: pl.DataFrame,
     lf: pl.LazyFrame,
     s1: pl.Series,
     s2: pl.Series,
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/conftest.py` & `polars_lts_cpu-0.18.5/tests/unit/conftest.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_binary.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_binary.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_bool.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_bool.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_categorical.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_categorical.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 from __future__ import annotations
 
 import io
-import typing
 from typing import Any
 
 import pytest
 
 import polars as pl
 from polars import StringCache
+from polars.exceptions import StringCacheMismatchError
 from polars.testing import assert_frame_equal
 
 
 @StringCache()
 def test_categorical_outer_join() -> None:
     df1 = pl.DataFrame(
         [
@@ -298,16 +298,16 @@
                 dtype=pl.Categorical,
             ),
             pl.Series("time", [-5, 5, 15, 25] * 2, dtype=pl.Int32),
             pl.Series("x", [1, 2, 3, 4] * 2, dtype=pl.Int32),
         ]
     )
     with pytest.raises(
-        pl.ComputeError,
-        match=r"joins/or comparisons on categoricals can only happen if they were created under the same global string cache",
+        StringCacheMismatchError,
+        match="cannot compare categoricals coming from different sources",
     ):
         df1.join_asof(df2, on=pl.col("time").set_sorted(), by="cat")
 
 
 def test_categorical_list_get_item() -> None:
     out = pl.Series([["a"]]).cast(pl.List(pl.Categorical)).item()
     assert isinstance(out, pl.Series)
@@ -379,26 +379,35 @@
     )
     a = df.select(pl.col("cat").fill_null("hi")).collect()
 
     assert a.to_dict(False) == {"cat": ["a", "b", "hi"]}
     assert a.dtypes == [pl.Categorical]
 
 
-@typing.no_type_check
 def test_fast_unique_flag_from_arrow() -> None:
     df = pl.DataFrame(
         {
             "colB": ["1", "2", "3", "4", "5", "5", "5", "5"],
         }
     ).with_columns([pl.col("colB").cast(pl.Categorical)])
 
     filtered = df.to_arrow().filter([True, False, True, True, False, True, True, True])
-    assert pl.from_arrow(filtered).select(pl.col("colB").n_unique()).item() == 4
+    assert pl.from_arrow(filtered).select(pl.col("colB").n_unique()).item() == 4  # type: ignore[union-attr]
 
 
 def test_construct_with_null() -> None:
     # Example from https://github.com/pola-rs/polars/issues/7188
     df = pl.from_dicts([{"A": None}, {"A": "foo"}], schema={"A": pl.Categorical})
     assert df.to_series().to_list() == [None, "foo"]
 
     s = pl.Series([{"struct_A": None}], dtype=pl.Struct({"struct_A": pl.Categorical}))
     assert s.to_list() == [{"struct_A": None}]
+
+
+def test_categorical_concat_string_cached() -> None:
+    with pl.StringCache():
+        df1 = pl.DataFrame({"x": ["A"]}).with_columns(pl.col("x").cast(pl.Categorical))
+        df2 = pl.DataFrame({"x": ["B"]}).with_columns(pl.col("x").cast(pl.Categorical))
+
+    out = pl.concat([df1, df2])
+    assert out.dtypes == [pl.Categorical]
+    assert out["x"].to_list() == ["A", "B"]
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_decimal.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_decimal.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_duration.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_duration.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_list.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_list.py`

 * *Files 2% similar despite different names*

```diff
@@ -293,14 +293,50 @@
     ).to_dict(False) == {"a": [1.0, 2.0, 2.5, 3.0]}
 
     assert pl.DataFrame({"a": [[1], [1, 2, 3], [1, 2, 3, 4], None]}).select(
         pl.col("a").list.mean()
     ).to_dict(False) == {"a": [1.0, 2.0, 2.5, None]}
 
 
+def test_list_all() -> None:
+    assert pl.DataFrame(
+        {
+            "a": [
+                [True],
+                [False],
+                [True, True],
+                [True, False],
+                [False, False],
+                [None],
+                [],
+            ]
+        }
+    ).select(pl.col("a").list.all()).to_dict(False) == {
+        "a": [True, False, True, False, False, False, True]
+    }
+
+
+def test_list_any() -> None:
+    assert pl.DataFrame(
+        {
+            "a": [
+                [True],
+                [False],
+                [True, True],
+                [True, False],
+                [False, False],
+                [None],
+                [],
+            ]
+        }
+    ).select(pl.col("a").list.any()).to_dict(False) == {
+        "a": [True, False, True, True, False, False, False]
+    }
+
+
 def test_list_min_max() -> None:
     for dt in pl.NUMERIC_DTYPES:
         if dt == pl.Decimal:
             continue
         df = pl.DataFrame(
             {"a": [[1], [1, 2, 3], [1, 2, 3, 4], [1, 2, 3, 4, 5]]},
             schema={"a": pl.List(dt)},
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_object.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_object.py`

 * *Files 5% similar despite different names*

```diff
@@ -104,7 +104,13 @@
     ]
     df = pl.DataFrame(
         data,
         orient="row",
     )
     assert df.dtypes == [pl.Object]
     assert df["column_0"].to_list() == [value[0] for value in data]
+
+
+def test_object_apply_to_struct() -> None:
+    s = pl.Series([0, 1, 2], dtype=pl.Object)
+    out = s.apply(lambda x: {"a": str(x), "b": x})
+    assert out.dtype == pl.Struct([pl.Field("a", pl.Utf8), pl.Field("b", pl.Int64)])
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_struct.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_struct.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 from __future__ import annotations
 
-import typing
 from dataclasses import dataclass
 from datetime import datetime, time
 
 import pandas as pd
 import pyarrow as pa
 import pytest
 
@@ -575,15 +574,14 @@
         pl.col("col_struct").list.eval(pl.element().first()).alias("first")
     ).to_dict(False) == {
         "col_struct": [[{"a": 1, "b": 11}, {"a": 2, "b": 12}, {"a": 1, "b": 11}]],
         "first": [[{"a": 1, "b": 11}]],
     }
 
 
-@typing.no_type_check
 def test_arr_unique() -> None:
     df = pl.DataFrame(
         {"col_struct": [[{"a": 1, "b": 11}, {"a": 2, "b": 12}, {"a": 1, "b": 11}]]}
     )
     # the order is unpredictable
     unique = df.with_columns(pl.col("col_struct").list.unique().alias("unique"))[
         "unique"
@@ -846,22 +844,21 @@
         pl.DataFrame({"x": [4, 3, 5, 9], "y": [0, 7, 6, 2]})
         .select(pl.struct(["x", "y"]))
         .to_series()
     )
     assert s1.is_in(s2).to_list() == [True, False, False, True]
 
 
-@typing.no_type_check
 def test_nested_struct_logicals() -> None:
     # single nested
-    payload = [[{"a": time(10)}], [{"a": time(10)}]]
-    assert pl.Series(payload).to_list() == payload
+    payload1 = [[{"a": time(10)}], [{"a": time(10)}]]
+    assert pl.Series(payload1).to_list() == payload1
     # double nested
-    payload = [[[{"a": time(10)}]], [[{"a": time(10)}]]]
-    assert pl.Series(payload).to_list() == payload
+    payload2 = [[[{"a": time(10)}]], [[{"a": time(10)}]]]
+    assert pl.Series(payload2).to_list() == payload2
 
 
 def test_struct_name_passed_in_agg_apply() -> None:
     struct_expr = pl.struct(
         [
             pl.col("A").min(),
             pl.col("B").search_sorted(pl.Series([3, 4])),
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/datatypes/test_temporal.py` & `polars_lts_cpu-0.18.5/tests/unit/datatypes/test_temporal.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 import contextlib
 import io
 from datetime import date, datetime, time, timedelta, timezone
-from typing import TYPE_CHECKING, Any, cast, no_type_check
+from typing import TYPE_CHECKING, Any, cast
 
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 import pytest
 
 import polars as pl
@@ -1457,24 +1457,25 @@
 def test_agg_logical() -> None:
     dates = [date(2001, 1, 1), date(2002, 1, 1)]
     s = pl.Series(dates)
     assert s.max() == dates[1]
     assert s.min() == dates[0]
 
 
-@no_type_check
 def test_from_time_arrow() -> None:
     pa_times = pa.table([pa.array([10, 20, 30], type=pa.time32("s"))], names=["times"])
 
-    assert pl.from_arrow(pa_times).to_series().to_list() == [
+    result: pl.DataFrame = pl.from_arrow(pa_times)  # type: ignore[assignment]
+
+    assert result.to_series().to_list() == [
         time(0, 0, 10),
         time(0, 0, 20),
         time(0, 0, 30),
     ]
-    assert pl.from_arrow(pa_times).rows() == [
+    assert result.rows() == [
         (time(0, 0, 10),),
         (time(0, 0, 20),),
         (time(0, 0, 30),),
     ]
 
 
 def test_timedelta_from() -> None:
@@ -1916,20 +1917,15 @@
 )
 def test_strptime_empty(time_unit: TimeUnit, time_zone: str | None) -> None:
     ts = pl.Series([None]).cast(pl.Utf8).str.strptime(pl.Datetime(time_unit, time_zone))
     assert ts.dtype == pl.Datetime(time_unit, time_zone)
 
 
 def test_strptime_with_invalid_tz() -> None:
-    with pytest.raises(
-        ComputeError, match="unable to parse time zone: 'foo'"
-    ), pytest.warns(
-        FutureWarning,
-        match="time zones other than those in `zoneinfo.available_timezones",
-    ):
+    with pytest.raises(ComputeError, match="unable to parse time zone: 'foo'"):
         pl.Series(["2020-01-01 03:00:00"]).str.strptime(pl.Datetime("us", "foo"))
     with pytest.raises(
         ComputeError,
         match="Please either drop the time zone from the function call, or set it to UTC",
     ):
         pl.Series(["2020-01-01 03:00:00+01:00"]).str.strptime(
             pl.Datetime("us", "foo"), "%Y-%m-%d %H:%M:%S%z"
@@ -1959,20 +1955,15 @@
         match="could not find an appropriate format to parse dates, please define a fmt",
     ):
         pl.Series(["foobar"]).str.strptime(pl.Datetime)
 
 
 def test_convert_time_zone_invalid() -> None:
     ts = pl.Series(["2020-01-01"]).str.strptime(pl.Datetime)
-    with pytest.raises(
-        ComputeError, match="unable to parse time zone: 'foo'"
-    ), pytest.warns(
-        FutureWarning,
-        match="time zones other than those in `zoneinfo.available_timezones",
-    ):
+    with pytest.raises(ComputeError, match="unable to parse time zone: 'foo'"):
         ts.dt.replace_time_zone("UTC").dt.convert_time_zone("foo")
 
 
 def test_convert_time_zone_lazy_schema() -> None:
     ts_us = pl.Series(["2020-01-01"]).str.strptime(pl.Datetime("us", "UTC"))
     ts_ms = pl.Series(["2020-01-01"]).str.strptime(pl.Datetime("ms", "UTC"))
     ldf = pl.DataFrame({"ts_us": ts_us, "ts_ms": ts_ms}).lazy()
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/functions/test_as_datatype.py` & `polars_lts_cpu-0.18.5/tests/unit/functions/test_as_datatype.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/functions/test_functions.py` & `polars_lts_cpu-0.18.5/tests/unit/functions/test_functions.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 from __future__ import annotations
 
-import typing
 from datetime import timedelta
 from typing import Any, cast
 
 import numpy as np
 import pytest
 
 import polars as pl
@@ -345,15 +344,14 @@
         }
     )
     assert df.select(pl.col("a").cast(pl.UInt64).diff()).to_dict(False) == {
         "a": [None, -10, 20]
     }
 
 
-@typing.no_type_check
 def test_fill_null_unknown_output_type() -> None:
     df = pl.DataFrame(
         {
             "a": [
                 None,
                 2,
                 3,
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/functions/test_range.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_datetime.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,567 +1,723 @@
 from __future__ import annotations
 
+import sys
 from datetime import date, datetime, time, timedelta
 from typing import TYPE_CHECKING
 
-import pandas as pd
 import pytest
 
 import polars as pl
 from polars.datatypes import DTYPE_TEMPORAL_UNITS
-from polars.testing import assert_frame_equal
-from polars.utils.convert import get_zoneinfo as ZoneInfo
+from polars.dependencies import _ZONEINFO_AVAILABLE
+from polars.exceptions import ComputeError, InvalidOperationError
+from polars.testing import assert_series_equal
+
+if sys.version_info >= (3, 9):
+    from zoneinfo import ZoneInfo
+elif _ZONEINFO_AVAILABLE:
+    # Import from submodule due to typing issue with backports.zoneinfo package:
+    # https://github.com/pganssle/zoneinfo/issues/125
+    from backports.zoneinfo._zoneinfo import ZoneInfo
 
 if TYPE_CHECKING:
     from polars.type_aliases import TimeUnit
 
 
-def test_arange() -> None:
-    ldf = pl.LazyFrame({"a": [1, 1, 1]})
-    result = ldf.filter(pl.col("a") >= pl.arange(0, 3)).collect()
-    expected = pl.DataFrame({"a": [1, 1]})
-    assert_frame_equal(result, expected)
-
-
-def test_arange_decreasing() -> None:
-    assert pl.arange(10, 1, -2, eager=True).to_list() == list(range(10, 1, -2))
-
-
-def test_arange_expr() -> None:
-    df = pl.DataFrame({"a": ["foobar", "barfoo"]})
-    out = df.select([pl.arange(0, pl.col("a").count() * 10)])
-    assert out.shape == (20, 1)
-    assert out.to_series(0)[-1] == 19
-
-    # eager arange
-    out2 = pl.arange(0, 10, 2, eager=True)
-    assert out2.to_list() == [0, 2, 4, 6, 8]
-
-    out3 = pl.arange(pl.Series([0, 19]), pl.Series([3, 39]), step=2, eager=True)
-    assert out3.dtype == pl.List
-    assert out3[0].to_list() == [0, 2]
-
-    df = pl.DataFrame({"start": [1, 2, 3, 5, 5, 5], "stop": [8, 3, 12, 8, 8, 8]})
-
-    assert df.select(pl.arange(pl.lit(1), pl.col("stop") + 1).alias("test")).to_dict(
-        False
-    ) == {
-        "test": [
-            [1, 2, 3, 4, 5, 6, 7, 8],
-            [1, 2, 3],
-            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],
-            [1, 2, 3, 4, 5, 6, 7, 8],
-            [1, 2, 3, 4, 5, 6, 7, 8],
-            [1, 2, 3, 4, 5, 6, 7, 8],
-        ]
-    }
+@pytest.fixture()
+def series_of_int_dates() -> pl.Series:
+    return pl.Series([10000, 20000, 30000], dtype=pl.Date)
 
 
-def test_arange_name() -> None:
-    expected_name = "arange"
-    result_eager = pl.arange(0, 5, eager=True)
-    assert result_eager.name == expected_name
-
-    result_lazy = pl.select(pl.arange(0, 5)).to_series()
-    assert result_lazy.name == expected_name
-
-
-def test_date_range() -> None:
-    result = pl.date_range(
-        date(1985, 1, 1), date(2015, 7, 1), timedelta(days=1, hours=12), eager=True
-    )
-    assert len(result) == 7426
-    assert result.dt[0] == datetime(1985, 1, 1)
-    assert result.dt[1] == datetime(1985, 1, 2, 12, 0)
-    assert result.dt[2] == datetime(1985, 1, 4, 0, 0)
-    assert result.dt[-1] == datetime(2015, 6, 30, 12, 0)
-
-    for time_unit in DTYPE_TEMPORAL_UNITS:
-        rng = pl.date_range(
-            datetime(2020, 1, 1),
-            date(2020, 1, 2),
-            "2h",
-            time_unit=time_unit,
-            eager=True,
-        )
-        with pytest.warns(
-            DeprecationWarning, match="`Series.time_unit` is deprecated.*"
-        ):
-            assert rng.time_unit == time_unit
-        assert rng.shape == (13,)
-        assert rng.dt[0] == datetime(2020, 1, 1)
-        assert rng.dt[-1] == datetime(2020, 1, 2)
-
-    # if low/high are both date, range is also be date _iif_ the granularity is >= 1d
-    result = pl.date_range(date(2022, 1, 1), date(2022, 3, 1), "1mo", eager=True)
-    assert result.to_list() == [date(2022, 1, 1), date(2022, 2, 1), date(2022, 3, 1)]
-
-    result = pl.date_range(date(2022, 1, 1), date(2022, 1, 2), "1h30m", eager=True)
-    assert list(result) == [
-        datetime(2022, 1, 1, 0, 0),
-        datetime(2022, 1, 1, 1, 30),
-        datetime(2022, 1, 1, 3, 0),
-        datetime(2022, 1, 1, 4, 30),
-        datetime(2022, 1, 1, 6, 0),
-        datetime(2022, 1, 1, 7, 30),
-        datetime(2022, 1, 1, 9, 0),
-        datetime(2022, 1, 1, 10, 30),
-        datetime(2022, 1, 1, 12, 0),
-        datetime(2022, 1, 1, 13, 30),
-        datetime(2022, 1, 1, 15, 0),
-        datetime(2022, 1, 1, 16, 30),
-        datetime(2022, 1, 1, 18, 0),
-        datetime(2022, 1, 1, 19, 30),
-        datetime(2022, 1, 1, 21, 0),
-        datetime(2022, 1, 1, 22, 30),
-        datetime(2022, 1, 2, 0, 0),
-    ]
+@pytest.fixture()
+def series_of_str_dates() -> pl.Series:
+    return pl.Series(["2020-01-01 00:00:00.000000000", "2020-02-02 03:20:10.987654321"])
 
-    result = pl.date_range(
-        datetime(2022, 1, 1), datetime(2022, 1, 1, 0, 1), "987456321ns", eager=True
-    )
-    assert len(result) == 61
-    assert result.dtype.time_unit == "ns"  # type: ignore[union-attr]
-    assert result.dt.second()[-1] == 59
-    assert result.cast(pl.Utf8)[-1] == "2022-01-01 00:00:59.247379260"
+
+def test_dt_to_string(series_of_int_dates: pl.Series) -> None:
+    expected_str_dates = pl.Series(["1997-05-19", "2024-10-04", "2052-02-20"])
+
+    assert series_of_int_dates.dtype == pl.Date
+    assert_series_equal(series_of_int_dates.dt.to_string("%F"), expected_str_dates)
+
+    # Check strftime alias as well
+    assert_series_equal(series_of_int_dates.dt.strftime("%F"), expected_str_dates)
 
 
 @pytest.mark.parametrize(
-    ("time_unit", "expected_micros"),
-    [
-        ("ms", 986000),
-        ("us", 986759),
-        ("ns", 986759),
-        (None, 986759),
-    ],
-)
-def test_date_range_precision(time_unit: TimeUnit | None, expected_micros: int) -> None:
-    micros = 986759
-    start = datetime(2000, 5, 30, 1, 53, 4, micros)
-    stop = datetime(2000, 5, 31, 1, 53, 4, micros)
-    result = pl.date_range(start, stop, time_unit=time_unit, eager=True)
-    expected_start = start.replace(microsecond=expected_micros)
-    expected_stop = stop.replace(microsecond=expected_micros)
-    assert result[0] == expected_start
-    assert result[1] == expected_stop
-
-
-def test_range_invalid_unit() -> None:
-    with pytest.raises(pl.PolarsPanicError, match="'D' not supported"):
-        pl.date_range(
-            start=datetime(2021, 12, 16),
-            end=datetime(2021, 12, 16, 3),
-            interval="1D",
-            eager=True,
-        )
-
-
-def test_date_range_lazy_with_literals() -> None:
-    df = pl.DataFrame({"misc": ["x"]}).with_columns(
-        pl.date_range(
-            date(2000, 1, 1),
-            date(2023, 8, 31),
-            interval="987d",
-            eager=False,
-        ).alias("dts")
-    )
-    assert df.rows() == [
-        (
-            "x",
-            [
-                date(2000, 1, 1),
-                date(2002, 9, 14),
-                date(2005, 5, 28),
-                date(2008, 2, 9),
-                date(2010, 10, 23),
-                date(2013, 7, 6),
-                date(2016, 3, 19),
-                date(2018, 12, 1),
-                date(2021, 8, 14),
-            ],
-        )
-    ]
-    assert (
-        df.rows()[0][1]
-        == pd.date_range(
-            date(2000, 1, 1), date(2023, 12, 31), freq="987d"
-        ).date.tolist()
-    )
+    ("unit_attr", "expected"),
+    [
+        ("year", pl.Series(values=[1997, 2024, 2052], dtype=pl.Int32)),
+        ("month", pl.Series(values=[5, 10, 2], dtype=pl.UInt32)),
+        ("week", pl.Series(values=[21, 40, 8], dtype=pl.UInt32)),
+        ("day", pl.Series(values=[19, 4, 20], dtype=pl.UInt32)),
+        ("ordinal_day", pl.Series(values=[139, 278, 51], dtype=pl.UInt32)),
+    ],
+)
+def test_dt_extract_year_month_week_day_ordinal_day(
+    unit_attr: str,
+    expected: pl.Series,
+    series_of_int_dates: pl.Series,
+) -> None:
+    assert_series_equal(getattr(series_of_int_dates.dt, unit_attr)(), expected)
 
 
-@pytest.mark.parametrize("low", ["start", pl.col("start")])
-@pytest.mark.parametrize("high", ["stop", pl.col("stop")])
-def test_date_range_lazy_with_expressions(
-    low: str | pl.Expr, high: str | pl.Expr
+@pytest.mark.parametrize(
+    ("unit_attr", "expected"),
+    [
+        ("hour", pl.Series(values=[0, 3], dtype=pl.UInt32)),
+        ("minute", pl.Series(values=[0, 20], dtype=pl.UInt32)),
+        ("second", pl.Series(values=[0, 10], dtype=pl.UInt32)),
+        ("millisecond", pl.Series(values=[0, 987], dtype=pl.UInt32)),
+        ("microsecond", pl.Series(values=[0, 987654], dtype=pl.UInt32)),
+        ("nanosecond", pl.Series(values=[0, 987654321], dtype=pl.UInt32)),
+    ],
+)
+def test_strptime_extract_times(
+    unit_attr: str,
+    expected: pl.Series,
+    series_of_int_dates: pl.Series,
+    series_of_str_dates: pl.Series,
 ) -> None:
-    ldf = (
-        pl.DataFrame({"start": [date(2015, 6, 30)], "stop": [date(2022, 12, 31)]})
-        .with_columns(
-            pl.date_range(low, high, interval="678d", eager=False).alias("dts")
-        )
-        .lazy()
-    )
+    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
 
-    assert ldf.collect().rows() == [
-        (
-            date(2015, 6, 30),
-            date(2022, 12, 31),
-            [
-                date(2015, 6, 30),
-                date(2017, 5, 8),
-                date(2019, 3, 17),
-                date(2021, 1, 23),
-                date(2022, 12, 2),
-            ],
-        )
-    ]
+    assert_series_equal(getattr(s.dt, unit_attr)(), expected)
 
-    assert pl.DataFrame(
-        {
-            "start": [date(2000, 1, 1), date(2022, 6, 1)],
-            "stop": [date(2000, 1, 2), date(2022, 6, 2)],
-        }
-    ).with_columns(
-        pl.date_range(
-            low,
-            high,
-            interval="1d",
-            eager=True,
-        ).alias("dts")
-    ).to_dict(
-        False
-    ) == {
-        "start": [date(2000, 1, 1), date(2022, 6, 1)],
-        "stop": [date(2000, 1, 2), date(2022, 6, 2)],
-        "dts": [
-            [date(2000, 1, 1), date(2000, 1, 2)],
-            [date(2022, 6, 1), date(2022, 6, 2)],
-        ],
-    }
 
-    assert pl.DataFrame(
-        {
-            "start": [datetime(2000, 1, 1), datetime(2022, 6, 1)],
-            "stop": [datetime(2000, 1, 2), datetime(2022, 6, 2)],
-        }
-    ).with_columns(
-        pl.date_range(
-            low,
-            high,
-            interval="1d",
-            eager=True,
-        ).alias("dts")
-    ).to_dict(
-        False
-    ) == {
-        "start": [datetime(2000, 1, 1, 0, 0), datetime(2022, 6, 1, 0, 0)],
-        "stop": [datetime(2000, 1, 2, 0, 0), datetime(2022, 6, 2, 0, 0)],
-        "dts": [
-            [datetime(2000, 1, 1, 0, 0), datetime(2000, 1, 2, 0, 0)],
-            [datetime(2022, 6, 1, 0, 0), datetime(2022, 6, 2, 0, 0)],
-        ],
-    }
+@pytest.mark.parametrize("time_zone", [None, "Asia/Kathmandu"])
+@pytest.mark.parametrize(
+    ("attribute", "expected"),
+    [
+        ("date", date(2022, 1, 1)),
+        ("time", time(23)),
+    ],
+)
+def test_dt_date_and_time(
+    attribute: str, time_zone: None | str, expected: date | time
+) -> None:
+    ser = pl.Series([datetime(2022, 1, 1, 23)]).dt.replace_time_zone(time_zone)
+    result = getattr(ser.dt, attribute)().item()
+    assert result == expected
+
+
+@pytest.mark.parametrize("time_zone", [None, "Asia/Kathmandu"])
+@pytest.mark.parametrize("time_unit", ["us", "ns", "ms"])
+def test_dt_datetime(time_zone: str | None, time_unit: TimeUnit) -> None:
+    ser = (
+        pl.Series([datetime(2022, 1, 1, 23)])
+        .dt.cast_time_unit(time_unit)
+        .dt.replace_time_zone(time_zone)
+    )
+    result = ser.dt.datetime()
+    expected = datetime(2022, 1, 1, 23)
+    assert result.dtype == pl.Datetime(time_unit, None)
+    assert result.item() == expected
 
 
-def test_date_range_single_row_lazy_7110() -> None:
-    df = pl.DataFrame(
-        {
-            "name": ["A"],
-            "from": [date(2020, 1, 1)],
-            "to": [date(2020, 1, 2)],
-        }
-    )
-    result = df.with_columns(
-        pl.date_range(
-            start=pl.col("from"),
-            end=pl.col("to"),
-            interval="1d",
-            eager=False,
-        ).alias("date_range")
-    )
-    expected = pl.DataFrame(
-        {
-            "name": ["A"],
-            "from": [date(2020, 1, 1)],
-            "to": [date(2020, 1, 2)],
-            "date_range": [[date(2020, 1, 1), date(2020, 1, 2)]],
-        }
-    )
-    assert_frame_equal(result, expected)
+@pytest.mark.parametrize(
+    ("time_zone", "expected"),
+    [
+        (None, True),
+        ("Asia/Kathmandu", False),
+        ("UTC", True),
+    ],
+)
+@pytest.mark.parametrize("attribute", ["datetime", "date"])
+def test_local_datetime_sortedness(
+    time_zone: str | None, expected: bool, attribute: str
+) -> None:
+    ser = (pl.Series([datetime(2022, 1, 1, 23)]).dt.replace_time_zone(time_zone)).sort()
+    result = getattr(ser.dt, attribute)()
+    assert result.flags["SORTED_ASC"] == expected
+    assert result.flags["SORTED_DESC"] is False
+
+
+@pytest.mark.parametrize("time_zone", [None, "Asia/Kathmandu", "UTC"])
+def test_local_time_sortedness(time_zone: str | None) -> None:
+    ser = (pl.Series([datetime(2022, 1, 1, 23)]).dt.replace_time_zone(time_zone)).sort()
+    result = ser.dt.time()
+    assert result.flags["SORTED_ASC"] is False
+    assert result.flags["SORTED_DESC"] is False
+
+
+def test_dt_datetime_date_time_invalid() -> None:
+    with pytest.raises(ComputeError, match="expected Datetime"):
+        pl.Series([date(2021, 1, 2)]).dt.datetime()
+    with pytest.raises(ComputeError, match="expected Datetime or Date"):
+        pl.Series([time(23)]).dt.date()
+    with pytest.raises(ComputeError, match="expected Datetime"):
+        pl.Series([time(23)]).dt.datetime()
+    with pytest.raises(ComputeError, match="expected Datetime or Date"):
+        pl.Series([timedelta(1)]).dt.date()
+    with pytest.raises(ComputeError, match="expected Datetime"):
+        pl.Series([timedelta(1)]).dt.datetime()
+    with pytest.raises(ComputeError, match="expected Datetime, Date, or Time"):
+        pl.Series([timedelta(1)]).dt.time()
 
 
-def test_date_range_invalid_time_zone() -> None:
-    with pytest.raises(
-        pl.ComputeError, match="unable to parse time zone: 'foo'"
-    ), pytest.warns(
-        DeprecationWarning,
-        match="time zones other than those in `zoneinfo.available_timezones",
-    ):
-        pl.date_range(
-            datetime(2001, 1, 1),
-            datetime(2001, 1, 3),
-            interval="1d",
-            time_zone="foo",
-            eager=True,
-        )
+@pytest.mark.parametrize(
+    ("dt", "expected"),
+    [
+        (datetime(2022, 3, 15, 3), datetime(2022, 3, 1, 3)),
+        (datetime(2022, 3, 15, 3, 2, 1, 123000), datetime(2022, 3, 1, 3, 2, 1, 123000)),
+        (datetime(2022, 3, 15), datetime(2022, 3, 1)),
+        (datetime(2022, 3, 1), datetime(2022, 3, 1)),
+    ],
+)
+@pytest.mark.parametrize(
+    ("tzinfo", "time_zone"),
+    [
+        (None, None),
+        (ZoneInfo("Asia/Kathmandu"), "Asia/Kathmandu"),
+    ],
+)
+@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
+def test_month_start_datetime(
+    dt: datetime,
+    expected: datetime,
+    time_unit: TimeUnit,
+    tzinfo: ZoneInfo | None,
+    time_zone: str | None,
+) -> None:
+    ser = pl.Series([dt]).dt.replace_time_zone(time_zone).dt.cast_time_unit(time_unit)
+    result = ser.dt.month_start().item()
+    assert result == expected.replace(tzinfo=tzinfo)
 
 
-def test_timezone_aware_date_range() -> None:
-    low = datetime(2022, 10, 17, 10, tzinfo=ZoneInfo("Asia/Shanghai"))
-    high = datetime(2022, 11, 17, 10, tzinfo=ZoneInfo("Asia/Shanghai"))
+@pytest.mark.parametrize(
+    ("dt", "expected"),
+    [
+        (date(2022, 3, 15), date(2022, 3, 1)),
+        (date(2022, 3, 31), date(2022, 3, 1)),
+    ],
+)
+def test_month_start_date(dt: date, expected: date) -> None:
+    ser = pl.Series([dt])
+    result = ser.dt.month_start().item()
+    assert result == expected
+
+
+@pytest.mark.parametrize(
+    ("dt", "expected"),
+    [
+        (datetime(2022, 3, 15, 3), datetime(2022, 3, 31, 3)),
+        (
+            datetime(2022, 3, 15, 3, 2, 1, 123000),
+            datetime(2022, 3, 31, 3, 2, 1, 123000),
+        ),
+        (datetime(2022, 3, 15), datetime(2022, 3, 31)),
+        (datetime(2022, 3, 31), datetime(2022, 3, 31)),
+    ],
+)
+@pytest.mark.parametrize(
+    ("tzinfo", "time_zone"),
+    [
+        (None, None),
+        (ZoneInfo("Asia/Kathmandu"), "Asia/Kathmandu"),
+    ],
+)
+@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
+def test_month_end_datetime(
+    dt: datetime,
+    expected: datetime,
+    time_unit: TimeUnit,
+    tzinfo: ZoneInfo | None,
+    time_zone: str | None,
+) -> None:
+    ser = pl.Series([dt]).dt.replace_time_zone(time_zone).dt.cast_time_unit(time_unit)
+    result = ser.dt.month_end().item()
+    assert result == expected.replace(tzinfo=tzinfo)
+
+
+@pytest.mark.parametrize(
+    ("dt", "expected"),
+    [
+        (date(2022, 3, 15), date(2022, 3, 31)),
+        (date(2022, 3, 31), date(2022, 3, 31)),
+    ],
+)
+def test_month_end_date(dt: date, expected: date) -> None:
+    ser = pl.Series([dt])
+    result = ser.dt.month_end().item()
+    assert result == expected
 
-    assert pl.date_range(
-        low, high, interval=timedelta(days=5), eager=True
-    ).to_list() == [
-        datetime(2022, 10, 17, 10, 0, tzinfo=ZoneInfo(key="Asia/Shanghai")),
-        datetime(2022, 10, 22, 10, 0, tzinfo=ZoneInfo(key="Asia/Shanghai")),
-        datetime(2022, 10, 27, 10, 0, tzinfo=ZoneInfo(key="Asia/Shanghai")),
-        datetime(2022, 11, 1, 10, 0, tzinfo=ZoneInfo(key="Asia/Shanghai")),
-        datetime(2022, 11, 6, 10, 0, tzinfo=ZoneInfo(key="Asia/Shanghai")),
-        datetime(2022, 11, 11, 10, 0, tzinfo=ZoneInfo(key="Asia/Shanghai")),
-        datetime(2022, 11, 16, 10, 0, tzinfo=ZoneInfo(key="Asia/Shanghai")),
-    ]
 
+def test_month_start_end_invalid() -> None:
+    ser = pl.Series([time(1, 2, 3)])
     with pytest.raises(
-        ValueError,
-        match="Cannot mix different timezone aware datetimes. "
-        "Got: 'Asia/Shanghai' and 'None'",
+        InvalidOperationError,
+        match=r"`month_start` operation not supported for dtype `time` \(expected: date/datetime\)",
     ):
-        pl.date_range(
-            low,
-            high.replace(tzinfo=None),
-            interval=timedelta(days=5),
-            time_zone="UTC",
-            eager=True,
-        )
-
+        ser.dt.month_start()
     with pytest.raises(
-        ValueError,
-        match="Given time_zone is different from that of timezone aware datetimes. "
-        "Given: 'UTC', got: 'Asia/Shanghai'.",
+        InvalidOperationError,
+        match=r"`month_end` operation not supported for dtype `time` \(expected: date/datetime\)",
     ):
-        pl.date_range(
-            low, high, interval=timedelta(days=5), time_zone="UTC", eager=True
-        )
+        ser.dt.month_end()
 
 
-def test_tzaware_date_range_crossing_dst_hourly() -> None:
-    result = pl.date_range(
-        datetime(2021, 11, 7),
-        datetime(2021, 11, 7, 2),
-        "1h",
-        time_zone="US/Central",
+@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
+def test_base_utc_offset(time_unit: TimeUnit) -> None:
+    ser = pl.date_range(
+        datetime(2011, 12, 29),
+        datetime(2012, 1, 1),
+        "2d",
+        time_zone="Pacific/Apia",
         eager=True,
-    )
-    assert result.to_list() == [
-        datetime(2021, 11, 7, 0, 0, tzinfo=ZoneInfo("US/Central")),
-        datetime(2021, 11, 7, 1, 0, tzinfo=ZoneInfo("US/Central")),
-        datetime(2021, 11, 7, 1, 0, fold=1, tzinfo=ZoneInfo("US/Central")),
-        datetime(2021, 11, 7, 2, 0, tzinfo=ZoneInfo("US/Central")),
-    ]
+    ).dt.cast_time_unit(time_unit)
+    result = ser.dt.base_utc_offset().rename("base_utc_offset")
+    expected = pl.Series(
+        "base_utc_offset",
+        [-11 * 3600 * 1000, 13 * 3600 * 1000],
+        dtype=pl.Duration("ms"),
+    )
+    assert_series_equal(result, expected)
 
 
-def test_tzaware_date_range_crossing_dst_daily() -> None:
-    result = pl.date_range(
-        datetime(2021, 11, 7),
-        datetime(2021, 11, 11),
-        "2d",
-        time_zone="US/Central",
+def test_base_utc_offset_lazy_schema() -> None:
+    ser = pl.date_range(
+        datetime(2020, 10, 25),
+        datetime(2020, 10, 26),
+        time_zone="Europe/London",
         eager=True,
     )
-    assert result.to_list() == [
-        datetime(2021, 11, 7, 0, 0, tzinfo=ZoneInfo("US/Central")),
-        datetime(2021, 11, 9, 0, 0, tzinfo=ZoneInfo("US/Central")),
-        datetime(2021, 11, 11, 0, 0, tzinfo=ZoneInfo("US/Central")),
-    ]
+    df = pl.DataFrame({"ts": ser}).lazy()
+    result = df.with_columns(base_utc_offset=pl.col("ts").dt.base_utc_offset()).schema
+    expected = {
+        "ts": pl.Datetime(time_unit="us", time_zone="Europe/London"),
+        "base_utc_offset": pl.Duration(time_unit="ms"),
+    }
+    assert result == expected
 
 
-def test_tzaware_date_range_crossing_dst_weekly() -> None:
-    result = pl.date_range(
-        datetime(2021, 11, 7),
-        datetime(2021, 11, 20),
-        "1w",
-        time_zone="US/Central",
+def test_base_utc_offset_invalid() -> None:
+    ser = pl.date_range(datetime(2020, 10, 25), datetime(2020, 10, 26), eager=True)
+    with pytest.raises(
+        InvalidOperationError,
+        match=r"`base_utc_offset` operation not supported for dtype `datetime\[s\]` \(expected: time-zone-aware datetime\)",
+    ):
+        ser.dt.base_utc_offset().rename("base_utc_offset")
+
+
+@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
+def test_dst_offset(time_unit: TimeUnit) -> None:
+    ser = pl.date_range(
+        datetime(2020, 10, 25),
+        datetime(2020, 10, 26),
+        time_zone="Europe/London",
         eager=True,
-    )
-    assert result.to_list() == [
-        datetime(2021, 11, 7, 0, 0, tzinfo=ZoneInfo("US/Central")),
-        datetime(2021, 11, 14, 0, 0, tzinfo=ZoneInfo("US/Central")),
-    ]
+    ).dt.cast_time_unit(time_unit)
+    result = ser.dt.dst_offset().rename("dst_offset")
+    expected = pl.Series("dst_offset", [3_600 * 1_000, 0], dtype=pl.Duration("ms"))
+    assert_series_equal(result, expected)
 
 
-def test_tzaware_date_range_crossing_dst_monthly() -> None:
-    result = pl.date_range(
-        datetime(2021, 11, 7),
-        datetime(2021, 12, 20),
-        "1mo",
-        time_zone="US/Central",
+def test_dst_offset_lazy_schema() -> None:
+    ser = pl.date_range(
+        datetime(2020, 10, 25),
+        datetime(2020, 10, 26),
+        time_zone="Europe/London",
         eager=True,
     )
-    assert result.to_list() == [
-        datetime(2021, 11, 7, 0, 0, tzinfo=ZoneInfo("US/Central")),
-        datetime(2021, 12, 7, 0, 0, tzinfo=ZoneInfo("US/Central")),
-    ]
+    df = pl.DataFrame({"ts": ser}).lazy()
+    result = df.with_columns(dst_offset=pl.col("ts").dt.dst_offset()).schema
+    expected = {
+        "ts": pl.Datetime(time_unit="us", time_zone="Europe/London"),
+        "dst_offset": pl.Duration(time_unit="ms"),
+    }
+    assert result == expected
 
 
-def test_date_range_with_unsupported_datetimes() -> None:
-    with pytest.raises(
-        pl.ComputeError,
-        match=r"datetime '2021-11-07 01:00:00' is ambiguous in time zone 'US/Central'",
-    ):
-        pl.date_range(
-            datetime(2021, 11, 7, 1),
-            datetime(2021, 11, 7, 2),
-            "1h",
-            time_zone="US/Central",
-            eager=True,
-        )
+def test_dst_offset_invalid() -> None:
+    ser = pl.date_range(datetime(2020, 10, 25), datetime(2020, 10, 26), eager=True)
     with pytest.raises(
-        pl.ComputeError,
-        match=r"datetime '2021-03-28 02:30:00' is non-existent in time zone 'Europe/Vienna'",
+        InvalidOperationError,
+        match=r"`dst_offset` operation not supported for dtype `datetime\[s\]` \(expected: time-zone-aware datetime\)",
     ):
-        pl.date_range(
-            datetime(2021, 3, 28, 2, 30),
-            datetime(2021, 3, 28, 4),
-            "1h",
-            time_zone="Europe/Vienna",
-            eager=True,
-        )
-
-
-def test_date_range_descending() -> None:
-    with pytest.raises(pl.ComputeError, match="'start' cannot be greater than 'stop'"):
-        pl.date_range(
-            datetime(2000, 3, 20), datetime(2000, 3, 5), interval="1h", eager=True
-        )
-    with pytest.raises(pl.ComputeError, match="'interval' cannot be negative"):
-        pl.date_range(
-            datetime(2000, 3, 20), datetime(2000, 3, 21), interval="-1h", eager=True
-        )
-
-
-def test_date_range_end_of_month_5441() -> None:
-    start = date(2020, 1, 31)
-    stop = date(2021, 1, 31)
-    with pytest.raises(
-        pl.ComputeError, match=r"cannot advance '2020-01-31 00:00:00' by 1 month\(s\)"
-    ):
-        pl.date_range(start, stop, interval="1mo", eager=True)
+        ser.dt.dst_offset().rename("dst_offset")
 
 
-def test_date_range_name() -> None:
-    expected_name = "date"
-    result_eager = pl.date_range(date(2020, 1, 1), date(2020, 1, 3), eager=True)
-    assert result_eager.name == expected_name
-
-    result_lazy = pl.select(
-        pl.date_range(date(2020, 1, 1), date(2020, 1, 3), eager=False)
-    ).to_series()
-    assert result_lazy.name == expected_name
-
-
-def test_time_range_lit() -> None:
-    for eager in (True, False):
-        tm = pl.select(
-            pl.time_range(
-                start=time(1, 2, 3),
-                end=time(23, 59, 59),
-                interval="5h45m10s333ms",
-                closed="right",
-                eager=eager,
-            ).alias("tm")
-        )
-        if not eager:
-            tm = tm.select(pl.col("tm").explode())
-        assert tm["tm"].to_list() == [
-            time(6, 47, 13, 333000),
-            time(12, 32, 23, 666000),
-            time(18, 17, 33, 999000),
-        ]
+@pytest.mark.parametrize(
+    ("time_unit", "expected"),
+    [
+        ("d", pl.Series(values=[18262, 18294], dtype=pl.Int32)),
+        ("s", pl.Series(values=[1_577_836_800, 1_580_613_610], dtype=pl.Int64)),
+        (
+            "ms",
+            pl.Series(values=[1_577_836_800_000, 1_580_613_610_000], dtype=pl.Int64),
+        ),
+    ],
+)
+def test_strptime_epoch(
+    time_unit: TimeUnit,
+    expected: pl.Series,
+    series_of_str_dates: pl.Series,
+) -> None:
+    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
 
-        # validate unset start/end
-        tm = pl.select(
-            pl.time_range(
-                interval="5h45m10s333ms",
-                eager=eager,
-            ).alias("tm")
-        )
-        if not eager:
-            tm = tm.select(pl.col("tm").explode())
-        assert tm["tm"].to_list() == [
-            time(0, 0),
-            time(5, 45, 10, 333000),
-            time(11, 30, 20, 666000),
-            time(17, 15, 30, 999000),
-            time(23, 0, 41, 332000),
-        ]
+    assert_series_equal(s.dt.epoch(time_unit=time_unit), expected)
 
-        tm = pl.select(
-            pl.time_range(
-                start=pl.lit(time(23, 59, 59, 999980)),
-                interval="10000ns",
-                eager=eager,
-            ).alias("tm")
-        )
-        tm = tm.select(pl.col("tm").explode())
-        assert tm["tm"].to_list() == [
-            time(23, 59, 59, 999980),
-            time(23, 59, 59, 999990),
-        ]
 
+def test_strptime_fractional_seconds(series_of_str_dates: pl.Series) -> None:
+    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
 
-def test_time_range_expr() -> None:
+    assert_series_equal(
+        s.dt.second(fractional=True),
+        pl.Series([0.0, 10.987654321], dtype=pl.Float64),
+    )
+
+
+@pytest.mark.parametrize(
+    ("unit_attr", "expected"),
+    [
+        ("days", pl.Series([1])),
+        ("hours", pl.Series([24])),
+        ("minutes", pl.Series([24 * 60])),
+        ("seconds", pl.Series([3600 * 24])),
+        ("milliseconds", pl.Series([3600 * 24 * int(1e3)])),
+        ("microseconds", pl.Series([3600 * 24 * int(1e6)])),
+        ("nanoseconds", pl.Series([3600 * 24 * int(1e9)])),
+    ],
+)
+def test_duration_extract_times(
+    unit_attr: str,
+    expected: pl.Series,
+) -> None:
+    duration = pl.Series([datetime(2022, 1, 2)]) - pl.Series([datetime(2022, 1, 1)])
+
+    assert_series_equal(getattr(duration.dt, unit_attr)(), expected)
+
+
+@pytest.mark.parametrize(
+    ("time_unit", "every"),
+    [
+        ("ms", "1h"),
+        ("us", "1h0m0s"),
+        ("ns", timedelta(hours=1)),
+    ],
+    ids=["milliseconds", "microseconds", "nanoseconds"],
+)
+def test_truncate(
+    time_unit: TimeUnit,
+    every: str | timedelta,
+) -> None:
+    start, stop = datetime(2022, 1, 1), datetime(2022, 1, 2)
+    s = pl.date_range(
+        start,
+        stop,
+        timedelta(minutes=30),
+        time_unit=time_unit,
+        eager=True,
+    ).alias(f"dates[{time_unit}]")
+
+    # can pass strings and time-deltas
+    out = s.dt.truncate(every)
+    assert out.dt[0] == start
+    assert out.dt[1] == start
+    assert out.dt[2] == start + timedelta(hours=1)
+    assert out.dt[3] == start + timedelta(hours=1)
+    # ...
+    assert out.dt[-3] == stop - timedelta(hours=1)
+    assert out.dt[-2] == stop - timedelta(hours=1)
+    assert out.dt[-1] == stop
+
+
+@pytest.mark.parametrize(
+    ("time_unit", "every"),
+    [
+        ("ms", "1h"),
+        ("us", "1h0m0s"),
+        ("ns", timedelta(hours=1)),
+    ],
+    ids=["milliseconds", "microseconds", "nanoseconds"],
+)
+def test_round(
+    time_unit: TimeUnit,
+    every: str | timedelta,
+) -> None:
+    start, stop = datetime(2022, 1, 1), datetime(2022, 1, 2)
+    s = pl.date_range(
+        start,
+        stop,
+        timedelta(minutes=30),
+        time_unit=time_unit,
+        eager=True,
+    ).alias(f"dates[{time_unit}]")
+
+    # can pass strings and time-deltas
+    out = s.dt.round(every)
+    assert out.dt[0] == start
+    assert out.dt[1] == start + timedelta(hours=1)
+    assert out.dt[2] == start + timedelta(hours=1)
+    assert out.dt[3] == start + timedelta(hours=2)
+    # ...
+    assert out.dt[-3] == stop - timedelta(hours=1)
+    assert out.dt[-2] == stop
+    assert out.dt[-1] == stop
+
+
+@pytest.mark.parametrize(
+    ("time_unit", "date_in_that_unit"),
+    [
+        ("ns", [978307200000000000, 981022089000000000]),
+        ("us", [978307200000000, 981022089000000]),
+        ("ms", [978307200000, 981022089000]),
+    ],
+    ids=["nanoseconds", "microseconds", "milliseconds"],
+)
+def test_cast_time_units(
+    time_unit: TimeUnit,
+    date_in_that_unit: list[int],
+) -> None:
+    dates = pl.Series([datetime(2001, 1, 1), datetime(2001, 2, 1, 10, 8, 9)])
+
+    assert dates.dt.cast_time_unit(time_unit).cast(int).to_list() == date_in_that_unit
+
+
+def test_epoch_matches_timestamp() -> None:
+    dates = pl.Series([datetime(2001, 1, 1), datetime(2001, 2, 1, 10, 8, 9)])
+
+    for unit in DTYPE_TEMPORAL_UNITS:
+        assert_series_equal(dates.dt.epoch(unit), dates.dt.timestamp(unit))
+
+    assert_series_equal(dates.dt.epoch("s"), dates.dt.timestamp("ms") // 1000)
+    assert_series_equal(
+        dates.dt.epoch("d"),
+        (dates.dt.timestamp("ms") // (1000 * 3600 * 24)).cast(pl.Int32),
+    )
+
+
+@pytest.mark.parametrize(
+    ("tzinfo", "time_zone"),
+    [(None, None), (ZoneInfo("Asia/Kathmandu"), "Asia/Kathmandu")],
+)
+def test_date_time_combine(tzinfo: ZoneInfo | None, time_zone: str | None) -> None:
+    # Define a DataFrame with columns for datetime, date, and time
     df = pl.DataFrame(
         {
-            "start": pl.time_range(interval="6h", eager=True),
-            "stop": pl.time_range(start=time(2, 59), interval="5h59m", eager=True),
+            "dtm": [
+                datetime(2022, 12, 31, 10, 30, 45),
+                datetime(2023, 7, 5, 23, 59, 59),
+            ],
+            "dt": [
+                date(2022, 10, 10),
+                date(2022, 7, 5),
+            ],
+            "tm": [
+                time(1, 2, 3, 456000),
+                time(7, 8, 9, 101000),
+            ],
         }
-    ).with_columns(
-        intervals=pl.time_range("start", pl.col("stop"), interval="1h29m", eager=False)
     )
-    # shape: (4, 3)
-    # 
-    #  start     stop      intervals                      
-    #  ---       ---       ---                            
-    #  time      time      list[time]                     
-    # 
-    #  00:00:00  02:59:00  [00:00:00, 01:29:00, 02:58:00] 
-    #  06:00:00  08:58:00  [06:00:00, 07:29:00, 08:58:00] 
-    #  12:00:00  14:57:00  [12:00:00, 13:29:00]           
-    #  18:00:00  20:56:00  [18:00:00, 19:29:00]           
-    # 
-    assert df.rows() == [
-        (time(0, 0), time(2, 59), [time(0, 0), time(1, 29), time(2, 58)]),
-        (time(6, 0), time(8, 58), [time(6, 0), time(7, 29), time(8, 58)]),
-        (time(12, 0), time(14, 57), [time(12, 0), time(13, 29)]),
-        (time(18, 0), time(20, 56), [time(18, 0), time(19, 29)]),
+    df = df.with_columns(pl.col("dtm").dt.replace_time_zone(time_zone))
+
+    # Combine datetime/date with time
+    df = df.select(
+        [
+            pl.col("dtm").dt.combine(pl.col("tm")).alias("d1"),  # datetime & time
+            pl.col("dt").dt.combine(pl.col("tm")).alias("d2"),  # date & time
+            pl.col("dt").dt.combine(time(4, 5, 6)).alias("d3"),  # date & specified time
+        ]
+    )
+
+    # Assert that the new columns have the expected values and datatypes
+    expected_dict = {
+        "d1": [  # Time component should be overwritten by `tm` values
+            datetime(2022, 12, 31, 1, 2, 3, 456000, tzinfo=tzinfo),
+            datetime(2023, 7, 5, 7, 8, 9, 101000, tzinfo=tzinfo),
+        ],
+        "d2": [  # Both date and time components combined "as-is" into new datetime
+            datetime(2022, 10, 10, 1, 2, 3, 456000),
+            datetime(2022, 7, 5, 7, 8, 9, 101000),
+        ],
+        "d3": [  # New datetime should use specified time component
+            datetime(2022, 10, 10, 4, 5, 6),
+            datetime(2022, 7, 5, 4, 5, 6),
+        ],
+    }
+    assert df.to_dict(False) == expected_dict
+
+    expected_schema = {
+        "d1": pl.Datetime("us", time_zone),
+        "d2": pl.Datetime("us"),
+        "d3": pl.Datetime("us"),
+    }
+    assert df.schema == expected_schema
+
+
+def test_combine_unsupported_types() -> None:
+    with pytest.raises(ComputeError, match="expected Date or Datetime, got time"):
+        pl.Series([time(1, 2)]).dt.combine(time(3, 4))
+
+
+@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
+@pytest.mark.parametrize("time_zone", ["Asia/Kathmandu", None])
+def test_combine_lazy_schema_datetime(
+    time_zone: str | None,
+    time_unit: TimeUnit,
+) -> None:
+    df = pl.DataFrame({"ts": pl.Series([datetime(2020, 1, 1)])})
+    df = df.with_columns(pl.col("ts").dt.replace_time_zone(time_zone))
+    result = (
+        df.lazy()
+        .select(pl.col("ts").dt.combine(time(1, 2, 3), time_unit=time_unit))
+        .dtypes
+    )
+    expected = [pl.Datetime(time_unit, time_zone)]
+    assert result == expected
+
+
+@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
+def test_combine_lazy_schema_date(time_unit: TimeUnit) -> None:
+    df = pl.DataFrame({"ts": pl.Series([date(2020, 1, 1)])})
+    result = (
+        df.lazy()
+        .select(pl.col("ts").dt.combine(time(1, 2, 3), time_unit=time_unit))
+        .dtypes
+    )
+    expected = [pl.Datetime(time_unit, None)]
+    assert result == expected
+
+
+def test_is_leap_year() -> None:
+    assert pl.date_range(
+        datetime(1990, 1, 1), datetime(2004, 1, 1), "1y", eager=True
+    ).dt.is_leap_year().to_list() == [
+        False,
+        False,
+        True,  # 1992
+        False,
+        False,
+        False,
+        True,  # 1996
+        False,
+        False,
+        False,
+        True,  # 2000
+        False,
+        False,
+        False,
+        True,  # 2004
     ]
 
 
-def test_time_range_name() -> None:
-    expected_name = "time"
-    result_eager = pl.time_range(time(10), time(12), eager=True)
-    assert result_eager.name == expected_name
-
-    result_lazy = pl.select(pl.time_range(time(10), time(12), eager=False)).to_series()
-    assert result_lazy.name == expected_name
-
-
-def test_deprecated_name_arg() -> None:
-    name = "x"
-    with pytest.deprecated_call():
-        result_lazy = pl.date_range(date(2023, 1, 1), date(2023, 1, 3), name=name)
-        assert result_lazy.meta.output_name() == name
-
-    with pytest.deprecated_call():
-        result_eager = pl.date_range(
-            date(2023, 1, 1), date(2023, 1, 3), name=name, eager=True
-        )
-        assert result_eager.name == name
-
-    with pytest.deprecated_call():
-        result_lazy = pl.time_range(time(10), time(12), name=name)
-        assert result_lazy.meta.output_name() == name
-
-    with pytest.deprecated_call():
-        result_eager = pl.time_range(time(10), time(12), name=name, eager=True)
-        assert result_eager.name == name
+def test_quarter() -> None:
+    assert pl.date_range(
+        datetime(2022, 1, 1), datetime(2022, 12, 1), "1mo", eager=True
+    ).dt.quarter().to_list() == [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4]
+
+
+def test_date_offset() -> None:
+    df = pl.DataFrame(
+        {
+            "dates": pl.date_range(
+                datetime(2000, 1, 1), datetime(2020, 1, 1), "1y", eager=True
+            )
+        }
+    )
+
+    # Add two new columns to the DataFrame using the offset_by() method
+    df = df.with_columns(
+        [
+            df["dates"].dt.offset_by("1y").alias("date_plus_1y"),
+            df["dates"].dt.offset_by("-1y2mo").alias("date_min"),
+        ]
+    )
+
+    # Assert that the day of the month for all the dates in new columns is 1
+    assert (df["date_plus_1y"].dt.day() == 1).all()
+    assert (df["date_min"].dt.day() == 1).all()
+
+    # Assert that the 'date_min' column contains the expected list of dates
+    expected_dates = [datetime(year, 11, 1, 0, 0) for year in range(1998, 2019)]
+    assert df["date_min"].to_list() == expected_dates
+
+
+@pytest.mark.parametrize("time_zone", ["US/Central", None])
+def test_offset_by_crossing_dst(time_zone: str | None) -> None:
+    ser = pl.Series([datetime(2021, 11, 7)]).dt.replace_time_zone(time_zone)
+    result = ser.dt.offset_by("1d")
+    expected = pl.Series([datetime(2021, 11, 8)]).dt.replace_time_zone(time_zone)
+    assert_series_equal(result, expected)
+
+
+def test_negative_offset_by_err_msg_8464() -> None:
+    with pytest.raises(
+        ComputeError, match=r"cannot advance '2022-03-30 00:00:00' by -1 month\(s\)"
+    ):
+        pl.Series([datetime(2022, 3, 30)]).dt.offset_by("-1mo")
+
+
+def test_offset_by_truncate_sorted_flag() -> None:
+    s = pl.Series([datetime(2001, 1, 1), datetime(2001, 1, 2)])
+    s = s.set_sorted()
+
+    assert s.flags["SORTED_ASC"]
+    s1 = s.dt.offset_by("1d")
+    assert s1.to_list() == [datetime(2001, 1, 2), datetime(2001, 1, 3)]
+    assert s1.flags["SORTED_ASC"]
+    s2 = s1.dt.truncate("1mo")
+    assert s2.flags["SORTED_ASC"]
+
+
+@pytest.mark.parametrize(
+    ("duration", "input_date", "expected"),
+    [
+        ("1mo_saturating", date(2018, 1, 31), date(2018, 2, 28)),
+        ("1y_saturating", date(2024, 2, 29), date(2025, 2, 28)),
+        ("1y1mo_saturating", date(2024, 1, 30), date(2025, 2, 28)),
+    ],
+)
+def test_offset_by_saturating_8217_8474(
+    duration: str, input_date: date, expected: date
+) -> None:
+    result = pl.Series([input_date]).dt.offset_by(duration).item()
+    assert result == expected
+
+
+def test_year_empty_df() -> None:
+    df = pl.DataFrame(pl.Series(name="date", dtype=pl.Date))
+    assert df.select(pl.col("date").dt.year()).dtypes == [pl.Int32]
+
+
+@pytest.mark.parametrize(
+    "time_unit",
+    ["ms", "us", "ns"],
+    ids=["milliseconds", "microseconds", "nanoseconds"],
+)
+def test_weekday(time_unit: TimeUnit) -> None:
+    friday = pl.Series([datetime(2023, 2, 17)])
+
+    assert friday.dt.cast_time_unit(time_unit).dt.weekday()[0] == 5
+    assert friday.cast(pl.Date).dt.weekday()[0] == 5
+
+
+@pytest.mark.parametrize(
+    ("values", "expected_median"),
+    [
+        ([], None),
+        ([None, None], None),
+        ([date(2022, 1, 1)], date(2022, 1, 1)),
+        ([date(2022, 1, 1), date(2022, 1, 2), date(2022, 1, 3)], date(2022, 1, 2)),
+        ([date(2022, 1, 1), date(2022, 1, 2), date(2024, 5, 15)], date(2022, 1, 2)),
+    ],
+    ids=["empty", "Nones", "single", "spread_even", "spread_skewed"],
+)
+def test_median(values: list[date | None], expected_median: date | None) -> None:
+    result = pl.Series(values).cast(pl.Date).dt.median()
+    assert result == expected_median
+
+
+@pytest.mark.parametrize(
+    ("values", "expected_mean"),
+    [
+        ([], None),
+        ([None, None], None),
+        ([date(2022, 1, 1)], date(2022, 1, 1)),
+        ([date(2022, 1, 1), date(2022, 1, 2), date(2022, 1, 3)], date(2022, 1, 2)),
+        ([date(2022, 1, 1), date(2022, 1, 2), date(2024, 5, 15)], date(2022, 10, 16)),
+    ],
+    ids=["empty", "Nones", "single", "spread_even", "spread_skewed"],
+)
+def test_mean(values: list[date | None], expected_mean: date | None) -> None:
+    result = pl.Series(values).cast(pl.Date).dt.mean()
+    assert result == expected_mean
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/functions/test_repeat.py` & `polars_lts_cpu-0.18.5/tests/unit/functions/test_repeat.py`

 * *Files 6% similar despite different names*

```diff
@@ -51,14 +51,17 @@
 
 def test_repeat_expr_input_lazy() -> None:
     df = pl.DataFrame({"a": [3, 2, 1]})
     result = df.select(pl.repeat(1, n=pl.col("a"))).to_series()
     expected = pl.Series("repeat", [1, 1, 1], dtype=pl.Int32)
     assert_series_equal(result, expected)
 
+    df = pl.DataFrame({"a": [3, 2, 1]})
+    assert df.select(pl.repeat(pl.sum("a"), n=2)).to_series().to_list() == [6, 6]
+
 
 def test_repeat_n_zero() -> None:
     assert pl.repeat(1, n=0, eager=True).len() == 0
 
 
 @pytest.mark.parametrize(
     "n",
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json` & `polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/_delta_log/00000000000000000000.json`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json` & `polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/_delta_log/00000000000000000001.json`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet` & `polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/part-00000-e42312d7-60e5-454d-acbc-db192d220e73-c000.snappy.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet` & `polars_lts_cpu-0.18.5/tests/unit/io/files/delta-table/part-00000-e4a999da-df45-4fb0-bdc4-d999fc0f58aa-c000.snappy.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/example.xlsx` & `polars_lts_cpu-0.18.5/tests/unit/io/files/example.xlsx`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/foods1.ipc` & `polars_lts_cpu-0.18.5/tests/unit/io/files/foods1.ipc`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/foods1.ndjson` & `polars_lts_cpu-0.18.5/tests/unit/io/files/foods1.ndjson`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/foods1.parquet` & `polars_lts_cpu-0.18.5/tests/unit/io/files/foods1.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/foods2.ipc` & `polars_lts_cpu-0.18.5/tests/unit/io/files/foods2.ipc`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/foods2.ndjson` & `polars_lts_cpu-0.18.5/tests/unit/io/files/foods2.ndjson`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/foods2.parquet` & `polars_lts_cpu-0.18.5/tests/unit/io/files/foods2.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/files/small.parquet` & `polars_lts_cpu-0.18.5/tests/unit/io/files/small.parquet`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_avro.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_avro.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_csv.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_csv.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 from __future__ import annotations
 
 import gzip
 import io
+import sys
 import textwrap
-import typing
 import zlib
 from datetime import date, datetime, time, timedelta, timezone
 from typing import TYPE_CHECKING
 
 import numpy as np
 import pytest
 
@@ -1148,15 +1148,14 @@
     pl.DataFrame({"x": ["A"] * N + ["B"] * N}).write_csv(f)
     f.seek(0)
     assert pl.read_csv(f, dtypes={"x": pl.Categorical}, sample_size=10).unique(
         maintain_order=True
     )["x"].to_list() == ["A", "B"]
 
 
-@typing.no_type_check
 def test_batched_csv_reader(foods_file_path: Path) -> None:
     reader = pl.read_csv_batched(foods_file_path, batch_size=4)
     batches = reader.next_batches(5)
 
     assert batches is not None
     assert len(batches) == 5
     assert batches[0].to_dict(False) == {
@@ -1171,21 +1170,21 @@
         "fats_g": [0.0, 7.0, 0.0, 0.0],
         "sugars_g": [25, 0, 5, 11],
     }
     assert_frame_equal(pl.concat(batches), pl.read_csv(foods_file_path))
     # the final batch of the low-memory variant is different
     reader = pl.read_csv_batched(foods_file_path, batch_size=4, low_memory=True)
     batches = reader.next_batches(5)
-    assert len(batches) == 5
-    batches += reader.next_batches(5)
+    assert len(batches) == 5  # type: ignore[arg-type]
+    batches += reader.next_batches(5)  # type: ignore[operator]
     assert_frame_equal(pl.concat(batches), pl.read_csv(foods_file_path))
 
     reader = pl.read_csv_batched(foods_file_path, batch_size=4, low_memory=True)
     batches = reader.next_batches(10)
-    assert_frame_equal(pl.concat(batches), pl.read_csv(foods_file_path))
+    assert_frame_equal(pl.concat(batches), pl.read_csv(foods_file_path))  # type: ignore[arg-type]
 
 
 def test_batched_csv_reader_all_batches(foods_file_path: Path) -> None:
     for new_columns in [None, ["Category", "Calories", "Fats_g", "Sugars_g"]]:
         out = pl.read_csv(foods_file_path, new_columns=new_columns)
         reader = pl.read_csv_batched(
             foods_file_path, new_columns=new_columns, batch_size=4
@@ -1336,7 +1335,38 @@
 
     f.write(",,,?????????\n" * 1000)
     f.write("?????????????????????????????????????????????????,,,\n")
     f.write(",,,?????????\n" * 1048)
 
     f.seek(0)
     assert pl.read_csv(f, n_rows=2048, has_header=False).shape == (2048, 4)
+
+
+def test_write_csv_stdout_stderr(capsys: pytest.CaptureFixture[str]) -> None:
+    # The capsys fixture allows pytest to access stdout/stderr. See
+    # https://docs.pytest.org/en/7.1.x/how-to/capture-stdout-stderr.html
+    df = pl.DataFrame(
+        {
+            "numbers": [1, 2, 3],
+            "strings": ["test", "csv", "stdout"],
+            "dates": [date(2023, 1, 1), date(2023, 1, 2), date(2023, 1, 3)],
+        }
+    )
+
+    # pytest hijacks sys.stdout and changes its type, which causes mypy failure
+    df.write_csv(sys.stdout)  # type: ignore[call-overload]
+    captured = capsys.readouterr()
+    assert captured.out == (
+        "numbers,strings,dates\n"
+        "1,test,2023-01-01\n"
+        "2,csv,2023-01-02\n"
+        "3,stdout,2023-01-03\n"
+    )
+
+    df.write_csv(sys.stderr)  # type: ignore[call-overload]
+    captured = capsys.readouterr()
+    assert captured.err == (
+        "numbers,strings,dates\n"
+        "1,test,2023-01-01\n"
+        "2,csv,2023-01-02\n"
+        "3,stdout,2023-01-03\n"
+    )
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_database.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_database.py`

 * *Files 7% similar despite different names*

```diff
@@ -76,18 +76,14 @@
             {
                 "id": pl.Int64,
                 "name": pl.Utf8,
                 "value": pl.Float64,
                 "date": pl.Date,
             },
             [date(2020, 1, 1), date(2021, 12, 31)],
-            marks=pytest.mark.skipif(
-                sys.version_info < (3, 8),
-                reason="connectorx not available below Python 3.8",
-            ),
         ),
         pytest.param(
             "adbc",
             {
                 "id": pl.Int64,
                 "name": pl.Utf8,
                 "value": pl.Float64,
@@ -119,43 +115,51 @@
     )
     assert df.schema == expected_dtypes
     assert df.shape == (2, 4)
     assert df["date"].to_list() == expected_dates
 
 
 @pytest.mark.parametrize(
-    ("engine", "query", "database", "err"),
+    ("engine", "query", "database", "errclass", "err"),
     [
         pytest.param(
             "not_engine",
             "SELECT * FROM test_data",
             "sqlite",
-            "Engine is not implemented, try either connectorx or adbc.",
+            ValueError,
+            "Engine 'not_engine' not implemented; use connectorx or adbc.",
             id="Not an available sql engine",
         ),
         pytest.param(
             "adbc",
             ["SELECT * FROM test_data", "SELECT * FROM test_data"],
             "sqlite",
+            ValueError,
             "Only a single SQL query string is accepted for adbc.",
-            id="Unavailable list of queries for adbc.",
+            id="Unavailable list of queries for adbc",
         ),
         pytest.param(
             "adbc",
             "SELECT * FROM test_data",
             "mysql",
-            "ADBC does not currently support this database.",
-            id="Unavailable database for adbc.",
+            ImportError,
+            "ADBC mysql driver not detected",
+            id="Unavailable adbc driver",
         ),
     ],
 )
 def test_read_database_exceptions(
-    engine: DbReadEngine, query: str, database: str, err: str, tmp_path: Path
+    engine: DbReadEngine,
+    query: str,
+    database: str,
+    errclass: type,
+    err: str,
+    tmp_path: Path,
 ) -> None:
-    with pytest.raises(ValueError, match=err):
+    with pytest.raises(errclass, match=err):
         pl.read_database(
             connection_uri=f"{database}://test",
             query=query,
             engine=engine,
         )
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_delta.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_delta.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_excel.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_excel.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_ipc.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_ipc.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_json.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_json.py`

 * *Files 5% similar despite different names*

```diff
@@ -134,7 +134,21 @@
 def test_json_sliced_list_serialization() -> None:
     data = {"col1": [0, 2], "col2": [[3, 4, 5], [6, 7, 8]]}
     df = pl.DataFrame(data)
     f = io.BytesIO()
     sliced_df = df[1, :]
     sliced_df.write_ndjson(f)
     assert f.getvalue() == b'{"col1":2,"col2":[6,7,8]}\n'
+
+
+def test_json_deserialize_9687() -> None:
+    response = {
+        "volume": [0.0, 0.0, 0.0],
+        "open": [1263.0, 1263.0, 1263.0],
+        "close": [1263.0, 1263.0, 1263.0],
+        "high": [1263.0, 1263.0, 1263.0],
+        "low": [1263.0, 1263.0, 1263.0],
+    }
+
+    result = pl.read_json(json.dumps(response).encode())
+
+    assert result.to_dict(False) == {k: [v] for k, v in response.items()}
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_lazy_csv.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_lazy_csv.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_lazy_ipc.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_lazy_ipc.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_lazy_json.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_lazy_json.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_lazy_parquet.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_lazy_parquet.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_other.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_other.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_parquet.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_parquet.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from __future__ import annotations
 
 import io
-import typing
 from typing import TYPE_CHECKING
 
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 import pyarrow.dataset as ds
 import pyarrow.parquet as pq
@@ -308,15 +307,14 @@
     )
     f = io.BytesIO()
     df_pd.to_parquet(f)
     f.seek(0)
     assert_frame_equal(pl.read_parquet(f), pl.from_pandas(df_pd))
 
 
-@typing.no_type_check
 def test_parquet_nesting_structs_list() -> None:
     f = io.BytesIO()
     df = pl.from_records(
         [
             {
                 "id": 1,
                 "list_of_structs_col": [
@@ -335,15 +333,14 @@
 
     df.write_parquet(f)
     f.seek(0)
 
     assert_frame_equal(pl.read_parquet(f), df)
 
 
-@typing.no_type_check
 def test_parquet_nested_dictionaries_6217() -> None:
     _type = pa.dictionary(pa.int64(), pa.string())
 
     fields = [("a_type", _type)]
     struct_type = pa.struct(fields)
 
     col1 = pa.StructArray.from_arrays(
@@ -356,15 +353,15 @@
     with pl.StringCache():
         df = pl.from_arrow(table)
 
         f = io.BytesIO()
         pq.write_table(table, f, compression="snappy")
         f.seek(0)
         read = pl.read_parquet(f)
-        assert_frame_equal(read, df)
+        assert_frame_equal(read, df)  # type: ignore[arg-type]
 
 
 @pytest.mark.write_disk()
 def test_sink_parquet(io_files_path: Path, tmp_path: Path) -> None:
     tmp_path.mkdir(exist_ok=True)
 
     file = io_files_path / "small.parquet"
@@ -418,27 +415,26 @@
     assert_frame_equal(result_one, expected)
 
     expected = pl.DataFrame({"a": [0, 3], "b": [1, 4]})
     assert_frame_equal(result_glob, expected)
 
 
 @pytest.mark.slow()
-@typing.no_type_check
 def test_struct_pyarrow_dataset_5796(tmp_path: Path) -> None:
     tmp_path.mkdir(exist_ok=True)
 
     num_rows = 2**17 + 1
 
     df = pl.from_records([{"id": i, "nested": {"a": i}} for i in range(num_rows)])
     file_path = tmp_path / "out.parquet"
     df.write_parquet(file_path, use_pyarrow=True)
     tbl = ds.dataset(file_path).to_table()
     result = pl.from_arrow(tbl)
 
-    assert_frame_equal(result, df)
+    assert_frame_equal(result, df)  # type: ignore[arg-type]
 
 
 @pytest.mark.slow()
 @pytest.mark.parametrize("case", [1048576, 1048577])
 def test_parquet_chunks_545(case: int) -> None:
     f = io.BytesIO()
     # repeat until it has case instances
@@ -471,20 +467,19 @@
 
     df.write_parquet(f)
     f.seek(0)
     df_read = pl.read_parquet(f)
     assert_frame_equal(df_read, df)
 
 
-@typing.no_type_check
 def test_parquet_nested_list_pandas() -> None:
     # pandas/pyarrow writes as nested null dict
-    df = pd.DataFrame({"listcol": [[] * 10]})
+    df_pd = pd.DataFrame({"listcol": [[] * 10]})
     f = io.BytesIO()
-    df.to_parquet(f)
+    df_pd.to_parquet(f)
     f.seek(0)
     df = pl.read_parquet(f)
     assert df.dtypes == [pl.List(pl.Null)]
     assert df.to_dict(False) == {"listcol": [[]]}
 
 
 def test_parquet_string_cache() -> None:
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_pickle.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_pickle.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/io/test_pyarrow_dataset.py` & `polars_lts_cpu-0.18.5/tests/unit/io/test_pyarrow_dataset.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from __future__ import annotations
 
-import typing
 from datetime import date, datetime, time
-from typing import TYPE_CHECKING
+from typing import TYPE_CHECKING, Callable
 
 import pyarrow.dataset as ds
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
 
 if TYPE_CHECKING:
     from pathlib import Path
 
 
-@typing.no_type_check
-def helper_dataset_test(file_path: Path, query) -> None:
+def helper_dataset_test(
+    file_path: Path, query: Callable[[pl.LazyFrame], pl.DataFrame]
+) -> None:
     dset = ds.dataset(file_path, format="ipc")
 
     expected = query(pl.scan_ipc(file_path))
     out = query(pl.scan_pyarrow_dataset(dset))
     assert_frame_equal(out, expected)
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/namespaces/test_array.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_array.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/namespaces/test_binary.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_binary.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/namespaces/test_categorical.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_categorical.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/namespaces/test_datetime.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_strptime.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,642 +1,617 @@
+"""
+Module for testing ``.str.strptime`` of the string namespace.
+
+This method gets its own module due to its complexity.
+"""
 from __future__ import annotations
 
+import contextlib
 import sys
-from datetime import date, datetime, time, timedelta
+from datetime import date, datetime, time, timedelta, timezone
 from typing import TYPE_CHECKING
 
 import pytest
 
 import polars as pl
-from polars.datatypes import DTYPE_TEMPORAL_UNITS
-from polars.dependencies import _ZONEINFO_AVAILABLE
-from polars.exceptions import ComputeError, InvalidOperationError
+from polars.exceptions import ArrowError, ComputeError, TimeZoneAwareConstructorWarning
 from polars.testing import assert_series_equal
 
 if sys.version_info >= (3, 9):
     from zoneinfo import ZoneInfo
-elif _ZONEINFO_AVAILABLE:
+else:
     # Import from submodule due to typing issue with backports.zoneinfo package:
     # https://github.com/pganssle/zoneinfo/issues/125
     from backports.zoneinfo._zoneinfo import ZoneInfo
 
 if TYPE_CHECKING:
-    from polars.type_aliases import TimeUnit
+    from polars.type_aliases import PolarsTemporalType, TimeUnit
 
 
-@pytest.fixture()
-def series_of_int_dates() -> pl.Series:
-    return pl.Series([10000, 20000, 30000], dtype=pl.Date)
+def test_str_strptime() -> None:
+    s = pl.Series(["2020-01-01", "2020-02-02"])
+    expected = pl.Series([date(2020, 1, 1), date(2020, 2, 2)])
+    assert_series_equal(s.str.strptime(pl.Date, "%Y-%m-%d"), expected)
 
+    s = pl.Series(["2020-01-01 00:00:00", "2020-02-02 03:20:10"])
+    expected = pl.Series(
+        [datetime(2020, 1, 1, 0, 0, 0), datetime(2020, 2, 2, 3, 20, 10)]
+    )
+    assert_series_equal(s.str.strptime(pl.Datetime, "%Y-%m-%d %H:%M:%S"), expected)
 
-@pytest.fixture()
-def series_of_str_dates() -> pl.Series:
-    return pl.Series(["2020-01-01 00:00:00.000000000", "2020-02-02 03:20:10.987654321"])
+    s = pl.Series(["00:00:00", "03:20:10"])
+    expected = pl.Series([0, 12010000000000], dtype=pl.Time)
+    assert_series_equal(s.str.strptime(pl.Time, "%H:%M:%S"), expected)
 
 
-def test_dt_to_string(series_of_int_dates: pl.Series) -> None:
-    expected_str_dates = pl.Series(["1997-05-19", "2024-10-04", "2052-02-20"])
+def test_date_parse_omit_day() -> None:
+    df = pl.DataFrame({"month": ["2022-01"]})
+    assert df.select(pl.col("month").str.to_date(format="%Y-%m")).item() == date(
+        2022, 1, 1
+    )
+    assert df.select(
+        pl.col("month").str.to_datetime(format="%Y-%m")
+    ).item() == datetime(2022, 1, 1)
 
-    assert series_of_int_dates.dtype == pl.Date
-    assert_series_equal(series_of_int_dates.dt.to_string("%F"), expected_str_dates)
 
-    # Check strftime alias as well
-    assert_series_equal(series_of_int_dates.dt.strftime("%F"), expected_str_dates)
+def test_to_datetime_precision() -> None:
+    s = pl.Series(
+        "date", ["2022-09-12 21:54:36.789321456", "2022-09-13 12:34:56.987456321"]
+    )
+    ds = s.str.to_datetime()
+    assert ds.cast(pl.Date) != None  # noqa: E711  (note: *deliberately* testing "!=")
+    assert getattr(ds.dtype, "time_unit", None) == "us"
+
+    time_units: list[TimeUnit] = ["ms", "us", "ns"]
+    suffixes = ["%.3f", "%.6f", "%.9f"]
+    test_data = zip(
+        time_units,
+        suffixes,
+        (
+            [789000000, 987000000],
+            [789321000, 987456000],
+            [789321456, 987456321],
+        ),
+    )
+    for time_unit, suffix, expected_values in test_data:
+        ds = s.str.to_datetime(f"%Y-%m-%d %H:%M:%S{suffix}", time_unit=time_unit)
+        assert getattr(ds.dtype, "time_unit", None) == time_unit
+        assert ds.dt.nanosecond().to_list() == expected_values
 
 
 @pytest.mark.parametrize(
-    ("unit_attr", "expected"),
-    [
-        ("year", pl.Series(values=[1997, 2024, 2052], dtype=pl.Int32)),
-        ("month", pl.Series(values=[5, 10, 2], dtype=pl.UInt32)),
-        ("week", pl.Series(values=[21, 40, 8], dtype=pl.UInt32)),
-        ("day", pl.Series(values=[19, 4, 20], dtype=pl.UInt32)),
-        ("ordinal_day", pl.Series(values=[139, 278, 51], dtype=pl.UInt32)),
-    ],
+    ("time_unit", "expected"),
+    [("ms", "123000000"), ("us", "123456000"), ("ns", "123456789")],
 )
-def test_dt_extract_year_month_week_day_ordinal_day(
-    unit_attr: str,
-    expected: pl.Series,
-    series_of_int_dates: pl.Series,
+@pytest.mark.parametrize("format", ["%Y-%m-%d %H:%M:%S%.f", None])
+def test_to_datetime_precision_with_time_unit(
+    time_unit: TimeUnit, expected: str, format: str
 ) -> None:
-    assert_series_equal(getattr(series_of_int_dates.dt, unit_attr)(), expected)
+    s = pl.Series(["2020-01-01 00:00:00.123456789"])
+    result = s.str.to_datetime(format, time_unit=time_unit).dt.to_string("%f")[0]
+    assert result == expected
 
 
 @pytest.mark.parametrize(
-    ("unit_attr", "expected"),
-    [
-        ("hour", pl.Series(values=[0, 3], dtype=pl.UInt32)),
-        ("minute", pl.Series(values=[0, 20], dtype=pl.UInt32)),
-        ("second", pl.Series(values=[0, 10], dtype=pl.UInt32)),
-        ("millisecond", pl.Series(values=[0, 987], dtype=pl.UInt32)),
-        ("microsecond", pl.Series(values=[0, 987654], dtype=pl.UInt32)),
-        ("nanosecond", pl.Series(values=[0, 987654321], dtype=pl.UInt32)),
-    ],
+    ("tz_string", "timedelta"),
+    [("+01:00", timedelta(minutes=60)), ("-01:30", timedelta(hours=-1, minutes=-30))],
 )
-def test_strptime_extract_times(
-    unit_attr: str,
-    expected: pl.Series,
-    series_of_int_dates: pl.Series,
-    series_of_str_dates: pl.Series,
-) -> None:
-    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
-
-    assert_series_equal(getattr(s.dt, unit_attr)(), expected)
+def test_timezone_aware_strptime(tz_string: str, timedelta: timedelta) -> None:
+    times = pl.DataFrame(
+        {
+            "delivery_datetime": [
+                "2021-12-05 06:00:00" + tz_string,
+                "2021-12-05 07:00:00" + tz_string,
+                "2021-12-05 08:00:00" + tz_string,
+            ]
+        }
+    )
+    assert times.with_columns(
+        pl.col("delivery_datetime").str.to_datetime(format="%Y-%m-%d %H:%M:%S%z")
+    ).to_dict(False) == {
+        "delivery_datetime": [
+            datetime(2021, 12, 5, 6, 0, tzinfo=timezone(timedelta)),
+            datetime(2021, 12, 5, 7, 0, tzinfo=timezone(timedelta)),
+            datetime(2021, 12, 5, 8, 0, tzinfo=timezone(timedelta)),
+        ]
+    }
 
 
-@pytest.mark.parametrize("time_zone", [None, "Asia/Kathmandu"])
-@pytest.mark.parametrize(
-    ("attribute", "expected"),
-    [
-        ("date", date(2022, 1, 1)),
-        ("time", time(23)),
-    ],
-)
-def test_dt_date_and_time(
-    attribute: str, time_zone: None | str, expected: date | time
-) -> None:
-    ser = pl.Series([datetime(2022, 1, 1, 23)]).dt.replace_time_zone(time_zone)
-    result = getattr(ser.dt, attribute)().item()
-    assert result == expected
+def test_to_date_non_exact_strptime() -> None:
+    s = pl.Series("a", ["2022-01-16", "2022-01-17", "foo2022-01-18", "b2022-01-19ar"])
+    format = "%Y-%m-%d"
 
+    result = s.str.to_date(format, strict=False, exact=True)
+    expected = pl.Series("a", [date(2022, 1, 16), date(2022, 1, 17), None, None])
+    assert_series_equal(result, expected)
 
-@pytest.mark.parametrize("time_zone", [None, "Asia/Kathmandu"])
-@pytest.mark.parametrize("time_unit", ["us", "ns", "ms"])
-def test_dt_datetime(time_zone: str | None, time_unit: TimeUnit) -> None:
-    ser = (
-        pl.Series([datetime(2022, 1, 1, 23)])
-        .dt.cast_time_unit(time_unit)
-        .dt.replace_time_zone(time_zone)
+    result = s.str.to_date(format, strict=False, exact=False)
+    expected = pl.Series(
+        "a",
+        [date(2022, 1, 16), date(2022, 1, 17), date(2022, 1, 18), date(2022, 1, 19)],
     )
-    result = ser.dt.datetime()
-    expected = datetime(2022, 1, 1, 23)
-    assert result.dtype == pl.Datetime(time_unit, None)
-    assert result.item() == expected
+    assert_series_equal(result, expected)
+
+    with pytest.raises(pl.ComputeError):
+        s.str.to_date(format, strict=True, exact=True)
 
 
 @pytest.mark.parametrize(
-    ("time_zone", "expected"),
+    ("offset", "time_zone", "tzinfo", "format"),
     [
-        (None, True),
-        ("Asia/Kathmandu", False),
-        ("UTC", True),
+        ("+01:00", "UTC", timezone(timedelta(hours=1)), "%Y-%m-%dT%H:%M%z"),
+        ("", None, None, "%Y-%m-%dT%H:%M"),
     ],
 )
-@pytest.mark.parametrize("attribute", ["datetime", "date"])
-def test_local_datetime_sortedness(
-    time_zone: str | None, expected: bool, attribute: str
+def test_to_datetime_non_exact_strptime(
+    offset: str, time_zone: str | None, tzinfo: timezone | None, format: str
 ) -> None:
-    ser = (pl.Series([datetime(2022, 1, 1, 23)]).dt.replace_time_zone(time_zone)).sort()
-    result = getattr(ser.dt, attribute)()
-    assert result.flags["SORTED_ASC"] == expected
-    assert result.flags["SORTED_DESC"] is False
+    msg = "Series with UTC time zone"
+    context_manager: contextlib.AbstractContextManager[pytest.WarningsRecorder | None]
+    if offset:
+        context_manager = pytest.warns(TimeZoneAwareConstructorWarning, match=msg)
+    else:
+        context_manager = contextlib.nullcontext()
 
+    s = pl.Series(
+        "a",
+        [
+            f"2022-01-16T00:00{offset}",
+            f"2022-01-17T00:00{offset}",
+            f"foo2022-01-18T00:00{offset}",
+            f"b2022-01-19T00:00{offset}ar",
+        ],
+    )
 
-@pytest.mark.parametrize("time_zone", [None, "Asia/Kathmandu", "UTC"])
-def test_local_time_sortedness(time_zone: str | None) -> None:
-    ser = (pl.Series([datetime(2022, 1, 1, 23)]).dt.replace_time_zone(time_zone)).sort()
-    result = ser.dt.time()
-    assert result.flags["SORTED_ASC"] is False
-    assert result.flags["SORTED_DESC"] is False
+    result = s.str.to_datetime(format, strict=False, exact=True)
+    with context_manager:
+        expected = pl.Series(
+            "a",
+            [
+                datetime(2022, 1, 16, tzinfo=tzinfo),
+                datetime(2022, 1, 17, tzinfo=tzinfo),
+                None,
+                None,
+            ],
+        )
+    assert_series_equal(result, expected)
+    assert result.dtype == pl.Datetime("us", time_zone)
 
+    result = s.str.to_datetime(format, strict=False, exact=False)
+    with context_manager:
+        expected = pl.Series(
+            "a",
+            [
+                datetime(2022, 1, 16, tzinfo=tzinfo),
+                datetime(2022, 1, 17, tzinfo=tzinfo),
+                datetime(2022, 1, 18, tzinfo=tzinfo),
+                datetime(2022, 1, 19, tzinfo=tzinfo),
+            ],
+        )
+    assert_series_equal(result, expected)
+    assert result.dtype == pl.Datetime("us", time_zone)
 
-def test_dt_datetime_date_time_invalid() -> None:
-    with pytest.raises(ComputeError, match="expected Datetime"):
-        pl.Series([date(2021, 1, 2)]).dt.datetime()
-    with pytest.raises(ComputeError, match="expected Datetime or Date"):
-        pl.Series([time(23)]).dt.date()
-    with pytest.raises(ComputeError, match="expected Datetime"):
-        pl.Series([time(23)]).dt.datetime()
-    with pytest.raises(ComputeError, match="expected Datetime or Date"):
-        pl.Series([timedelta(1)]).dt.date()
-    with pytest.raises(ComputeError, match="expected Datetime"):
-        pl.Series([timedelta(1)]).dt.datetime()
-    with pytest.raises(ComputeError, match="expected Datetime, Date, or Time"):
-        pl.Series([timedelta(1)]).dt.time()
+    with pytest.raises(pl.ComputeError):
+        s.str.to_datetime(format, strict=True, exact=True)
 
 
-@pytest.mark.parametrize(
-    ("dt", "expected"),
-    [
-        (datetime(2022, 3, 15, 3), datetime(2022, 3, 1, 3)),
-        (datetime(2022, 3, 15, 3, 2, 1, 123000), datetime(2022, 3, 1, 3, 2, 1, 123000)),
-        (datetime(2022, 3, 15), datetime(2022, 3, 1)),
-        (datetime(2022, 3, 1), datetime(2022, 3, 1)),
-    ],
-)
-@pytest.mark.parametrize(
-    ("tzinfo", "time_zone"),
-    [
-        (None, None),
-        (ZoneInfo("Asia/Kathmandu"), "Asia/Kathmandu"),
-    ],
-)
-@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
-def test_month_start_datetime(
-    dt: datetime,
-    expected: datetime,
-    time_unit: TimeUnit,
-    tzinfo: ZoneInfo | None,
-    time_zone: str | None,
-) -> None:
-    ser = pl.Series([dt]).dt.replace_time_zone(time_zone).dt.cast_time_unit(time_unit)
-    result = ser.dt.month_start().item()
-    assert result == expected.replace(tzinfo=tzinfo)
+def test_to_datetime_dates_datetimes() -> None:
+    s = pl.Series("date", ["2021-04-22", "2022-01-04 00:00:00"])
+    assert s.str.to_datetime().to_list() == [
+        datetime(2021, 4, 22, 0, 0),
+        datetime(2022, 1, 4, 0, 0),
+    ]
 
 
 @pytest.mark.parametrize(
-    ("dt", "expected"),
+    ("time_string", "expected"),
     [
-        (date(2022, 3, 15), date(2022, 3, 1)),
-        (date(2022, 3, 31), date(2022, 3, 1)),
+        ("09-05-2019", datetime(2019, 5, 9)),
+        ("2018-09-05", datetime(2018, 9, 5)),
+        ("2018-09-05T04:05:01", datetime(2018, 9, 5, 4, 5, 1)),
+        ("2018-09-05T04:24:01.9", datetime(2018, 9, 5, 4, 24, 1, 900000)),
+        ("2018-09-05T04:24:02.11", datetime(2018, 9, 5, 4, 24, 2, 110000)),
+        ("2018-09-05T14:24:02.123", datetime(2018, 9, 5, 14, 24, 2, 123000)),
+        ("2019-04-18T02:45:55.555000000", datetime(2019, 4, 18, 2, 45, 55, 555000)),
+        ("2019-04-18T22:45:55.555123", datetime(2019, 4, 18, 22, 45, 55, 555123)),
+        (
+            "2018-09-05T04:05:01+01:00",
+            datetime(2018, 9, 5, 4, 5, 1, tzinfo=timezone(timedelta(hours=1))),
+        ),
+        (
+            "2018-09-05T04:24:01.9+01:00",
+            datetime(2018, 9, 5, 4, 24, 1, 900000, tzinfo=timezone(timedelta(hours=1))),
+        ),
+        (
+            "2018-09-05T04:24:02.11+01:00",
+            datetime(2018, 9, 5, 4, 24, 2, 110000, tzinfo=timezone(timedelta(hours=1))),
+        ),
+        (
+            "2018-09-05T14:24:02.123+01:00",
+            datetime(
+                2018, 9, 5, 14, 24, 2, 123000, tzinfo=timezone(timedelta(hours=1))
+            ),
+        ),
+        (
+            "2019-04-18T02:45:55.555000000+01:00",
+            datetime(
+                2019, 4, 18, 2, 45, 55, 555000, tzinfo=timezone(timedelta(hours=1))
+            ),
+        ),
+        (
+            "2019-04-18T22:45:55.555123+01:00",
+            datetime(
+                2019, 4, 18, 22, 45, 55, 555123, tzinfo=timezone(timedelta(hours=1))
+            ),
+        ),
     ],
 )
-def test_month_start_date(dt: date, expected: date) -> None:
-    ser = pl.Series([dt])
-    result = ser.dt.month_start().item()
+def test_to_datetime_patterns_single(time_string: str, expected: str) -> None:
+    result = pl.Series([time_string]).str.to_datetime().item()
     assert result == expected
 
 
-@pytest.mark.parametrize(
-    ("dt", "expected"),
-    [
-        (datetime(2022, 3, 15, 3), datetime(2022, 3, 31, 3)),
-        (
-            datetime(2022, 3, 15, 3, 2, 1, 123000),
-            datetime(2022, 3, 31, 3, 2, 1, 123000),
-        ),
-        (datetime(2022, 3, 15), datetime(2022, 3, 31)),
-        (datetime(2022, 3, 31), datetime(2022, 3, 31)),
-    ],
-)
-@pytest.mark.parametrize(
-    ("tzinfo", "time_zone"),
-    [
-        (None, None),
-        (ZoneInfo("Asia/Kathmandu"), "Asia/Kathmandu"),
-    ],
-)
 @pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
-def test_month_end_datetime(
-    dt: datetime,
-    expected: datetime,
-    time_unit: TimeUnit,
-    tzinfo: ZoneInfo | None,
-    time_zone: str | None,
-) -> None:
-    ser = pl.Series([dt]).dt.replace_time_zone(time_zone).dt.cast_time_unit(time_unit)
-    result = ser.dt.month_end().item()
-    assert result == expected.replace(tzinfo=tzinfo)
+def test_infer_tz_aware_time_unit(time_unit: TimeUnit) -> None:
+    result = pl.Series(["2020-01-02T04:00:00+02:00"]).str.to_datetime(
+        time_unit=time_unit
+    )
+    assert result.dtype == pl.Datetime(time_unit, "UTC")
+    assert result.item() == datetime(2020, 1, 2, 2, 0, tzinfo=timezone.utc)
 
 
-@pytest.mark.parametrize(
-    ("dt", "expected"),
-    [
-        (date(2022, 3, 15), date(2022, 3, 31)),
-        (date(2022, 3, 31), date(2022, 3, 31)),
-    ],
-)
-def test_month_end_date(dt: date, expected: date) -> None:
-    ser = pl.Series([dt])
-    result = ser.dt.month_end().item()
-    assert result == expected
+@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
+def test_infer_tz_aware_with_utc(time_unit: TimeUnit) -> None:
+    result = pl.Series(["2020-01-02T04:00:00+02:00"]).str.to_datetime(
+        time_unit=time_unit
+    )
+    assert result.dtype == pl.Datetime(time_unit, "UTC")
+    assert result.item() == datetime(2020, 1, 2, 2, 0, tzinfo=timezone.utc)
 
 
-def test_month_start_end_invalid() -> None:
-    ser = pl.Series([time(1, 2, 3)])
-    with pytest.raises(
-        InvalidOperationError,
-        match=r"`month_start` operation not supported for dtype `time` \(expected: date/datetime\)",
-    ):
-        ser.dt.month_start()
-    with pytest.raises(
-        InvalidOperationError,
-        match=r"`month_end` operation not supported for dtype `time` \(expected: date/datetime\)",
-    ):
-        ser.dt.month_end()
+def test_infer_tz_aware_raises() -> None:
+    msg = "Please either drop the time zone from the function call, or set it to UTC"
+    with pytest.raises(ComputeError, match=msg):
+        pl.Series(["2020-01-02T04:00:00+02:00"]).str.to_datetime(
+            time_unit="us", time_zone="Europe/Vienna"
+        )
 
 
 @pytest.mark.parametrize(
-    ("time_unit", "expected"),
+    "result",
     [
-        ("d", pl.Series(values=[18262, 18294], dtype=pl.Int32)),
-        ("s", pl.Series(values=[1_577_836_800, 1_580_613_610], dtype=pl.Int64)),
-        (
-            "ms",
-            pl.Series(values=[1_577_836_800_000, 1_580_613_610_000], dtype=pl.Int64),
+        pl.Series(["2020-01-01T00:00:00+00:00"]).str.strptime(
+            pl.Datetime("us", "UTC"), format="%Y-%m-%dT%H:%M:%S%z"
+        ),
+        pl.Series(["2020-01-01T00:00:00+00:00"]).str.strptime(
+            pl.Datetime("us"), format="%Y-%m-%dT%H:%M:%S%z"
+        ),
+        pl.Series(["2020-01-01T00:00:00+00:00"]).str.strptime(pl.Datetime("us", "UTC")),
+        pl.Series(["2020-01-01T00:00:00+00:00"]).str.strptime(pl.Datetime("us")),
+        pl.Series(["2020-01-01T00:00:00+00:00"]).str.to_datetime(
+            time_zone="UTC", format="%Y-%m-%dT%H:%M:%S%z"
+        ),
+        pl.Series(["2020-01-01T00:00:00+00:00"]).str.to_datetime(
+            format="%Y-%m-%dT%H:%M:%S%z"
         ),
+        pl.Series(["2020-01-01T00:00:00+00:00"]).str.to_datetime(time_zone="UTC"),
+        pl.Series(["2020-01-01T00:00:00+00:00"]).str.to_datetime(),
     ],
 )
-def test_strptime_epoch(
-    time_unit: TimeUnit,
-    expected: pl.Series,
-    series_of_str_dates: pl.Series,
-) -> None:
-    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
+def test_parsing_offset_aware_with_utc_dtype(result: pl.Series) -> None:
+    expected = pl.Series([datetime(2020, 1, 1, tzinfo=timezone.utc)])
+    assert_series_equal(result, expected)
 
-    assert_series_equal(s.dt.epoch(time_unit=time_unit), expected)
 
+def test_datetime_strptime_patterns_consistent() -> None:
+    # note that all should be year first
+    df = pl.Series(
+        "date",
+        [
+            "2018-09-05",
+            "2018-09-05T04:05:01",
+            "2018-09-05T04:24:01.9",
+            "2018-09-05T04:24:02.11",
+            "2018-09-05T14:24:02.123",
+            "2018-09-05T14:24:02.123Z",
+            "2019-04-18T02:45:55.555000000",
+            "2019-04-18T22:45:55.555123",
+        ],
+    ).to_frame()
+    s = df.with_columns(
+        [
+            pl.col("date").str.to_datetime(strict=False).alias("parsed"),
+        ]
+    )["parsed"]
+    assert s.null_count() == 1
+    assert s[5] is None
 
-def test_strptime_fractional_seconds(series_of_str_dates: pl.Series) -> None:
-    s = series_of_str_dates.str.strptime(pl.Datetime, format="%Y-%m-%d %H:%M:%S.%9f")
 
-    assert_series_equal(
-        s.dt.second(fractional=True),
-        pl.Series([0.0, 10.987654321], dtype=pl.Float64),
-    )
+def test_datetime_strptime_patterns_inconsistent() -> None:
+    # note that the pattern is inferred from the first element to
+    # be DatetimeDMY, and so the others (correctly) parse as `null`.
+    df = pl.Series(
+        "date",
+        [
+            "09-05-2019",
+            "2018-09-05",
+            "2018-09-05T04:05:01",
+            "2018-09-05T04:24:01.9",
+            "2018-09-05T04:24:02.11",
+            "2018-09-05T14:24:02.123",
+            "2018-09-05T14:24:02.123Z",
+            "2019-04-18T02:45:55.555000000",
+            "2019-04-18T22:45:55.555123",
+        ],
+    ).to_frame()
+    s = df.with_columns(pl.col("date").str.to_datetime(strict=False).alias("parsed"))[
+        "parsed"
+    ]
+    assert s.null_count() == 8
+    assert s[0] is not None
 
 
 @pytest.mark.parametrize(
-    ("unit_attr", "expected"),
-    [
-        ("days", pl.Series([1])),
-        ("hours", pl.Series([24])),
-        ("minutes", pl.Series([24 * 60])),
-        ("seconds", pl.Series([3600 * 24])),
-        ("milliseconds", pl.Series([3600 * 24 * int(1e3)])),
-        ("microseconds", pl.Series([3600 * 24 * int(1e6)])),
-        ("nanoseconds", pl.Series([3600 * 24 * int(1e9)])),
-    ],
-)
-def test_duration_extract_times(
-    unit_attr: str,
-    expected: pl.Series,
-) -> None:
-    duration = pl.Series([datetime(2022, 1, 2)]) - pl.Series([datetime(2022, 1, 1)])
-
-    assert_series_equal(getattr(duration.dt, unit_attr)(), expected)
+    (
+        "ts",
+        "format",
+        "exp_year",
+        "exp_month",
+        "exp_day",
+        "exp_hour",
+        "exp_minute",
+        "exp_second",
+    ),
+    [
+        ("-0031-04-24 22:13:20", "%Y-%m-%d %H:%M:%S", -31, 4, 24, 22, 13, 20),
+        ("-0031-04-24", "%Y-%m-%d", -31, 4, 24, 0, 0, 0),
+    ],
+)
+def test_parse_negative_dates(
+    ts: str,
+    format: str,
+    exp_year: int,
+    exp_month: int,
+    exp_day: int,
+    exp_hour: int,
+    exp_minute: int,
+    exp_second: int,
+) -> None:
+    s = pl.Series([ts])
+    result = s.str.to_datetime(format, time_unit="ms")
+    # Python datetime.datetime doesn't support negative dates, so comparing
+    # with `result.item()` directly won't work.
+    assert result.dt.year().item() == exp_year
+    assert result.dt.month().item() == exp_month
+    assert result.dt.day().item() == exp_day
+    assert result.dt.hour().item() == exp_hour
+    assert result.dt.minute().item() == exp_minute
+    assert result.dt.second().item() == exp_second
+
+
+def test_short_formats() -> None:
+    s = pl.Series(["20202020", "2020"])
+    assert s.str.to_date("%Y", strict=False).to_list() == [
+        None,
+        date(2020, 1, 1),
+    ]
+    assert s.str.to_date("%bar", strict=False).to_list() == [None, None]
 
 
 @pytest.mark.parametrize(
-    ("time_unit", "every"),
+    ("time_string", "fmt", "datatype", "expected"),
     [
-        ("ms", "1h"),
-        ("us", "1h0m0s"),
-        ("ns", timedelta(hours=1)),
+        ("Jul/2020", "%b/%Y", pl.Date, date(2020, 7, 1)),
+        ("Jan/2020", "%b/%Y", pl.Date, date(2020, 1, 1)),
+        ("02/Apr/2020", "%d/%b/%Y", pl.Date, date(2020, 4, 2)),
+        ("Dec/2020", "%b/%Y", pl.Datetime, datetime(2020, 12, 1, 0, 0)),
+        ("Nov/2020", "%b/%Y", pl.Datetime, datetime(2020, 11, 1, 0, 0)),
+        ("02/Feb/2020", "%d/%b/%Y", pl.Datetime, datetime(2020, 2, 2, 0, 0)),
     ],
-    ids=["milliseconds", "microseconds", "nanoseconds"],
 )
-def test_truncate(
-    time_unit: TimeUnit,
-    every: str | timedelta,
+def test_strptime_abbrev_month(
+    time_string: str, fmt: str, datatype: PolarsTemporalType, expected: date
 ) -> None:
-    start, stop = datetime(2022, 1, 1), datetime(2022, 1, 2)
-    s = pl.date_range(
-        start,
-        stop,
-        timedelta(minutes=30),
-        time_unit=time_unit,
-        eager=True,
-    ).alias(f"dates[{time_unit}]")
-
-    # can pass strings and time-deltas
-    out = s.dt.truncate(every)
-    assert out.dt[0] == start
-    assert out.dt[1] == start
-    assert out.dt[2] == start + timedelta(hours=1)
-    assert out.dt[3] == start + timedelta(hours=1)
-    # ...
-    assert out.dt[-3] == stop - timedelta(hours=1)
-    assert out.dt[-2] == stop - timedelta(hours=1)
-    assert out.dt[-1] == stop
+    s = pl.Series([time_string])
+    result = s.str.strptime(datatype, fmt).item()
+    assert result == expected
 
 
-@pytest.mark.parametrize(
-    ("time_unit", "every"),
-    [
-        ("ms", "1h"),
-        ("us", "1h0m0s"),
-        ("ns", timedelta(hours=1)),
-    ],
-    ids=["milliseconds", "microseconds", "nanoseconds"],
-)
-def test_round(
-    time_unit: TimeUnit,
-    every: str | timedelta,
-) -> None:
-    start, stop = datetime(2022, 1, 1), datetime(2022, 1, 2)
-    s = pl.date_range(
-        start,
-        stop,
-        timedelta(minutes=30),
-        time_unit=time_unit,
-        eager=True,
-    ).alias(f"dates[{time_unit}]")
-
-    # can pass strings and time-deltas
-    out = s.dt.round(every)
-    assert out.dt[0] == start
-    assert out.dt[1] == start + timedelta(hours=1)
-    assert out.dt[2] == start + timedelta(hours=1)
-    assert out.dt[3] == start + timedelta(hours=2)
-    # ...
-    assert out.dt[-3] == stop - timedelta(hours=1)
-    assert out.dt[-2] == stop
-    assert out.dt[-1] == stop
+def test_full_month_name() -> None:
+    s = pl.Series(["2022-December-01"]).str.to_datetime("%Y-%B-%d")
+    assert s[0] == datetime(2022, 12, 1)
 
 
 @pytest.mark.parametrize(
-    ("time_unit", "date_in_that_unit"),
-    [
-        ("ns", [978307200000000000, 981022089000000000]),
-        ("us", [978307200000000, 981022089000000]),
-        ("ms", [978307200000, 981022089000]),
-    ],
-    ids=["nanoseconds", "microseconds", "milliseconds"],
-)
-def test_cast_time_units(
-    time_unit: TimeUnit,
-    date_in_that_unit: list[int],
+    ("datatype", "expected"),
+    [
+        (pl.Datetime, datetime(2022, 1, 1)),
+        (pl.Date, date(2022, 1, 1)),
+    ],
+)
+def test_single_digit_month(
+    datatype: PolarsTemporalType, expected: datetime | date
 ) -> None:
-    dates = pl.Series([datetime(2001, 1, 1), datetime(2001, 2, 1, 10, 8, 9)])
+    s = pl.Series(["2022-1-1"]).str.strptime(datatype, "%Y-%m-%d")
+    assert s[0] == expected
 
-    assert dates.dt.cast_time_unit(time_unit).cast(int).to_list() == date_in_that_unit
 
+def test_invalid_date_parsing_4898() -> None:
+    assert pl.Series(["2022-09-18", "2022-09-50"]).str.to_date(
+        "%Y-%m-%d", strict=False
+    ).to_list() == [date(2022, 9, 18), None]
 
-def test_epoch_matches_timestamp() -> None:
-    dates = pl.Series([datetime(2001, 1, 1), datetime(2001, 2, 1, 10, 8, 9)])
 
-    for unit in DTYPE_TEMPORAL_UNITS:
-        assert_series_equal(dates.dt.epoch(unit), dates.dt.timestamp(unit))
+def test_strptime_invalid_timezone() -> None:
+    ts = pl.Series(["2020-01-01 00:00:00+01:00"]).str.to_datetime("%Y-%m-%d %H:%M:%S%z")
+    with pytest.raises(ComputeError, match=r"unable to parse time zone: 'foo'"):
+        ts.dt.replace_time_zone("foo")
 
-    assert_series_equal(dates.dt.epoch("s"), dates.dt.timestamp("ms") // 1000)
-    assert_series_equal(
-        dates.dt.epoch("d"),
-        (dates.dt.timestamp("ms") // (1000 * 3600 * 24)).cast(pl.Int32),
-    )
+
+def test_to_datetime_ambiguous_or_non_existent() -> None:
+    with pytest.raises(
+        ArrowError,
+        match="datetime '2021-11-07 01:00:00' is ambiguous in time zone 'US/Central'",
+    ):
+        pl.Series(["2021-11-07 01:00"]).str.to_datetime(
+            time_unit="us", time_zone="US/Central"
+        )
+    with pytest.raises(
+        ArrowError,
+        match="datetime '2021-03-28 02:30:00' is non-existent in time zone 'Europe/Warsaw'",
+    ):
+        pl.Series(["2021-03-28 02:30"]).str.to_datetime(
+            time_unit="us", time_zone="Europe/Warsaw"
+        )
 
 
 @pytest.mark.parametrize(
-    ("tzinfo", "time_zone"),
-    [(None, None), (ZoneInfo("Asia/Kathmandu"), "Asia/Kathmandu")],
+    ("ts", "fmt", "expected"),
+    [
+        ("2020-01-01T00:00:00Z", None, datetime(2020, 1, 1, tzinfo=timezone.utc)),
+        ("2020-01-01T00:00:00Z", "%+", datetime(2020, 1, 1, tzinfo=timezone.utc)),
+        (
+            "2020-01-01T00:00:00+01:00",
+            "%Y-%m-%dT%H:%M:%S%z",
+            datetime(2020, 1, 1, tzinfo=timezone(timedelta(seconds=3600))),
+        ),
+        (
+            "2020-01-01T00:00:00+01:00",
+            "%Y-%m-%dT%H:%M:%S%:z",
+            datetime(2020, 1, 1, tzinfo=timezone(timedelta(seconds=3600))),
+        ),
+        (
+            "2020-01-01T00:00:00+01:00",
+            "%Y-%m-%dT%H:%M:%S%#z",
+            datetime(2020, 1, 1, tzinfo=timezone(timedelta(seconds=3600))),
+        ),
+    ],
 )
-def test_date_time_combine(tzinfo: ZoneInfo | None, time_zone: str | None) -> None:
-    # Define a DataFrame with columns for datetime, date, and time
-    df = pl.DataFrame(
-        {
-            "dtm": [
-                datetime(2022, 12, 31, 10, 30, 45),
-                datetime(2023, 7, 5, 23, 59, 59),
-            ],
-            "dt": [
-                date(2022, 10, 10),
-                date(2022, 7, 5),
-            ],
-            "tm": [
-                time(1, 2, 3, 456000),
-                time(7, 8, 9, 101000),
-            ],
-        }
-    )
-    df = df.with_columns(pl.col("dtm").dt.replace_time_zone(time_zone))
-
-    # Combine datetime/date with time
-    df = df.select(
-        [
-            pl.col("dtm").dt.combine(pl.col("tm")).alias("d1"),  # datetime & time
-            pl.col("dt").dt.combine(pl.col("tm")).alias("d2"),  # date & time
-            pl.col("dt").dt.combine(time(4, 5, 6)).alias("d3"),  # date & specified time
-        ]
-    )
-
-    # Assert that the new columns have the expected values and datatypes
-    expected_dict = {
-        "d1": [  # Time component should be overwritten by `tm` values
-            datetime(2022, 12, 31, 1, 2, 3, 456000, tzinfo=tzinfo),
-            datetime(2023, 7, 5, 7, 8, 9, 101000, tzinfo=tzinfo),
-        ],
-        "d2": [  # Both date and time components combined "as-is" into new datetime
-            datetime(2022, 10, 10, 1, 2, 3, 456000),
-            datetime(2022, 7, 5, 7, 8, 9, 101000),
-        ],
-        "d3": [  # New datetime should use specified time component
-            datetime(2022, 10, 10, 4, 5, 6),
-            datetime(2022, 7, 5, 4, 5, 6),
-        ],
-    }
-    assert df.to_dict(False) == expected_dict
-
-    expected_schema = {
-        "d1": pl.Datetime("us", time_zone),
-        "d2": pl.Datetime("us"),
-        "d3": pl.Datetime("us"),
-    }
-    assert df.schema == expected_schema
-
-
-def test_combine_unsupported_types() -> None:
-    with pytest.raises(ComputeError, match="expected Date or Datetime, got time"):
-        pl.Series([time(1, 2)]).dt.combine(time(3, 4))
-
-
-@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
-@pytest.mark.parametrize("time_zone", ["Asia/Kathmandu", None])
-def test_combine_lazy_schema_datetime(
-    time_zone: str | None,
-    time_unit: TimeUnit,
-) -> None:
-    df = pl.DataFrame({"ts": pl.Series([datetime(2020, 1, 1)])})
-    df = df.with_columns(pl.col("ts").dt.replace_time_zone(time_zone))
-    result = (
-        df.lazy()
-        .select(pl.col("ts").dt.combine(time(1, 2, 3), time_unit=time_unit))
-        .dtypes
-    )
-    expected = [pl.Datetime(time_unit, time_zone)]
-    assert result == expected
-
-
-@pytest.mark.parametrize("time_unit", ["ms", "us", "ns"])
-def test_combine_lazy_schema_date(time_unit: TimeUnit) -> None:
-    df = pl.DataFrame({"ts": pl.Series([date(2020, 1, 1)])})
-    result = (
-        df.lazy()
-        .select(pl.col("ts").dt.combine(time(1, 2, 3), time_unit=time_unit))
-        .dtypes
-    )
-    expected = [pl.Datetime(time_unit, None)]
+def test_to_datetime_tz_aware_strptime(ts: str, fmt: str, expected: datetime) -> None:
+    result = pl.Series([ts]).str.to_datetime(fmt).item()
     assert result == expected
 
 
-def test_is_leap_year() -> None:
-    assert pl.date_range(
-        datetime(1990, 1, 1), datetime(2004, 1, 1), "1y", eager=True
-    ).dt.is_leap_year().to_list() == [
-        False,
-        False,
-        True,  # 1992
-        False,
-        False,
-        False,
-        True,  # 1996
-        False,
-        False,
-        False,
-        True,  # 2000
-        False,
-        False,
-        False,
-        True,  # 2004
-    ]
-
-
-def test_quarter() -> None:
-    assert pl.date_range(
-        datetime(2022, 1, 1), datetime(2022, 12, 1), "1mo", eager=True
-    ).dt.quarter().to_list() == [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4]
+@pytest.mark.parametrize("format", ["%+", "%Y-%m-%dT%H:%M:%S%z"])
+def test_crossing_dst(format: str) -> None:
+    ts = ["2021-03-27T23:59:59+01:00", "2021-03-28T23:59:59+02:00"]
+    result = pl.Series(ts).str.to_datetime(format)
+    assert result[0] == datetime(2021, 3, 27, 22, 59, 59, tzinfo=ZoneInfo(key="UTC"))
+    assert result[1] == datetime(2021, 3, 28, 21, 59, 59, tzinfo=ZoneInfo(key="UTC"))
 
 
-def test_date_offset() -> None:
-    df = pl.DataFrame(
-        {
-            "dates": pl.date_range(
-                datetime(2000, 1, 1), datetime(2020, 1, 1), "1y", eager=True
-            )
-        }
-    )
-
-    # Add two new columns to the DataFrame using the offset_by() method
-    df = df.with_columns(
+@pytest.mark.parametrize("format", ["%+", "%Y-%m-%dT%H:%M:%S%z"])
+def test_crossing_dst_tz_aware(format: str) -> None:
+    ts = ["2021-03-27T23:59:59+01:00", "2021-03-28T23:59:59+02:00"]
+    result = pl.Series(ts).str.to_datetime(format)
+    expected = pl.Series(
         [
-            df["dates"].dt.offset_by("1y").alias("date_plus_1y"),
-            df["dates"].dt.offset_by("-1y2mo").alias("date_min"),
+            datetime(2021, 3, 27, 22, 59, 59, tzinfo=timezone.utc),
+            datetime(2021, 3, 28, 21, 59, 59, tzinfo=timezone.utc),
         ]
     )
-
-    # Assert that the day of the month for all the dates in new columns is 1
-    assert (df["date_plus_1y"].dt.day() == 1).all()
-    assert (df["date_min"].dt.day() == 1).all()
-
-    # Assert that the 'date_min' column contains the expected list of dates
-    expected_dates = [datetime(year, 11, 1, 0, 0) for year in range(1998, 2019)]
-    assert df["date_min"].to_list() == expected_dates
-
-
-@pytest.mark.parametrize("time_zone", ["US/Central", None])
-def test_offset_by_crossing_dst(time_zone: str | None) -> None:
-    ser = pl.Series([datetime(2021, 11, 7)]).dt.replace_time_zone(time_zone)
-    result = ser.dt.offset_by("1d")
-    expected = pl.Series([datetime(2021, 11, 8)]).dt.replace_time_zone(time_zone)
     assert_series_equal(result, expected)
 
 
-def test_negative_offset_by_err_msg_8464() -> None:
-    with pytest.raises(
-        ComputeError, match=r"cannot advance '2022-03-30 00:00:00' by -1 month\(s\)"
-    ):
-        pl.Series([datetime(2022, 3, 30)]).dt.offset_by("-1mo")
-
-
-def test_offset_by_truncate_sorted_flag() -> None:
-    s = pl.Series([datetime(2001, 1, 1), datetime(2001, 1, 2)])
-    s = s.set_sorted()
-
-    assert s.flags["SORTED_ASC"]
-    s1 = s.dt.offset_by("1d")
-    assert s1.to_list() == [datetime(2001, 1, 2), datetime(2001, 1, 3)]
-    assert s1.flags["SORTED_ASC"]
-    s2 = s1.dt.truncate("1mo")
-    assert s2.flags["SORTED_ASC"]
-
-
 @pytest.mark.parametrize(
-    ("duration", "input_date", "expected"),
+    ("data", "format", "expected"),
     [
-        ("1mo_saturating", date(2018, 1, 31), date(2018, 2, 28)),
-        ("1y_saturating", date(2024, 2, 29), date(2025, 2, 28)),
-        ("1y1mo_saturating", date(2024, 1, 30), date(2025, 2, 28)),
+        (
+            "2023-02-05T05:10:10.074000",
+            "%Y-%m-%dT%H:%M:%S%.f",
+            datetime(2023, 2, 5, 5, 10, 10, 74000),
+        ),
     ],
 )
-def test_offset_by_saturating_8217_8474(
-    duration: str, input_date: date, expected: date
-) -> None:
-    result = pl.Series([input_date]).dt.offset_by(duration).item()
+def test_strptime_subseconds_datetime(data: str, format: str, expected: time) -> None:
+    s = pl.Series([data])
+    result = s.str.to_datetime(format).item()
     assert result == expected
 
 
-def test_year_empty_df() -> None:
-    df = pl.DataFrame(pl.Series(name="date", dtype=pl.Date))
-    assert df.select(pl.col("date").dt.year()).dtypes == [pl.Int32]
-
-
 @pytest.mark.parametrize(
-    "time_unit",
-    ["ms", "us", "ns"],
-    ids=["milliseconds", "microseconds", "nanoseconds"],
+    ("string", "fmt"),
+    [
+        pytest.param("2023-05-04|7", "%Y-%m-%d|%H", id="hour but no minute"),
+        pytest.param("2023-05-04|7", "%Y-%m-%d|%k", id="padded hour but no minute"),
+        pytest.param("2023-05-04|10", "%Y-%m-%d|%M", id="minute but no hour"),
+        pytest.param("2023-05-04|10", "%Y-%m-%d|%S", id="second but no hour"),
+        pytest.param(
+            "2000-Jan-01 01 00 01", "%Y-%b-%d %I %M %S", id="12-hour clock but no AM/PM"
+        ),
+        pytest.param(
+            "2000-Jan-01 01 00 01",
+            "%Y-%b-%d %l %M %S",
+            id="padded 12-hour clock but no AM/PM",
+        ),
+    ],
 )
-def test_weekday(time_unit: TimeUnit) -> None:
-    friday = pl.Series([datetime(2023, 2, 17)])
-
-    assert friday.dt.cast_time_unit(time_unit).dt.weekday()[0] == 5
-    assert friday.cast(pl.Date).dt.weekday()[0] == 5
+def test_strptime_incomplete_formats(string: str, fmt: str) -> None:
+    with pytest.raises(
+        ComputeError,
+        match="Invalid format string",
+    ):
+        pl.Series([string]).str.to_datetime(fmt)
 
 
 @pytest.mark.parametrize(
-    ("values", "expected_median"),
+    ("string", "fmt", "expected"),
     [
-        ([], None),
-        ([None, None], None),
-        ([date(2022, 1, 1)], date(2022, 1, 1)),
-        ([date(2022, 1, 1), date(2022, 1, 2), date(2022, 1, 3)], date(2022, 1, 2)),
-        ([date(2022, 1, 1), date(2022, 1, 2), date(2024, 5, 15)], date(2022, 1, 2)),
+        ("2023-05-04|7:3", "%Y-%m-%d|%H:%M", datetime(2023, 5, 4, 7, 3)),
+        ("2023-05-04|10:03", "%Y-%m-%d|%H:%M", datetime(2023, 5, 4, 10, 3)),
+        (
+            "2000-Jan-01 01 00 01 am",
+            "%Y-%b-%d %I %M %S %P",
+            datetime(2000, 1, 1, 1, 0, 1),
+        ),
+        (
+            "2000-Jan-01 01 00 01 am",
+            "%Y-%b-%d %_I %M %S %P",
+            datetime(2000, 1, 1, 1, 0, 1),
+        ),
+        (
+            "2000-Jan-01 01 00 01 am",
+            "%Y-%b-%d %l %M %S %P",
+            datetime(2000, 1, 1, 1, 0, 1),
+        ),
+        (
+            "2000-Jan-01 01 00 01 AM",
+            "%Y-%b-%d %I %M %S %p",
+            datetime(2000, 1, 1, 1, 0, 1),
+        ),
+        (
+            "2000-Jan-01 01 00 01 AM",
+            "%Y-%b-%d %_I %M %S %p",
+            datetime(2000, 1, 1, 1, 0, 1),
+        ),
+        (
+            "2000-Jan-01 01 00 01 AM",
+            "%Y-%b-%d %l %M %S %p",
+            datetime(2000, 1, 1, 1, 0, 1),
+        ),
     ],
-    ids=["empty", "Nones", "single", "spread_even", "spread_skewed"],
 )
-def test_median(values: list[date | None], expected_median: date | None) -> None:
-    result = pl.Series(values).cast(pl.Date).dt.median()
-    assert result == expected_median
+def test_strptime_complete_formats(string: str, fmt: str, expected: datetime) -> None:
+    # Similar to the above, but these formats are complete and should work
+    result = pl.Series([string]).str.to_datetime(fmt).item()
+    assert result == expected
 
 
 @pytest.mark.parametrize(
-    ("values", "expected_mean"),
+    ("data", "format", "expected"),
     [
-        ([], None),
-        ([None, None], None),
-        ([date(2022, 1, 1)], date(2022, 1, 1)),
-        ([date(2022, 1, 1), date(2022, 1, 2), date(2022, 1, 3)], date(2022, 1, 2)),
-        ([date(2022, 1, 1), date(2022, 1, 2), date(2024, 5, 15)], date(2022, 10, 16)),
+        ("05:10:10.074000", "%H:%M:%S%.f", time(5, 10, 10, 74000)),
+        ("05:10:10.074000", "%T%.6f", time(5, 10, 10, 74000)),
+        ("05:10:10.074000", "%H:%M:%S%.3f", time(5, 10, 10, 74000)),
     ],
-    ids=["empty", "Nones", "single", "spread_even", "spread_skewed"],
 )
-def test_mean(values: list[date | None], expected_mean: date | None) -> None:
-    result = pl.Series(values).cast(pl.Date).dt.mean()
-    assert result == expected_mean
+def test_to_time_subseconds(data: str, format: str, expected: time) -> None:
+    s = pl.Series([data])
+    result = s.str.to_time(format).item()
+    assert result == expected
+
+
+def test_to_time_format_warning() -> None:
+    s = pl.Series(["05:10:10.074000"])
+    with pytest.warns(pl.ChronoFormatWarning, match=".%f"):
+        result = s.str.to_time("%H:%M:%S.%f").item()
+    assert result == time(5, 10, 10, 74)
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/namespaces/test_list.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_list.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,9 @@
 from __future__ import annotations
 
-import typing
 from datetime import date, datetime
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_series_equal
@@ -251,15 +250,14 @@
         "lst": [[2], [1]]
     }
     assert df.select([pl.col("lst").list.slice(-2, "len")]).to_dict(False) == {
         "lst": [[3, 4], [2, 1]]
     }
 
 
-@typing.no_type_check
 def test_list_sliced_get_5186() -> None:
     # https://github.com/pola-rs/polars/issues/5186
     n = 30
     df = pl.from_dict(
         {
             "ind": pl.arange(0, n, eager=True),
             "inds": np.stack([np.arange(n), -np.arange(n)], axis=-1),
@@ -450,7 +448,51 @@
     ]
 
 
 def test_list_count_match_boolean_nulls_9141() -> None:
     a = pl.DataFrame({"a": [[True, None, False]]})
 
     assert a.select(pl.col("a").list.count_match(True))["a"].to_list() == [1]
+
+
+def test_list_set_operations() -> None:
+    df = pl.DataFrame(
+        {"a": [[1, 2, 3], [1, 1, 1], [4]], "b": [[4, 2, 1], [2, 1, 12], [4]]}
+    )
+
+    assert df.select(pl.col("a").list.union("b"))["a"].to_list() == [
+        [1, 2, 3, 4],
+        [1, 2, 12],
+        [4],
+    ]
+    assert df.select(pl.col("a").list.intersection("b"))["a"].to_list() == [
+        [2, 1],
+        [1],
+        [4],
+    ]
+    assert df.select(pl.col("a").list.difference("b"))["a"].to_list() == [[3], [], []]
+    assert df.select(pl.col("b").list.difference("a"))["b"].to_list() == [
+        [4],
+        [2, 12],
+        [],
+    ]
+
+    # check logical types
+    dtype = pl.List(pl.Date)
+    assert (
+        df.select(pl.col("b").cast(dtype).list.difference(pl.col("a").cast(dtype)))[
+            "b"
+        ].dtype
+        == dtype
+    )
+
+    df = pl.DataFrame(
+        {
+            "a": [["a", "b", "c"], ["b", "e", "z"]],
+            "b": [["b", "s", "a"], ["a", "e", "f"]],
+        }
+    )
+
+    assert df.select(pl.col("a").list.union("b"))["a"].to_list() == [
+        ["a", "b", "c", "s"],
+        ["b", "e", "z", "a", "f"],
+    ]
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/namespaces/test_meta.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_meta.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 from __future__ import annotations
 
 import pytest
 
 import polars as pl
+from polars import col
 
 
 def test_meta_pop_and_cmp() -> None:
     e = pl.col("foo").alias("bar")
 
     first = e.meta.pop()[0]
     assert first.meta == pl.col("foo")
@@ -60,7 +61,15 @@
     assert e.meta.has_multiple_outputs()
 
 
 def test_meta_is_regex_projection() -> None:
     e = pl.col("^.*$").alias("bar")
     assert e.meta.is_regex_projection()
     assert e.meta.has_multiple_outputs()
+
+
+def test_meta_tree_format() -> None:
+    e = (col("foo") * col("bar")).sum().over(col("ham")) / 2
+    assert (
+        e.meta.tree_format(return_as_string=True)
+        == """    binary: /    \n\n      |              |       \n\n    lit(2)           window      \n\n                     |               |        \n\n                     col(ham)        sum          \n\n                                     |        \n\n                                     binary: *    \n\n                                     |                |       \n\n                                     col(bar)         col(foo)    \n"""
+    )
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/namespaces/test_string.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_string.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/namespaces/test_struct.py` & `polars_lts_cpu-0.18.5/tests/unit/namespaces/test_struct.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_aggregations.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_aggregations.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,17 +1,20 @@
 import math
-import typing
 from datetime import date, datetime, timedelta
+from typing import TYPE_CHECKING, Any, Optional
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
 
+if TYPE_CHECKING:
+    import numpy.typing as npt
+
 
 def test_quantile_expr_input() -> None:
     df = pl.DataFrame({"a": [1, 2, 3, 4, 5], "b": [0, 0, 0.3, 0.2, 0]})
 
     assert_frame_equal(
         df.select([pl.col("a").quantile(pl.col("b").sum() + 0.1)]),
         df.select(pl.col("a").quantile(0.6)),
@@ -93,60 +96,60 @@
 def test_median() -> None:
     s = pl.Series([1, 2, 3])
     assert s.median() == 2
 
 
 def test_single_element_std() -> None:
     s = pl.Series([1])
-    assert math.isnan(typing.cast(float, s.std(ddof=1)))
+    assert math.isnan(s.std(ddof=1))  # type: ignore[arg-type]
     assert s.std(ddof=0) == 0.0
 
 
 def test_quantile() -> None:
     s = pl.Series([1, 2, 3])
     assert s.quantile(0.5, "nearest") == 2
     assert s.quantile(0.5, "lower") == 2
     assert s.quantile(0.5, "higher") == 2
 
 
 @pytest.mark.slow()
-@typing.no_type_check
-def test_quantile_vs_numpy() -> None:
-    for tp in [int, float]:
-        for n in [1, 2, 10, 100]:
-            a = np.random.randint(0, 50, n).astype(tp)
-            np_result = np.median(a)
-            # nan check
-            if np_result != np_result:
-                np_result = None
-            median = pl.Series(a).median()
-            if median is not None:
-                assert np.isclose(median, np_result)
-            else:
-                assert np_result is None
-
-            q = np.random.sample()
-            try:
-                np_result = np.quantile(a, q)
-            except IndexError:
-                np_result = None
-                pass
-            if np_result:
-                # nan check
-                if np_result != np_result:
-                    np_result = None
-                assert np.isclose(
-                    pl.Series(a).quantile(q, interpolation="linear"), np_result
-                )
+@pytest.mark.parametrize("tp", [int, float])
+@pytest.mark.parametrize("n", [1, 2, 10, 100])
+def test_quantile_vs_numpy(tp: type, n: int) -> None:
+    a: np.ndarray[Any, Any] = np.random.randint(0, 50, n).astype(tp)
+    np_result: Optional[npt.ArrayLike] = np.median(a)
+    # nan check
+    if np_result != np_result:
+        np_result = None
+    median = pl.Series(a).median()
+    if median is not None:
+        assert np.isclose(median, np_result)  # type: ignore[arg-type]
+    else:
+        assert np_result is None
+
+    q = np.random.sample()
+    try:
+        np_result = np.quantile(a, q)
+    except IndexError:
+        np_result = None
+        pass
+    if np_result:
+        # nan check
+        if np_result != np_result:
+            np_result = None
+        assert np.isclose(
+            pl.Series(a).quantile(q, interpolation="linear"),  # type: ignore[arg-type]
+            np_result,  # type: ignore[arg-type]
+        )
 
 
-@typing.no_type_check
 def test_mean_overflow() -> None:
     assert np.isclose(
-        pl.Series([9_223_372_036_854_775_800, 100]).mean(), 4.611686018427388e18
+        pl.Series([9_223_372_036_854_775_800, 100]).mean(),  # type: ignore[arg-type]
+        4.611686018427388e18,
     )
 
 
 def test_mean_null_simd() -> None:
     for dtype in [int, float]:
         df = (
             pl.Series(np.random.randint(0, 100, 1000))
@@ -261,7 +264,15 @@
 
 
 def test_mapped_literal_to_literal_9217() -> None:
     df = pl.DataFrame({"unique_id": ["a", "b"]})
     assert df.groupby(True).agg(
         pl.struct(pl.lit("unique_id").alias("unique_id"))
     ).to_dict(False) == {"literal": [True], "unique_id": [{"unique_id": "unique_id"}]}
+
+
+def test_sum_empty_and_null_set() -> None:
+    series = pl.Series("a", [])
+    assert series.sum() == 0
+
+    series = pl.Series("a", [None])
+    assert series.sum() == 0
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_apply.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_apply.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,13 @@
 from __future__ import annotations
 
 import json
-import typing
 from datetime import date, datetime, timedelta
 from functools import reduce
-from typing import Sequence, no_type_check
+from typing import Any, Sequence
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
 
@@ -55,26 +54,25 @@
 
 def test_apply_return_py_object() -> None:
     df = pl.DataFrame({"A": [1, 2, 3], "B": [4, 5, 6]})
     out = df.select([pl.all().map(lambda s: reduce(lambda a, b: a + b, s))])
     assert out.rows() == [(6, 15)]
 
 
-@no_type_check
 def test_agg_objects() -> None:
     df = pl.DataFrame(
         {
             "names": ["foo", "ham", "spam", "cheese", "egg", "foo"],
             "dates": ["1", "1", "2", "3", "3", "4"],
             "groups": ["A", "A", "B", "B", "B", "C"],
         }
     )
 
     class Foo:
-        def __init__(self, payload):
+        def __init__(self, payload: Any):
             self.payload = payload
 
     out = df.groupby("groups").agg(
         [
             pl.apply(
                 [pl.col("dates"), pl.col("names")], lambda s: Foo(dict(zip(s[0], s[1])))
             )
@@ -341,16 +339,15 @@
         "a"
     ].to_list() == [payload]
 
 
 def test_err_df_apply_return_type() -> None:
     df = pl.DataFrame({"a": [[1, 2], [2, 3]], "b": [[4, 5], [6, 7]]})
 
-    @typing.no_type_check
-    def cmb(row):
+    def cmb(row: tuple[Any, ...]) -> list[Any]:
         res = [x + y for x, y in zip(row[0], row[1])]
         return [res]
 
     with pytest.raises(pl.ComputeError, match="expected tuple, got list"):
         df.apply(cmb)
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_arithmetic.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_arithmetic.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import typing
 from datetime import date, datetime, timedelta
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.testing import assert_series_equal
@@ -107,15 +106,14 @@
         0.6579683924555951,
         0.6579683924555951,
         0.6579683924555951,
         0.6579683924555951,
     ]
 
 
-@typing.no_type_check
 def test_floor_division_float_int_consistency() -> None:
     a = np.random.randn(10) * 10
 
     assert (pl.Series(a) // 5).to_list() == list(a // 5)
     assert (pl.Series(a, dtype=pl.Int32) // 5).to_list() == list(
         (a.astype(int) // 5).astype(int)
     )
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_comparison.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_comparison.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-import typing
-
 import polars as pl
 from polars.testing import assert_frame_equal
 
 
 def test_comparison_order_null_broadcasting() -> None:
     # see more: 8183
     exprs = [
@@ -118,17 +116,31 @@
                 "gt": [False, True, False],
                 "ge": [False, True, True],
             }
         ),
     )
 
 
-@typing.no_type_check
 def test_offset_handling_arg_where_7863() -> None:
     df_check = pl.DataFrame({"a": [0, 1]})
     df_check.select((pl.lit(0).append(pl.col("a")).append(0)) != 0)
     assert (
         df_check.select((pl.lit(0).append(pl.col("a")).append(0)) != 0)
         .select(pl.col("literal").arg_true())
         .item()
         == 2
     )
+
+
+def test_missing_equality_on_bools() -> None:
+    df = pl.DataFrame(
+        {
+            "a": [True, None, False],
+        }
+    )
+
+    assert df.select(pl.col("a").ne_missing(True))["a"].to_list() == [False, True, True]
+    assert df.select(pl.col("a").ne_missing(False))["a"].to_list() == [
+        True,
+        True,
+        False,
+    ]
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_drop.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_drop.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_explode.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_explode.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_filter.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_filter.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_folds.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_folds.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_groupby.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_groupby.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_groupby_rolling.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_groupby_rolling.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_is_in.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_is_in.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_join.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_join.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 from __future__ import annotations
 
-import typing
 from datetime import datetime
-from typing import TYPE_CHECKING
+from typing import TYPE_CHECKING, Literal
 
 import numpy as np
 import pandas as pd
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_series_equal
@@ -357,15 +356,14 @@
 
     joined = dfb.join(dfa, on="b", how="semi")
     assert not joined["a"].flags["SORTED_ASC"]
     joined = dfb.join(dfa, on="b", how="anti")
     assert not joined["a"].flags["SORTED_ASC"]
 
 
-@typing.no_type_check
 def test_jit_sort_joins() -> None:
     n = 200
     # Explicitly specify numpy dtype because of different defaults on Windows
     dfa = pd.DataFrame(
         {
             "a": np.random.randint(0, 100, n, dtype=np.int64),
             "b": np.arange(0, n, dtype=np.int64),
@@ -378,36 +376,36 @@
             "a": np.random.randint(0, 100, n, dtype=np.int64),
             "b": np.arange(0, n, dtype=np.int64),
         }
     )
     dfa_pl = pl.from_pandas(dfa).sort("a")
     dfb_pl = pl.from_pandas(dfb)
 
-    for how in ["left", "inner"]:
+    join_strategies: list[Literal["left", "inner"]] = ["left", "inner"]
+    for how in join_strategies:
         pd_result = dfa.merge(dfb, on="a", how=how)
-        pd_result.columns = ["a", "b", "b_right"]
+        pd_result.columns = pd.Index(["a", "b", "b_right"])
 
         # left key sorted right is not
         pl_result = dfa_pl.join(dfb_pl, on="a", how=how).sort(["a", "b"])
 
         a = pl.from_pandas(pd_result).with_columns(pl.all().cast(int)).sort(["a", "b"])
         assert_frame_equal(a, pl_result)
         assert pl_result["a"].flags["SORTED_ASC"]
 
         # left key sorted right is not
         pd_result = dfb.merge(dfa, on="a", how=how)
-        pd_result.columns = ["a", "b", "b_right"]
+        pd_result.columns = pd.Index(["a", "b", "b_right"])
         pl_result = dfb_pl.join(dfa_pl, on="a", how=how).sort(["a", "b"])
 
         a = pl.from_pandas(pd_result).with_columns(pl.all().cast(int)).sort(["a", "b"])
         assert_frame_equal(a, pl_result)
         assert pl_result["a"].flags["SORTED_ASC"]
 
 
-@typing.no_type_check
 def test_streaming_joins() -> None:
     n = 100
     dfa = pd.DataFrame(
         {
             "a": np.random.randint(0, 40, n),
             "b": np.arange(0, n),
         }
@@ -419,17 +417,18 @@
             "a": np.random.randint(0, 40, n),
             "b": np.arange(0, n),
         }
     )
     dfa_pl = pl.from_pandas(dfa).sort("a")
     dfb_pl = pl.from_pandas(dfb)
 
-    for how in ["inner", "left"]:
+    join_strategies: list[Literal["inner", "left"]] = ["inner", "left"]
+    for how in join_strategies:
         pd_result = dfa.merge(dfb, on="a", how=how)
-        pd_result.columns = ["a", "b", "b_right"]
+        pd_result.columns = pd.Index(["a", "b", "b_right"])
 
         pl_result = (
             dfa_pl.lazy()
             .join(dfb_pl.lazy(), on="a", how=how)
             .sort(["a", "b"])
             .collect(streaming=True)
         )
@@ -508,27 +507,26 @@
     a = pl.DataFrame({"a": [1, 2, 3]})
     b = pl.DataFrame({"b": [4, 5]})
     c = a.update(b)
 
     assert c.rows() == a.rows()
 
 
-@typing.no_type_check
 def test_join_frame_consistency() -> None:
     df = pl.DataFrame({"A": [1, 2, 3]})
     ldf = pl.DataFrame({"A": [1, 2, 5]}).lazy()
 
     with pytest.raises(TypeError, match="Expected 'other'.* LazyFrame"):
-        _ = ldf.join(df, on="A")
+        _ = ldf.join(df, on="A")  # type: ignore[arg-type]
     with pytest.raises(TypeError, match="Expected 'other'.* DataFrame"):
-        _ = df.join(ldf, on="A")
+        _ = df.join(ldf, on="A")  # type: ignore[arg-type]
     with pytest.raises(TypeError, match="Expected 'other'.* LazyFrame"):
-        _ = ldf.join_asof(df, on="A")
+        _ = ldf.join_asof(df, on="A")  # type: ignore[arg-type]
     with pytest.raises(TypeError, match="Expected 'other'.* DataFrame"):
-        _ = df.join_asof(ldf, on="A")
+        _ = df.join_asof(ldf, on="A")  # type: ignore[arg-type]
 
 
 def test_join_concat_projection_pd_case_7071() -> None:
     ldf = pl.DataFrame({"id": [1, 2], "value": [100, 200]}).lazy()
     ldf2 = pl.DataFrame({"id": [1, 3], "value": [100, 300]}).lazy()
 
     ldf = ldf.join(ldf2, on=["id", "value"])
@@ -554,20 +552,19 @@
     assert df1.join(df2, on="x", how="semi").to_dict(False) == {"x": [0, 0]}
     assert df1.join(df2, on="x", how="outer").to_dict(False) == {
         "x": [0, 0, 1, None],
         "y": [0, 0, None, 1],
     }
 
 
-@typing.no_type_check
 def test_outer_join_list_() -> None:
     schema = {"id": pl.Int64, "vals": pl.List(pl.Float64)}
 
-    df1 = pl.DataFrame({"id": [1], "vals": [[]]}, schema=schema)
-    df2 = pl.DataFrame({"id": [2, 3], "vals": [[], [4]]}, schema=schema)
+    df1 = pl.DataFrame({"id": [1], "vals": [[]]}, schema=schema)  # type: ignore[arg-type]
+    df2 = pl.DataFrame({"id": [2, 3], "vals": [[], [4]]}, schema=schema)  # type: ignore[arg-type]
     assert df1.join(df2, on="id", how="outer").to_dict(False) == {
         "id": [2, 3, 1],
         "vals": [None, None, []],
         "vals_right": [[], [4.0], None],
     }
 
 
@@ -585,7 +582,30 @@
         a.join(b, on="a", validate="1:m")
     with pytest.raises(pl.ComputeError):
         a.join(b, on="a", validate="1:1")
     with pytest.raises(pl.ComputeError):
         b.join(a, on="a", validate="m:1")
     with pytest.raises(pl.ComputeError):
         b.join(a, on="a", validate="1:1")
+
+    df = pl.DataFrame(
+        {
+            "foo": [1, 2],
+            "ham": ["a", "a"],
+        }
+    )
+
+    other_df = pl.DataFrame(
+        {
+            "apple": ["x", "y", "z"],
+            "ham": ["a", "b", "z"],
+        }
+    )
+
+    with pytest.raises(pl.ComputeError):
+        df.join(other_df, on="ham", validate="1:m")
+
+    assert df.join(other_df, on="ham", validate="m:1")["foo"].to_list() == [1, 2]
+    assert other_df.join(df, on="ham", validate="1:m")["foo"].to_list() == [1, 2]
+
+    with pytest.raises(pl.ComputeError):
+        other_df.join(df, on="ham", validate="m:1")
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_join_asof.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_join_asof.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_melt.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_melt.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_pivot.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_pivot.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_rolling.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_rolling.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from __future__ import annotations
 
 import sys
-import typing
 from datetime import date, datetime, timedelta
 from typing import TYPE_CHECKING
 
 import pytest
 from numpy import nan
 
 from polars.exceptions import ComputeError
@@ -216,21 +215,21 @@
 
 
 def test_rolling_extrema() -> None:
     # sorted data and nulls flags trigger different kernels
     df = (
         pl.DataFrame(
             {
-                "col1": pl.arange(0, 7, eager=True),
-                "col2": pl.arange(0, 7, eager=True).reverse(),
+                "col1": pl.int_range(0, 7, eager=True),
+                "col2": pl.int_range(0, 7, eager=True).reverse(),
             }
         )
     ).with_columns(
         [
-            pl.when(pl.arange(0, pl.count(), eager=False) < 2)
+            pl.when(pl.int_range(0, pl.count(), eager=False) < 2)
             .then(None)
             .otherwise(pl.all())
             .suffix("_nulls")
         ]
     )
 
     assert df.select([pl.all().rolling_min(3)]).to_dict(False) == {
@@ -244,15 +243,15 @@
         "col1": [None, None, 2, 3, 4, 5, 6],
         "col2": [None, None, 6, 5, 4, 3, 2],
         "col1_nulls": [None, None, None, None, 4, 5, 6],
         "col2_nulls": [None, None, None, None, 4, 3, 2],
     }
 
     # shuffled data triggers other kernels
-    df = df.select([pl.all().shuffle(0)])
+    df = df.select([pl.all().shuffle(0, fixed_seed=True)])
     assert df.select([pl.all().rolling_min(3)]).to_dict(False) == {
         "col1": [None, None, 0, 0, 1, 2, 2],
         "col2": [None, None, 0, 2, 1, 1, 1],
         "col1_nulls": [None, None, None, None, None, 2, 2],
         "col2_nulls": [None, None, None, None, None, 1, 1],
     }
 
@@ -496,16 +495,24 @@
             0.0,
             0.0,
         ]
     )
     assert res[:4] == [None] * 4
 
 
-@typing.no_type_check
-def test_dynamic_groupby_timezone_awareness() -> None:
+@pytest.mark.parametrize(
+    ("every", "offset"),
+    [
+        ("3d", "-1d"),
+        (timedelta(days=3), timedelta(days=-1)),
+    ],
+)
+def test_dynamic_groupby_timezone_awareness(
+    every: str | timedelta, offset: str | timedelta
+) -> None:
     df = pl.DataFrame(
         (
             pl.date_range(
                 datetime(2020, 1, 1),
                 datetime(2020, 1, 10),
                 timedelta(days=1),
                 time_unit="ns",
@@ -513,25 +520,24 @@
             )
             .alias("datetime")
             .dt.replace_time_zone("UTC"),
             pl.arange(1, 11, eager=True).alias("value"),
         )
     )
 
-    for every, offset in (("3d", "-1d"), (timedelta(days=3), timedelta(days=-1))):
-        assert (
-            df.groupby_dynamic(
-                "datetime",
-                every=every,
-                offset=offset,
-                closed="right",
-                include_boundaries=True,
-                truncate=False,
-            ).agg(pl.col("value").last())
-        ).dtypes == [pl.Datetime("ns", "UTC")] * 3 + [pl.Int64]
+    assert (
+        df.groupby_dynamic(
+            "datetime",
+            every=every,
+            offset=offset,
+            closed="right",
+            include_boundaries=True,
+            truncate=False,
+        ).agg(pl.col("value").last())
+    ).dtypes == [pl.Datetime("ns", "UTC")] * 3 + [pl.Int64]
 
 
 @pytest.mark.parametrize("tzinfo", [None, ZoneInfo("Asia/Kathmandu")])
 def test_groupby_dynamic_startby_5599(tzinfo: ZoneInfo | None) -> None:
     # start by datapoint
     start = datetime(2022, 12, 16, tzinfo=tzinfo)
     stop = datetime(2022, 12, 16, hour=3, tzinfo=tzinfo)
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_select.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_select.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_sort.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_sort.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_statistics.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_statistics.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,13 +1,15 @@
 from datetime import timedelta
+from typing import cast
 
 import numpy as np
+from numpy import inf
 
 import polars as pl
-from polars.testing import assert_frame_equal
+from polars.testing import assert_frame_equal, assert_series_equal
 
 
 def test_corr() -> None:
     df = pl.DataFrame(
         {
             "a": [1, 2, 4],
             "b": [-1, 23, 8],
@@ -21,15 +23,15 @@
         }
     )
     assert_frame_equal(result, expected)
 
 
 def test_cut() -> None:
     a = pl.Series("a", [v / 10 for v in range(-30, 30, 5)])
-    out = a.cut(bins=[-1, 1])
+    out = cast(pl.DataFrame, a.cut(bins=[-1, 1]))
 
     assert out.shape == (12, 3)
     assert out.filter(pl.col("break_point") < 1e9).to_dict(False) == {
         "a": [-3.0, -2.5, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0],
         "break_point": [-1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0],
         "category": [
             "(-inf, -1.0]",
@@ -44,57 +46,136 @@
         ],
     }
 
     # test cut on integers #4939
     inf = float("inf")
     df = pl.DataFrame({"a": list(range(5))})
     ser = df.select("a").to_series()
-    assert ser.cut(bins=[-1, 1]).rows() == [
+    assert cast(pl.DataFrame, ser.cut(bins=[-1, 1])).rows() == [
         (0.0, 1.0, "(-1.0, 1.0]"),
         (1.0, 1.0, "(-1.0, 1.0]"),
         (2.0, inf, "(1.0, inf]"),
         (3.0, inf, "(1.0, inf]"),
         (4.0, inf, "(1.0, inf]"),
     ]
 
 
 def test_cut_maintain_order() -> None:
+    expected_df = pl.DataFrame(
+        {
+            "a": [5.0, 8.0, 9.0, 5.0, 0.0, 0.0, 1.0, 7.0, 6.0, 9.0],
+            "break_point": [inf, inf, inf, inf, 1.0, 1.0, 1.0, inf, inf, inf],
+            "category": [
+                "(1.0, inf]",
+                "(1.0, inf]",
+                "(1.0, inf]",
+                "(1.0, inf]",
+                "(-1.0, 1.0]",
+                "(-1.0, 1.0]",
+                "(-1.0, 1.0]",
+                "(1.0, inf]",
+                "(1.0, inf]",
+                "(1.0, inf]",
+            ],
+        }
+    )
     np.random.seed(1)
     a = pl.Series("a", np.random.randint(0, 10, 10))
-    out = a.cut(bins=[-1, 1], maintain_order=True)
+    out = cast(pl.DataFrame, a.cut(bins=[-1, 1], maintain_order=True))
+    out_s = cast(pl.Series, a.cut(bins=[-1, 1], series=True))
     assert out["a"].cast(int).series_equal(a)
-    assert (
-        str(out.to_dict(False))
-        == "{'a': [5.0, 8.0, 9.0, 5.0, 0.0, 0.0, 1.0, 7.0, 6.0, 9.0], 'break_point': [inf, inf, inf, inf, 1.0, 1.0, 1.0, inf, inf, inf], 'category': ['(1.0, inf]', '(1.0, inf]', '(1.0, inf]', '(1.0, inf]', '(-1.0, 1.0]', '(-1.0, 1.0]', '(-1.0, 1.0]', '(1.0, inf]', '(1.0, inf]', '(1.0, inf]']}"
+    # Compare strings and categoricals without a hassle
+    assert_frame_equal(expected_df, out, check_dtype=False)
+    # It formats differently
+    assert_series_equal(
+        pl.Series(["(1, inf]"] * 4 + ["(-1, 1]"] * 3 + ["(1, inf]"] * 3),
+        out_s,
+        check_dtype=False,
+        check_names=False,
     )
 
 
 def test_qcut() -> None:
-    assert (
-        str(pl.Series("a", range(-5, 3)).qcut([0.0, 0.25, 0.75]).to_dict(False))
-        == "{'a': [-5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0], 'break_point': [-5.0, -3.25, 0.25, 0.25, 0.25, 0.25, inf, inf], 'category': ['(-inf, -5.0]', '(-5.0, -3.25]', '(-3.25, 0.25]', '(-3.25, 0.25]', '(-3.25, 0.25]', '(-3.25, 0.25]', '(0.25, inf]', '(0.25, inf]']}"
+    input = pl.Series("a", range(-5, 3))
+    exp = pl.DataFrame(
+        {
+            "a": [-5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0],
+            "break_point": [-5.0, -3.25, 0.25, 0.25, 0.25, 0.25, inf, inf],
+            "category": [
+                "(-inf, -5.0]",
+                "(-5.0, -3.25]",
+                "(-3.25, 0.25]",
+                "(-3.25, 0.25]",
+                "(-3.25, 0.25]",
+                "(-3.25, 0.25]",
+                "(0.25, inf]",
+                "(0.25, inf]",
+            ],
+        }
+    )
+    out = cast(pl.DataFrame, input.qcut([0.0, 0.25, 0.75]))
+    out_s = cast(pl.Series, input.qcut([0.0, 0.25, 0.75], series=True))
+    assert_frame_equal(out, exp, check_dtype=False)
+    assert_series_equal(
+        pl.Series(
+            ["(-inf, -5]", "(-5, -3.25]"] + ["(-3.25, 0.25]"] * 4 + ["(0.25, inf]"] * 2
+        ),
+        out_s,
+        check_dtype=False,
+        check_names=False,
     )
 
 
 def test_hist() -> None:
     a = pl.Series("a", [1, 3, 8, 8, 2, 1, 3])
     assert (
         str(a.hist(bin_count=4).to_dict(False))
         == "{'break_point': [0.0, 2.25, 4.5, 6.75, inf], 'category': ['(-inf, 0.0]', '(0.0, 2.25]', '(2.25, 4.5]', '(4.5, 6.75]', '(6.75, inf]'], 'a_count': [0, 3, 2, 0, 2]}"
     )
 
 
 def test_cut_null_values() -> None:
     s = pl.Series([-1.0, None, 1.0, 2.0, None, 8.0, 4.0])
-    assert (
-        str(s.qcut([0.2, 0.3], maintain_order=True).to_dict(False))
-        == "{'': [-1.0, None, 1.0, 2.0, None, 8.0, 4.0], 'break_point': [0.5999999999999996, None, 1.2000000000000002, inf, None, inf, inf], 'category': ['(-inf, 0.5999999999999996]', None, '(0.5999999999999996, 1.2000000000000002]', '(1.2000000000000002, inf]', None, '(1.2000000000000002, inf]', '(1.2000000000000002, inf]']}"
+    exp = pl.DataFrame(
+        {
+            "": [-1.0, None, 1.0, 2.0, None, 8.0, 4.0],
+            "break_point": [
+                0.5999999999999996,
+                None,
+                1.2000000000000002,
+                inf,
+                None,
+                inf,
+                inf,
+            ],
+            "category": [
+                "(-inf, 0.5999999999999996]",
+                None,
+                "(0.5999999999999996, 1.2000000000000002]",
+                "(1.2000000000000002, inf]",
+                None,
+                "(1.2000000000000002, inf]",
+                "(1.2000000000000002, inf]",
+            ],
+        }
+    )
+    assert_frame_equal(
+        cast(pl.DataFrame, s.qcut([0.2, 0.3], maintain_order=True)),
+        exp,
+        check_dtype=False,
+    )
+    assert_series_equal(
+        cast(pl.Series, s.qcut([0.2, 0.3], series=True)),
+        exp.get_column("category"),
+        check_dtype=False,
+        check_names=False,
     )
+
     assert (
-        str(s.qcut([0.2, 0.3], maintain_order=False).to_dict(False))
+        str(cast(pl.DataFrame, s.qcut([0.2, 0.3], maintain_order=False)).to_dict(False))
         == "{'': [-1.0, 1.0, 2.0, 4.0, 8.0, None, None], 'break_point': [0.5999999999999996, 1.2000000000000002, inf, inf, inf, None, None], 'category': ['(-inf, 0.5999999999999996]', '(0.5999999999999996, 1.2000000000000002]', '(1.2000000000000002, inf]', '(1.2000000000000002, inf]', '(1.2000000000000002, inf]', None, None]}"
     )
 
 
 def test_median_quantile_duration() -> None:
     df = pl.DataFrame({"A": [timedelta(days=0), timedelta(days=1)]})
     assert df.select(pl.col("A").median()).to_dict(False) == {
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_transpose.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_transpose.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_unique.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_unique.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_window.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_window.py`

 * *Files 2% similar despite different names*

```diff
@@ -112,28 +112,26 @@
         [2, 3, 4],
         [2, 3, 4],
     ]
     assert out["values_flat"].to_list() == [0, 1, 2, 3, 4]
     assert out["values_rev"].to_list() == [1, 0, 4, 3, 2]
 
 
-def test_arange_no_rows() -> None:
+def test_window_range_no_rows() -> None:
     df = pl.DataFrame({"x": [5, 5, 4, 4, 2, 2]})
-    expr = pl.arange(0, pl.count()).over("x")
+    expr = pl.int_range(0, pl.count()).over("x")
     out = df.with_columns(expr)
     assert_frame_equal(
-        out, pl.DataFrame({"x": [5, 5, 4, 4, 2, 2], "arange": [0, 1, 0, 1, 0, 1]})
+        out, pl.DataFrame({"x": [5, 5, 4, 4, 2, 2], "int": [0, 1, 0, 1, 0, 1]})
     )
 
     df = pl.DataFrame({"x": []})
     out = df.with_columns(expr)
-    print(out)
-    expected = pl.DataFrame(
-        {"x": [], "arange": []}, schema={"x": pl.Float32, "arange": pl.Int64}
-    )
+
+    expected = pl.DataFrame(schema={"x": pl.Float32, "int": pl.Int64})
     assert_frame_equal(out, expected)
 
 
 def test_no_panic_on_nan_3067() -> None:
     df = pl.DataFrame(
         {
             "group": ["a", "a", "a", "b", "b", "b"],
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/operations/test_with_columns.py` & `polars_lts_cpu-0.18.5/tests/unit/operations/test_with_columns.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/streaming/test_ooc.py` & `polars_lts_cpu-0.18.5/tests/unit/streaming/test_ooc.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/streaming/test_streaming.py` & `polars_lts_cpu-0.18.5/tests/unit/streaming/test_streaming.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,18 +1,24 @@
+from __future__ import annotations
+
 import time
-import typing
 from datetime import date
-from typing import Any
+from typing import TYPE_CHECKING, Any
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_series_equal
 
+if TYPE_CHECKING:
+    from pathlib import Path
+
+    from polars.type_aliases import JoinStrategy
+
 
 def test_streaming_groupby_types() -> None:
     df = pl.DataFrame(
         {
             "person_id": [1, 1],
             "year": [1995, 1995],
             "person_name": ["bob", "foo"],
@@ -470,15 +476,14 @@
                 .groupby(keys)
                 .agg(pl.col("z").sum().alias("z_sum"))
                 .collect(streaming=True)
             )
             assert dfd["z_sum"].sum() == dfc["z"].sum()
 
 
-@typing.no_type_check
 def test_streaming_groupby_categorical_aggregate() -> None:
     with pl.StringCache():
         out = (
             pl.LazyFrame(
                 {
                     "a": pl.Series(
                         ["a", "a", "b", "b", "c", "c", None, None], dtype=pl.Categorical
@@ -597,7 +602,37 @@
             1836,
             1976,
             2091,
             2120,
             2124,
         ],
     }
+
+
+@pytest.mark.write_disk()
+@pytest.mark.slow()
+def test_streaming_generic_left_and_inner_join_from_disk(tmp_path: Path) -> None:
+    tmp_path.mkdir(exist_ok=True)
+    p0 = tmp_path / "df0.parquet"
+    p1 = tmp_path / "df1.parquet"
+    # by loading from disk, we get different chunks
+    n = 200_000
+    k = 100
+
+    d0: dict[str, np.ndarray[Any, Any]] = {
+        f"x{i}": np.random.random(n) for i in range(k)
+    }
+    d0.update({"id": np.arange(n)})
+
+    df0 = pl.DataFrame(d0)
+    df1 = df0.clone().select(pl.all().shuffle(111))
+
+    df0.write_parquet(p0)
+    df1.write_parquet(p1)
+
+    lf0 = pl.scan_parquet(p0)
+    lf1 = pl.scan_parquet(p1).select(pl.all().suffix("_r"))
+
+    join_strategies: list[JoinStrategy] = ["left", "inner"]
+    for how in join_strategies:
+        q = lf0.join(lf1, left_on="id", right_on="id_r", how=how)
+        assert_frame_equal(q.collect(streaming=True), q.collect(streaming=False))
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_api.py` & `polars_lts_cpu-0.18.5/tests/unit/test_api.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,11 +1,9 @@
 from __future__ import annotations
 
-from typing import no_type_check
-
 import polars as pl
 from polars.testing import assert_frame_equal
 
 
 def test_custom_df_namespace() -> None:
     @pl.api.register_dataframe_namespace("split")
     class SplitFrame:
@@ -38,15 +36,14 @@
     dfs = df.split.by_first_letter_of_column_values("a1")  # type: ignore[attr-defined]
     assert [d.rows() for d in dfs] == [
         [("xx", 2, 3, 4), ("xy", 4, 5, 6)],
         [("yy", 5, 6, 7), ("yz", 6, 7, 8)],
     ]
 
 
-@no_type_check
 def test_custom_expr_namespace() -> None:
     @pl.api.register_expr_namespace("power")
     class PowersOfN:
         def __init__(self, expr: pl.Expr):
             self._expr = expr
 
         def next(self, p: int) -> pl.Expr:
@@ -58,27 +55,26 @@
         def nearest(self, p: int) -> pl.Expr:
             return (p ** (self._expr.log(p)).round(0).cast(pl.Int64)).cast(pl.Int64)
 
     df = pl.DataFrame([1.4, 24.3, 55.0, 64.001], schema=["n"])
     assert df.select(
         [
             pl.col("n"),
-            pl.col("n").power.next(p=2).alias("next_pow2"),
-            pl.col("n").power.previous(p=2).alias("prev_pow2"),
-            pl.col("n").power.nearest(p=2).alias("nearest_pow2"),
+            pl.col("n").power.next(p=2).alias("next_pow2"),  # type: ignore[attr-defined]
+            pl.col("n").power.previous(p=2).alias("prev_pow2"),  # type: ignore[attr-defined]
+            pl.col("n").power.nearest(p=2).alias("nearest_pow2"),  # type: ignore[attr-defined]
         ]
     ).rows() == [
         (1.4, 2, 1, 1),
         (24.3, 32, 16, 32),
         (55.0, 64, 32, 64),
         (64.001, 128, 64, 64),
     ]
 
 
-@no_type_check
 def test_custom_lazy_namespace() -> None:
     @pl.api.register_lazyframe_namespace("split")
     class SplitFrame:
         def __init__(self, ldf: pl.LazyFrame):
             self._ldf = ldf
 
         def by_column_dtypes(self) -> list[pl.LazyFrame]:
@@ -88,15 +84,15 @@
 
     ldf = pl.DataFrame(
         data=[["xx", 2, 3, 4], ["xy", 4, 5, 6], ["yy", 5, 6, 7], ["yz", 6, 7, 8]],
         schema=["a1", "a2", "b1", "b2"],
         orient="row",
     ).lazy()
 
-    df1, df2 = (d.collect() for d in ldf.split.by_column_dtypes())
+    df1, df2 = (d.collect() for d in ldf.split.by_column_dtypes())  # type: ignore[attr-defined]
     assert_frame_equal(
         df1, pl.DataFrame([("xx",), ("xy",), ("yy",), ("yz",)], schema=["a1"])
     )
     assert_frame_equal(
         df2,
         pl.DataFrame(
             [(2, 3, 4), (4, 5, 6), (5, 6, 7), (6, 7, 8)], schema=["a2", "b1", "b2"]
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_arity.py` & `polars_lts_cpu-0.18.5/tests/unit/test_arity.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_cfg.py` & `polars_lts_cpu-0.18.5/tests/unit/test_cfg.py`

 * *Files 0% similar despite different names*

```diff
@@ -3,14 +3,15 @@
 import os
 from typing import TYPE_CHECKING, Iterator
 
 import pytest
 
 import polars as pl
 from polars.config import _get_float_fmt
+from polars.exceptions import StringCacheMismatchError
 from polars.testing import assert_frame_equal
 
 if TYPE_CHECKING:
     from pathlib import Path
 
 
 @pytest.fixture(autouse=True)
@@ -477,15 +478,15 @@
 
     # ensure cache is off when casting to categorical; the join will fail
     pl.enable_string_cache(False)
     assert pl.using_string_cache() is False
 
     df1a = df1.with_columns(pl.col("a").cast(pl.Categorical))
     df2a = df2.with_columns(pl.col("a").cast(pl.Categorical))
-    with pytest.raises(pl.ComputeError):
+    with pytest.raises(StringCacheMismatchError):
         _ = df1a.join(df2a, on="a", how="inner")
 
     # now turn on the cache
     pl.enable_string_cache(True)
     assert pl.using_string_cache() is True
 
     df1b = df1.with_columns(pl.col("a").cast(pl.Categorical))
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_constructors.py` & `polars_lts_cpu-0.18.5/tests/unit/test_constructors.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,31 +1,27 @@
 from __future__ import annotations
 
 import sys
 from datetime import date, datetime, timedelta, timezone
 from decimal import Decimal
 from random import shuffle
-from typing import TYPE_CHECKING, Any, NamedTuple, no_type_check
+from typing import TYPE_CHECKING, Any, List, Literal, NamedTuple
 
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 import pytest
+from pydantic import BaseModel, Field, TypeAdapter
 
 import polars as pl
 from polars.dependencies import _ZONEINFO_AVAILABLE, dataclasses, pydantic
-from polars.exceptions import TimeZoneAwareConstructorWarning
+from polars.exceptions import ShapeError, TimeZoneAwareConstructorWarning
 from polars.testing import assert_frame_equal, assert_series_equal
 from polars.utils._construction import type_hints
 
-if sys.version_info >= (3, 8):
-    from typing import Literal
-else:
-    from typing_extensions import Literal  # noqa: TCH002
-
 if TYPE_CHECKING:
     from polars.datatypes import PolarsDataType
 
 if sys.version_info >= (3, 9):
     from zoneinfo import ZoneInfo
 elif _ZONEINFO_AVAILABLE:
     # Import from submodule due to typing issue with backports.zoneinfo package:
@@ -178,24 +174,23 @@
     # empty nested objects
     for empty_val in [None, "", {}, []]:  # type: ignore[var-annotated]
         test = [{"field": {"sub_field": empty_val, "sub_field_2": 2}}]
         df = pl.DataFrame(test, schema={"field": pl.Object})
         assert df.to_dict(False)["field"][0] == test[0]["field"]
 
 
-@no_type_check
 def test_error_string_dtypes() -> None:
     with pytest.raises(ValueError, match="Cannot infer dtype"):
         pl.DataFrame(
             data={"x": [1, 2], "y": [3, 4], "z": [5, 6]},
-            schema={"x": "i16", "y": "i32", "z": "f32"},
+            schema={"x": "i16", "y": "i32", "z": "f32"},  # type: ignore[dict-item]
         )
 
     with pytest.raises(ValueError, match="not a valid Polars data type"):
-        pl.Series("n", [1, 2, 3], dtype="f32")
+        pl.Series("n", [1, 2, 3], dtype="f32")  # type: ignore[arg-type]
 
 
 def test_init_structured_objects(monkeypatch: Any) -> None:
     # validate init from dataclass, namedtuple, and pydantic model objects
     monkeypatch.setenv("POLARS_ACTIVATE_DECIMAL", "1")
 
     @dataclasses.dataclass
@@ -267,49 +262,46 @@
         }
         assert df.rows() == raw_data
 
         # cover a miscellaneous edge-case when detecting the annotations
         assert type_hints(obj=type(None)) == {}
 
 
-@pytest.mark.skipif(pydantic.__version__ < "2.0", reason="requires pydantic 2.x")
-@no_type_check
 def test_init_pydantic_2x() -> None:
-    from pydantic import BaseModel, Field
-
     class PageView(BaseModel):
         user_id: str
-        ts: datetime = Field(alias=["ts", "$date"])  # type: ignore[literal-required]
-        path: str = Field("?", alias=["url", "path"])  # type: ignore[literal-required]
+        ts: datetime = Field(alias=["ts", "$date"])  # type: ignore[literal-required, arg-type]
+        path: str = Field("?", alias=["url", "path"])  # type: ignore[literal-required, arg-type]
         referer: str = Field("?", alias="referer")
         event: Literal["leave", "enter"] = Field("enter")
         time_on_page: int = Field(0, serialization_alias="top")
 
-    if sys.version_info > (3, 7):
-        data_json = """
-        [{
-            "user_id": "x",
-            "ts": {"$date": "2021-01-01T00:00:00.000Z"},
-            "url": "/latest/foobar",
-            "referer": "https://google.com",
-            "event": "enter",
-            "top": 123
-        }]
-        """
-        at = pydantic.TypeAdapter(list[PageView])
-        models = at.validate_json(data_json)
-
-        assert pl.DataFrame(models).to_dict(False) == {
-            "user_id": ["x"],
-            "ts": [datetime(2021, 1, 1, 0, 0)],
-            "path": ["?"],
-            "referer": ["https://google.com"],
-            "event": ["enter"],
-            "time_on_page": [0],
-        }
+    data_json = """
+    [{
+        "user_id": "x",
+        "ts": {"$date": "2021-01-01T00:00:00.000Z"},
+        "url": "/latest/foobar",
+        "referer": "https://google.com",
+        "event": "enter",
+        "top": 123
+    }]
+    """
+    adapter: TypeAdapter[Any] = TypeAdapter(List[PageView])
+    models = adapter.validate_json(data_json)
+
+    result = pl.DataFrame(models)
+
+    assert result.to_dict(False) == {
+        "user_id": ["x"],
+        "ts": [datetime(2021, 1, 1, 0, 0)],
+        "path": ["?"],
+        "referer": ["https://google.com"],
+        "event": ["enter"],
+        "time_on_page": [0],
+    }
 
 
 def test_init_structured_objects_unhashable() -> None:
     # cover an edge-case with namedtuple fields that aren't hashable
 
     class Test(NamedTuple):
         dt: datetime
@@ -757,15 +749,15 @@
 
     # override column names, types
     df = pl.DataFrame(pandas_df, schema=[("x", pl.Float64), ("y", pl.Float64)])
     assert df.schema == {"x": pl.Float64, "y": pl.Float64}
     assert df.rows() == [(1.0, 2.0), (3.0, 4.0)]
 
     # subclassed pandas object, with/without data & overrides
-    class XSeries(pd.Series):
+    class XSeries(pd.Series):  # type: ignore[type-arg]
         @property
         def _constructor(self) -> type:
             return XSeries
 
     df = pl.DataFrame(
         data=[
             XSeries(name="x", data=[], dtype=np.dtype("<M8[ns]")),
@@ -944,23 +936,30 @@
 def test_u64_lit_5031() -> None:
     df = pl.DataFrame({"foo": [1, 2, 3]}).with_columns(pl.col("foo").cast(pl.UInt64))
     assert df.filter(pl.col("foo") < (1 << 64) - 20).shape == (3, 1)
     assert df["foo"].to_list() == [1, 2, 3]
 
 
 def test_from_dicts_missing_columns() -> None:
+    # missing columns from some of the data dicts
     data = [
         {"a": 1},
         {"b": 2},
     ]
-
     assert pl.from_dicts(data).to_dict(False) == {"a": [1, None], "b": [None, 2]}
 
+    # missing columns in the schema; only load the declared keys
+    data = [{"a": 1, "b": 2}]
+    assert pl.from_dicts(data, schema=["a"]).to_dict(False) == {"a": [1]}
+
+    # invalid
+    with pytest.raises(ShapeError):
+        pl.from_dicts([{"a": 1, "b": 2}], schema=["xyz"])
+
 
-@no_type_check
 def test_from_rows_dtype() -> None:
     # 50 is the default inference length
     # 5182
     df = pl.DataFrame(
         data=[(None, None)] * 50 + [("1.23", None)],
         schema=[("foo", pl.Utf8), ("bar", pl.Utf8)],
         orient="row",
@@ -1011,14 +1010,22 @@
         assert df.dtypes == [pl.Int64, pl.Int64, pl.Int32]
         assert df.to_dict(False) == {
             "a": [1, 2, 3],
             "b": [4, 5, 6],
             "c": [None, None, None],
         }
 
+    # provide data that resolves to an empty frame (ref: scalar
+    # expansion shortcut), with schema/override hints
+    schema = {"colx": pl.Utf8, "coly": pl.Int32}
+
+    for param in ("schema", "schema_overrides"):
+        df = pl.DataFrame({"colx": [], "coly": 0}, **{param: schema})  # type: ignore[arg-type]
+        assert df.schema == schema
+
 
 def test_nested_read_dict_4143() -> None:
     assert pl.from_dicts(
         [
             {
                 "id": 1,
                 "hint": [
@@ -1082,53 +1089,55 @@
                 {"some_text_here": "text", "list_": []},
                 {"some_text_here": "text", "list_": []},
             ],
         ],
     }
 
 
-@no_type_check
 def test_from_records_nullable_structs() -> None:
     records = [
         {"id": 1, "items": [{"item_id": 100, "description": None}]},
         {"id": 1, "items": [{"item_id": 100, "description": "hi"}]},
     ]
 
-    schema = [
+    schema: list[tuple[str, pl.PolarsDataType]] = [
         ("id", pl.UInt16),
         (
             "items",
             pl.List(
                 pl.Struct(
                     [pl.Field("item_id", pl.UInt32), pl.Field("description", pl.Utf8)]
                 )
             ),
         ),
     ]
 
-    for s in [schema, None]:
-        assert pl.DataFrame(records, schema=s, orient="row").to_dict(False) == {
+    schema_options: list[list[tuple[str, pl.PolarsDataType]] | None] = [schema, None]
+    for s in schema_options:
+        result = pl.DataFrame(records, schema=s, orient="row")
+        assert result.to_dict(False) == {
             "id": [1, 1],
             "items": [
                 [{"item_id": 100, "description": None}],
                 [{"item_id": 100, "description": "hi"}],
             ],
         }
 
     # check initialisation without any records
     df = pl.DataFrame(schema=schema)
     dict_schema = dict(schema)
 
     assert df.to_dict(False) == {"id": [], "items": []}
     assert df.schema == dict_schema
 
-    s = pl.Series("items", dtype=dict_schema["items"])
-    assert s.to_frame().to_dict(False) == {"items": []}
-    assert s.dtype == dict_schema["items"]
-    assert s.to_list() == []
+    dtype: pl.PolarsDataType = dict_schema["items"]
+    series = pl.Series("items", dtype=dtype)
+    assert series.to_frame().to_dict(False) == {"items": []}
+    assert series.dtype == dict_schema["items"]
+    assert series.to_list() == []
 
 
 def test_from_categorical_in_struct_defined_by_schema() -> None:
     df = pl.DataFrame(
         {
             "a": [
                 {"value": "foo", "counts": 1},
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_datatypes.py` & `polars_lts_cpu-0.18.5/tests/unit/test_datatypes.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from __future__ import annotations
 
 import pickle
-import typing
 from datetime import datetime, timedelta
 
 import pytest
 
 import polars as pl
 from polars import datatypes
 from polars.datatypes import (
@@ -116,15 +115,14 @@
         ),
     ],
 )
 def test_repr(dtype: pl.PolarsDataType, representation: str) -> None:
     assert repr(dtype) == representation
 
 
-@typing.no_type_check
 def test_conversion_dtype() -> None:
     df = (
         pl.DataFrame(
             {
                 "id_column": [1, 2, 3, 4],
                 "some_column": ["a", "b", "c", "d"],
                 "some_partition_column": [
@@ -143,17 +141,17 @@
                 pl.col("some_partition_column"),
             ]
         )
         .groupby(["some_partition_column"], maintain_order=True)
         .agg([pl.col(["struct"])])
     )
 
-    df = pl.from_arrow(df.to_arrow())
+    df = pl.from_arrow(df.to_arrow())  # type: ignore[assignment]
     # the assertion is not the real test
-    # this tests if dtype as bubbled up correctly in conversion
+    # this tests if dtype has bubbled up correctly in conversion
     # if not we would UB
     assert df.to_dict(False) == {
         "some_partition_column": ["partition_1", "partition_2"],
         "struct": [
             [
                 {"id_column": 1, "some_column": "a"},
                 {"id_column": 3, "some_column": "c"},
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_df.py` & `polars_lts_cpu-0.18.5/tests/unit/test_df.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,15 @@
     assert_frame_not_equal,
     assert_series_equal,
 )
 from polars.testing.parametric import columns
 from polars.utils._construction import iterable_to_pydf
 
 if TYPE_CHECKING:
-    from polars.type_aliases import JoinStrategy, UniqueKeepStrategy
+    from polars.type_aliases import IndexOrder, JoinStrategy, UniqueKeepStrategy
 
 if sys.version_info >= (3, 9):
     from zoneinfo import ZoneInfo
 else:
     # Import from submodule due to typing issue with backports.zoneinfo package:
     # https://github.com/pganssle/zoneinfo/issues/125
     from backports.zoneinfo._zoneinfo import ZoneInfo
@@ -451,14 +451,25 @@
     dfx = df8.select(pl.exclude("idx"))
 
     assert len(df8) == n_range
     assert dfx[:5].rows() == dfx[5:10].rows()
     assert dfx[-10:-5].rows() == dfx[-5:].rows()
     assert dfx.row(n_range // 2, named=True) == mixed_dtype_data
 
+    # misc generators/iterables
+    df9 = pl.DataFrame(
+        {
+            "a": iter([0, 1, 2]),
+            "b": (2, 1, 0).__iter__(),
+            "c": (v for v in (0, 0, 0)),
+            "d": "x",
+        }
+    )
+    assert df9.rows() == [(0, 2, 0, "x"), (1, 1, 0, "x"), (2, 0, 0, "x")]
+
 
 def test_dataframe_membership_operator() -> None:
     # cf. issue #4032
     df = pl.DataFrame({"name": ["Jane", "John"], "age": [20, 30]})
     assert "name" in df
     assert "phone" not in df
     assert df._ipython_key_completions_() == ["name", "age"]
@@ -1428,28 +1439,33 @@
     # check if can assign in case of a single column
     df = pl.DataFrame({"a": [1, 2, 3]})
     # test if we can assign in case of single column
     df = df.with_columns(pl.col("a") * 2)
     assert list(df["a"]) == [2, 4, 6]
 
 
-def test_to_numpy() -> None:
+@pytest.mark.parametrize(
+    ("order", "f_contiguous", "c_contiguous"),
+    [("fortran", True, False), ("c", False, True)],
+)
+def test_to_numpy(order: IndexOrder, f_contiguous: bool, c_contiguous: bool) -> None:
     df = pl.DataFrame({"a": [1, 2, 3], "b": [1.0, 2.0, 3.0]})
 
-    out_array = df.to_numpy()
+    out_array = df.to_numpy(order=order)
     expected_array = np.array([[1.0, 1.0], [2.0, 2.0], [3.0, 3.0]], dtype=np.float64)
     assert_array_equal(out_array, expected_array)
-    assert out_array.flags["F_CONTIGUOUS"] is True
+    assert out_array.flags["F_CONTIGUOUS"] == f_contiguous
+    assert out_array.flags["C_CONTIGUOUS"] == c_contiguous
 
-    structured_array = df.to_numpy(structured=True)
+    structured_array = df.to_numpy(structured=True, order=order)
     expected_array = np.array(
         [(1, 1.0), (2, 2.0), (3, 3.0)], dtype=[("a", "<i8"), ("b", "<f8")]
     )
     assert_array_equal(structured_array, expected_array)
-    assert structured_array.flags["F_CONTIGUOUS"] is True
+    assert structured_array.flags["F_CONTIGUOUS"]
 
 
 def test_to_numpy_structured() -> None:
     # round-trip structured array: validate init/export
     structured_array = np.array(
         [
             ("Google Pixel 7", 521.90, True),
@@ -2405,21 +2421,14 @@
     assert df.n_unique(subset=pl.col("c")) == 2
     assert (
         df.n_unique(subset=[(pl.col("a") // 2), (pl.col("c") | (pl.col("b") >= 2))])
         == 3
     )
 
 
-def test_sample() -> None:
-    df = pl.DataFrame({"foo": [1, 2, 3], "bar": [6, 7, 8], "ham": ["a", "b", "c"]})
-
-    assert df.sample(n=2, seed=0).shape == (2, 3)
-    assert df.sample(fraction=0.4, seed=0).shape == (1, 3)
-
-
 def test_shrink_to_fit() -> None:
     df = pl.DataFrame({"foo": [1, 2, 3], "bar": [6, 7, 8], "ham": ["a", "b", "c"]})
 
     assert df.shrink_to_fit(in_place=True) is df
     assert df.shrink_to_fit(in_place=False) is not df
     assert_frame_equal(df.shrink_to_fit(in_place=False), df)
 
@@ -2884,15 +2893,14 @@
     result = lhs.join_asof(
         rhs, on=pl.col("a").set_sorted(), by=["by", "by2"], strategy="backward"
     ).select(["a", "by"])
     expected = pl.DataFrame({"a": [-20, -19, 8, 12, 14], "by": [1, 1, 2, 2, 2]})
     assert_frame_equal(result, expected)
 
 
-@typing.no_type_check
 def test_partition_by() -> None:
     df = pl.DataFrame(
         {
             "foo": ["A", "A", "B", "B", "C"],
             "N": [1, 2, 2, 4, 2],
             "bar": ["k", "l", "m", "m", "l"],
         }
@@ -2924,25 +2932,24 @@
     }
     assert df.partition_by(["a"], as_dict=True)["one"].to_dict(False) == {
         "a": ["one", "one"],
         "b": [1, 3],
     }
 
 
-@typing.no_type_check
 def test_list_of_list_of_struct() -> None:
     expected = [{"list_of_list_of_struct": [[{"a": 1}, {"a": 2}]]}]
     pa_df = pa.Table.from_pylist(expected)
 
     df = pl.from_arrow(pa_df)
-    assert df.rows() == [([[{"a": 1}, {"a": 2}]],)]
-    assert df.to_dicts() == expected
+    assert df.rows() == [([[{"a": 1}, {"a": 2}]],)]  # type: ignore[union-attr]
+    assert df.to_dicts() == expected  # type: ignore[union-attr]
 
     df = pl.from_arrow(pa_df[:0])
-    assert df.to_dicts() == []
+    assert df.to_dicts() == []  # type: ignore[union-attr]
 
 
 def test_concat_to_empty() -> None:
     assert pl.concat([pl.DataFrame([]), pl.DataFrame({"a": [1]})]).to_dict(False) == {
         "a": [1]
     }
 
@@ -3684,40 +3691,30 @@
 
     assert (roll_app_sum - roll_sum).abs().sum() < 0.0001
 
     s = pl.Series("A", list(range(6)), dtype=pl.Float64)
     roll_app_std = s.rolling_apply(
         function=lambda s: s.std(),
         window_size=4,
-        weights=[1.0, 2.0, 3.0, 0.1],
         min_periods=3,
         center=False,
     )
 
-    roll_std = s.rolling_std(
-        window_size=4, weights=[1.0, 2.0, 3.0, 0.1], min_periods=3, center=False
-    )
+    roll_std = s.rolling_std(window_size=4, min_periods=3, center=False)
 
     assert (roll_app_std - roll_std).abs().sum() < 0.0001
 
 
 def test_ufunc() -> None:
-    # NOTE: unfortunately we must use cast instead of a type: ignore comment
-    #   1. CI job with Python 3.10, numpy==1.23.1 -> mypy complains about arg-type
-    #   2. so we try to resolve it with type: ignore[arg-type]
-    #   3. CI job with Python 3.7, numpy==1.21.6 -> mypy complains about
-    #       unused type: ignore comment
-    # for more information, see: https://github.com/python/mypy/issues/8823
-
     df = pl.DataFrame([pl.Series("a", [1, 2, 3, 4], dtype=pl.UInt8)])
     out = df.select(
         [
-            np.power(cast(Any, pl.col("a")), 2).alias("power_uint8"),
-            np.power(cast(Any, pl.col("a")), 2.0).alias("power_float64"),
-            np.power(cast(Any, pl.col("a")), 2, dtype=np.uint16).alias("power_uint16"),
+            np.power(pl.col("a"), 2).alias("power_uint8"),  # type: ignore[call-overload]
+            np.power(pl.col("a"), 2.0).alias("power_float64"),  # type: ignore[call-overload]
+            np.power(pl.col("a"), 2, dtype=np.uint16).alias("power_uint16"),  # type: ignore[call-overload]
         ]
     )
     expected = pl.DataFrame(
         [
             pl.Series("power_uint8", [1, 4, 9, 16], dtype=pl.UInt8),
             pl.Series("power_float64", [1.0, 4.0, 9.0, 16.0], dtype=pl.Float64),
             pl.Series("power_uint16", [1, 4, 9, 16], dtype=pl.UInt16),
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_empty.py` & `polars_lts_cpu-0.18.5/tests/unit/test_empty.py`

 * *Files 4% similar despite different names*

```diff
@@ -74,7 +74,16 @@
 
 def test_empty_groupby_apply_err() -> None:
     df = pl.DataFrame(schema={"x": pl.Int64})
     with pytest.raises(
         pl.ComputeError, match=r"cannot groupby \+ apply on empty 'DataFrame'"
     ):
         df.groupby("x").apply(lambda x: x)
+
+
+def test_empty_list_namespace_output_9585() -> None:
+    dtype = pl.List(pl.Utf8)
+    names = ["sort", "unique", "head", "tail", "shift", "reverse"]
+    df = pl.DataFrame([[None]], schema={"A": dtype})
+    assert df.select(
+        [eval(f"pl.col('A').list.{name}().suffix(f'_{name}')") for name in names]
+    ).dtypes == [dtype] * len(names)
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_errors.py` & `polars_lts_cpu-0.18.5/tests/unit/test_errors.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,19 +1,22 @@
 from __future__ import annotations
 
 import io
-import typing
 from datetime import date, datetime, time, timedelta
+from typing import TYPE_CHECKING
 
 import numpy as np
 import pytest
 
 import polars as pl
 from polars.datatypes.convert import dtype_to_py_type
 
+if TYPE_CHECKING:
+    from polars.type_aliases import ConcatMethod
+
 
 def test_error_on_empty_groupby() -> None:
     with pytest.raises(
         pl.ComputeError, match="at least one key is required in a groupby operation"
     ):
         pl.DataFrame({"x": [0, 0, 1, 1]}).groupby([]).agg(pl.count())
 
@@ -98,35 +101,34 @@
     with pytest.raises(
         pl.PolarsPanicError,
         match="""dimensions cannot be empty""",
     ):
         pl.Series("a", [1, 2, 3]).reshape(())
 
 
-@typing.no_type_check
 def test_join_lazy_on_df() -> None:
     df_left = pl.DataFrame(
         {
             "Id": [1, 2, 3, 4],
             "Names": ["A", "B", "C", "D"],
         }
     )
     df_right = pl.DataFrame({"Id": [1, 3], "Tags": ["xxx", "yyy"]})
 
     with pytest.raises(
         TypeError,
         match="Expected 'other' .* to be a LazyFrame.* not a DataFrame",
     ):
-        df_left.lazy().join(df_right, on="Id")
+        df_left.lazy().join(df_right, on="Id")  # type: ignore[arg-type]
 
     with pytest.raises(
         TypeError,
         match="Expected 'other' .* to be a LazyFrame.* not a DataFrame",
     ):
-        df_left.lazy().join_asof(df_right, on="Id")
+        df_left.lazy().join_asof(df_right, on="Id")  # type: ignore[arg-type]
 
 
 def test_projection_update_schema_missing_column() -> None:
     with pytest.raises(
         pl.ComputeError, match="column 'colC' not available in schema Schema:*"
     ):
         (
@@ -146,41 +148,40 @@
     with pytest.raises(err_type):
         df.rename({"does_not_exist": "exists"})
 
     with pytest.raises(err_type):
         df.select(pl.col("does_not_exist").alias("new_name"))
 
 
-@typing.no_type_check
 def test_getitem_errs() -> None:
     df = pl.DataFrame({"a": [1, 2, 3]})
 
     with pytest.raises(
         ValueError,
         match=r"Cannot __getitem__ on DataFrame with item: "
         r"'{'some'}' of type: '<class 'set'>'.",
     ):
-        df[{"some"}]
+        df[{"some"}]  # type: ignore[call-overload]
 
     with pytest.raises(
         ValueError,
         match=r"Cannot __getitem__ on Series of dtype: "
         r"'Int64' with argument: "
         r"'{'strange'}' of type: '<class 'set'>'.",
     ):
-        df["a"][{"strange"}]
+        df["a"][{"strange"}]  # type: ignore[call-overload]
 
     with pytest.raises(
         ValueError,
         match=r"Cannot __setitem__ on "
         r"DataFrame with key: '{'some'}' of "
         r"type: '<class 'set'>' and value: "
         r"'foo' of type: '<class 'str'>'",
     ):
-        df[{"some"}] = "foo"
+        df[{"some"}] = "foo"  # type: ignore[index]
 
 
 def test_err_bubbling_up_to_lit() -> None:
     df = pl.DataFrame({"date": [date(2020, 1, 1)], "value": [42]})
 
     with pytest.raises(ValueError):
         df.filter(pl.col("date") == pl.Date("2020-01-01"))
@@ -276,15 +277,14 @@
             "the length of the window expression did not match that of the group" in msg
         )
         assert "group:" in msg
         assert "group length:" in msg
         assert "output: 'shape:" in msg
 
 
-@typing.no_type_check
 def test_lazy_concat_err() -> None:
     df1 = pl.DataFrame(
         {
             "foo": [1, 2],
             "bar": [6, 7],
             "ham": ["a", "b"],
         }
@@ -299,23 +299,22 @@
     with pytest.raises(
         ValueError,
         match="'LazyFrame' only allows {'vertical','vertical_relaxed','diagonal','align'} concat strategies.",
     ):
         pl.concat([df1.lazy(), df2.lazy()], how="horizontal").collect()
 
 
-@typing.no_type_check
-def test_series_concat_err() -> None:
+@pytest.mark.parametrize("how", ["horizontal", "diagonal"])
+def test_series_concat_err(how: ConcatMethod) -> None:
     s = pl.Series([1, 2, 3])
-    for how in ("horizontal", "diagonal"):
-        with pytest.raises(
-            ValueError,
-            match="'Series' only allows {'vertical'} concat strategy.",
-        ):
-            pl.concat([s, s], how=how)
+    with pytest.raises(
+        ValueError,
+        match="'Series' only allows {'vertical'} concat strategy.",
+    ):
+        pl.concat([s, s], how=how)
 
 
 def test_invalid_sort_by() -> None:
     df = pl.DataFrame(
         {
             "a": ["bill", "bob", "jen", "allie", "george"],
             "b": ["M", "M", "F", "F", "M"],
@@ -350,21 +349,20 @@
 
 
 def test_datetime_time_add_err() -> None:
     with pytest.raises(pl.ComputeError):
         pl.Series([datetime(1970, 1, 1, 0, 0, 1)]) + pl.Series([time(0, 0, 2)])
 
 
-@typing.no_type_check
 def test_invalid_dtype() -> None:
     with pytest.raises(
         ValueError,
         match=r"Given dtype: 'mayonnaise' is not a valid Polars data type and cannot be converted into one",
     ):
-        pl.Series([1, 2], dtype="mayonnaise")
+        pl.Series([1, 2], dtype="mayonnaise")  # type: ignore[arg-type]
 
 
 def test_arr_eval_named_cols() -> None:
     df = pl.DataFrame({"A": ["a", "b"], "B": [["a", "b"], ["c", "d"]]})
 
     with pytest.raises(
         pl.ComputeError,
@@ -421,29 +419,36 @@
     with pytest.raises(
         pl.ComputeError, match=r"The predicate expanded to zero expressions"
     ):
         # we filter by ints
         df.filter(pl.col(pl.Int16).min() < 0.1)
 
 
-def test_date_string_comparison() -> None:
+@pytest.mark.parametrize(
+    ("e"),
+    [
+        pl.col("date") > "2021-11-10",
+        pl.col("date") < "2021-11-10",
+    ],
+)
+def test_date_string_comparison(e: pl.Expr) -> None:
     df = pl.DataFrame(
         {
             "date": [
                 "2022-11-01",
                 "2022-11-02",
                 "2022-11-05",
             ],
         }
     ).with_columns(pl.col("date").str.strptime(pl.Date, "%Y-%m-%d"))
 
     with pytest.raises(
         pl.ComputeError, match=r"cannot compare 'date/datetime/time' to a string value"
     ):
-        df.select(pl.col("date") > "2021-11-10")
+        df.select(e)
 
 
 def test_err_on_multiple_column_expansion() -> None:
     # this would be a great feature :)
     with pytest.raises(
         pl.ComputeError, match=r"expanding more than one `col` is not allowed"
     ):
@@ -523,14 +528,20 @@
 
 def test_err_on_time_datetime_cast() -> None:
     s = pl.Series([time(10, 0, 0), time(11, 30, 59)])
     with pytest.raises(pl.ComputeError, match=r"cannot cast `Time` to `Datetime`"):
         s.cast(pl.Datetime)
 
 
+def test_err_on_invalid_time_zone_cast() -> None:
+    s = pl.Series([datetime(2021, 1, 1)])
+    with pytest.raises(pl.ComputeError, match=r"unable to parse time zone: 'qwerty'"):
+        s.cast(pl.Datetime("us", "qwerty"))
+
+
 def test_invalid_inner_type_cast_list() -> None:
     s = pl.Series([[-1, 1]])
     with pytest.raises(
         pl.ComputeError, match=r"cannot cast List inner type: 'Int64' to Categorical"
     ):
         s.cast(pl.List(pl.Categorical))
 
@@ -568,20 +579,19 @@
 def test_window_size_validation() -> None:
     df = pl.DataFrame({"x": [1.0]})
 
     with pytest.raises(ValueError, match=r"'window_size' should be positive"):
         df.with_columns(trailing_min=pl.col("x").rolling_min(window_size=-3))
 
 
-@typing.no_type_check
 def test_invalid_getitem_key_err() -> None:
     df = pl.DataFrame({"x": [1.0], "y": [1.0]})
 
     with pytest.raises(KeyError, match=r"('x', 'y')"):
-        df["x", "y"]
+        df["x", "y"]  # type: ignore[index]
 
 
 def test_invalid_groupby_arg() -> None:
     df = pl.DataFrame({"a": [1]})
     with pytest.raises(
         ValueError, match="specifying aggregations as a dictionary is not supported"
     ):
@@ -655,7 +665,19 @@
         {"a": [1, 1, 1], "b": [3, 2, 1], "c": [1, 1, 2]},
         schema={"a": pl.Float32, "b": pl.Float32, "c": pl.Float32},
     )
     with pytest.raises(pl.ComputeError):
         df.lazy().groupby("c").agg(
             [pl.col("a").sort_by(pl.col("b").filter(pl.col("b") > 100)).sum()]
         ).collect()
+
+
+def test_raise_cut_in_over() -> None:
+    with pl.StringCache():
+        x = pl.Series(range(20))
+    r = pl.Series(
+        [pl.repeat("a", 10, eager=True), pl.repeat("b", 10, eager=True)]
+    ).explode()
+    df = pl.DataFrame({"x": x, "g": r})
+
+    with pytest.raises(pl.ComputeError):
+        df.with_columns(pl.col("x").qcut([0.5]).over("g").to_physical())
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_expr_multi_cols.py` & `polars_lts_cpu-0.18.5/tests/unit/test_expr_multi_cols.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_exprs.py` & `polars_lts_cpu-0.18.5/tests/unit/test_exprs.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,10 @@
 from __future__ import annotations
 
-import random
 import sys
-import typing
 from datetime import date, datetime, time, timedelta, timezone
 from itertools import permutations
 from typing import Any, cast
 
 if sys.version_info >= (3, 9):
     from zoneinfo import ZoneInfo
 else:
@@ -150,51 +148,14 @@
     assert cast(int, out.item()) == 5
 
     out = df.groupby("b", maintain_order=True).agg(pl.count())
     assert out["b"].to_list() == ["a", "b"]
     assert out["count"].to_list() == [4, 1]
 
 
-def test_shuffle() -> None:
-    # setting 'random.seed' should lead to reproducible results
-    s = pl.Series("a", range(20))
-    s_list = s.to_list()
-
-    random.seed(1)
-    result1 = pl.select(pl.lit(s).shuffle()).to_series()
-
-    random.seed(1)
-    result2 = pl.select(a=pl.lit(s_list).shuffle()).to_series()
-    assert_series_equal(result1, result2)
-
-
-def test_sample() -> None:
-    a = pl.Series("a", range(0, 20))
-    out = pl.select(
-        pl.lit(a).sample(fraction=0.5, with_replacement=False, seed=1)
-    ).to_series()
-
-    assert out.shape == (10,)
-    assert out.to_list() != out.sort().to_list()
-    assert out.unique().shape == (10,)
-    assert set(out).issubset(set(a))
-
-    out = pl.select(pl.lit(a).sample(n=10, with_replacement=False, seed=1)).to_series()
-    assert out.shape == (10,)
-    assert out.to_list() != out.sort().to_list()
-    assert out.unique().shape == (10,)
-
-    # Setting random.seed should lead to reproducible results
-    random.seed(1)
-    result1 = pl.select(pl.lit(a).sample(n=10)).to_series()
-    random.seed(1)
-    result2 = pl.select(pl.lit(a).sample(n=10)).to_series()
-    assert_series_equal(result1, result2)
-
-
 def test_map_alias() -> None:
     out = pl.DataFrame({"foo": [1, 2, 3]}).select(
         (pl.col("foo") * 2).map_alias(lambda name: f"{name}{name}")
     )
     expected = pl.DataFrame({"foofoo": [2, 4, 6]})
     assert_frame_equal(out, expected)
 
@@ -456,43 +417,28 @@
             [1.0, 2.0, 3.0, 4.0],
             [None, 1.0, 2.0, 3.0],
             [None, 1.0, 2.0, 3.0],
         ],
     }
 
 
-def test_rank_random() -> None:
-    df = pl.from_dict(
-        {"a": [1] * 5, "b": [1, 2, 3, 4, 5], "c": [200, 100, 100, 50, 100]}
-    )
-
-    df_ranks1 = df.with_columns(
-        pl.col("c").rank(method="random", seed=1).over("a").alias("rank")
-    )
-    df_ranks2 = df.with_columns(
-        pl.col("c").rank(method="random", seed=1).over("a").alias("rank")
-    )
-    assert_frame_equal(df_ranks1, df_ranks2)
-
-
 def test_unique_empty() -> None:
     for dt in [pl.Utf8, pl.Boolean, pl.Int32, pl.UInt32]:
         s = pl.Series([], dtype=dt)
         assert_series_equal(s.unique(), s)
 
 
-@typing.no_type_check
 def test_search_sorted() -> None:
     for seed in [1, 2, 3]:
         np.random.seed(seed)
-        a = np.sort(np.random.randn(10) * 100)
-        s = pl.Series(a)
+        arr = np.sort(np.random.randn(10) * 100)
+        s = pl.Series(arr)
 
-        for v in range(int(np.min(a)), int(np.max(a)), 20):
-            assert np.searchsorted(a, v) == s.search_sorted(v)
+        for v in range(int(np.min(arr)), int(np.max(arr)), 20):
+            assert np.searchsorted(arr, v) == s.search_sorted(v)
 
     a = pl.Series([1, 2, 3])
     b = pl.Series([1, 2, 2, -1])
     assert a.search_sorted(b).to_list() == [0, 1, 1, 0]
     b = pl.Series([1, 2, 2, None, 3])
     assert a.search_sorted(b).to_list() == [0, 1, 1, 0, 2]
 
@@ -1078,15 +1024,15 @@
     x = (pl.col("x") * 10).cache()
 
     assert (df.groupby(1).agg([x * x * x])).to_dict(False) == {
         "literal": [1],
         "x": [[27000, 27000, 27000, 125000, 512000]],
     }
     _, err = capfd.readouterr()
-    assert """cache hit: CACHE [(col("x")) * (10)]""" in err
+    assert """cache hit: [(col("x")) * (10)].cache()""" in err
 
 
 @pytest.mark.parametrize(
     ("const", "dtype"),
     [
         (1, pl.Int8),
         (4, pl.UInt32),
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_fmt.py` & `polars_lts_cpu-0.18.5/tests/unit/test_fmt.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_interchange.py` & `polars_lts_cpu-0.18.5/tests/unit/test_interchange.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import sys
 from typing import Any
 
 import pandas as pd
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
@@ -53,32 +52,24 @@
 def test_from_dataframe() -> None:
     df = pl.DataFrame({"a": [1, 2], "b": [3.0, 4.0], "c": ["foo", "bar"]})
     dfi = df.__dataframe__()
     result = pl.from_dataframe(dfi)
     assert_frame_equal(result, df)
 
 
-@pytest.mark.xfail(
-    sys.version_info < (3, 8),
-    reason="Pandas does not implement the protocol on Python 3.7",
-)
 def test_from_dataframe_pandas() -> None:
     data = {"a": [1, 2], "b": [3.0, 4.0], "c": ["foo", "bar"]}
 
     # Pandas dataframe
     df = pd.DataFrame(data)
     result = pl.from_dataframe(df)
     expected = pl.DataFrame(data)
     assert_frame_equal(result, expected)
 
 
-@pytest.mark.xfail(
-    sys.version_info < (3, 8),
-    reason="Pandas does not implement the protocol on Python 3.7",
-)
 def test_from_dataframe_allow_copy() -> None:
     # Zero copy only allowed when input is already a Polars dataframe
     df = pl.DataFrame({"a": [1, 2]})
     result = pl.from_dataframe(df, allow_copy=True)
     assert_frame_equal(result, df)
 
     df1_pandas = pd.DataFrame({"a": [1, 2]})
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_interop.py` & `polars_lts_cpu-0.18.5/tests/unit/test_interop.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 from __future__ import annotations
 
-import typing
 import warnings
 from datetime import date, datetime, time
-from typing import Any, cast, no_type_check
+from typing import Any, cast
 
 import numpy as np
 import pandas as pd
 import pyarrow as pa
 import pytest
 from numpy.testing import assert_array_equal
 
 import polars as pl
+from polars.exceptions import ComputeError
 from polars.testing import assert_frame_equal, assert_series_equal
 
 
 @pytest.fixture(
     params=[
         ("int8", [1, 3, 2], pl.Int8, np.int8),
         ("int16", [1, 3, 2], pl.Int16, np.int16),
@@ -37,16 +37,15 @@
             "bytes",
             [b"byte_string1", b"byte_string2", b"byte_string3"],
             pl.Binary,
             np.bytes_,
         ),
     ]
 )
-@no_type_check
-def numpy_interop_test_data(request):
+def numpy_interop_test_data(request: Any) -> Any:
     return request.param
 
 
 def test_df_from_numpy(numpy_interop_test_data: Any) -> None:
     name, values, pl_dtype, np_dtype = numpy_interop_test_data
     df = pl.DataFrame({name: np.array(values, dtype=np_dtype)})
     assert [pl_dtype] == df.dtypes
@@ -68,17 +67,18 @@
     numpy_array = np.asarray(values, dtype=np_dtype)
     assert_array_equal(pl_series_to_numpy_array, numpy_array)
 
 
 @pytest.mark.parametrize("use_pyarrow", [True, False])
 @pytest.mark.parametrize("has_null", [True, False])
 @pytest.mark.parametrize("dtype", [pl.Time, pl.Boolean, pl.Utf8])
-@no_type_check
-def test_to_numpy_no_zero_copy(use_pyarrow, has_null, dtype):
-    data = ["a", None] if dtype == pl.Utf8 else [0, None]
+def test_to_numpy_no_zero_copy(
+    use_pyarrow: bool, has_null: bool, dtype: pl.PolarsDataType
+) -> None:
+    data: list[Any] = ["a", None] if dtype == pl.Utf8 else [0, None]
     series = pl.Series(data if has_null else data[:1], dtype=dtype)
     with pytest.raises(ValueError):
         series.to_numpy(zero_copy_only=True, use_pyarrow=use_pyarrow)
 
 
 def test_from_pandas() -> None:
     df = pd.DataFrame(
@@ -535,25 +535,22 @@
     # chunked array
     assert pl.from_arrow(table["x"], rechunk=False).n_chunks() == 2
 
 
 def test_cat_to_pandas() -> None:
     df = pl.DataFrame({"a": ["best", "test"]})
     df = df.with_columns(pl.all().cast(pl.Categorical))
+
     pd_out = df.to_pandas()
-    assert "category" in str(pd_out["a"].dtype)
-    try:
-        pd_pa_out = df.to_pandas(use_pyarrow_extension_array=True)
-        assert pd_pa_out["a"].dtype.type in (
-            pd.core.dtypes.dtypes.CategoricalDtypeType,
-            pa.DictionaryType,
-        )
-    except ModuleNotFoundError:
-        # Skip test if suitable pandas version not installed.
-        pass
+    assert isinstance(pd_out["a"].dtype, pd.CategoricalDtype)
+
+    pd_pa_out = df.to_pandas(use_pyarrow_extension_array=True)
+    assert pd_pa_out["a"].dtype == pd.ArrowDtype(
+        pa.dictionary(pa.int64(), pa.large_string())
+    )
 
 
 def test_to_pandas() -> None:
     df = pl.DataFrame(
         {
             "a": [1, 2, 3],
             "b": [6, None, 8],
@@ -696,17 +693,16 @@
     df = pd.DataFrame(
         [pd.Timestamp(year=2021, month=1, day=1, hour=1, second=1, nanosecond=1)],
         columns=["date"],
     )
     assert cast(datetime, pl.from_pandas(df)[0, 0]) == datetime(2021, 1, 1, 1, 0, 1)
 
 
-@no_type_check
 def test_pandas_string_none_conversion_3298() -> None:
-    data = {"col_1": ["a", "b", "c", "d"]}
+    data: dict[str, list[str | None]] = {"col_1": ["a", "b", "c", "d"]}
     data["col_1"][0] = None
     df_pd = pd.DataFrame(data)
     df_pl = pl.DataFrame(df_pd)
     assert df_pl.to_series().to_list() == [None, "b", "c", "d"]
 
 
 def test_cat_int_types_3500() -> None:
@@ -764,25 +760,24 @@
         },
         {"a": None},
     ]
     df_pandas = pd.DataFrame(data)
     assert pl.from_pandas(df_pandas).to_dict(False) == {"a": [{"b": None}, {"b": None}]}
 
 
-@typing.no_type_check
 def test_from_pyarrow_map() -> None:
     pa_table = pa.table(
         [[1, 2], [[("a", "something")], [("a", "else"), ("b", "another key")]]],
         schema=pa.schema(
             [("idx", pa.int16()), ("mapping", pa.map_(pa.string(), pa.string()))]
         ),
     )
 
-    df = pl.from_arrow(pa_table)
-    assert df.to_dict(False) == {
+    result = cast(pl.DataFrame, pl.from_arrow(pa_table))
+    assert result.to_dict(False) == {
         "idx": [1, 2],
         "mapping": [
             [{"key": "a", "value": "something"}],
             [{"key": "a", "value": "else"}, {"key": "b", "value": "another key"}],
         ],
     }
 
@@ -806,19 +801,18 @@
         np.array(
             ["2022-07-05T10:30:45.123456", "2023-02-05T15:22:30.987654"],
             dtype="datetime64[us]",
         )
     )
 
 
-@typing.no_type_check
 def test_from_fixed_size_binary_list() -> None:
     val = [[b"63A0B1C66575DD5708E1EB2B"]]
     arrow_array = pa.array(val, type=pa.list_(pa.binary(24)))
-    s = pl.from_arrow(arrow_array)
+    s = cast(pl.Series, pl.from_arrow(arrow_array))
     assert s.dtype == pl.List(pl.Binary)
     assert s.to_list() == val
 
 
 def test_dataframe_from_repr() -> None:
     # round-trip various types
     with pl.StringCache():
@@ -1082,15 +1076,14 @@
     df = pd.DataFrame({"x": pd.Categorical(["x"], ["x", "y"])})
     assert pl.from_pandas(df).groupby("x").count().to_dict(False) == {
         "x": ["x"],
         "count": [1],
     }
 
 
-@typing.no_type_check
 def test_sliced_struct_from_arrow() -> None:
     # Create a dataset with 3 rows
     tbl = pa.Table.from_arrays(
         arrays=[
             pa.StructArray.from_arrays(
                 arrays=[
                     pa.array([1, 2, 3], pa.int32()),
@@ -1100,13 +1093,22 @@
             )
         ],
         names=["struct_col"],
     )
 
     # slice the table
     # check if FFI correctly reads sliced
-    assert pl.from_arrow(tbl.slice(1, 2)).to_dict(False) == {
+    result = cast(pl.DataFrame, pl.from_arrow(tbl.slice(1, 2)))
+    assert result.to_dict(False) == {
         "struct_col": [{"a": 2, "b": "bar"}, {"a": 3, "b": "baz"}]
     }
-    assert pl.from_arrow(tbl.slice(1, 1)).to_dict(False) == {
-        "struct_col": [{"a": 2, "b": "bar"}]
-    }
+
+    result = cast(pl.DataFrame, pl.from_arrow(tbl.slice(1, 1)))
+    assert result.to_dict(False) == {"struct_col": [{"a": 2, "b": "bar"}]}
+
+
+def test_from_arrow_invalid_time_zone() -> None:
+    arr = pa.array(
+        [datetime(2021, 1, 1, 0, 0, 0, 0)], type=pa.timestamp("ns", tz="+01:00")
+    )
+    with pytest.raises(ComputeError, match=r"unable to parse time zone: '\+01:00'"):
+        pl.from_arrow(arr)
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_lazy.py` & `polars_lts_cpu-0.18.5/tests/unit/test_lazy.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_polars_import.py` & `polars_lts_cpu-0.18.5/tests/unit/test_polars_import.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_predicates.py` & `polars_lts_cpu-0.18.5/tests/unit/test_predicates.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-import typing
 from datetime import date, datetime, timedelta
 
 import numpy as np
 
 import polars as pl
 
 
@@ -86,26 +85,30 @@
             datetime(2022, 1, 1, 10, 1),
             datetime(2022, 1, 1, 10, 2),
         ],
         "value": ["a", "b", "c"],
     }
 
 
-@typing.no_type_check
 def test_streaming_empty_df() -> None:
     df = pl.DataFrame(
         [
             pl.Series("a", ["a", "b", "c", "b", "a", "a"], dtype=pl.Categorical()),
             pl.Series("b", ["b", "c", "c", "b", "a", "c"], dtype=pl.Categorical()),
         ]
     )
 
-    assert df.lazy().join(df.lazy(), on="a", how="inner").filter(2 == 1).collect(
-        streaming=True
-    ).to_dict(False) == {"a": [], "b": [], "b_right": []}
+    result = (
+        df.lazy()
+        .join(df.lazy(), on="a", how="inner")
+        .filter(False)
+        .collect(streaming=True)
+    )
+
+    assert result.to_dict(False) == {"a": [], "b": [], "b_right": []}
 
 
 def test_when_then_empty_list_5547() -> None:
     out = pl.DataFrame({"a": []}).select([pl.when(pl.col("a") > 1).then([1])])
     assert out.shape == (0, 1)
     assert out.dtypes == [pl.List(pl.Int64)]
 
@@ -153,7 +156,15 @@
             "t": [1, 2, 3, 4, 4, 3, 2, 1],
             "x": [10, 20, 30, 40, 10, 20, 30, 40],
         }
     )
     assert df.lazy().sort(["g", "t"]).filter(
         (pl.col("x").shift() > 20).over("g")
     ).collect().to_dict(False) == {"g": [1, 2, 2], "t": [4, 2, 3], "x": [40, 30, 20]}
+
+
+def test_predicate_pushdown_cumsum_9566() -> None:
+    df = pl.DataFrame({"A": range(10), "B": ["b"] * 5 + ["a"] * 5})
+
+    q = df.lazy().sort(["B", "A"]).filter(pl.col("A").is_in([8, 2]).cumsum() == 1)
+
+    assert q.collect()["A"].to_list() == [8, 9, 0, 1]
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_projections.py` & `polars_lts_cpu-0.18.5/tests/unit/test_projections.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,7 @@
-import typing
-
 import numpy as np
 
 import polars as pl
 
 
 def test_projection_on_semi_join_4789() -> None:
     lfa = pl.DataFrame({"a": [1], "p": [1]}).lazy()
@@ -154,15 +152,14 @@
     q = q.groupby("c", maintain_order=True).agg([pl.col("a")])
     assert q.collect().to_dict(False) == {
         "c": [1, 2, 3],
         "a": [[1, 2, 5, 7], [3, 4, 6], [8]],
     }
 
 
-@typing.no_type_check
 def test_asof_join_projection_() -> None:
     lf1 = (
         pl.DataFrame(
             {
                 "m": np.linspace(0, 5, 7),
                 "a": np.linspace(0, 5, 7),
                 "b": np.linspace(0, 5, 7),
@@ -267,7 +264,27 @@
     )
 
     q = df.lazy().unique().groupby("bar").agg(pl.count())
     assert q.collect().sort("bar").to_dict(False) == {
         "bar": ["a", "b"],
         "count": [3, 2],
     }
+
+
+def test_join_suffix_collision_9562() -> None:
+    df = pl.DataFrame(
+        {
+            "foo": [1, 2, 3],
+            "bar": [6.0, 7.0, 8.0],
+            "ham": ["a", "b", "c"],
+        }
+    )
+    other_df = pl.DataFrame(
+        {
+            "apple": ["x", "y", "z"],
+            "ham": ["a", "b", "d"],
+        }
+    )
+    df.join(other_df, on="ham")
+    assert df.lazy().join(
+        other_df.lazy(), how="inner", left_on="ham", right_on="ham", suffix="m"
+    ).select("ham").collect().to_dict(False) == {"ham": ["a", "b"]}
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_queries.py` & `polars_lts_cpu-0.18.5/tests/unit/test_queries.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_schema.py` & `polars_lts_cpu-0.18.5/tests/unit/test_schema.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,10 @@
-import typing
+from __future__ import annotations
+
+from typing import Any
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal
 
 
@@ -410,45 +412,48 @@
         pl.Int64,
         pl.List(pl.Float64),
         pl.List(pl.Float64),
         pl.List(pl.Float64),
     ]
 
 
-@typing.no_type_check
-def test_schemas() -> None:
-    # add all expression output tests here:
-    args = [
-        # coalesce
-        {
-            "data": {"x": ["x"], "y": ["y"]},
-            "expr": pl.coalesce(pl.col("x"), pl.col("y")),
-            "expected_select": {"x": pl.Utf8},
-            "expected_gb": {"x": pl.List(pl.Utf8)},
-        },
-        # boolean sum
-        {
-            "data": {"x": [True]},
-            "expr": pl.col("x").sum(),
-            "expected_select": {"x": pl.UInt32},
-            "expected_gb": {"x": pl.UInt32},
-        },
-    ]
-    for arg in args:
-        df = pl.DataFrame(arg["data"])
-
-        # test selection schema
-        schema = df.select(arg["expr"]).schema
-        for key, dtype in arg["expected_select"].items():
-            assert schema[key] == dtype
-
-        # test groupby schema
-        schema = df.groupby(pl.lit(1)).agg(arg["expr"]).schema
-        for key, dtype in arg["expected_gb"].items():
-            assert schema[key] == dtype
+@pytest.mark.parametrize(
+    ("data", "expr", "expected_select", "expected_gb"),
+    [
+        (
+            {"x": ["x"], "y": ["y"]},
+            pl.coalesce(pl.col("x"), pl.col("y")),
+            {"x": pl.Utf8},
+            {"x": pl.List(pl.Utf8)},
+        ),
+        (
+            {"x": [True]},
+            pl.col("x").sum(),
+            {"x": pl.UInt32},
+            {"x": pl.UInt32},
+        ),
+    ],
+)
+def test_schemas(
+    data: dict[str, list[Any]],
+    expr: pl.Expr,
+    expected_select: dict[str, pl.PolarsDataType],
+    expected_gb: dict[str, pl.PolarsDataType],
+) -> None:
+    df = pl.DataFrame(data)
+
+    # test selection schema
+    schema = df.select(expr).schema
+    for key, dtype in expected_select.items():
+        assert schema[key] == dtype
+
+    # test groupby schema
+    schema = df.groupby(pl.lit(1)).agg(expr).schema
+    for key, dtype in expected_gb.items():
+        assert schema[key] == dtype
 
 
 def test_list_null_constructor_schema() -> None:
     expected = pl.List(pl.Null)
     assert pl.Series([[]]).dtype == expected
     assert pl.Series([[]], dtype=pl.List).dtype == expected
     assert pl.DataFrame({"a": [[]]}).dtypes[0] == expected
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_selectors.py` & `polars_lts_cpu-0.18.5/tests/unit/test_selectors.py`

 * *Files 22% similar despite different names*

```diff
@@ -82,14 +82,92 @@
 def test_selector_datetime(df: pl.DataFrame) -> None:
     assert df.select(cs.datetime()).schema == {"opp": pl.Datetime("ms")}
     assert df.select(cs.datetime("ns")).schema == {}
 
     all_columns = set(df.columns)
     assert set(df.select(~cs.datetime()).columns) == all_columns - {"opp"}
 
+    df = pl.DataFrame(
+        schema={
+            "d1": pl.Datetime("ns", "Asia/Tokyo"),
+            "d2": pl.Datetime("ns", "UTC"),
+            "d3": pl.Datetime("us", "UTC"),
+            "d4": pl.Datetime("us"),
+            "d5": pl.Datetime("ms"),
+        },
+    )
+    assert df.select(cs.datetime()).columns == ["d1", "d2", "d3", "d4", "d5"]
+    assert df.select(~cs.datetime()).schema == {}
+
+    assert df.select(cs.datetime(["ms", "ns"])).columns == ["d1", "d2", "d5"]
+    assert df.select(cs.datetime(["ms", "ns"], time_zone="*")).columns == ["d1", "d2"]
+
+    assert df.select(~cs.datetime(["ms", "ns"])).columns == ["d3", "d4"]
+    assert df.select(~cs.datetime(["ms", "ns"], time_zone="*")).columns == [
+        "d3",
+        "d4",
+        "d5",
+    ]
+    assert df.select(
+        cs.datetime(time_zone=["UTC", "Asia/Tokyo", "Europe/London"])
+    ).columns == ["d1", "d2", "d3"]
+
+    assert df.select(cs.datetime(time_zone="*")).columns == ["d1", "d2", "d3"]
+    assert df.select(cs.datetime("ns", time_zone="*")).columns == ["d1", "d2"]
+    assert df.select(cs.datetime(time_zone="UTC")).columns == ["d2", "d3"]
+    assert df.select(cs.datetime("us", time_zone="UTC")).columns == ["d3"]
+    assert df.select(cs.datetime(time_zone="Asia/Tokyo")).columns == ["d1"]
+    assert df.select(cs.datetime("us", time_zone="Asia/Tokyo")).columns == []
+    assert df.select(cs.datetime(time_zone=None)).columns == ["d4", "d5"]
+    assert df.select(cs.datetime("ns", time_zone=None)).columns == []
+
+    assert df.select(~cs.datetime(time_zone="*")).columns == ["d4", "d5"]
+    assert df.select(~cs.datetime("ns", time_zone="*")).columns == ["d3", "d4", "d5"]
+    assert df.select(~cs.datetime(time_zone="UTC")).columns == ["d1", "d4", "d5"]
+    assert df.select(~cs.datetime("us", time_zone="UTC")).columns == [
+        "d1",
+        "d2",
+        "d4",
+        "d5",
+    ]
+    assert df.select(~cs.datetime(time_zone="Asia/Tokyo")).columns == [
+        "d2",
+        "d3",
+        "d4",
+        "d5",
+    ]
+    assert df.select(~cs.datetime("us", time_zone="Asia/Tokyo")).columns == [
+        "d1",
+        "d2",
+        "d3",
+        "d4",
+        "d5",
+    ]
+    assert df.select(~cs.datetime(time_zone=None)).columns == ["d1", "d2", "d3"]
+    assert df.select(~cs.datetime("ns", time_zone=None)).columns == [
+        "d1",
+        "d2",
+        "d3",
+        "d4",
+        "d5",
+    ]
+    assert df.select(cs.datetime("ns")).columns == ["d1", "d2"]
+    assert df.select(cs.datetime("us")).columns == ["d3", "d4"]
+    assert df.select(cs.datetime("ms")).columns == ["d5"]
+
+    # bonus check; significantly more verbose, but equivalent to a selector -
+    assert (
+        df.select(
+            pl.all().exclude(
+                pl.Datetime("ms", time_zone="*"), pl.Datetime("ns", time_zone="*")
+            )
+        ).columns
+        == df.select(~cs.datetime(["ms", "ns"], time_zone="*")).columns
+    )
+
 
 def test_selector_ends_with(df: pl.DataFrame) -> None:
     assert df.select(cs.ends_with("e")).columns == ["cde", "eee"]
     assert df.select(cs.ends_with("ee")).columns == ["eee"]
     assert df.select(cs.ends_with("e", "g", "i", "n", "p")).columns == [
         "cde",
         "eee",
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_serde.py` & `polars_lts_cpu-0.18.5/tests/unit/test_serde.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,11 +1,10 @@
 from __future__ import annotations
 
 import pickle
-import typing
 from datetime import datetime, timedelta
 
 import pytest
 
 import polars as pl
 from polars.testing import assert_frame_equal, assert_series_equal
 
@@ -99,16 +98,15 @@
     e = pl.col("foo").sum().over("bar")
     json = e.meta.write_json()
 
     round_tripped = pl.Expr.from_json(json)
     assert round_tripped.meta == e
 
 
-@typing.no_type_check
-def times2(x):
+def times2(x: pl.Series) -> pl.Series:
     return x * 2
 
 
 def test_pickle_udf_expression() -> None:
     df = pl.DataFrame({"a": [1, 2, 3]})
 
     e = pl.col("a").map(times2)
@@ -136,7 +134,21 @@
             pl.Series([3, 2], dtype=pl.Int8),
             pl.Series([32, 2], dtype=pl.UInt8),
             pl.Series([3, 3], dtype=pl.UInt16),
         ]
     )
     b = pickle.dumps(df)
     assert_frame_equal(pickle.loads(b), df)
+
+
+def df_times2(df: pl.DataFrame) -> pl.DataFrame:
+    return df.select(pl.all() * 2)
+
+
+def test_pickle_lazyframe_udf() -> None:
+    df = pl.DataFrame({"a": [1, 2, 3]})
+
+    q = df.lazy().map(df_times2)
+    b = pickle.dumps(q)
+
+    q = pickle.loads(b)
+    assert q.collect()["a"].to_list() == [2, 4, 6]
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_series.py` & `polars_lts_cpu-0.18.5/tests/unit/test_series.py`

 * *Files 0% similar despite different names*

```diff
@@ -367,24 +367,14 @@
     with pytest.raises(ValueError):
         +a
     a = pl.Series("a", [""])
     with pytest.raises(ValueError):
         +a
 
 
-def test_arithmetic_empty() -> None:
-    series = pl.Series("a", [])
-    assert series.sum() == 0
-
-
-def test_arithmetic_null() -> None:
-    series = pl.Series("a", [None])
-    assert series.sum() is None
-
-
 def test_power() -> None:
     a = pl.Series([1, 2], dtype=Int64)
     b = pl.Series([None, 2.0], dtype=Float64)
     c = pl.Series([date(2020, 2, 28), date(2020, 3, 1)], dtype=Date)
 
     # pow
     assert_series_equal(a**2, pl.Series([1.0, 4.0], dtype=Float64))
@@ -564,15 +554,15 @@
 
         assert a.name == b.name
         assert b.isnull().sum() == 1
 
         if a.dtype == pl.List:
             vals_b = [(None if x is None else x.tolist()) for x in b]
         else:
-            vals_b = b.replace({np.nan: None}).values.tolist()  # type: ignore[union-attr]
+            vals_b = b.replace({np.nan: None}).values.tolist()
 
         assert vals_b == test_data
 
         try:
             c = a.to_pandas(use_pyarrow_extension_array=True)
             assert a.name == c.name
             assert c.isnull().sum() == 1
@@ -1293,21 +1283,14 @@
 
     assert_series_equal(
         s.rank("dense", descending=True),
         pl.Series("a", [3, 2, 1, 2, 2, 1, 4], dtype=UInt32),
     )
 
 
-def test_rank_random() -> None:
-    s = pl.Series("a", [1, 2, 3, 2, 2, 3, 0])
-    assert_series_equal(
-        s.rank("random", seed=1), pl.Series("a", [2, 4, 7, 3, 5, 6, 1], dtype=UInt32)
-    )
-
-
 def test_diff() -> None:
     s = pl.Series("a", [1, 2, 3, 2, 2, 3, 0])
     expected = pl.Series("a", [1, 1, -1, 0, 1, -3])
 
     assert_series_equal(s.diff(null_behavior="drop"), expected)
 
     df = pl.DataFrame([s])
@@ -1820,29 +1803,14 @@
     ):
         assert dot_result == 32
 
     with pytest.raises(ShapeError, match="length mismatch"):
         s1 @ [4, 5, 6, 7, 8]
 
 
-def test_sample() -> None:
-    s = pl.Series("a", [1, 2, 3, 4, 5])
-
-    assert len(s.sample(n=2, seed=0)) == 2
-    assert len(s.sample(fraction=0.4, seed=0)) == 2
-
-    assert len(s.sample(n=2, with_replacement=True, seed=0)) == 2
-
-    # on a series of length 5, you cannot sample more than 5 items
-    with pytest.raises(pl.ShapeError):
-        s.sample(n=10, with_replacement=False, seed=0)
-    # unless you use with_replacement=True
-    assert len(s.sample(n=10, with_replacement=True, seed=0)) == 10
-
-
 def test_peak_max_peak_min() -> None:
     s = pl.Series("a", [4, 1, 3, 2, 5])
     result = s.peak_min()
     expected = pl.Series([False, True, False, True, False])
     assert_series_equal(result, expected)
 
     result = s.peak_max()
@@ -1955,24 +1923,14 @@
     expected = pl.Series("a", np.exp(b.to_numpy()))
     assert_series_equal(b.exp(), expected)
 
     expected = pl.Series("a", np.log1p(a.to_numpy()))
     assert_series_equal(a.log1p(), expected)
 
 
-def test_shuffle() -> None:
-    a = pl.Series("a", [1, 2, 3])
-    out = a.shuffle(2)
-    expected = pl.Series("a", [2, 1, 3])
-    assert_series_equal(out, expected)
-
-    out = pl.select(pl.lit(a).shuffle(2)).to_series()
-    assert_series_equal(out, expected)
-
-
 def test_to_physical() -> None:
     # casting an int result in an int
     s = pl.Series("a", [1, 2, 3])
     assert_series_equal(s.to_physical(), s)
 
     # casting a date results in an Int32
     s = pl.Series("a", [date(2020, 1, 1)] * 3)
```

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_single.py` & `polars_lts_cpu-0.18.5/tests/unit/test_single.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_sql.py` & `polars_lts_cpu-0.18.5/tests/unit/test_sql.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/test_testing.py` & `polars_lts_cpu-0.18.5/tests/unit/test_testing.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/utils/test_parse_expr_input.py` & `polars_lts_cpu-0.18.5/tests/unit/utils/test_parse_expr_input.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/tests/unit/utils/test_utils.py` & `polars_lts_cpu-0.18.5/tests/unit/utils/test_utils.py`

 * *Files identical despite different names*

### Comparing `polars_lts_cpu-0.18.4/Cargo.lock` & `polars_lts_cpu-0.18.5/Cargo.lock`

 * *Files 1% similar despite different names*

```diff
@@ -47,14 +47,20 @@
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "94fb8275041c72129eb51b7d0322c29b8387a0386127718b096429201a5d6ece"
 dependencies = [
  "alloc-no-stdlib",
 ]
 
 [[package]]
+name = "allocator-api2"
+version = "0.2.15"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "56fc6cf8dc8c4158eed8649f9b8b0ea1518eb62b544fe9490d66fa0b349eafe9"
+
+[[package]]
 name = "android-tzdata"
 version = "0.1.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e999941b234f3131b00bc13c22d06e8c5ff726d1b6318ac7eb276997bbb4fef0"
 
 [[package]]
 name = "android_system_properties"
@@ -89,15 +95,15 @@
  "planus",
  "serde",
 ]
 
 [[package]]
 name = "arrow2"
 version = "0.17.1"
-source = "git+https://github.com/ritchie46/arrow2?branch=polars_2023-06-23#84f06d6bf9442394116ba2a083fbf1975bbd57f1"
+source = "git+https://github.com/ritchie46/arrow2?branch=polars_2023-06-26#e71d66689f6ebde0e01f185bad0db8ef46f5fc8e"
 dependencies = [
  "ahash",
  "arrow-format",
  "avro-schema",
  "base64",
  "bytemuck",
  "chrono",
@@ -358,15 +364,15 @@
 name = "comfy-table"
 version = "6.2.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7e959d788268e3bf9d35ace83e81b124190378e4c91c9067524675e33394b8ba"
 dependencies = [
  "crossterm",
  "strum",
- "strum_macros",
+ "strum_macros 0.24.3",
  "unicode-width",
 ]
 
 [[package]]
 name = "core-foundation-sys"
 version = "0.8.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
@@ -495,14 +501,20 @@
  "once_cell",
  "proc-macro2",
  "quote",
  "syn 1.0.109",
 ]
 
 [[package]]
+name = "equivalent"
+version = "1.0.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "88bffebc5d80432c9b140ee17875ff173a8ab62faad5b257da912bd2f6c1c0a1"
+
+[[package]]
 name = "ethnum"
 version = "1.3.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "0198b9d0078e0f30dedc7acbb21c974e838fc8fae3ee170128658a98cb2c1c04"
 
 [[package]]
 name = "fallible-streaming-iterator"
@@ -713,14 +725,24 @@
 [[package]]
 name = "hashbrown"
 version = "0.13.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "43a3c133739dddd0d2990f9a4bdf8eb4b21ef50e4851ca85ab661199821d510e"
 dependencies = [
  "ahash",
+]
+
+[[package]]
+name = "hashbrown"
+version = "0.14.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "2c6201b9ff9fd90a5a3bac2e56a830d0caa509576f0e503818ee82c181b3437a"
+dependencies = [
+ "ahash",
+ "allocator-api2",
  "rayon",
 ]
 
 [[package]]
 name = "heck"
 version = "0.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
@@ -787,14 +809,24 @@
 name = "indexmap"
 version = "1.9.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bd070e393353796e801d209ad339e89596eb4c8d430d18ede6a1cced8fafbd99"
 dependencies = [
  "autocfg",
  "hashbrown 0.12.3",
+]
+
+[[package]]
+name = "indexmap"
+version = "2.0.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "d5477fe2230a79769d8dc68e0eabf5437907c0457a5614a9e8dddb67f65eb65d"
+dependencies = [
+ "equivalent",
+ "hashbrown 0.14.0",
  "serde",
 ]
 
 [[package]]
 name = "indoc"
 version = "1.0.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
@@ -1423,15 +1455,15 @@
 version = "0.30.0"
 dependencies = [
  "arrow2",
  "atoi",
  "chrono",
  "chrono-tz",
  "ethnum",
- "hashbrown 0.13.2",
+ "hashbrown 0.14.0",
  "multiversion",
  "num-traits",
  "polars-error",
  "serde",
  "thiserror",
 ]
 
@@ -1442,16 +1474,16 @@
  "ahash",
  "arrow2",
  "bitflags",
  "chrono",
  "chrono-tz",
  "comfy-table",
  "either",
- "hashbrown 0.13.2",
- "indexmap",
+ "hashbrown 0.14.0",
+ "indexmap 2.0.0",
  "itoap",
  "ndarray",
  "num-traits",
  "once_cell",
  "polars-arrow",
  "polars-error",
  "polars-row",
@@ -1515,16 +1547,16 @@
 [[package]]
 name = "polars-json"
 version = "0.30.0"
 dependencies = [
  "ahash",
  "arrow2",
  "fallible-streaming-iterator",
- "hashbrown 0.13.2",
- "indexmap",
+ "hashbrown 0.14.0",
+ "indexmap 2.0.0",
  "num-traits",
  "polars-arrow",
  "polars-error",
  "polars-utils",
  "simd-json",
 ]
 
@@ -1555,14 +1587,15 @@
 version = "0.30.0"
 dependencies = [
  "argminmax",
  "arrow2",
  "base64",
  "either",
  "hex",
+ "indexmap 2.0.0",
  "jsonpath_lib",
  "memchr",
  "polars-arrow",
  "polars-core",
  "polars-json",
  "polars-utils",
  "serde",
@@ -1573,15 +1606,15 @@
 [[package]]
 name = "polars-pipe"
 version = "0.30.0"
 dependencies = [
  "crossbeam-channel",
  "crossbeam-queue",
  "enum_dispatch",
- "hashbrown 0.13.2",
+ "hashbrown 0.14.0",
  "num-traits",
  "polars-arrow",
  "polars-core",
  "polars-io",
  "polars-ops",
  "polars-plan",
  "polars-row",
@@ -1607,14 +1640,15 @@
  "polars-time",
  "polars-utils",
  "pyo3",
  "rayon",
  "regex",
  "serde",
  "smartstring",
+ "strum_macros 0.25.0",
 ]
 
 [[package]]
 name = "polars-row"
 version = "0.30.0"
 dependencies = [
  "arrow2",
@@ -1655,15 +1689,15 @@
 ]
 
 [[package]]
 name = "polars-utils"
 version = "0.30.0"
 dependencies = [
  "ahash",
- "hashbrown 0.13.2",
+ "hashbrown 0.14.0",
  "num-traits",
  "once_cell",
  "rayon",
  "smartstring",
  "sysinfo",
 ]
 
@@ -1680,15 +1714,15 @@
 checksum = "6aeca18b86b413c660b781aa319e4e2648a3e6f9eadc9b47e9038e6fe9f3451b"
 dependencies = [
  "unicode-ident",
 ]
 
 [[package]]
 name = "py-polars"
-version = "0.18.4"
+version = "0.18.5"
 dependencies = [
  "ahash",
  "built",
  "ciborium",
  "jemallocator",
  "lexical-core",
  "libc",
@@ -1959,15 +1993,15 @@
 
 [[package]]
 name = "serde_json"
 version = "1.0.96"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "057d394a50403bcac12672b2b18fb387ab6d289d957dab67dd201875391e52f1"
 dependencies = [
- "indexmap",
+ "indexmap 1.9.3",
  "itoa",
  "ryu",
  "serde",
 ]
 
 [[package]]
 name = "signal-hook"
@@ -2122,14 +2156,27 @@
  "proc-macro2",
  "quote",
  "rustversion",
  "syn 1.0.109",
 ]
 
 [[package]]
+name = "strum_macros"
+version = "0.25.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "fe9f3bd7d2e45dcc5e265fbb88d6513e4747d8ef9444cf01a533119bce28a157"
+dependencies = [
+ "heck",
+ "proc-macro2",
+ "quote",
+ "rustversion",
+ "syn 2.0.18",
+]
+
+[[package]]
 name = "syn"
 version = "1.0.109"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "72b64191b275b66ffe2469e8af2c1cfe3bafa67b529ead792a6d0160888b4237"
 dependencies = [
  "proc-macro2",
  "quote",
```

### Comparing `polars_lts_cpu-0.18.4/PKG-INFO` & `polars_lts_cpu-0.18.5/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,76 +1,72 @@
 Metadata-Version: 2.1
 Name: polars-lts-cpu
-Version: 0.18.4
+Version: 0.18.5
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Environment :: Console
 Classifier: Intended Audience :: Science/Research
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3 :: Only
-Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Rust
 Classifier: Topic :: Scientific/Engineering
-Requires-Dist: typing_extensions >=4.0.1 ; python_version < '3.8'
 Requires-Dist: pyarrow >=7.0.0 ; extra == 'pyarrow'
 Requires-Dist: pyarrow >=7.0.0 ; extra == 'pandas'
 Requires-Dist: pandas ; extra == 'pandas'
 Requires-Dist: numpy >=1.16.0 ; extra == 'numpy'
 Requires-Dist: fsspec ; extra == 'fsspec'
 Requires-Dist: connectorx ; extra == 'connectorx'
 Requires-Dist: xlsx2csv >=0.8.0 ; extra == 'xlsx2csv'
-Requires-Dist: deltalake >=0.8.0 ; extra == 'deltalake'
+Requires-Dist: deltalake >=0.10.0 ; extra == 'deltalake'
 Requires-Dist: backports.zoneinfo ; python_version < '3.9' and extra == 'timezone'
 Requires-Dist: tzdata ; platform_system == 'Windows' and extra == 'timezone'
 Requires-Dist: matplotlib ; extra == 'matplotlib'
+Requires-Dist: pydantic ; extra == 'pydantic'
 Requires-Dist: sqlalchemy ; extra == 'sqlalchemy'
 Requires-Dist: pandas ; extra == 'sqlalchemy'
 Requires-Dist: xlsxwriter ; extra == 'xlsxwriter'
-Requires-Dist: polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter] ; extra == 'all'
+Requires-Dist: adbc_driver_sqlite ; extra == 'adbc'
+Requires-Dist: polars[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,pydantic,sqlalchemy,xlsxwriter,adbc] ; extra == 'all'
 Provides-Extra: pyarrow
 Provides-Extra: pandas
 Provides-Extra: numpy
 Provides-Extra: fsspec
 Provides-Extra: connectorx
 Provides-Extra: xlsx2csv
 Provides-Extra: deltalake
 Provides-Extra: timezone
 Provides-Extra: matplotlib
+Provides-Extra: pydantic
 Provides-Extra: sqlalchemy
 Provides-Extra: xlsxwriter
+Provides-Extra: adbc
 Provides-Extra: all
 License-File: LICENSE
 Summary: Blazingly fast DataFrame library
 Keywords: dataframe,arrow,out-of-core
 Author-email: Ritchie Vink <ritchie46@gmail.com>
-Requires-Python: >=3.7
+Requires-Python: >=3.8
 Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
 Project-URL: Homepage, https://www.pola.rs/
 Project-URL: Documentation, https://pola-rs.github.io/polars/py-polars/html/reference/index.html
 Project-URL: Repository, https://github.com/pola-rs/polars
 Project-URL: Changelog, https://github.com/pola-rs/polars/releases
 
 <h1 align="center">
   <img src="https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg">
   <br>
 </h1>
 
 <div align="center">
-  <a href="https://docs.rs/polars/latest/polars/">
-    <img src="https://docs.rs/polars/badge.svg" alt="rust docs"/>
-  </a>
-  <a href="https://github.com/pola-rs/polars/actions">
-    <img src="https://github.com/pola-rs/polars/workflows/Build%20and%20test/badge.svg" alt="Build and test"/>
-  </a>
   <a href="https://crates.io/crates/polars">
     <img src="https://img.shields.io/crates/v/polars.svg"/>
   </a>
   <a href="https://pypi.org/project/polars/">
     <img src="https://img.shields.io/pypi/v/polars.svg" alt="PyPi Latest Release"/>
   </a>
   <a href="https://www.npmjs.com/package/nodejs-polars">
@@ -84,15 +80,15 @@
   </a>
 </div>
 
 <p align="center">
   <b>Documentation</b>:
   <a href="https://pola-rs.github.io/polars/py-polars/html/reference/index.html">Python</a>
   -
-  <a href="https://pola-rs.github.io/polars/polars/index.html">Rust</a>
+  <a href="https://docs.rs/polars/latest/polars/">Rust</a>
   -
   <a href="https://pola-rs.github.io/nodejs-polars/index.html">Node.js</a>
   -
   <a href="https://rpolars.github.io/index.html">R</a>
   |
   <b>StackOverflow</b>:
   <a href="https://stackoverflow.com/questions/tagged/python-polars">Python</a>
```

#### html2text {}

```diff
@@ -1,47 +1,47 @@
-Metadata-Version: 2.1 Name: polars-lts-cpu Version: 0.18.4 Classifier:
+Metadata-Version: 2.1 Name: polars-lts-cpu Version: 0.18.5 Classifier:
 Development Status :: 5 - Production/Stable Classifier: Environment :: Console
 Classifier: Intended Audience :: Science/Research Classifier: License :: OSI
 Approved :: MIT License Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python Classifier: Programming Language ::
 Python :: 3 Classifier: Programming Language :: Python :: 3 :: Only Classifier:
-Programming Language :: Python :: 3.7 Classifier: Programming Language ::
-Python :: 3.8 Classifier: Programming Language :: Python :: 3.9 Classifier:
-Programming Language :: Python :: 3.10 Classifier: Programming Language ::
-Python :: 3.11 Classifier: Programming Language :: Rust Classifier: Topic ::
-Scientific/Engineering Requires-Dist: typing_extensions >=4.0.1 ;
-python_version < '3.8' Requires-Dist: pyarrow >=7.0.0 ; extra == 'pyarrow'
-Requires-Dist: pyarrow >=7.0.0 ; extra == 'pandas' Requires-Dist: pandas ;
-extra == 'pandas' Requires-Dist: numpy >=1.16.0 ; extra == 'numpy' Requires-
-Dist: fsspec ; extra == 'fsspec' Requires-Dist: connectorx ; extra ==
-'connectorx' Requires-Dist: xlsx2csv >=0.8.0 ; extra == 'xlsx2csv' Requires-
-Dist: deltalake >=0.8.0 ; extra == 'deltalake' Requires-Dist:
+Programming Language :: Python :: 3.8 Classifier: Programming Language ::
+Python :: 3.9 Classifier: Programming Language :: Python :: 3.10 Classifier:
+Programming Language :: Python :: 3.11 Classifier: Programming Language :: Rust
+Classifier: Topic :: Scientific/Engineering Requires-Dist: pyarrow >=7.0.0 ;
+extra == 'pyarrow' Requires-Dist: pyarrow >=7.0.0 ; extra == 'pandas' Requires-
+Dist: pandas ; extra == 'pandas' Requires-Dist: numpy >=1.16.0 ; extra ==
+'numpy' Requires-Dist: fsspec ; extra == 'fsspec' Requires-Dist: connectorx ;
+extra == 'connectorx' Requires-Dist: xlsx2csv >=0.8.0 ; extra == 'xlsx2csv'
+Requires-Dist: deltalake >=0.10.0 ; extra == 'deltalake' Requires-Dist:
 backports.zoneinfo ; python_version < '3.9' and extra == 'timezone' Requires-
 Dist: tzdata ; platform_system == 'Windows' and extra == 'timezone' Requires-
-Dist: matplotlib ; extra == 'matplotlib' Requires-Dist: sqlalchemy ; extra ==
-'sqlalchemy' Requires-Dist: pandas ; extra == 'sqlalchemy' Requires-Dist:
-xlsxwriter ; extra == 'xlsxwriter' Requires-Dist: polars
-[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,sqlalchemy,xlsxwriter]
+Dist: matplotlib ; extra == 'matplotlib' Requires-Dist: pydantic ; extra ==
+'pydantic' Requires-Dist: sqlalchemy ; extra == 'sqlalchemy' Requires-Dist:
+pandas ; extra == 'sqlalchemy' Requires-Dist: xlsxwriter ; extra ==
+'xlsxwriter' Requires-Dist: adbc_driver_sqlite ; extra == 'adbc' Requires-Dist:
+polars
+[pyarrow,pandas,numpy,fsspec,connectorx,xlsx2csv,deltalake,timezone,matplotlib,pydantic,sqlalchemy,xlsxwriter,adbc]
 ; extra == 'all' Provides-Extra: pyarrow Provides-Extra: pandas Provides-Extra:
 numpy Provides-Extra: fsspec Provides-Extra: connectorx Provides-Extra:
 xlsx2csv Provides-Extra: deltalake Provides-Extra: timezone Provides-Extra:
-matplotlib Provides-Extra: sqlalchemy Provides-Extra: xlsxwriter Provides-
-Extra: all License-File: LICENSE Summary: Blazingly fast DataFrame library
-Keywords: dataframe,arrow,out-of-core Author-email: Ritchie Vink
-gmail.com> Requires-Python: >=3.7 Description-Content-Type: text/markdown;
+matplotlib Provides-Extra: pydantic Provides-Extra: sqlalchemy Provides-Extra:
+xlsxwriter Provides-Extra: adbc Provides-Extra: all License-File: LICENSE
+Summary: Blazingly fast DataFrame library Keywords: dataframe,arrow,out-of-core
+Author-email: Ritchie Vink
+gmail.com> Requires-Python: >=3.8 Description-Content-Type: text/markdown;
 charset=UTF-8; variant=GFM Project-URL: Homepage, https://www.pola.rs/ Project-
 URL: Documentation, https://pola-rs.github.io/polars/py-polars/html/reference/
 index.html Project-URL: Repository, https://github.com/pola-rs/polars Project-
 URL: Changelog, https://github.com/pola-rs/polars/releases
  ****** [https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/
                     polars_github_logo_rect_dark_name.svg]
                                      ******
-[rust_docs] [Build_and_test] [https://img.shields.io/crates/v/polars.svg] [PyPi
- Latest_Release] [NPM_Latest_Release] [R-universe_Latest_Release] [DOI_Latest
-                                   Release]
+[https://img.shields.io/crates/v/polars.svg] [PyPi_Latest_Release] [NPM_Latest
+           Release] [R-universe_Latest_Release] [DOI_Latest_Release]
   Documentation: Python - Rust - Node.js - R | StackOverflow: Python - Rust -
                       Node.js - R | User_Guide | Discord
 ## Polars: Blazingly fast DataFrames in Rust, Python, Node.js, R and SQL Polars
 is a DataFrame interface on top of an OLAP Query Engine implemented in Rust
 using [Apache Arrow Columnar Format](https://arrow.apache.org/docs/format/
 Columnar.html) as the memory model. - Lazy | eager execution - Multi-threaded -
 SIMD - Query optimization - Powerful expression API - Hybrid Streaming (larger
```

