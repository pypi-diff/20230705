# Comparing `tmp/quickBayes-1.0.0b8-cp38-cp38-win_amd64.whl.zip` & `tmp/quickBayes-1.0.0b9-cp39-cp39-macosx_10_9_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,76 +1,76 @@
-Zip file size: 1034499 bytes, number of entries: 74
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-31 13:08 quickBayes/__init__.py
--rw-rw-rw-  2.0 fat    43520 b- defN 23-May-31 13:12 quickBayes/log_likelihood.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat     2542 b- defN 23-May-31 13:08 quickBayes/log_likelihood.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-31 13:08 quickBayes/fit_engines/__init__.py
--rw-rw-rw-  2.0 fat     7049 b- defN 23-May-31 13:08 quickBayes/fit_engines/fit_engine.py
--rw-rw-rw-  2.0 fat     3714 b- defN 23-May-31 13:08 quickBayes/fit_engines/fit_utils.py
--rw-rw-rw-  2.0 fat     4074 b- defN 23-May-31 13:08 quickBayes/fit_engines/gofit_engine.py
--rw-rw-rw-  2.0 fat     3691 b- defN 23-May-31 13:08 quickBayes/fit_engines/scipy_fit_engine.py
--rw-rw-rw-  2.0 fat     4586 b- defN 23-May-31 13:08 quickBayes/fit_functions/BG.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-31 13:08 quickBayes/fit_functions/__init__.py
--rw-rw-rw-  2.0 fat     6666 b- defN 23-May-31 13:08 quickBayes/fit_functions/base.py
--rw-rw-rw-  2.0 fat     4875 b- defN 23-May-31 13:08 quickBayes/fit_functions/composite_fun.py
--rw-rw-rw-  2.0 fat     2839 b- defN 23-May-31 13:08 quickBayes/fit_functions/conv_with_res.py
--rw-rw-rw-  2.0 fat     2761 b- defN 23-May-31 13:08 quickBayes/fit_functions/delta_function.py
--rw-rw-rw-  2.0 fat     2349 b- defN 23-May-31 13:08 quickBayes/fit_functions/exp_decay.py
--rw-rw-rw-  2.0 fat     2889 b- defN 23-May-31 13:08 quickBayes/fit_functions/gaussian.py
--rw-rw-rw-  2.0 fat     2826 b- defN 23-May-31 13:08 quickBayes/fit_functions/lorentz.py
--rw-rw-rw-  2.0 fat     5025 b- defN 23-May-31 13:08 quickBayes/fit_functions/qldata_function.py
--rw-rw-rw-  2.0 fat     3598 b- defN 23-May-31 13:08 quickBayes/fit_functions/qse.py
--rw-rw-rw-  2.0 fat     3307 b- defN 23-May-31 13:08 quickBayes/fit_functions/qse_fixed.py
--rw-rw-rw-  2.0 fat    13849 b- defN 23-May-31 13:08 quickBayes/fit_functions/quasielastic_function.py
--rw-rw-rw-  2.0 fat     8219 b- defN 23-May-31 13:08 quickBayes/fit_functions/stretch_exp.py
--rw-rw-rw-  2.0 fat     4595 b- defN 23-May-31 13:08 quickBayes/fit_functions/stretch_exp_fixed.py
--rw-rw-rw-  2.0 fat    88064 b- defN 23-May-31 13:12 quickBayes/fitting/fit_engine.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    63488 b- defN 23-May-31 13:12 quickBayes/fitting/fit_utils.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    57856 b- defN 23-May-31 13:12 quickBayes/fitting/gofit_engine.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    57344 b- defN 23-May-31 13:12 quickBayes/fitting/scipy_engine.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    77824 b- defN 23-May-31 13:12 quickBayes/functions/BG.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    99840 b- defN 23-May-31 13:12 quickBayes/functions/SE.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    69632 b- defN 23-May-31 13:12 quickBayes/functions/SE_fix.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    84480 b- defN 23-May-31 13:12 quickBayes/functions/base.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    79360 b- defN 23-May-31 13:12 quickBayes/functions/composite.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    56320 b- defN 23-May-31 13:12 quickBayes/functions/convolution.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    55808 b- defN 23-May-31 13:12 quickBayes/functions/delta.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    52736 b- defN 23-May-31 13:12 quickBayes/functions/exp_decay.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    58880 b- defN 23-May-31 13:12 quickBayes/functions/gaussian.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    55808 b- defN 23-May-31 13:12 quickBayes/functions/lorentz.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat   138240 b- defN 23-May-31 13:12 quickBayes/functions/qe_function.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    71168 b- defN 23-May-31 13:12 quickBayes/functions/qldata_function.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    57856 b- defN 23-May-31 13:12 quickBayes/functions/qse_fixed.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    63488 b- defN 23-May-31 13:12 quickBayes/functions/qse_function.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    41472 b- defN 23-May-31 13:12 quickBayes/test_helpers/fitting_data.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat   137216 b- defN 23-May-31 13:12 quickBayes/test_helpers/template_fit_test.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    49664 b- defN 23-May-31 13:12 quickBayes/test_helpers/template_scipy_fit.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    54784 b- defN 23-May-31 13:12 quickBayes/test_helpers/workflows.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-31 13:08 quickBayes/utils/__init__.py
--rw-rw-rw-  2.0 fat    34304 b- defN 23-May-31 13:13 quickBayes/utils/crop_data.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat      863 b- defN 23-May-31 13:08 quickBayes/utils/crop_data.py
--rw-rw-rw-  2.0 fat    39424 b- defN 23-May-31 13:13 quickBayes/utils/general.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat     1119 b- defN 23-May-31 13:08 quickBayes/utils/general.py
--rw-rw-rw-  2.0 fat    32256 b- defN 23-May-31 13:13 quickBayes/utils/spline.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat      549 b- defN 23-May-31 13:08 quickBayes/utils/spline.py
--rw-rw-rw-  2.0 fat    63488 b- defN 23-May-31 13:13 quickBayes/workflow/MuonExpDecay.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    80384 b- defN 23-May-31 13:13 quickBayes/workflow/QSE.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    72192 b- defN 23-May-31 13:13 quickBayes/workflow/QlData.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    97792 b- defN 23-May-31 13:13 quickBayes/workflow/grid_template.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    72704 b- defN 23-May-31 13:13 quickBayes/workflow/model_template.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    51712 b- defN 23-May-31 13:13 quickBayes/workflow/qse_search.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat    72192 b- defN 23-May-31 13:13 quickBayes/workflow/template.cp38-win_amd64.pyd
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-31 13:08 quickBayes/workflows/__init__.py
--rw-rw-rw-  2.0 fat     6229 b- defN 23-May-31 13:08 quickBayes/workflows/workflow_template.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-31 13:08 quickBayes/workflows/grid_search/__init__.py
--rw-rw-rw-  2.0 fat     8208 b- defN 23-May-31 13:08 quickBayes/workflows/grid_search/grid_search_template.py
--rw-rw-rw-  2.0 fat     3082 b- defN 23-May-31 13:08 quickBayes/workflows/grid_search/qse_grid_search.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-May-31 13:08 quickBayes/workflows/model_selection/__init__.py
--rw-rw-rw-  2.0 fat     5583 b- defN 23-May-31 13:08 quickBayes/workflows/model_selection/model_template.py
--rw-rw-rw-  2.0 fat     3803 b- defN 23-May-31 13:08 quickBayes/workflows/model_selection/muon_exp_decay_main.py
--rw-rw-rw-  2.0 fat     4638 b- defN 23-May-31 13:08 quickBayes/workflows/model_selection/qldata_main.py
--rw-rw-rw-  2.0 fat     5669 b- defN 23-May-31 13:08 quickBayes/workflows/model_selection/qse_main.py
--rw-rw-rw-  2.0 fat     1472 b- defN 23-May-31 13:13 quickBayes-1.0.0b8.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat      663 b- defN 23-May-31 13:13 quickBayes-1.0.0b8.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 23-May-31 13:13 quickBayes-1.0.0b8.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       11 b- defN 23-May-31 13:13 quickBayes-1.0.0b8.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     7370 b- defN 23-May-31 13:13 quickBayes-1.0.0b8.dist-info/RECORD
-74 files, 2370109 bytes uncompressed, 1022459 bytes compressed:  56.9%
+Zip file size: 1249531 bytes, number of entries: 74
+-rwxr-xr-x  2.0 unx    74056 b- defN 23-Jul-05 10:39 quickBayes/log_likelihood.cpython-39-darwin.so
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-05 10:30 quickBayes/__init__.py
+-rw-r--r--  2.0 unx     2477 b- defN 23-Jul-05 10:30 quickBayes/log_likelihood.py
+-rw-r--r--  2.0 unx     3590 b- defN 23-Jul-05 10:30 quickBayes/fit_engines/fit_utils.py
+-rw-r--r--  2.0 unx     6873 b- defN 23-Jul-05 10:30 quickBayes/fit_engines/fit_engine.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-05 10:30 quickBayes/fit_engines/__init__.py
+-rw-r--r--  2.0 unx     3968 b- defN 23-Jul-05 10:30 quickBayes/fit_engines/gofit_engine.py
+-rw-r--r--  2.0 unx     3487 b- defN 23-Jul-05 10:30 quickBayes/fit_engines/scipy_fit_engine.py
+-rwxr-xr-x  2.0 unx   100768 b- defN 23-Jul-05 10:39 quickBayes/fitting/gofit_engine.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   169744 b- defN 23-Jul-05 10:39 quickBayes/fitting/fit_engine.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   121288 b- defN 23-Jul-05 10:39 quickBayes/fitting/fit_utils.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    99344 b- defN 23-Jul-05 10:39 quickBayes/fitting/scipy_engine.cpython-39-darwin.so
+-rw-r--r--  2.0 unx     2283 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/exp_decay.py
+-rw-r--r--  2.0 unx     4446 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/BG.py
+-rw-r--r--  2.0 unx     4905 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/qldata_function.py
+-rw-r--r--  2.0 unx     2747 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/lorentz.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/__init__.py
+-rw-r--r--  2.0 unx     3210 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/qse_fixed.py
+-rw-r--r--  2.0 unx     4734 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/composite_fun.py
+-rw-r--r--  2.0 unx     2767 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/conv_with_res.py
+-rw-r--r--  2.0 unx     4471 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/stretch_exp_fixed.py
+-rw-r--r--  2.0 unx     7996 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/stretch_exp.py
+-rw-r--r--  2.0 unx    13477 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/quasielastic_function.py
+-rw-r--r--  2.0 unx     3505 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/qse.py
+-rw-r--r--  2.0 unx     6478 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/base.py
+-rw-r--r--  2.0 unx     2809 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/gaussian.py
+-rw-r--r--  2.0 unx     2682 b- defN 23-Jul-05 10:30 quickBayes/fit_functions/delta_function.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-05 10:30 quickBayes/workflows/__init__.py
+-rw-r--r--  2.0 unx     5802 b- defN 23-Jul-05 10:30 quickBayes/workflows/workflow_template.py
+-rw-r--r--  2.0 unx     8067 b- defN 23-Jul-05 10:30 quickBayes/workflows/grid_search/grid_search_template.py
+-rw-r--r--  2.0 unx     2988 b- defN 23-Jul-05 10:30 quickBayes/workflows/grid_search/qse_grid_search.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-05 10:30 quickBayes/workflows/grid_search/__init__.py
+-rw-r--r--  2.0 unx     3709 b- defN 23-Jul-05 10:30 quickBayes/workflows/model_selection/muon_exp_decay_main.py
+-rw-r--r--  2.0 unx     5437 b- defN 23-Jul-05 10:30 quickBayes/workflows/model_selection/model_template.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-05 10:30 quickBayes/workflows/model_selection/__init__.py
+-rw-r--r--  2.0 unx     4524 b- defN 23-Jul-05 10:30 quickBayes/workflows/model_selection/qldata_main.py
+-rw-r--r--  2.0 unx     5528 b- defN 23-Jul-05 10:30 quickBayes/workflows/model_selection/qse_main.py
+-rw-r--r--  2.0 unx      532 b- defN 23-Jul-05 10:30 quickBayes/utils/spline.py
+-rwxr-xr-x  2.0 unx    66424 b- defN 23-Jul-05 10:40 quickBayes/utils/spline.cpython-39-darwin.so
+-rw-r--r--  2.0 unx        0 b- defN 23-Jul-05 10:30 quickBayes/utils/__init__.py
+-rwxr-xr-x  2.0 unx    71984 b- defN 23-Jul-05 10:40 quickBayes/utils/general.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    67864 b- defN 23-Jul-05 10:40 quickBayes/utils/crop_data.cpython-39-darwin.so
+-rw-r--r--  2.0 unx      839 b- defN 23-Jul-05 10:30 quickBayes/utils/crop_data.py
+-rw-r--r--  2.0 unx     1086 b- defN 23-Jul-05 10:30 quickBayes/utils/general.py
+-rwxr-xr-x  2.0 unx   144256 b- defN 23-Jul-05 10:40 quickBayes/workflow/QSE.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   197968 b- defN 23-Jul-05 10:40 quickBayes/workflow/grid_template.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   125024 b- defN 23-Jul-05 10:40 quickBayes/workflow/model_template.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   139768 b- defN 23-Jul-05 10:40 quickBayes/workflow/QlData.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   120160 b- defN 23-Jul-05 10:40 quickBayes/workflow/MuonExpDecay.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   127472 b- defN 23-Jul-05 10:40 quickBayes/workflow/template.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    97344 b- defN 23-Jul-05 10:40 quickBayes/workflow/qse_search.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   258608 b- defN 23-Jul-05 10:40 quickBayes/functions/qe_function.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    96688 b- defN 23-Jul-05 10:39 quickBayes/functions/lorentz.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   120704 b- defN 23-Jul-05 10:40 quickBayes/functions/qse_function.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   121432 b- defN 23-Jul-05 10:40 quickBayes/functions/SE_fix.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    99248 b- defN 23-Jul-05 10:40 quickBayes/functions/convolution.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   187632 b- defN 23-Jul-05 10:40 quickBayes/functions/SE.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   150520 b- defN 23-Jul-05 10:39 quickBayes/functions/base.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   100496 b- defN 23-Jul-05 10:40 quickBayes/functions/qse_fixed.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    96272 b- defN 23-Jul-05 10:39 quickBayes/functions/delta.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    95152 b- defN 23-Jul-05 10:40 quickBayes/functions/exp_decay.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   141112 b- defN 23-Jul-05 10:40 quickBayes/functions/qldata_function.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   141880 b- defN 23-Jul-05 10:39 quickBayes/functions/BG.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    98760 b- defN 23-Jul-05 10:40 quickBayes/functions/gaussian.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   142912 b- defN 23-Jul-05 10:40 quickBayes/functions/composite.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   102696 b- defN 23-Jul-05 10:40 quickBayes/test_helpers/template_scipy_fit.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    75816 b- defN 23-Jul-05 10:40 quickBayes/test_helpers/fitting_data.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx    99104 b- defN 23-Jul-05 10:40 quickBayes/test_helpers/workflows.cpython-39-darwin.so
+-rwxr-xr-x  2.0 unx   259016 b- defN 23-Jul-05 10:40 quickBayes/test_helpers/template_fit_test.cpython-39-darwin.so
+-rw-rw-r--  2.0 unx     7454 b- defN 23-Jul-05 10:40 quickBayes-1.0.0b9.dist-info/RECORD
+-rw-r--r--  2.0 unx      109 b- defN 23-Jul-05 10:40 quickBayes-1.0.0b9.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 23-Jul-05 10:40 quickBayes-1.0.0b9.dist-info/top_level.txt
+-rw-r--r--  2.0 unx     1462 b- defN 23-Jul-05 10:40 quickBayes-1.0.0b9.dist-info/LICENSE.txt
+-rw-r--r--  2.0 unx      663 b- defN 23-Jul-05 10:40 quickBayes-1.0.0b9.dist-info/METADATA
+74 files, 4246628 bytes uncompressed, 1237359 bytes compressed:  70.9%
```

## zipnote {}

```diff
@@ -1,223 +1,223 @@
-Filename: quickBayes/__init__.py
+Filename: quickBayes/log_likelihood.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/log_likelihood.cp38-win_amd64.pyd
+Filename: quickBayes/__init__.py
 Comment: 
 
 Filename: quickBayes/log_likelihood.py
 Comment: 
 
-Filename: quickBayes/fit_engines/__init__.py
+Filename: quickBayes/fit_engines/fit_utils.py
 Comment: 
 
 Filename: quickBayes/fit_engines/fit_engine.py
 Comment: 
 
-Filename: quickBayes/fit_engines/fit_utils.py
+Filename: quickBayes/fit_engines/__init__.py
 Comment: 
 
 Filename: quickBayes/fit_engines/gofit_engine.py
 Comment: 
 
 Filename: quickBayes/fit_engines/scipy_fit_engine.py
 Comment: 
 
-Filename: quickBayes/fit_functions/BG.py
+Filename: quickBayes/fitting/gofit_engine.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/fit_functions/__init__.py
+Filename: quickBayes/fitting/fit_engine.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/fit_functions/base.py
+Filename: quickBayes/fitting/fit_utils.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/fit_functions/composite_fun.py
+Filename: quickBayes/fitting/scipy_engine.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/fit_functions/conv_with_res.py
+Filename: quickBayes/fit_functions/exp_decay.py
 Comment: 
 
-Filename: quickBayes/fit_functions/delta_function.py
+Filename: quickBayes/fit_functions/BG.py
 Comment: 
 
-Filename: quickBayes/fit_functions/exp_decay.py
+Filename: quickBayes/fit_functions/qldata_function.py
 Comment: 
 
-Filename: quickBayes/fit_functions/gaussian.py
+Filename: quickBayes/fit_functions/lorentz.py
 Comment: 
 
-Filename: quickBayes/fit_functions/lorentz.py
+Filename: quickBayes/fit_functions/__init__.py
 Comment: 
 
-Filename: quickBayes/fit_functions/qldata_function.py
+Filename: quickBayes/fit_functions/qse_fixed.py
 Comment: 
 
-Filename: quickBayes/fit_functions/qse.py
+Filename: quickBayes/fit_functions/composite_fun.py
 Comment: 
 
-Filename: quickBayes/fit_functions/qse_fixed.py
+Filename: quickBayes/fit_functions/conv_with_res.py
 Comment: 
 
-Filename: quickBayes/fit_functions/quasielastic_function.py
+Filename: quickBayes/fit_functions/stretch_exp_fixed.py
 Comment: 
 
 Filename: quickBayes/fit_functions/stretch_exp.py
 Comment: 
 
-Filename: quickBayes/fit_functions/stretch_exp_fixed.py
+Filename: quickBayes/fit_functions/quasielastic_function.py
 Comment: 
 
-Filename: quickBayes/fitting/fit_engine.cp38-win_amd64.pyd
+Filename: quickBayes/fit_functions/qse.py
 Comment: 
 
-Filename: quickBayes/fitting/fit_utils.cp38-win_amd64.pyd
+Filename: quickBayes/fit_functions/base.py
 Comment: 
 
-Filename: quickBayes/fitting/gofit_engine.cp38-win_amd64.pyd
+Filename: quickBayes/fit_functions/gaussian.py
 Comment: 
 
-Filename: quickBayes/fitting/scipy_engine.cp38-win_amd64.pyd
+Filename: quickBayes/fit_functions/delta_function.py
 Comment: 
 
-Filename: quickBayes/functions/BG.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/__init__.py
 Comment: 
 
-Filename: quickBayes/functions/SE.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/workflow_template.py
 Comment: 
 
-Filename: quickBayes/functions/SE_fix.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/grid_search/grid_search_template.py
 Comment: 
 
-Filename: quickBayes/functions/base.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/grid_search/qse_grid_search.py
 Comment: 
 
-Filename: quickBayes/functions/composite.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/grid_search/__init__.py
 Comment: 
 
-Filename: quickBayes/functions/convolution.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/model_selection/muon_exp_decay_main.py
 Comment: 
 
-Filename: quickBayes/functions/delta.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/model_selection/model_template.py
 Comment: 
 
-Filename: quickBayes/functions/exp_decay.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/model_selection/__init__.py
 Comment: 
 
-Filename: quickBayes/functions/gaussian.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/model_selection/qldata_main.py
 Comment: 
 
-Filename: quickBayes/functions/lorentz.cp38-win_amd64.pyd
+Filename: quickBayes/workflows/model_selection/qse_main.py
 Comment: 
 
-Filename: quickBayes/functions/qe_function.cp38-win_amd64.pyd
+Filename: quickBayes/utils/spline.py
 Comment: 
 
-Filename: quickBayes/functions/qldata_function.cp38-win_amd64.pyd
+Filename: quickBayes/utils/spline.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/functions/qse_fixed.cp38-win_amd64.pyd
+Filename: quickBayes/utils/__init__.py
 Comment: 
 
-Filename: quickBayes/functions/qse_function.cp38-win_amd64.pyd
+Filename: quickBayes/utils/general.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/test_helpers/fitting_data.cp38-win_amd64.pyd
+Filename: quickBayes/utils/crop_data.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/test_helpers/template_fit_test.cp38-win_amd64.pyd
+Filename: quickBayes/utils/crop_data.py
 Comment: 
 
-Filename: quickBayes/test_helpers/template_scipy_fit.cp38-win_amd64.pyd
+Filename: quickBayes/utils/general.py
 Comment: 
 
-Filename: quickBayes/test_helpers/workflows.cp38-win_amd64.pyd
+Filename: quickBayes/workflow/QSE.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/utils/__init__.py
+Filename: quickBayes/workflow/grid_template.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/utils/crop_data.cp38-win_amd64.pyd
+Filename: quickBayes/workflow/model_template.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/utils/crop_data.py
+Filename: quickBayes/workflow/QlData.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/utils/general.cp38-win_amd64.pyd
+Filename: quickBayes/workflow/MuonExpDecay.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/utils/general.py
+Filename: quickBayes/workflow/template.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/utils/spline.cp38-win_amd64.pyd
+Filename: quickBayes/workflow/qse_search.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/utils/spline.py
+Filename: quickBayes/functions/qe_function.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflow/MuonExpDecay.cp38-win_amd64.pyd
+Filename: quickBayes/functions/lorentz.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflow/QSE.cp38-win_amd64.pyd
+Filename: quickBayes/functions/qse_function.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflow/QlData.cp38-win_amd64.pyd
+Filename: quickBayes/functions/SE_fix.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflow/grid_template.cp38-win_amd64.pyd
+Filename: quickBayes/functions/convolution.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflow/model_template.cp38-win_amd64.pyd
+Filename: quickBayes/functions/SE.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflow/qse_search.cp38-win_amd64.pyd
+Filename: quickBayes/functions/base.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflow/template.cp38-win_amd64.pyd
+Filename: quickBayes/functions/qse_fixed.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/__init__.py
+Filename: quickBayes/functions/delta.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/workflow_template.py
+Filename: quickBayes/functions/exp_decay.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/grid_search/__init__.py
+Filename: quickBayes/functions/qldata_function.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/grid_search/grid_search_template.py
+Filename: quickBayes/functions/BG.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/grid_search/qse_grid_search.py
+Filename: quickBayes/functions/gaussian.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/model_selection/__init__.py
+Filename: quickBayes/functions/composite.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/model_selection/model_template.py
+Filename: quickBayes/test_helpers/template_scipy_fit.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/model_selection/muon_exp_decay_main.py
+Filename: quickBayes/test_helpers/fitting_data.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/model_selection/qldata_main.py
+Filename: quickBayes/test_helpers/workflows.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes/workflows/model_selection/qse_main.py
+Filename: quickBayes/test_helpers/template_fit_test.cpython-39-darwin.so
 Comment: 
 
-Filename: quickBayes-1.0.0b8.dist-info/LICENSE.txt
+Filename: quickBayes-1.0.0b9.dist-info/RECORD
 Comment: 
 
-Filename: quickBayes-1.0.0b8.dist-info/METADATA
+Filename: quickBayes-1.0.0b9.dist-info/WHEEL
 Comment: 
 
-Filename: quickBayes-1.0.0b8.dist-info/WHEEL
+Filename: quickBayes-1.0.0b9.dist-info/top_level.txt
 Comment: 
 
-Filename: quickBayes-1.0.0b8.dist-info/top_level.txt
+Filename: quickBayes-1.0.0b9.dist-info/LICENSE.txt
 Comment: 
 
-Filename: quickBayes-1.0.0b8.dist-info/RECORD
+Filename: quickBayes-1.0.0b9.dist-info/METADATA
 Comment: 
 
 Zip file comment:
```

## quickBayes/log_likelihood.py

 * *Ordering differences only*

```diff
@@ -1,65 +1,65 @@
-from quickBayes.fitting.fit_utils import log10_hessian_det
-from numpy import ndarray
-import numpy as np
-from math import exp, log10
-
-
-def loglikelihood(x_len: ndarray, chi2: float, covar: ndarray,
-                  N_peaks: int, beta: float) -> float:
-    """
-    Calculate the unnormalised logliklihood.
-    log_10 probabilities -> priors
-
-    The equation for the probability is taken from
-    "Data Analysis A bayesian tutorial second edition",
-    by D. S. Sivia
-    equation 4.20 page 88:
-    P(M|{D_k},I) prop \\frac{N! (4\\pi)^N}{\\beta^N\\sqrt(\\det(H))}\\exp{(-\\frac{\\chi^2}{2})}  # noqa E501
-    where \\beta = (x_{max}-x_{min})A_{max}, H is the Hessian matrix
-
-    We want this as a logliklihood, so take \\log_{10} and use:
-    - \\log_{10}(\\exp{\\alpha}) = \\ln(\\exp{\\alpha})\\log_{10}(\\exp{1})
-    \\log_{10}(\\exp({\\alpha}) = \\alpha\\log_{10}(\\exp{1})
-    - N! = \\Pi_{i=0}{N} i => \\log{N!} = \\sum_{i=0}^N \\log(i)
-    - \\log(ab) = \\log(a) + \\log(b)
-    - \\log(\\frac{a}{b}) = \\log(a) - \\log(b)
-    - \\log(a^N) = N\\log(a)
-
-    to get:
-    \\sum_{j=1}{N}\\log(j) + N\\log(4\\pi) - 0.5\\chi^2\\log(exp(1))
-    - N\\log(\\beta) - 0.5\\log(\\det(H))
-
-    :param x_len: the length of the x data
-    :param chi2: the chi squared for the fit
-    :param covar: the covariance matrix
-    :param N_peaks: the number of peaks
-    :param beta: the scale factor, A_max*(x_max - x_min) eq. 4.17
-    :return the loglikelihood
-    """
-
-    """
-    If the fit is overparameterised the loglikelihood
-    will artifically be low. This is because the equation
-    has used a Taylor expansion of exp(-0.5*chi^2).
-    This requires us to be at a minimum, which is not the
-    case with overparameterised data (consider fitting 2 flat
-    backgrounds to flat data, there will be a vally of good fits
-    that sum to the correct background value).
-    We will therefore add a penality to the loglikelihood
-    via the hessian.
-    """
-    log_hess_det = log10_hessian_det(covar)
-    if np.max(np.abs(covar)) > 1:
-        log_hess_det = 100*np.abs(log_hess_det)
-
-    # want the unscaled chi^2 -> multiple by length of data
-    log_chi2 = log10(exp(1.))*chi2*float(x_len)/2.
-
-    log_likelihood = np.sum(
-        np.log10(np.asarray([k + 1 for k in range(N_peaks)])))
-    log_likelihood += float(N_peaks)*log10(4.*np.pi)
-    log_likelihood -= log_chi2
-    log_likelihood -= float(N_peaks)*log10(beta)
-    log_likelihood -= 0.5*(log_hess_det)
-
-    return log_likelihood
+from quickBayes.fitting.fit_utils import log10_hessian_det
+from numpy import ndarray
+import numpy as np
+from math import exp, log10
+
+
+def loglikelihood(x_len: ndarray, chi2: float, covar: ndarray,
+                  N_peaks: int, beta: float) -> float:
+    """
+    Calculate the unnormalised logliklihood.
+    log_10 probabilities -> priors
+
+    The equation for the probability is taken from
+    "Data Analysis A bayesian tutorial second edition",
+    by D. S. Sivia
+    equation 4.20 page 88:
+    P(M|{D_k},I) prop \\frac{N! (4\\pi)^N}{\\beta^N\\sqrt(\\det(H))}\\exp{(-\\frac{\\chi^2}{2})}  # noqa E501
+    where \\beta = (x_{max}-x_{min})A_{max}, H is the Hessian matrix
+
+    We want this as a logliklihood, so take \\log_{10} and use:
+    - \\log_{10}(\\exp{\\alpha}) = \\ln(\\exp{\\alpha})\\log_{10}(\\exp{1})
+    \\log_{10}(\\exp({\\alpha}) = \\alpha\\log_{10}(\\exp{1})
+    - N! = \\Pi_{i=0}{N} i => \\log{N!} = \\sum_{i=0}^N \\log(i)
+    - \\log(ab) = \\log(a) + \\log(b)
+    - \\log(\\frac{a}{b}) = \\log(a) - \\log(b)
+    - \\log(a^N) = N\\log(a)
+
+    to get:
+    \\sum_{j=1}{N}\\log(j) + N\\log(4\\pi) - 0.5\\chi^2\\log(exp(1))
+    - N\\log(\\beta) - 0.5\\log(\\det(H))
+
+    :param x_len: the length of the x data
+    :param chi2: the chi squared for the fit
+    :param covar: the covariance matrix
+    :param N_peaks: the number of peaks
+    :param beta: the scale factor, A_max*(x_max - x_min) eq. 4.17
+    :return the loglikelihood
+    """
+
+    """
+    If the fit is overparameterised the loglikelihood
+    will artifically be low. This is because the equation
+    has used a Taylor expansion of exp(-0.5*chi^2).
+    This requires us to be at a minimum, which is not the
+    case with overparameterised data (consider fitting 2 flat
+    backgrounds to flat data, there will be a vally of good fits
+    that sum to the correct background value).
+    We will therefore add a penality to the loglikelihood
+    via the hessian.
+    """
+    log_hess_det = log10_hessian_det(covar)
+    if np.max(np.abs(covar)) > 1:
+        log_hess_det = 100*np.abs(log_hess_det)
+
+    # want the unscaled chi^2 -> multiple by length of data
+    log_chi2 = log10(exp(1.))*chi2*float(x_len)/2.
+
+    log_likelihood = np.sum(
+        np.log10(np.asarray([k + 1 for k in range(N_peaks)])))
+    log_likelihood += float(N_peaks)*log10(4.*np.pi)
+    log_likelihood -= log_chi2
+    log_likelihood -= float(N_peaks)*log10(beta)
+    log_likelihood -= 0.5*(log_hess_det)
+
+    return log_likelihood
```

## quickBayes/fit_engines/fit_engine.py

 * *Ordering differences only*

```diff
@@ -1,176 +1,176 @@
-from numpy import ndarray
-from typing import Callable
-from abc import abstractmethod
-import numpy as np
-from quickBayes.fitting.fit_utils import (chi_squared,
-                                          param_errors,
-                                          derivative,
-                                          fit_errors,
-                                          var, res)
-from quickBayes.utils.spline import spline
-
-
-class FitEngine(object):
-    """
-    A basic class for the fit engine, includes a history
-    """
-    def __init__(self, name: str, x_data: ndarray, y_data: ndarray,
-                 e_data: ndarray):
-        """
-        Creates the basic fit engine class
-        Stores useful information about each fit
-        :param name: name of the fit engine
-        :param x_data: original x data (can fit to an interpolation)
-        :param y_data: original y data (can fit to an interpolation)
-        :param e_data: original e data (can fit to an interpolation)
-        """
-        self._name = name
-        self._fits = []
-        self._fit_errors = []
-        self._params = []
-        self._param_errors = []
-        self._msgs = []
-        self._chi2 = []
-        self._covars = []
-        self._diffs = []
-        self._fit = None
-
-        self._x_data = x_data
-        self._y_data = y_data
-        self._e_data = e_data
-
-    def get_chi_squared(self, index: int = -1) -> float:
-        """
-        Get the chi squared value
-        :param index: the index (number) of chi squared that you want,
-        count from 0
-        :return chi squared value
-        """
-        return self._chi2[index]
-
-    def get_covariance_matrix(self, index: int = -1) -> ndarray:
-        """
-        :param index: the index (number) of covariance matrix that you want,
-        count from 0
-        :return covariance matrix
-        """
-        return self._covars[index]
-
-    def get_fit_values(self, index: int = -1) -> (ndarray, ndarray,
-                                                  ndarray, ndarray, ndarray):
-        """
-        Gets the fit values from the history.
-        These are interpolated onto the same x values as the
-        fit history was created with.
-        The fit errors are calculated by quadrature sqrt(sigma_f^2 + sigma_y^2)
-        :param index: the index (number) of fit that you want,
-        counts from 0
-        :return fit values (x data, y values, y errors, diffs, diff errors)
-        """
-        return (self._x_data, self._fits[index], self._fit_errors[index],
-                self._diffs[index], np.sqrt(self._fit_errors[index]**2 +
-                                            self._e_data**2))
-
-    def get_fit_parameters(self, index: int = -1) -> (ndarray, ndarray):
-        """
-        Get the fit parameters and errors, that you want
-        :param index: the index (number) of fit parameters (and errors) that
-        you want, counts from 0
-        :return list of fit parameters and their errors
-        """
-        return self._params[index], self._param_errors[index]
-
-    @property
-    def name(self) -> str:
-        """
-        :return name of the fit engine
-        """
-        return self._name
-
-    @abstractmethod
-    def _do_fit(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
-                func: Callable) -> ndarray:
-        """
-        The main function for doing the fitting_algorithm
-        :param x_data: the x data to fit
-        :param y_data: the y data to fit
-        :param e_data: the error data to fit
-        :return the fit parameters
-        """
-        raise NotImplementedError()
-
-    def add_fit(self, x_data: ndarray, func: Callable, df_by_dp: ndarray,
-                params: ndarray) -> None:
-        """
-        Adds the fit result to the fit history
-        :param x_data: the x data to fit
-        :param func: the fitting function
-        :param df_by_dp: the derivatives wrt the parameters
-        :param params: the parameters from the fit
-        """
-        fit_y = func(x_data, *params)
-        errors = fit_errors(x_data, params, fit_y, self._covars[-1], df_by_dp)
-        self._fit = fit_y
-        # record fit on same x axis as the FitHistory was create with
-        if not np.array_equal(x_data, self._x_data):
-            fit_y = spline(x_data, fit_y, self._x_data)
-            errors = spline(x_data, errors, self._x_data)
-        self._fits.append(fit_y)
-        self._fit_errors.append(errors)
-        self._diffs.append(fit_y - self._y_data)
-
-    def add_params(self, params) -> None:
-        """
-        Add the parameters and errors to the history
-        :param params: the fit parameters
-        """
-        self._params.append(params)
-        self._param_errors.append(param_errors(self._covars[-1]))
-
-    def do_fit(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
-               func: Callable) -> None:
-        """
-        Call for doing a fit and updating the history
-        :param x_data: the x data to fit against
-        :param y_data: the y data to fit against
-        :param e_data: the error data to fit against
-        :param func: the fitting function
-        """
-        params = self._do_fit(x_data, y_data, e_data, func)
-
-        df_by_dp = derivative(x_data, params, func)
-        self.calculate_covar(x_data, y_data, e_data, func, df_by_dp, params)
-        self.add_params(params)
-        self.add_fit(x_data, func, df_by_dp, params)
-        self._chi2.append(chi_squared(x_data, y_data, e_data,
-                                      self._fit, params))
-        self._fit = None
-
-    def calculate_covar(self, x_data: ndarray, y_data: ndarray,
-                        e_data: ndarray,
-                        func: Callable, df_by_dp: ndarray,
-                        params: ndarray) -> None:
-        """
-        Calculate the covariance matrix and add it to the history
-        :param x_data: the x data to fitted against
-        :param y_data: the y data to fitted against
-        :param e_data: the error data to fitted against
-        :param func: the fitting function
-        :param df_by_dp: the derivatives wrt the parameters
-        :param params: the fit parameters
-        """
-        # make Jacobian matrix (derivatives)
-        jac = np.array(df_by_dp).T
-        # factorize the matrix
-        _, upper_triangle = np.linalg.qr(jac)
-        # Calculate the inverse value of upper triangle
-        inverse = np.linalg.solve(upper_triangle,
-                                  np.identity(upper_triangle.shape[0]))
-        # Matrix multiplication: (J^T J)^{-1}
-        JTJ_inv = np.matmul(inverse, inverse.transpose())
-
-        # weight: sum( y - f)^2/sum( (y-f)^2/e^2) -> cannot cancel due to sum
-        weight = var(func, x_data, y_data, params)/res(func, x_data, y_data,
-                                                       e_data, params)
-        CovMatrix = JTJ_inv * weight
-        self._covars.append(CovMatrix)
+from numpy import ndarray
+from typing import Callable
+from abc import abstractmethod
+import numpy as np
+from quickBayes.fitting.fit_utils import (chi_squared,
+                                          param_errors,
+                                          derivative,
+                                          fit_errors,
+                                          var, res)
+from quickBayes.utils.spline import spline
+
+
+class FitEngine(object):
+    """
+    A basic class for the fit engine, includes a history
+    """
+    def __init__(self, name: str, x_data: ndarray, y_data: ndarray,
+                 e_data: ndarray):
+        """
+        Creates the basic fit engine class
+        Stores useful information about each fit
+        :param name: name of the fit engine
+        :param x_data: original x data (can fit to an interpolation)
+        :param y_data: original y data (can fit to an interpolation)
+        :param e_data: original e data (can fit to an interpolation)
+        """
+        self._name = name
+        self._fits = []
+        self._fit_errors = []
+        self._params = []
+        self._param_errors = []
+        self._msgs = []
+        self._chi2 = []
+        self._covars = []
+        self._diffs = []
+        self._fit = None
+
+        self._x_data = x_data
+        self._y_data = y_data
+        self._e_data = e_data
+
+    def get_chi_squared(self, index: int = -1) -> float:
+        """
+        Get the chi squared value
+        :param index: the index (number) of chi squared that you want,
+        count from 0
+        :return chi squared value
+        """
+        return self._chi2[index]
+
+    def get_covariance_matrix(self, index: int = -1) -> ndarray:
+        """
+        :param index: the index (number) of covariance matrix that you want,
+        count from 0
+        :return covariance matrix
+        """
+        return self._covars[index]
+
+    def get_fit_values(self, index: int = -1) -> (ndarray, ndarray,
+                                                  ndarray, ndarray, ndarray):
+        """
+        Gets the fit values from the history.
+        These are interpolated onto the same x values as the
+        fit history was created with.
+        The fit errors are calculated by quadrature sqrt(sigma_f^2 + sigma_y^2)
+        :param index: the index (number) of fit that you want,
+        counts from 0
+        :return fit values (x data, y values, y errors, diffs, diff errors)
+        """
+        return (self._x_data, self._fits[index], self._fit_errors[index],
+                self._diffs[index], np.sqrt(self._fit_errors[index]**2 +
+                                            self._e_data**2))
+
+    def get_fit_parameters(self, index: int = -1) -> (ndarray, ndarray):
+        """
+        Get the fit parameters and errors, that you want
+        :param index: the index (number) of fit parameters (and errors) that
+        you want, counts from 0
+        :return list of fit parameters and their errors
+        """
+        return self._params[index], self._param_errors[index]
+
+    @property
+    def name(self) -> str:
+        """
+        :return name of the fit engine
+        """
+        return self._name
+
+    @abstractmethod
+    def _do_fit(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
+                func: Callable) -> ndarray:
+        """
+        The main function for doing the fitting_algorithm
+        :param x_data: the x data to fit
+        :param y_data: the y data to fit
+        :param e_data: the error data to fit
+        :return the fit parameters
+        """
+        raise NotImplementedError()
+
+    def add_fit(self, x_data: ndarray, func: Callable, df_by_dp: ndarray,
+                params: ndarray) -> None:
+        """
+        Adds the fit result to the fit history
+        :param x_data: the x data to fit
+        :param func: the fitting function
+        :param df_by_dp: the derivatives wrt the parameters
+        :param params: the parameters from the fit
+        """
+        fit_y = func(x_data, *params)
+        errors = fit_errors(x_data, params, fit_y, self._covars[-1], df_by_dp)
+        self._fit = fit_y
+        # record fit on same x axis as the FitHistory was create with
+        if not np.array_equal(x_data, self._x_data):
+            fit_y = spline(x_data, fit_y, self._x_data)
+            errors = spline(x_data, errors, self._x_data)
+        self._fits.append(fit_y)
+        self._fit_errors.append(errors)
+        self._diffs.append(fit_y - self._y_data)
+
+    def add_params(self, params) -> None:
+        """
+        Add the parameters and errors to the history
+        :param params: the fit parameters
+        """
+        self._params.append(params)
+        self._param_errors.append(param_errors(self._covars[-1]))
+
+    def do_fit(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
+               func: Callable) -> None:
+        """
+        Call for doing a fit and updating the history
+        :param x_data: the x data to fit against
+        :param y_data: the y data to fit against
+        :param e_data: the error data to fit against
+        :param func: the fitting function
+        """
+        params = self._do_fit(x_data, y_data, e_data, func)
+
+        df_by_dp = derivative(x_data, params, func)
+        self.calculate_covar(x_data, y_data, e_data, func, df_by_dp, params)
+        self.add_params(params)
+        self.add_fit(x_data, func, df_by_dp, params)
+        self._chi2.append(chi_squared(x_data, y_data, e_data,
+                                      self._fit, params))
+        self._fit = None
+
+    def calculate_covar(self, x_data: ndarray, y_data: ndarray,
+                        e_data: ndarray,
+                        func: Callable, df_by_dp: ndarray,
+                        params: ndarray) -> None:
+        """
+        Calculate the covariance matrix and add it to the history
+        :param x_data: the x data to fitted against
+        :param y_data: the y data to fitted against
+        :param e_data: the error data to fitted against
+        :param func: the fitting function
+        :param df_by_dp: the derivatives wrt the parameters
+        :param params: the fit parameters
+        """
+        # make Jacobian matrix (derivatives)
+        jac = np.array(df_by_dp).T
+        # factorize the matrix
+        _, upper_triangle = np.linalg.qr(jac)
+        # Calculate the inverse value of upper triangle
+        inverse = np.linalg.solve(upper_triangle,
+                                  np.identity(upper_triangle.shape[0]))
+        # Matrix multiplication: (J^T J)^{-1}
+        JTJ_inv = np.matmul(inverse, inverse.transpose())
+
+        # weight: sum( y - f)^2/sum( (y-f)^2/e^2) -> cannot cancel due to sum
+        weight = var(func, x_data, y_data, params)/res(func, x_data, y_data,
+                                                       e_data, params)
+        CovMatrix = JTJ_inv * weight
+        self._covars.append(CovMatrix)
```

## quickBayes/fit_engines/fit_utils.py

 * *Ordering differences only*

```diff
@@ -1,124 +1,124 @@
-from numpy import ndarray
-import numpy as np
-from typing import Callable
-from scipy.stats import t as student_t_dist
-
-
-TWO_SIGMA = 0.6826
-
-
-def var(func: Callable, x_data: ndarray, y_data: ndarray,
-        params: ndarray) -> float:
-    """
-    Calculate the variance of the data: sum_i (f(x_i) - y_i)^2
-    :param func: the fitting function
-    :param x_data: the x data
-    :param y_data: the y data
-    :param params: the fitting parameters
-    :return the variance
-    """
-    return np.sum(pow(func(x_data, *params) - y_data, 2))
-
-
-def res(func, x_data, y_data, e_data, param):
-    """
-    Calculate the residuals of the data: sum_i ((f(x_i) - y_i)/e_i)^2
-    :param func: the fitting function
-    :param x_data: the x data
-    :param y_data: the y data
-    :param e_data: the e data
-    :param params: the fitting parameters
-    :return the residuals
-    """
-    tmp = (func(x_data, *param) - y_data)/e_data
-    return np.sum(tmp*tmp)
-
-
-def log10_hessian_det(covar: ndarray) -> float:
-    """
-    Calculate the log base 10 of the determinant
-    of the Hessian matrix
-    :param covar: the covarience matrix
-    :return the log of the determinant of the
-    Hessian matrix
-    """
-    hessian = np.linalg.inv(covar)
-    det = np.linalg.det(hessian)
-    # cannot have a negative value in log
-    if det <= 0:
-        det = 1.e-9
-    return np.log10(det)
-
-
-def chi_squared(x_data: ndarray, y_data: ndarray, e_data: ndarray,
-                fit: ndarray, params: ndarray) -> float:
-    """
-    Method for calculating the reduced chi squared value
-    :param x_data: x data to fit
-    :param y_data: y data to fit
-    :param e_data: error data for fit
-    :param fit: the fit
-    :param params: the fit parameters
-    :return the chi squared value
-    """
-    chisq = np.sum(((y_data - fit)/e_data)**2)
-    chisq /= (len(x_data) - len(params))
-    return chisq
-
-
-def param_errors(covar: ndarray) -> ndarray:
-    """
-    Get the errors for the parameters
-    :param covar: the covarience matrix
-    :return the errors for the parameters
-    """
-    return np.sqrt(np.diag(covar))
-
-
-def derivative(x_data: ndarray, params: ndarray, func: Callable) -> ndarray:
-    """
-    Get numerical derivative for a function
-    :param x_data: the x data
-    :param params: the paramaters
-    :param func: the function
-    :return numerical derivatives (with respect to fitting parameter)
-    """
-    df_by_dp = []
-    N = len(params)
-    for j in range(N):
-        # only want to change one parameter at a time
-        dparams = np.zeros(N)
-        # small (0.1%) change in parameter value
-        dparams[j] = params[j]*0.001
-        # forward difference
-        df_by_dp.append((func(x_data, *(params + dparams)) -
-                         func(x_data, *(params)))/np.sum(dparams))
-    return df_by_dp
-
-
-def fit_errors(x_data: ndarray, params: ndarray, fit: ndarray,
-               covar: ndarray, df_by_dp: ndarray) -> ndarray:
-    """
-    Generate the errors for the fit line
-    :param x_data: the x data
-    :param params: the parameters for the function
-    :param fit: the y data values from the fit
-    :param covar: the covarience matrix
-    :param df_by_dp: the derivatives
-    :return the error values
-    """
-    confidence = TWO_SIGMA
-
-    prob = 0.5 + confidence/2.  # even distribution above and below data point
-    N = len(params)
-    M = len(x_data)
-    dof = M - N
-    tval = student_t_dist.ppf(prob, dof)
-
-    df_sq = np.zeros(M)
-    for j in range(N):
-        for k in range(N):
-            df_sq += df_by_dp[j]*df_by_dp[k]*covar[j, k]
-    df = np.sqrt(df_sq)
-
-    return tval*df
+from numpy import ndarray
+import numpy as np
+from typing import Callable
+from scipy.stats import t as student_t_dist
+
+
+TWO_SIGMA = 0.6826
+
+
+def var(func: Callable, x_data: ndarray, y_data: ndarray,
+        params: ndarray) -> float:
+    """
+    Calculate the variance of the data: sum_i (f(x_i) - y_i)^2
+    :param func: the fitting function
+    :param x_data: the x data
+    :param y_data: the y data
+    :param params: the fitting parameters
+    :return the variance
+    """
+    return np.sum(pow(func(x_data, *params) - y_data, 2))
+
+
+def res(func, x_data, y_data, e_data, param):
+    """
+    Calculate the residuals of the data: sum_i ((f(x_i) - y_i)/e_i)^2
+    :param func: the fitting function
+    :param x_data: the x data
+    :param y_data: the y data
+    :param e_data: the e data
+    :param params: the fitting parameters
+    :return the residuals
+    """
+    tmp = (func(x_data, *param) - y_data)/e_data
+    return np.sum(tmp*tmp)
+
+
+def log10_hessian_det(covar: ndarray) -> float:
+    """
+    Calculate the log base 10 of the determinant
+    of the Hessian matrix
+    :param covar: the covarience matrix
+    :return the log of the determinant of the
+    Hessian matrix
+    """
+    hessian = np.linalg.inv(covar)
+    det = np.linalg.det(hessian)
+    # cannot have a negative value in log
+    if det <= 0:
+        det = 1.e-9
+    return np.log10(det)
+
+
+def chi_squared(x_data: ndarray, y_data: ndarray, e_data: ndarray,
+                fit: ndarray, params: ndarray) -> float:
+    """
+    Method for calculating the reduced chi squared value
+    :param x_data: x data to fit
+    :param y_data: y data to fit
+    :param e_data: error data for fit
+    :param fit: the fit
+    :param params: the fit parameters
+    :return the chi squared value
+    """
+    chisq = np.sum(((y_data - fit)/e_data)**2)
+    chisq /= (len(x_data) - len(params))
+    return chisq
+
+
+def param_errors(covar: ndarray) -> ndarray:
+    """
+    Get the errors for the parameters
+    :param covar: the covarience matrix
+    :return the errors for the parameters
+    """
+    return np.sqrt(np.diag(covar))
+
+
+def derivative(x_data: ndarray, params: ndarray, func: Callable) -> ndarray:
+    """
+    Get numerical derivative for a function
+    :param x_data: the x data
+    :param params: the paramaters
+    :param func: the function
+    :return numerical derivatives (with respect to fitting parameter)
+    """
+    df_by_dp = []
+    N = len(params)
+    for j in range(N):
+        # only want to change one parameter at a time
+        dparams = np.zeros(N)
+        # small (0.1%) change in parameter value
+        dparams[j] = params[j]*0.001
+        # forward difference
+        df_by_dp.append((func(x_data, *(params + dparams)) -
+                         func(x_data, *(params)))/np.sum(dparams))
+    return df_by_dp
+
+
+def fit_errors(x_data: ndarray, params: ndarray, fit: ndarray,
+               covar: ndarray, df_by_dp: ndarray) -> ndarray:
+    """
+    Generate the errors for the fit line
+    :param x_data: the x data
+    :param params: the parameters for the function
+    :param fit: the y data values from the fit
+    :param covar: the covarience matrix
+    :param df_by_dp: the derivatives
+    :return the error values
+    """
+    confidence = TWO_SIGMA
+
+    prob = 0.5 + confidence/2.  # even distribution above and below data point
+    N = len(params)
+    M = len(x_data)
+    dof = M - N
+    tval = student_t_dist.ppf(prob, dof)
+
+    df_sq = np.zeros(M)
+    for j in range(N):
+        for k in range(N):
+            df_sq += df_by_dp[j]*df_by_dp[k]*covar[j, k]
+    df = np.sqrt(df_sq)
+
+    return tval*df
```

## quickBayes/fit_engines/gofit_engine.py

 * *Ordering differences only*

```diff
@@ -1,106 +1,106 @@
-from gofit import multistart
-from numpy import ndarray
-from typing import Callable
-from quickBayes.fitting.fit_engine import FitEngine
-
-
-"""
-This file contains all of the code needed for a gofit
-engine, because of the way gofit works we need to provide
-a cost function. However, when the cost function is called
-by gofit it is not provided with the original data. Hence,
-we need to construct a cost function class first that has
-the data as a member variable.
-"""
-
-
-class ChiSquared(object):
-    def __init__(self, x_data: ndarray, y_data: ndarray,
-                 e_data: ndarray, func: Callable):
-        """
-        A chi^2 cost function class for use with gofit
-        :param x_data: x data that fitted against
-        :param y_data: y data that fitted against
-        :param e_data: e data that fitted against
-        :param func: the fitting function used
-        """
-        self._x_data = x_data
-        self._y_data = y_data
-        self._e_data = e_data
-        self._func = func
-
-    def __call__(self, params: ndarray) -> float:
-        """
-        Calls the evaluation of the cost function
-        :param params: the fit parameters
-        :return the cost function evaluation
-        """
-        fit = self._func(self._x_data, *params)
-        return (fit - self._y_data)**2 / self._e_data**2
-
-
-class GoFitEngine(FitEngine):
-    """
-    A gofit multistart fit engine.
-    This will use gofit's multistart to
-    fit data.
-    """
-
-    def __init__(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
-                 lower: ndarray, upper: ndarray, samples: int = 10,
-                 max_iterations: int = 220000):
-        """
-        Creates the scipy curve fit engine class
-        Stores useful information about each fit
-        :param name: name of the fit engine
-        :param x_data: original x data (can fit to an interpolation)
-        :param y_data: original y data (can fit to an interpolation)
-        :param e_data: original e data (can fit to an interpolation)
-        :param lower: the lower bounds for the fit parameters
-        :param upper: the upper bounds for the fit parameters
-        :param samples: the number of samples to use in multistart
-        :param max_iterations: the maximum number of iterations for the fit
-        """
-        super().__init__("gofit", x_data, y_data, e_data)
-        # extra parameters
-        self.set_bounds_and_N_params(lower, upper)
-        self._max_iterations = max_iterations
-        self._samples = samples
-
-    def set_bounds_and_N_params(self, lower: ndarray, upper: ndarray) -> None:
-        """
-        Sets the current bounds and number of parameters for the fit function.
-        If the functional form changes this method will need to be called
-        with updated values.
-        :param lower: the lower bound for the function parameters
-        :param upper: the upper bound for the function parameters
-        """
-        # validate
-        if len(upper) != len(lower):
-            raise ValueError(f"The lower {lower} and "
-                             f"upper {upper} bounds must "
-                             "be the same length")
-        self._lower = lower
-        self._upper = upper
-        self._N_params = len(upper)
-
-    def _do_fit(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
-                func: Callable) -> ndarray:
-        """
-        Calls gofit multistart
-        :param x_data: the x data to fit
-        :param y_data: the y data to fit
-        :param e_data: the error data to fit
-        :param func: the fitting function
-        :return the fit parameters
-        """
-        cost_function = ChiSquared(x_data, y_data, e_data, func)
-
-        data_length = len(x_data)
-
-        params, _ = multistart(data_length, self._N_params,
-                               self._lower, self._upper,
-                               cost_function, samples=self._samples,
-                               maxit=self._max_iterations)
-
-        return params
+from gofit import multistart
+from numpy import ndarray
+from typing import Callable
+from quickBayes.fitting.fit_engine import FitEngine
+
+
+"""
+This file contains all of the code needed for a gofit
+engine, because of the way gofit works we need to provide
+a cost function. However, when the cost function is called
+by gofit it is not provided with the original data. Hence,
+we need to construct a cost function class first that has
+the data as a member variable.
+"""
+
+
+class ChiSquared(object):
+    def __init__(self, x_data: ndarray, y_data: ndarray,
+                 e_data: ndarray, func: Callable):
+        """
+        A chi^2 cost function class for use with gofit
+        :param x_data: x data that fitted against
+        :param y_data: y data that fitted against
+        :param e_data: e data that fitted against
+        :param func: the fitting function used
+        """
+        self._x_data = x_data
+        self._y_data = y_data
+        self._e_data = e_data
+        self._func = func
+
+    def __call__(self, params: ndarray) -> float:
+        """
+        Calls the evaluation of the cost function
+        :param params: the fit parameters
+        :return the cost function evaluation
+        """
+        fit = self._func(self._x_data, *params)
+        return (fit - self._y_data)**2 / self._e_data**2
+
+
+class GoFitEngine(FitEngine):
+    """
+    A gofit multistart fit engine.
+    This will use gofit's multistart to
+    fit data.
+    """
+
+    def __init__(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
+                 lower: ndarray, upper: ndarray, samples: int = 10,
+                 max_iterations: int = 220000):
+        """
+        Creates the scipy curve fit engine class
+        Stores useful information about each fit
+        :param name: name of the fit engine
+        :param x_data: original x data (can fit to an interpolation)
+        :param y_data: original y data (can fit to an interpolation)
+        :param e_data: original e data (can fit to an interpolation)
+        :param lower: the lower bounds for the fit parameters
+        :param upper: the upper bounds for the fit parameters
+        :param samples: the number of samples to use in multistart
+        :param max_iterations: the maximum number of iterations for the fit
+        """
+        super().__init__("gofit", x_data, y_data, e_data)
+        # extra parameters
+        self.set_bounds_and_N_params(lower, upper)
+        self._max_iterations = max_iterations
+        self._samples = samples
+
+    def set_bounds_and_N_params(self, lower: ndarray, upper: ndarray) -> None:
+        """
+        Sets the current bounds and number of parameters for the fit function.
+        If the functional form changes this method will need to be called
+        with updated values.
+        :param lower: the lower bound for the function parameters
+        :param upper: the upper bound for the function parameters
+        """
+        # validate
+        if len(upper) != len(lower):
+            raise ValueError(f"The lower {lower} and "
+                             f"upper {upper} bounds must "
+                             "be the same length")
+        self._lower = lower
+        self._upper = upper
+        self._N_params = len(upper)
+
+    def _do_fit(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
+                func: Callable) -> ndarray:
+        """
+        Calls gofit multistart
+        :param x_data: the x data to fit
+        :param y_data: the y data to fit
+        :param e_data: the error data to fit
+        :param func: the fitting function
+        :return the fit parameters
+        """
+        cost_function = ChiSquared(x_data, y_data, e_data, func)
+
+        data_length = len(x_data)
+
+        params, _ = multistart(data_length, self._N_params,
+                               self._lower, self._upper,
+                               cost_function, samples=self._samples,
+                               maxit=self._max_iterations)
+
+        return params
```

## quickBayes/fit_engines/scipy_fit_engine.py

```diff
@@ -1,86 +1,83 @@
-from scipy.optimize import curve_fit
-from numpy import ndarray
-from typing import Callable
-from quickBayes.fitting.fit_engine import FitEngine
-
-
-class ScipyFitEngine(FitEngine):
-    """
-    A scipy curve fit fit engine.
-    This will use scipy's curve fit to
-    fit data.
-    """
-
-    def __init__(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
-                 lower: ndarray, upper: ndarray, guess: ndarray,
-                 max_iterations: int = 220000):
-        """
-        Creates the scipy curve fit engine class
-        Stores useful information about each fit
-        :param name: name of the fit engine
-        :param x_data: original x data (can fit to an interpolation)
-        :param y_data: original y data (can fit to an interpolation)
-        :param e_data: original e data (can fit to an interpolation)
-        :param lower: the lower bounds for the fit parameters
-        :param upper: the upper bounds for the fit parameters
-        :param guess: the initial guess for the fit parameters
-        :param max_iterations: the maximum number of iterations for the fit
-        """
-        super().__init__("scipy", x_data, y_data, e_data)
-        # extra parameters
-        self.set_guess_and_bounds(guess, lower, upper)
-        self._max_iterations = max_iterations
-
-    def set_guess_and_bounds(self, guess: ndarray,
-                             lower: ndarray, upper: ndarray) -> None:
-        """
-        Sets the current guess and bounds for the fit function.
-        If the functional form changes this method will need to be called
-        with updated values.
-        :param guess: the initial guess for the fit function parameters
-        :param lower: the lower bound for the function parameters
-        :param upper: the upper bound for the function parameters
-        """
-        # validate
-        if len(guess) != len(upper) or len(upper) != len(lower):
-            raise ValueError(f"The guess {guess}, lower {lower} and "
-                             f"upper {upper} bounds must "
-                             "be the same length")
-        self._guess = guess
-        self._lower = lower
-        self._upper = upper
-
-    def _do_fit(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
-                func: Callable) -> ndarray:
-        """
-        Calls scipy curve fit
-        :param x_data: the x data to fit
-        :param y_data: the y data to fit
-        :param e_data: the error data to fit
-        :return the fit parameters
-        """
-        print("guess", self._guess)
-        print("bounds", self._lower, self._upper)
-        params, covar = curve_fit(func, x_data, y_data, self._guess,
-                                  sigma=e_data, absolute_sigma=True,
-                                  maxfev=self._max_iterations,
-                                  bounds=(self._lower, self._upper))
-        self._covars.append(covar)
-        print("params", params)
-        return params
-
-    def calculate_covar(self, x_data: ndarray, y_data: ndarray,
-                        e_data: ndarray,
-                        func: Callable, df_by_dp: ndarray,
-                        params: ndarray) -> None:
-        """
-        Calculated the covariance matrix during the fit
-        So do nothing here as we already have the value
-        :param x_data: the x data to fitted against
-        :param y_data: the y data to fitted against
-        :param e_data: the error data to fitted against
-        :param func: the fitting function
-        :param df_by_dp: the derivatives wrt the parameters
-        :param params: the fit parameters
-        """
-        return
+from scipy.optimize import curve_fit
+from numpy import ndarray
+from typing import Callable
+from quickBayes.fitting.fit_engine import FitEngine
+
+
+class ScipyFitEngine(FitEngine):
+    """
+    A scipy curve fit fit engine.
+    This will use scipy's curve fit to
+    fit data.
+    """
+
+    def __init__(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
+                 lower: ndarray, upper: ndarray, guess: ndarray,
+                 max_iterations: int = 220000):
+        """
+        Creates the scipy curve fit engine class
+        Stores useful information about each fit
+        :param name: name of the fit engine
+        :param x_data: original x data (can fit to an interpolation)
+        :param y_data: original y data (can fit to an interpolation)
+        :param e_data: original e data (can fit to an interpolation)
+        :param lower: the lower bounds for the fit parameters
+        :param upper: the upper bounds for the fit parameters
+        :param guess: the initial guess for the fit parameters
+        :param max_iterations: the maximum number of iterations for the fit
+        """
+        super().__init__("scipy", x_data, y_data, e_data)
+        # extra parameters
+        self.set_guess_and_bounds(guess, lower, upper)
+        self._max_iterations = max_iterations
+
+    def set_guess_and_bounds(self, guess: ndarray,
+                             lower: ndarray, upper: ndarray) -> None:
+        """
+        Sets the current guess and bounds for the fit function.
+        If the functional form changes this method will need to be called
+        with updated values.
+        :param guess: the initial guess for the fit function parameters
+        :param lower: the lower bound for the function parameters
+        :param upper: the upper bound for the function parameters
+        """
+        # validate
+        if len(guess) != len(upper) or len(upper) != len(lower):
+            raise ValueError(f"The guess {guess}, lower {lower} and "
+                             f"upper {upper} bounds must "
+                             "be the same length")
+        self._guess = guess
+        self._lower = lower
+        self._upper = upper
+
+    def _do_fit(self, x_data: ndarray, y_data: ndarray, e_data: ndarray,
+                func: Callable) -> ndarray:
+        """
+        Calls scipy curve fit
+        :param x_data: the x data to fit
+        :param y_data: the y data to fit
+        :param e_data: the error data to fit
+        :return the fit parameters
+        """
+        params, covar = curve_fit(func, x_data, y_data, self._guess,
+                                  sigma=e_data, absolute_sigma=True,
+                                  maxfev=self._max_iterations,
+                                  bounds=(self._lower, self._upper))
+        self._covars.append(covar)
+        return params
+
+    def calculate_covar(self, x_data: ndarray, y_data: ndarray,
+                        e_data: ndarray,
+                        func: Callable, df_by_dp: ndarray,
+                        params: ndarray) -> None:
+        """
+        Calculated the covariance matrix during the fit
+        So do nothing here as we already have the value
+        :param x_data: the x data to fitted against
+        :param y_data: the y data to fitted against
+        :param e_data: the error data to fitted against
+        :param func: the fitting function
+        :param df_by_dp: the derivatives wrt the parameters
+        :param params: the fit parameters
+        """
+        return
```

## quickBayes/fit_functions/BG.py

 * *Ordering differences only*

```diff
@@ -1,140 +1,140 @@
-from quickBayes.functions.base import BaseFitFunction
-from numpy import ndarray
-import numpy as np
-from typing import Dict, List
-
-
-class NoBG(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        :param prefix: prefix for function parameters in report
-        """
-        super().__init__(0, prefix, [], [], [])
-
-    def __call__(self, x: ndarray) -> ndarray:
-        """
-        Implement mo BG.
-        Need to follow the expected
-        form for scipy
-        :param x: x values
-        :return no background
-        """
-        return np.zeros(len(x))
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        return []
-
-    def report(self, report_dict: Dict[str,
-                                       List[float]]) -> Dict[str, List[float]]:
-        """
-        reporting method
-        :param report_dict: dict of parameters
-        :return dict of parameters
-        """
-        return report_dict
-
-
-class FlatBG(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        :param prefix: prefix for function parameters in report
-        """
-        super().__init__(1, prefix, [0.], [-1.], [1.])
-
-    @property
-    def constant(self) -> str:
-        return str(f'{self._prefix}BG constant')
-
-    def __call__(self, x: ndarray, c: float) -> ndarray:
-        """
-        Implement the flat BG.
-        Need to follow the expected
-        form for scipy
-        :param x: x values
-        :param c: constant
-        :return linear background y values
-        """
-        return c*np.ones(len(x))
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        return [self._read_report(report_dict, self.constant, index)]
-
-    def report(self, report_dict: Dict[str, List[float]],
-               c: float) -> Dict[str, List[float]]:
-        """
-        reporting method
-        :param report_dict: dict of parameters
-        :param c: constant
-        :return dict of parameters, including BG
-        """
-        report_dict = self._add_to_report(self.constant,
-                                          c, report_dict)
-        return report_dict
-
-
-class LinearBG(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        :param prefix: prefix for function parameters in report
-        """
-        super().__init__(2, prefix, [0., 0.], [-1., -1.], [1., 1.])
-
-    @property
-    def constant(self) -> str:
-        return str(f'{self._prefix}BG constant')
-
-    @property
-    def grad(self) -> str:
-        return str(f'{self._prefix}BG gradient')
-
-    def __call__(self, x: ndarray, m: float, c: float) -> ndarray:
-        """
-        Implement the Linear BG.
-        Need to follow the expected
-        form for scipy
-        :param x: x values
-        :param m: gradient
-        :param c: constant
-        :return linear background y values
-        """
-        return m*x + c
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        return [self._read_report(report_dict, self.grad, index),
-                self._read_report(report_dict, self.constant, index)]
-
-    def report(self, report_dict: Dict[str, List[float]],
-               m: float, c: float) -> Dict[str, List[float]]:
-        """
-        reporting method
-        :param report_dict: dict of parameters
-        :param m: gradient
-        :param c: constant
-        :return dict of parameters, including BG
-        """
-        report_dict = self._add_to_report(self.grad,
-                                          m, report_dict)
-        report_dict = self._add_to_report(self.constant,
-                                          c, report_dict)
-        return report_dict
+from quickBayes.functions.base import BaseFitFunction
+from numpy import ndarray
+import numpy as np
+from typing import Dict, List
+
+
+class NoBG(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        :param prefix: prefix for function parameters in report
+        """
+        super().__init__(0, prefix, [], [], [])
+
+    def __call__(self, x: ndarray) -> ndarray:
+        """
+        Implement mo BG.
+        Need to follow the expected
+        form for scipy
+        :param x: x values
+        :return no background
+        """
+        return np.zeros(len(x))
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        return []
+
+    def report(self, report_dict: Dict[str,
+                                       List[float]]) -> Dict[str, List[float]]:
+        """
+        reporting method
+        :param report_dict: dict of parameters
+        :return dict of parameters
+        """
+        return report_dict
+
+
+class FlatBG(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        :param prefix: prefix for function parameters in report
+        """
+        super().__init__(1, prefix, [0.], [-1.], [1.])
+
+    @property
+    def constant(self) -> str:
+        return str(f'{self._prefix}BG constant')
+
+    def __call__(self, x: ndarray, c: float) -> ndarray:
+        """
+        Implement the flat BG.
+        Need to follow the expected
+        form for scipy
+        :param x: x values
+        :param c: constant
+        :return linear background y values
+        """
+        return c*np.ones(len(x))
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        return [self._read_report(report_dict, self.constant, index)]
+
+    def report(self, report_dict: Dict[str, List[float]],
+               c: float) -> Dict[str, List[float]]:
+        """
+        reporting method
+        :param report_dict: dict of parameters
+        :param c: constant
+        :return dict of parameters, including BG
+        """
+        report_dict = self._add_to_report(self.constant,
+                                          c, report_dict)
+        return report_dict
+
+
+class LinearBG(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        :param prefix: prefix for function parameters in report
+        """
+        super().__init__(2, prefix, [0., 0.], [-1., -1.], [1., 1.])
+
+    @property
+    def constant(self) -> str:
+        return str(f'{self._prefix}BG constant')
+
+    @property
+    def grad(self) -> str:
+        return str(f'{self._prefix}BG gradient')
+
+    def __call__(self, x: ndarray, m: float, c: float) -> ndarray:
+        """
+        Implement the Linear BG.
+        Need to follow the expected
+        form for scipy
+        :param x: x values
+        :param m: gradient
+        :param c: constant
+        :return linear background y values
+        """
+        return m*x + c
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        return [self._read_report(report_dict, self.grad, index),
+                self._read_report(report_dict, self.constant, index)]
+
+    def report(self, report_dict: Dict[str, List[float]],
+               m: float, c: float) -> Dict[str, List[float]]:
+        """
+        reporting method
+        :param report_dict: dict of parameters
+        :param m: gradient
+        :param c: constant
+        :return dict of parameters, including BG
+        """
+        report_dict = self._add_to_report(self.grad,
+                                          m, report_dict)
+        report_dict = self._add_to_report(self.constant,
+                                          c, report_dict)
+        return report_dict
```

## quickBayes/fit_functions/base.py

 * *Ordering differences only*

```diff
@@ -1,188 +1,188 @@
-from typing import Dict, List
-from abc import ABC, abstractmethod
-from numpy import ndarray
-
-
-"""
-There are no direct tests for this class.
-This is because all of the functionality
-is tested by the classes that inherit
-from it
-"""
-
-
-class BaseFitFunction(ABC):
-    """
-    A basic class outline for fit functions
-    """
-    def __init__(self, N_params: int, prefix: str, guess: List[float],
-                 lower: List[float], upper: List[float]):
-        """
-        Base class for fit function
-        :param N_params: number of parameters in function
-        :param prefix: prefix for parameters when reporting
-        :param guess: the default guess values for the parameters
-        :param lower: the default lower limits for the parameters
-        :param upper: the default upper limits for the parameters
-        """
-        self._N_params = N_params
-        self._prefix = prefix
-        self.set_guess(guess)
-        self.set_bounds(lower, upper)
-        return
-
-    def update_prefix(self, new: str) -> None:
-        """
-        Updates the begining of the prefix (before ":")
-        Assume there are only 1 or 0 instances of ":"
-        :param new: the new text to go before the ":"
-        """
-        if ":" not in self._prefix:
-            self._prefix = new + self._prefix
-        else:
-            tmp = self._prefix.split(":")
-            self._prefix = new + tmp[1]
-
-    def add_to_prefix(self, to_add: str) -> None:
-        """
-        Used to update the prefix
-        :param to_add: the name to insert
-        """
-        tmp = self._prefix.split('.')
-        name = ''
-        for j in range(len(tmp)-1):
-            name += tmp[j] + '.'
-        name += to_add + tmp[-1] + '.'
-        self._prefix = name
-
-    @property
-    def N_params(self) -> int:
-        """
-        :return the number of parameters in function
-        """
-        return self._N_params
-
-    @staticmethod
-    def _add_to_report(name: str, value: float,
-                       report_dict:
-                       Dict[str, List[float]]) -> Dict[str, List[float]]:
-        """
-        Method for adding parameters to dict of results.
-        If the param is present it will append the list
-        :param name: name of the parameter
-        :param value: the value for the parameter
-        :param report_dict: the results dict
-        :return the modified results dict
-        """
-        if name not in report_dict.keys():
-            report_dict[name] = [value]
-        else:
-            report_dict[name].append(value)
-        return report_dict
-
-    def _read_report(self, report_dict: Dict[str, List[float]],
-                     name: str, index: int) -> float:
-        if name not in report_dict.keys():
-            raise ValueError(f"parameter {name} not in results")
-        tmp = report_dict[name]
-        if index >= len(tmp):
-            raise ValueError("Not enough parameters for this index")
-        return tmp[index]
-
-    @abstractmethod
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def report(self, results: Dict[str, List[float]],
-               *kwargs: float) -> Dict[str, List[float]]:
-        """
-        This method is for accumalating the parameters
-        into a single dict. This is useful for multiple
-        calls where the aim is to get the results for
-        different conditions (e.g. Q value).
-        :param results: the dict of results
-        :param kwargs: the parameters for the function
-        :return the updated results dict
-        """
-        raise NotImplementedError()
-
-    def report_errors(self, results: Dict[str, List[float]],
-                      errors: List[float],
-                      params: List[float]) -> Dict[str, List[float]]:
-        """
-        This method is for accumalating the parameter errors
-        into a single dict. This is useful for multiple
-        calls where the aim is to get the results for
-        different conditions (e.g. Q value).
-        :param results: the dict of parameter errors
-        :param errors: the parameter errors
-        :param params: the parameter values
-        :return the updated results dict
-        """
-        return self.report(results, *errors)
-
-    @abstractmethod
-    def __call__(self, x: ndarray,
-                 *kwargs: float) -> ndarray:
-        """
-        Implement the function call.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for function evaluation
-        :param kwargs: parameters for the function
-        :return y values for function evaluation
-        """
-        raise NotImplementedError()
-
-    def _check_length(self, values: List[float], label: str) -> None:
-        """
-        Runs a check that the input has a value for each of the
-        parameters in the function.
-        :param values: the input values to check
-        :param label: a string to signify what is being checked
-        """
-        if len(values) != self.N_params:
-            raise ValueError(f"The number of {label} parameters {len(values)} "
-                             "do not match the expected "
-                             f" number {self._N_params}.")
-
-    def set_guess(self, guess: List[float]) -> None:
-        """
-        Method to set the guess values
-        :param guess: the new guess values
-        """
-        self._check_length(guess, "guess")
-        self._guess = guess
-
-    def get_guess(self) -> List[float]:
-        """
-        Generates a guess for the fit values
-        :return a list of guesses
-        """
-        return self._guess
-
-    def set_bounds(self, lower: List[float], upper: List[float]) -> None:
-        """
-        Set the lower and upper bounds for the function
-        :param lower: the lower limits for the parameters
-        :param upper: the upper limits for the parameters
-        """
-        self._check_length(lower, "lower")
-        self._check_length(upper, "upper")
-        self._lower = lower
-        self._upper = upper
-
-    def get_bounds(self) -> (List[float], List[float]):
-        """
-        Gets the bounds for the fit
-        :retun lists of the lower and upper bounds
-        """
-        return self._lower, self._upper
+from typing import Dict, List
+from abc import ABC, abstractmethod
+from numpy import ndarray
+
+
+"""
+There are no direct tests for this class.
+This is because all of the functionality
+is tested by the classes that inherit
+from it
+"""
+
+
+class BaseFitFunction(ABC):
+    """
+    A basic class outline for fit functions
+    """
+    def __init__(self, N_params: int, prefix: str, guess: List[float],
+                 lower: List[float], upper: List[float]):
+        """
+        Base class for fit function
+        :param N_params: number of parameters in function
+        :param prefix: prefix for parameters when reporting
+        :param guess: the default guess values for the parameters
+        :param lower: the default lower limits for the parameters
+        :param upper: the default upper limits for the parameters
+        """
+        self._N_params = N_params
+        self._prefix = prefix
+        self.set_guess(guess)
+        self.set_bounds(lower, upper)
+        return
+
+    def update_prefix(self, new: str) -> None:
+        """
+        Updates the begining of the prefix (before ":")
+        Assume there are only 1 or 0 instances of ":"
+        :param new: the new text to go before the ":"
+        """
+        if ":" not in self._prefix:
+            self._prefix = new + self._prefix
+        else:
+            tmp = self._prefix.split(":")
+            self._prefix = new + tmp[1]
+
+    def add_to_prefix(self, to_add: str) -> None:
+        """
+        Used to update the prefix
+        :param to_add: the name to insert
+        """
+        tmp = self._prefix.split('.')
+        name = ''
+        for j in range(len(tmp)-1):
+            name += tmp[j] + '.'
+        name += to_add + tmp[-1] + '.'
+        self._prefix = name
+
+    @property
+    def N_params(self) -> int:
+        """
+        :return the number of parameters in function
+        """
+        return self._N_params
+
+    @staticmethod
+    def _add_to_report(name: str, value: float,
+                       report_dict:
+                       Dict[str, List[float]]) -> Dict[str, List[float]]:
+        """
+        Method for adding parameters to dict of results.
+        If the param is present it will append the list
+        :param name: name of the parameter
+        :param value: the value for the parameter
+        :param report_dict: the results dict
+        :return the modified results dict
+        """
+        if name not in report_dict.keys():
+            report_dict[name] = [value]
+        else:
+            report_dict[name].append(value)
+        return report_dict
+
+    def _read_report(self, report_dict: Dict[str, List[float]],
+                     name: str, index: int) -> float:
+        if name not in report_dict.keys():
+            raise ValueError(f"parameter {name} not in results")
+        tmp = report_dict[name]
+        if index >= len(tmp):
+            raise ValueError("Not enough parameters for this index")
+        return tmp[index]
+
+    @abstractmethod
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def report(self, results: Dict[str, List[float]],
+               *kwargs: float) -> Dict[str, List[float]]:
+        """
+        This method is for accumalating the parameters
+        into a single dict. This is useful for multiple
+        calls where the aim is to get the results for
+        different conditions (e.g. Q value).
+        :param results: the dict of results
+        :param kwargs: the parameters for the function
+        :return the updated results dict
+        """
+        raise NotImplementedError()
+
+    def report_errors(self, results: Dict[str, List[float]],
+                      errors: List[float],
+                      params: List[float]) -> Dict[str, List[float]]:
+        """
+        This method is for accumalating the parameter errors
+        into a single dict. This is useful for multiple
+        calls where the aim is to get the results for
+        different conditions (e.g. Q value).
+        :param results: the dict of parameter errors
+        :param errors: the parameter errors
+        :param params: the parameter values
+        :return the updated results dict
+        """
+        return self.report(results, *errors)
+
+    @abstractmethod
+    def __call__(self, x: ndarray,
+                 *kwargs: float) -> ndarray:
+        """
+        Implement the function call.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for function evaluation
+        :param kwargs: parameters for the function
+        :return y values for function evaluation
+        """
+        raise NotImplementedError()
+
+    def _check_length(self, values: List[float], label: str) -> None:
+        """
+        Runs a check that the input has a value for each of the
+        parameters in the function.
+        :param values: the input values to check
+        :param label: a string to signify what is being checked
+        """
+        if len(values) != self.N_params:
+            raise ValueError(f"The number of {label} parameters {len(values)} "
+                             "do not match the expected "
+                             f" number {self._N_params}.")
+
+    def set_guess(self, guess: List[float]) -> None:
+        """
+        Method to set the guess values
+        :param guess: the new guess values
+        """
+        self._check_length(guess, "guess")
+        self._guess = guess
+
+    def get_guess(self) -> List[float]:
+        """
+        Generates a guess for the fit values
+        :return a list of guesses
+        """
+        return self._guess
+
+    def set_bounds(self, lower: List[float], upper: List[float]) -> None:
+        """
+        Set the lower and upper bounds for the function
+        :param lower: the lower limits for the parameters
+        :param upper: the upper limits for the parameters
+        """
+        self._check_length(lower, "lower")
+        self._check_length(upper, "upper")
+        self._lower = lower
+        self._upper = upper
+
+    def get_bounds(self) -> (List[float], List[float]):
+        """
+        Gets the bounds for the fit
+        :retun lists of the lower and upper bounds
+        """
+        return self._lower, self._upper
```

## quickBayes/fit_functions/composite_fun.py

 * *Ordering differences only*

```diff
@@ -1,141 +1,141 @@
-from quickBayes.functions.base import BaseFitFunction
-from numpy import ndarray
-import numpy as np
-from typing import Dict, List
-
-
-class CompositeFunction(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        Defines a function to wrap a sum of functions
-        :param prefix: the prefix for parameters
-        """
-        self._funcs = []
-        super().__init__(0, prefix, [], [], [])
-
-    def add_function(self, func: BaseFitFunction) -> None:
-        """
-        Adds a function to the sum
-        :param func: the function to add
-        """
-        func.add_to_prefix(f'f{len(self._funcs)+1}')
-        self._funcs.append(func)
-        self._N_params += func.N_params
-
-    def update_prefix(self, new: str) -> None:
-        """
-        Update the begining of the prefixes
-        :param new: the new part of the prefix
-        """
-        for j in range(len(self._funcs)):
-            self._funcs[j].update_prefix(new)
-
-    def split_args(self, args: List[float]) -> List[List[float]]:
-        """
-        Split the single args list into a list of lists
-        for use with individual functions
-        :param args: list of all the parameters
-        :return list of the parameters for each individual function
-        """
-        j = 0
-        split = []
-        for func in self._funcs:
-            N = func.N_params
-            split.append(list(args[j:j+N]))
-            j += N
-        return split
-
-    def __call__(self, x: ndarray, *args: float) -> ndarray:
-        """
-        Implement a sum of functions.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for function evaluation
-        :param args: parameters for functions
-        :return y values for evaluated function
-        """
-        if len(self._funcs) == 0:
-            return np.zeros(len(x))
-        elif len(args) != self.N_params:
-            raise ValueError(f"Expected {self.N_params} args, got {len(args)}")
-
-        fun_args = self.split_args(args)
-        result = np.zeros(len(x))
-        for j, func in enumerate(self._funcs):
-            result += func(x, *fun_args[j])
-        return result
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        params = []
-        for fun in self._funcs:
-            params += fun.read_from_report(report_dict, index)
-        return params
-
-    def report(self, report_dict: Dict[str, List[float]],
-               *args: float) -> Dict[str, List[float]]:
-        """
-        report the results
-        :param report_dic: dict of results
-        :param args: parameters for functions
-        :return updated dict of results
-        """
-        if len(args) != self.N_params:
-            raise ValueError(f"Expected {self.N_params} args, got {len(args)}")
-
-        fun_args = self.split_args(args)
-        for j, func in enumerate(self._funcs):
-            report_dict = func.report(report_dict, *fun_args[j])
-        return report_dict
-
-    def get_guess(self) -> List[float]:
-        """
-        Get the starting guess for a fit function
-        :return the initial guess
-        """
-        guess = []
-        for func in self._funcs:
-            guess += func.get_guess()
-        return guess
-
-    def get_bounds(self) -> (List[float], List[float]):
-        """
-        Get the fitting bounds
-        :return lists for lower and upper bounds
-        """
-        upper, lower = [], []
-        for func in self._funcs:
-            bounds = func.get_bounds()
-            lower += bounds[0]
-            upper += bounds[1]
-        return lower, upper
-
-    def set_guess(self, guess: List[float], index: int = -1):
-        """
-        Allows the user to set the guess values for a
-        specific function in the composite.
-        :param guess: the new guess values
-        :param index: the index of the function to update
-        """
-        if index > len(self._funcs) or len(self._funcs) == 0:
-            return
-        self._funcs[index].set_guess(guess)
-
-    def set_bounds(self, lower: List[float],
-                   upper: List[float], index: int = -1):
-        """
-        Allows the user to set the guess values for a
-        specific function in the composite.
-        :param lower: the new lower values
-        :param upper: the new upper values
-        :param index: the index of the function to update
-        """
-        if index > len(self._funcs) or len(self._funcs) == 0:
-            return
-        self._funcs[index].set_bounds(lower, upper)
+from quickBayes.functions.base import BaseFitFunction
+from numpy import ndarray
+import numpy as np
+from typing import Dict, List
+
+
+class CompositeFunction(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        Defines a function to wrap a sum of functions
+        :param prefix: the prefix for parameters
+        """
+        self._funcs = []
+        super().__init__(0, prefix, [], [], [])
+
+    def add_function(self, func: BaseFitFunction) -> None:
+        """
+        Adds a function to the sum
+        :param func: the function to add
+        """
+        func.add_to_prefix(f'f{len(self._funcs)+1}')
+        self._funcs.append(func)
+        self._N_params += func.N_params
+
+    def update_prefix(self, new: str) -> None:
+        """
+        Update the begining of the prefixes
+        :param new: the new part of the prefix
+        """
+        for j in range(len(self._funcs)):
+            self._funcs[j].update_prefix(new)
+
+    def split_args(self, args: List[float]) -> List[List[float]]:
+        """
+        Split the single args list into a list of lists
+        for use with individual functions
+        :param args: list of all the parameters
+        :return list of the parameters for each individual function
+        """
+        j = 0
+        split = []
+        for func in self._funcs:
+            N = func.N_params
+            split.append(list(args[j:j+N]))
+            j += N
+        return split
+
+    def __call__(self, x: ndarray, *args: float) -> ndarray:
+        """
+        Implement a sum of functions.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for function evaluation
+        :param args: parameters for functions
+        :return y values for evaluated function
+        """
+        if len(self._funcs) == 0:
+            return np.zeros(len(x))
+        elif len(args) != self.N_params:
+            raise ValueError(f"Expected {self.N_params} args, got {len(args)}")
+
+        fun_args = self.split_args(args)
+        result = np.zeros(len(x))
+        for j, func in enumerate(self._funcs):
+            result += func(x, *fun_args[j])
+        return result
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        params = []
+        for fun in self._funcs:
+            params += fun.read_from_report(report_dict, index)
+        return params
+
+    def report(self, report_dict: Dict[str, List[float]],
+               *args: float) -> Dict[str, List[float]]:
+        """
+        report the results
+        :param report_dic: dict of results
+        :param args: parameters for functions
+        :return updated dict of results
+        """
+        if len(args) != self.N_params:
+            raise ValueError(f"Expected {self.N_params} args, got {len(args)}")
+
+        fun_args = self.split_args(args)
+        for j, func in enumerate(self._funcs):
+            report_dict = func.report(report_dict, *fun_args[j])
+        return report_dict
+
+    def get_guess(self) -> List[float]:
+        """
+        Get the starting guess for a fit function
+        :return the initial guess
+        """
+        guess = []
+        for func in self._funcs:
+            guess += func.get_guess()
+        return guess
+
+    def get_bounds(self) -> (List[float], List[float]):
+        """
+        Get the fitting bounds
+        :return lists for lower and upper bounds
+        """
+        upper, lower = [], []
+        for func in self._funcs:
+            bounds = func.get_bounds()
+            lower += bounds[0]
+            upper += bounds[1]
+        return lower, upper
+
+    def set_guess(self, guess: List[float], index: int = -1):
+        """
+        Allows the user to set the guess values for a
+        specific function in the composite.
+        :param guess: the new guess values
+        :param index: the index of the function to update
+        """
+        if index > len(self._funcs) or len(self._funcs) == 0:
+            return
+        self._funcs[index].set_guess(guess)
+
+    def set_bounds(self, lower: List[float],
+                   upper: List[float], index: int = -1):
+        """
+        Allows the user to set the guess values for a
+        specific function in the composite.
+        :param lower: the new lower values
+        :param upper: the new upper values
+        :param index: the index of the function to update
+        """
+        if index > len(self._funcs) or len(self._funcs) == 0:
+            return
+        self._funcs[index].set_bounds(lower, upper)
```

## quickBayes/fit_functions/conv_with_res.py

 * *Ordering differences only*

```diff
@@ -1,72 +1,72 @@
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.functions.composite import CompositeFunction
-from quickBayes.utils.crop_data import crop
-from quickBayes.utils.spline import spline
-from numpy import ndarray
-from scipy import signal
-import copy
-
-
-class ConvolutionWithResolution(CompositeFunction):
-    def __init__(self, res_x: ndarray, res_y: ndarray,
-                 start_x: float, end_x: float, prefix: str = ''):
-        """
-        Creates a convolution with a tabulated resolution function.
-        Can add functions to be convoluted with the resolution.
-        :param res_x: x values for resolution function
-        :param res_y: y values for resolution function
-        :param start_x: the start of the fitting range
-        :param end_x: the end of the fitting range
-        :param prefix: prefix for fitting function
-        """
-        super().__init__(prefix)
-        self._rx = copy.deepcopy(res_x)
-        self._ry = copy.deepcopy(res_y)
-        self._rx, self._ry, _ = crop(self._rx, self._ry, None, start_x, end_x)
-        # this is to normalise the kernal to get correct amplitudes
-        self._ry /= sum(self._ry)
-
-    def update_x_range(self, new_x: ndarray) -> None:
-        """
-        The sampling of the resolution function can make
-        a big difference to the quality of the function.
-        This is because of sampling issues. To solve
-        this problem a user can update the x (and y)
-        ranges using this method.
-        :param new_x: the new x range (y is interpolated)
-        """
-        self._ry = spline(self._rx, self._ry, new_x)
-        self._ry /= sum(self._ry)
-        self._rx = new_x
-
-    def update_prefix(self, new: str) -> None:
-        """
-        Update the begining of the prefixes
-        :param new: the new part of the prefix
-        """
-        for j in range(len(self._funcs)):
-            self._funcs[j].update_prefix(new)
-
-    def add_function(self, func: BaseFitFunction) -> None:
-        """
-        Adds a function to the convolution
-        :param func: the function to add
-        """
-        # add prefix for convolution
-        if self._prefix == '':
-            self._prefix = 'f1'
-        func.add_to_prefix(self._prefix)
-        super().add_function(func)
-
-    def __call__(self, x: ndarray, *args: float) -> ndarray:
-        """
-        Implement a convolution with a resolution function.
-        Need to follow the expected
-        form for scipy
-        :param x: x range to calculate function over
-        :param args: the arguments for the convolution function
-        :return y values for the convolution
-        """
-        result = super().__call__(x, *args)
-        # assume rx and x are the same
-        return signal.convolve(result, self._ry, mode='same')
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.functions.composite import CompositeFunction
+from quickBayes.utils.crop_data import crop
+from quickBayes.utils.spline import spline
+from numpy import ndarray
+from scipy import signal
+import copy
+
+
+class ConvolutionWithResolution(CompositeFunction):
+    def __init__(self, res_x: ndarray, res_y: ndarray,
+                 start_x: float, end_x: float, prefix: str = ''):
+        """
+        Creates a convolution with a tabulated resolution function.
+        Can add functions to be convoluted with the resolution.
+        :param res_x: x values for resolution function
+        :param res_y: y values for resolution function
+        :param start_x: the start of the fitting range
+        :param end_x: the end of the fitting range
+        :param prefix: prefix for fitting function
+        """
+        super().__init__(prefix)
+        self._rx = copy.deepcopy(res_x)
+        self._ry = copy.deepcopy(res_y)
+        self._rx, self._ry, _ = crop(self._rx, self._ry, None, start_x, end_x)
+        # this is to normalise the kernal to get correct amplitudes
+        self._ry /= sum(self._ry)
+
+    def update_x_range(self, new_x: ndarray) -> None:
+        """
+        The sampling of the resolution function can make
+        a big difference to the quality of the function.
+        This is because of sampling issues. To solve
+        this problem a user can update the x (and y)
+        ranges using this method.
+        :param new_x: the new x range (y is interpolated)
+        """
+        self._ry = spline(self._rx, self._ry, new_x)
+        self._ry /= sum(self._ry)
+        self._rx = new_x
+
+    def update_prefix(self, new: str) -> None:
+        """
+        Update the begining of the prefixes
+        :param new: the new part of the prefix
+        """
+        for j in range(len(self._funcs)):
+            self._funcs[j].update_prefix(new)
+
+    def add_function(self, func: BaseFitFunction) -> None:
+        """
+        Adds a function to the convolution
+        :param func: the function to add
+        """
+        # add prefix for convolution
+        if self._prefix == '':
+            self._prefix = 'f1'
+        func.add_to_prefix(self._prefix)
+        super().add_function(func)
+
+    def __call__(self, x: ndarray, *args: float) -> ndarray:
+        """
+        Implement a convolution with a resolution function.
+        Need to follow the expected
+        form for scipy
+        :param x: x range to calculate function over
+        :param args: the arguments for the convolution function
+        :return y values for the convolution
+        """
+        result = super().__call__(x, *args)
+        # assume rx and x are the same
+        return signal.convolve(result, self._ry, mode='same')
```

## quickBayes/fit_functions/delta_function.py

 * *Ordering differences only*

```diff
@@ -1,79 +1,79 @@
-from quickBayes.functions.base import BaseFitFunction
-from numpy import ndarray
-import numpy as np
-from typing import Dict, List
-
-
-class Delta(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        Strictly this is not a true delta function.
-        Instead it is a top hat function, which
-        in the limit of binwidth-> 0 is a delta
-        :param prefix: prefix for the parameters
-        """
-        super().__init__(2, prefix, [1., 0.], [0., -1], [np.inf, 1.])
-
-    @property
-    def amplitude(self) -> str:
-        """
-        :return the string for the amplitude
-        """
-        return str(f"{self._prefix}Amplitude")
-
-    @property
-    def centre(self) -> str:
-        """
-        :return the string for peak centre
-        """
-        return str(f"{self._prefix}Centre")
-
-    def __call__(self, x: ndarray, amplitude: float, x0: float) -> ndarray:
-        """
-        Implement the delta/top hat.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for function evaluation
-        :param amplitude: height of the top hat function
-        :param x0: the position of the top hat
-        :return y values for the function evaluation
-        """
-        data = np.zeros(len(x))
-        index = np.searchsorted(x, x0)-1
-
-        # integral should normalise to 1*amplitude
-        # so need to divide by bin width
-        dx = 0.0
-        if index == len(data)-1:
-            dx = x[index] - x[index-1]
-        else:
-            dx = x[index+1] - x[index]
-
-        data[index] = amplitude/dx
-        return data
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        return [self._read_report(report_dict, self.amplitude, index),
-                self._read_report(report_dict, self.centre, index)]
-
-    def report(self, report_dict: Dict[str, List[float]],
-               amplitude: float, x0: float) -> Dict[str, List[float]]:
-        """
-        report the results
-        :param report_dict: dict of results
-        :param amplitude: height of the top hat function
-        :param x0: the position of the top hat
-        :return updated results dict
-        """
-        report_dict = self._add_to_report(self.amplitude,
-                                          amplitude, report_dict)
-        report_dict = self._add_to_report(self.centre,
-                                          x0, report_dict)
-        return report_dict
+from quickBayes.functions.base import BaseFitFunction
+from numpy import ndarray
+import numpy as np
+from typing import Dict, List
+
+
+class Delta(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        Strictly this is not a true delta function.
+        Instead it is a top hat function, which
+        in the limit of binwidth-> 0 is a delta
+        :param prefix: prefix for the parameters
+        """
+        super().__init__(2, prefix, [1., 0.], [0., -1], [np.inf, 1.])
+
+    @property
+    def amplitude(self) -> str:
+        """
+        :return the string for the amplitude
+        """
+        return str(f"{self._prefix}Amplitude")
+
+    @property
+    def centre(self) -> str:
+        """
+        :return the string for peak centre
+        """
+        return str(f"{self._prefix}Centre")
+
+    def __call__(self, x: ndarray, amplitude: float, x0: float) -> ndarray:
+        """
+        Implement the delta/top hat.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for function evaluation
+        :param amplitude: height of the top hat function
+        :param x0: the position of the top hat
+        :return y values for the function evaluation
+        """
+        data = np.zeros(len(x))
+        index = np.searchsorted(x, x0)-1
+
+        # integral should normalise to 1*amplitude
+        # so need to divide by bin width
+        dx = 0.0
+        if index == len(data)-1:
+            dx = x[index] - x[index-1]
+        else:
+            dx = x[index+1] - x[index]
+
+        data[index] = amplitude/dx
+        return data
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        return [self._read_report(report_dict, self.amplitude, index),
+                self._read_report(report_dict, self.centre, index)]
+
+    def report(self, report_dict: Dict[str, List[float]],
+               amplitude: float, x0: float) -> Dict[str, List[float]]:
+        """
+        report the results
+        :param report_dict: dict of results
+        :param amplitude: height of the top hat function
+        :param x0: the position of the top hat
+        :return updated results dict
+        """
+        report_dict = self._add_to_report(self.amplitude,
+                                          amplitude, report_dict)
+        report_dict = self._add_to_report(self.centre,
+                                          x0, report_dict)
+        return report_dict
```

## quickBayes/fit_functions/exp_decay.py

 * *Ordering differences only*

```diff
@@ -1,66 +1,66 @@
-from quickBayes.functions.base import BaseFitFunction
-from numpy import ndarray
-import numpy as np
-from typing import Dict, List
-
-
-class ExpDecay(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        Create an exponential decay function
-        :param prefix: prefix for parameter reporting
-        """
-        super().__init__(2, prefix, [1., 0.1], [0., 0.001], [1., 20.])
-
-    @property
-    def amplitude(self) -> str:
-        """
-        :retrun string for amplitude name
-        """
-        return str(f"{self._prefix}Amplitude")
-
-    @property
-    def decay_rate(self) -> str:
-        """
-        :return string for name of lambda
-        """
-        return str(f"{self._prefix}lambda")
-
-    def __call__(self, x: ndarray, amplitude: float,
-                 decay_rate: float) -> ndarray:
-        """
-        Implement an exponential decay.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for the function evaluation
-        :param amplitude: amplitude of decay
-        :param decay_rate: the lambda value (decay rate)
-        :return y values for the function
-        """
-        return amplitude*np.exp(-decay_rate*x)
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        return [self._read_report(report_dict, self.amplitude, index),
-                self._read_report(report_dict, self.decay_rate, index)]
-
-    def report(self, report_dict: Dict[str, List[float]], a: float,
-               decay_rate: float) -> Dict[str, List[float]]:
-        """
-        Report the results
-        :param report_dict: dict of results
-        :param a: amplitude of exp decay
-        :param decay_rate: the lambda value
-        returns the updated results dict
-        """
-        report_dict = self._add_to_report(self.amplitude,
-                                          a, report_dict)
-        report_dict = self._add_to_report(self.decay_rate,
-                                          decay_rate, report_dict)
-        return report_dict
+from quickBayes.functions.base import BaseFitFunction
+from numpy import ndarray
+import numpy as np
+from typing import Dict, List
+
+
+class ExpDecay(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        Create an exponential decay function
+        :param prefix: prefix for parameter reporting
+        """
+        super().__init__(2, prefix, [1., 0.1], [0., 0.001], [1., 20.])
+
+    @property
+    def amplitude(self) -> str:
+        """
+        :retrun string for amplitude name
+        """
+        return str(f"{self._prefix}Amplitude")
+
+    @property
+    def decay_rate(self) -> str:
+        """
+        :return string for name of lambda
+        """
+        return str(f"{self._prefix}lambda")
+
+    def __call__(self, x: ndarray, amplitude: float,
+                 decay_rate: float) -> ndarray:
+        """
+        Implement an exponential decay.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for the function evaluation
+        :param amplitude: amplitude of decay
+        :param decay_rate: the lambda value (decay rate)
+        :return y values for the function
+        """
+        return amplitude*np.exp(-decay_rate*x)
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        return [self._read_report(report_dict, self.amplitude, index),
+                self._read_report(report_dict, self.decay_rate, index)]
+
+    def report(self, report_dict: Dict[str, List[float]], a: float,
+               decay_rate: float) -> Dict[str, List[float]]:
+        """
+        Report the results
+        :param report_dict: dict of results
+        :param a: amplitude of exp decay
+        :param decay_rate: the lambda value
+        returns the updated results dict
+        """
+        report_dict = self._add_to_report(self.amplitude,
+                                          a, report_dict)
+        report_dict = self._add_to_report(self.decay_rate,
+                                          decay_rate, report_dict)
+        return report_dict
```

## quickBayes/fit_functions/gaussian.py

 * *Ordering differences only*

```diff
@@ -1,80 +1,80 @@
-from quickBayes.functions.base import BaseFitFunction
-from numpy import ndarray, pi
-import numpy as np
-from typing import Dict, List
-
-
-class Gaussian(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        Create a gaussian function
-        :param prefix: prefix for parameter reporting
-        """
-        super().__init__(3, prefix, [1., 0, 0.1],
-                         [0., -1., 0.], [np.inf, 1., np.inf])
-
-    @property
-    def amplitude(self) -> str:
-        """
-        :retrun string for amplitude name
-        """
-        return str(f"{self._prefix}Amplitude")
-
-    @property
-    def mean(self) -> str:
-        """
-        :return string for name of mean
-        """
-        return str(f"{self._prefix}Mean")
-
-    @property
-    def sigma(self) -> str:
-        """
-        :return string for the name of sigma
-        """
-        return str(f"{self._prefix}Sigma")
-
-    def __call__(self, x: ndarray, amplitude: float, x0: float,
-                 sigma: float) -> ndarray:
-        """
-        Implement a gaussian.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for the function evaluation
-        :param amplitude: amplitude of gaussian
-        :param x0: the mean value of the gaussian
-        :param sigma: the sigma value of the gaussian
-        :return y values for the gaussian
-        """
-        pre_factor = amplitude/(sigma*np.sqrt(2.*pi))
-        return pre_factor*np.exp(-pow(x-x0, 2)/(2.*sigma*sigma))
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        return [self._read_report(report_dict, self.amplitude, index),
-                self._read_report(report_dict, self.mean, index),
-                self._read_report(report_dict, self.sigma, index)]
-
-    def report(self, report_dict: Dict[str, List[float]], a: float,
-               x0: float, sigma: float) -> Dict[str, List[float]]:
-        """
-        Report the results
-        :param report_dict: dict of results
-        :param a: amplitude of gaussian
-        :param x0: the mean value of the gaussian
-        :param sigma: the sigma value of the gaussian
-        returns the updated results dict
-        """
-        report_dict = self._add_to_report(self.amplitude,
-                                          a, report_dict)
-        report_dict = self._add_to_report(self.mean,
-                                          x0, report_dict)
-        report_dict = self._add_to_report(self.sigma,
-                                          sigma, report_dict)
-        return report_dict
+from quickBayes.functions.base import BaseFitFunction
+from numpy import ndarray, pi
+import numpy as np
+from typing import Dict, List
+
+
+class Gaussian(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        Create a gaussian function
+        :param prefix: prefix for parameter reporting
+        """
+        super().__init__(3, prefix, [1., 0, 0.1],
+                         [0., -1., 0.], [np.inf, 1., np.inf])
+
+    @property
+    def amplitude(self) -> str:
+        """
+        :retrun string for amplitude name
+        """
+        return str(f"{self._prefix}Amplitude")
+
+    @property
+    def mean(self) -> str:
+        """
+        :return string for name of mean
+        """
+        return str(f"{self._prefix}Mean")
+
+    @property
+    def sigma(self) -> str:
+        """
+        :return string for the name of sigma
+        """
+        return str(f"{self._prefix}Sigma")
+
+    def __call__(self, x: ndarray, amplitude: float, x0: float,
+                 sigma: float) -> ndarray:
+        """
+        Implement a gaussian.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for the function evaluation
+        :param amplitude: amplitude of gaussian
+        :param x0: the mean value of the gaussian
+        :param sigma: the sigma value of the gaussian
+        :return y values for the gaussian
+        """
+        pre_factor = amplitude/(sigma*np.sqrt(2.*pi))
+        return pre_factor*np.exp(-pow(x-x0, 2)/(2.*sigma*sigma))
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        return [self._read_report(report_dict, self.amplitude, index),
+                self._read_report(report_dict, self.mean, index),
+                self._read_report(report_dict, self.sigma, index)]
+
+    def report(self, report_dict: Dict[str, List[float]], a: float,
+               x0: float, sigma: float) -> Dict[str, List[float]]:
+        """
+        Report the results
+        :param report_dict: dict of results
+        :param a: amplitude of gaussian
+        :param x0: the mean value of the gaussian
+        :param sigma: the sigma value of the gaussian
+        returns the updated results dict
+        """
+        report_dict = self._add_to_report(self.amplitude,
+                                          a, report_dict)
+        report_dict = self._add_to_report(self.mean,
+                                          x0, report_dict)
+        report_dict = self._add_to_report(self.sigma,
+                                          sigma, report_dict)
+        return report_dict
```

## quickBayes/fit_functions/lorentz.py

 * *Ordering differences only*

```diff
@@ -1,79 +1,79 @@
-from quickBayes.functions.base import BaseFitFunction
-from numpy import ndarray, pi
-from typing import Dict, List
-
-
-class Lorentzian(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        Create a Lorentzian function
-        :param prefix: the prefix for the parameters
-        """
-        super().__init__(3, prefix, [0.01, 0.0, 0.02],
-                         [0., -1., 1.e-6], [1., 1., 1.])
-
-    @property
-    def amplitude(self) -> str:
-        """
-        :return string for the amplitude
-        """
-        return str(f"{self._prefix}Amplitude")
-
-    @property
-    def centre(self) -> str:
-        """
-        :return the string for the peak centre
-        """
-        return str(f"{self._prefix}Peak Centre")
-
-    @property
-    def Gamma(self) -> str:
-        """
-        :return the string for Gamma
-        """
-        return str(f"{self._prefix}Gamma")
-
-    def __call__(self, x: ndarray, amplitude: float,
-                 x0: float, Gamma: float) -> ndarray:
-        """
-        Implement the Lorentzian.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for function evaluation
-        :param amplitude: amplitude of the lorentzian
-        :param x0: the peak centre
-        :param Gamma: half width at half maxima (HWHM)
-        :return y values for function evaluation
-        """
-        G = Gamma/2.
-        return amplitude*G/(pi*(pow(x-x0, 2)+pow(G, 2)))
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        return [self._read_report(report_dict, self.amplitude, index),
-                self._read_report(report_dict, self.centre, index),
-                self._read_report(report_dict, self.Gamma, index)]
-
-    def report(self, report_dict: Dict[str, List[float]], a: float,
-               x0: float, Gamma: float) -> Dict[str, List[float]]:
-        """
-        report parameters
-        :param report_dic: dict of results
-        :param a: amplitude of the lorentzian
-        :param x0: the peak centre
-        :param Gamma: half width at half maxima (HWHM)
-        :return update results dict
-        """
-        report_dict = self._add_to_report(self.amplitude,
-                                          a, report_dict)
-        report_dict = self._add_to_report(self.centre,
-                                          x0, report_dict)
-        report_dict = self._add_to_report(self.Gamma,
-                                          Gamma, report_dict)
-        return report_dict
+from quickBayes.functions.base import BaseFitFunction
+from numpy import ndarray, pi
+from typing import Dict, List
+
+
+class Lorentzian(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        Create a Lorentzian function
+        :param prefix: the prefix for the parameters
+        """
+        super().__init__(3, prefix, [0.01, 0.0, 0.02],
+                         [0., -1., 1.e-6], [1., 1., 1.])
+
+    @property
+    def amplitude(self) -> str:
+        """
+        :return string for the amplitude
+        """
+        return str(f"{self._prefix}Amplitude")
+
+    @property
+    def centre(self) -> str:
+        """
+        :return the string for the peak centre
+        """
+        return str(f"{self._prefix}Peak Centre")
+
+    @property
+    def Gamma(self) -> str:
+        """
+        :return the string for Gamma
+        """
+        return str(f"{self._prefix}Gamma")
+
+    def __call__(self, x: ndarray, amplitude: float,
+                 x0: float, Gamma: float) -> ndarray:
+        """
+        Implement the Lorentzian.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for function evaluation
+        :param amplitude: amplitude of the lorentzian
+        :param x0: the peak centre
+        :param Gamma: half width at half maxima (HWHM)
+        :return y values for function evaluation
+        """
+        G = Gamma/2.
+        return amplitude*G/(pi*(pow(x-x0, 2)+pow(G, 2)))
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        return [self._read_report(report_dict, self.amplitude, index),
+                self._read_report(report_dict, self.centre, index),
+                self._read_report(report_dict, self.Gamma, index)]
+
+    def report(self, report_dict: Dict[str, List[float]], a: float,
+               x0: float, Gamma: float) -> Dict[str, List[float]]:
+        """
+        report parameters
+        :param report_dic: dict of results
+        :param a: amplitude of the lorentzian
+        :param x0: the peak centre
+        :param Gamma: half width at half maxima (HWHM)
+        :return update results dict
+        """
+        report_dict = self._add_to_report(self.amplitude,
+                                          a, report_dict)
+        report_dict = self._add_to_report(self.centre,
+                                          x0, report_dict)
+        report_dict = self._add_to_report(self.Gamma,
+                                          Gamma, report_dict)
+        return report_dict
```

## quickBayes/fit_functions/qldata_function.py

 * *Ordering differences only*

```diff
@@ -1,120 +1,120 @@
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.functions.qe_function import QEFunction
-from quickBayes.functions.lorentz import Lorentzian
-from numpy import ndarray
-from math import sqrt
-from typing import Dict, List
-
-
-class QlDataFunction(QEFunction):
-    def __init__(self, bg_function: BaseFitFunction, elastic_peak: bool,
-                 r_x: ndarray, r_y: ndarray, start_x: float, end_x: float):
-        """
-        Create a quasi elastic fitting function using lorentzians
-        :param bg_function: background fitting function
-        :param elastic_peak: if to include an elastic peak (True/False)
-        :param res_x: x values for resolution function
-        :param res_y: y values for resolution function
-        :param start_x: the start of the fitting range
-        :param end_x: the end of the fitting range
-        """
-        super().__init__(bg_function, elastic_peak, r_x,
-                         r_y, start_x, end_x)
-
-    def add_single_lorentzian(self) -> None:
-        """
-        Add a single Lorentzian function to the qldata function
-        """
-        lor = Lorentzian()
-        self.add_single_function(lor)
-
-    def _add_params(self, offset: int, x0: float,
-                    args: List[float]) -> List[float]:
-
-        # adds amplitude, peak centre and FWHM
-        return [args[offset], x0, args[offset + 1]]
-
-    def _get_func_from_report(self, args: List[float]) -> List[float]:
-        # skip the peak centre
-        return [args[0], args[2]]
-
-    def report(self, report_dict: Dict[str, List[float]],
-               *args: float) -> Dict[str, List[float]]:
-        """
-        Reports the results
-        :param report_dict: dict of results
-        :param args: args for functions
-        :returns updated results dict
-        """
-        report_dict = super().report(report_dict, *args)
-        params = self._get_params(args)
-        # manually add EISF
-        if self.delta and self.conv.N_params > 2:
-            BG_N_params = self.BG.N_params
-            e_amp = args[BG_N_params]
-            N_e = self.conv._funcs[0].N_params
-            for j in range(len(self.conv._funcs)-1):
-                k = j + 1
-                N_qe = self.conv._funcs[k].N_params
-                # params has values for delta + lorentz
-                qe_amp = params[j*N_qe + N_e]
-                EISF = e_amp/(e_amp + qe_amp)
-                report_dict = self._add_to_report(self.conv._funcs[k]._prefix
-                                                  + "EISF",
-                                                  EISF, report_dict)
-        return report_dict
-
-    def report_errors(self, report_dict: Dict[str, List[float]],
-                      errors: List[float],
-                      params: List[float]) -> Dict[str, List[float]]:
-        """
-        Reports the parameter errors
-        :param report_dict: dict of errors
-        :param errrors: error values
-        :param params: parameter values
-        :returns updated errors dict
-        """
-        report_dict = super().report(report_dict, *errors)
-        # manually add EISF errors
-        if self.delta and self.conv.N_params > 2:
-            BG_N_params = self.BG.N_params
-            e_amp = params[BG_N_params]
-            sigma_e_amp = errors[BG_N_params]
-            N_e = self.conv._funcs[0].N_params
-            for j in range(len(self.conv._funcs)-1):
-                k = j + 1
-                N_qe = self.conv._funcs[k].N_params
-                # params has values for delta + lorentz
-                qe_amp = params[j*N_qe + N_e]
-                sigma_qe_amp = errors[j*N_qe + N_e]
-                EISF = sqrt(((qe_amp**2)*(sigma_e_amp**2) +
-                             (sigma_qe_amp**2)*(e_amp**2))/pow(e_amp +
-                                                               qe_amp, 4))
-                report_dict = self._add_to_report(self.conv._funcs[k]._prefix
-                                                  + "EISF",
-                                                  EISF, report_dict)
-        return report_dict
-
-    @staticmethod
-    def _func_guess(full_guess: List[float]) -> List[float]:
-        """
-        Get the intial guess values.
-        This takes into account the tied
-        parameters.
-        :return a list of guess parameters for the fit
-        """
-        # skip peak centre
-        return [full_guess[0], full_guess[2]]
-
-    @staticmethod
-    def update_first_values(to_update: List[float],
-                            guess: List[float]) -> List[float]:
-        """
-        Method for copying the updated values into the first function
-        in the convolution (this determines the value in evaluation).
-        :param to_update: the values to update (due to ties)
-        :param guess: the new guess values for the function being changed
-        :return the updated list
-        """
-        to_update[1] = guess[1]
-        return to_update
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.functions.qe_function import QEFunction
+from quickBayes.functions.lorentz import Lorentzian
+from numpy import ndarray
+from math import sqrt
+from typing import Dict, List
+
+
+class QlDataFunction(QEFunction):
+    def __init__(self, bg_function: BaseFitFunction, elastic_peak: bool,
+                 r_x: ndarray, r_y: ndarray, start_x: float, end_x: float):
+        """
+        Create a quasi elastic fitting function using lorentzians
+        :param bg_function: background fitting function
+        :param elastic_peak: if to include an elastic peak (True/False)
+        :param res_x: x values for resolution function
+        :param res_y: y values for resolution function
+        :param start_x: the start of the fitting range
+        :param end_x: the end of the fitting range
+        """
+        super().__init__(bg_function, elastic_peak, r_x,
+                         r_y, start_x, end_x)
+
+    def add_single_lorentzian(self) -> None:
+        """
+        Add a single Lorentzian function to the qldata function
+        """
+        lor = Lorentzian()
+        self.add_single_function(lor)
+
+    def _add_params(self, offset: int, x0: float,
+                    args: List[float]) -> List[float]:
+
+        # adds amplitude, peak centre and FWHM
+        return [args[offset], x0, args[offset + 1]]
+
+    def _get_func_from_report(self, args: List[float]) -> List[float]:
+        # skip the peak centre
+        return [args[0], args[2]]
+
+    def report(self, report_dict: Dict[str, List[float]],
+               *args: float) -> Dict[str, List[float]]:
+        """
+        Reports the results
+        :param report_dict: dict of results
+        :param args: args for functions
+        :returns updated results dict
+        """
+        report_dict = super().report(report_dict, *args)
+        params = self._get_params(args)
+        # manually add EISF
+        if self.delta and self.conv.N_params > 2:
+            BG_N_params = self.BG.N_params
+            e_amp = args[BG_N_params]
+            N_e = self.conv._funcs[0].N_params
+            for j in range(len(self.conv._funcs)-1):
+                k = j + 1
+                N_qe = self.conv._funcs[k].N_params
+                # params has values for delta + lorentz
+                qe_amp = params[j*N_qe + N_e]
+                EISF = e_amp/(e_amp + qe_amp)
+                report_dict = self._add_to_report(self.conv._funcs[k]._prefix
+                                                  + "EISF",
+                                                  EISF, report_dict)
+        return report_dict
+
+    def report_errors(self, report_dict: Dict[str, List[float]],
+                      errors: List[float],
+                      params: List[float]) -> Dict[str, List[float]]:
+        """
+        Reports the parameter errors
+        :param report_dict: dict of errors
+        :param errrors: error values
+        :param params: parameter values
+        :returns updated errors dict
+        """
+        report_dict = super().report(report_dict, *errors)
+        # manually add EISF errors
+        if self.delta and self.conv.N_params > 2:
+            BG_N_params = self.BG.N_params
+            e_amp = params[BG_N_params]
+            sigma_e_amp = errors[BG_N_params]
+            N_e = self.conv._funcs[0].N_params
+            for j in range(len(self.conv._funcs)-1):
+                k = j + 1
+                N_qe = self.conv._funcs[k].N_params
+                # params has values for delta + lorentz
+                qe_amp = params[j*N_qe + N_e]
+                sigma_qe_amp = errors[j*N_qe + N_e]
+                EISF = sqrt(((qe_amp**2)*(sigma_e_amp**2) +
+                             (sigma_qe_amp**2)*(e_amp**2))/pow(e_amp +
+                                                               qe_amp, 4))
+                report_dict = self._add_to_report(self.conv._funcs[k]._prefix
+                                                  + "EISF",
+                                                  EISF, report_dict)
+        return report_dict
+
+    @staticmethod
+    def _func_guess(full_guess: List[float]) -> List[float]:
+        """
+        Get the intial guess values.
+        This takes into account the tied
+        parameters.
+        :return a list of guess parameters for the fit
+        """
+        # skip peak centre
+        return [full_guess[0], full_guess[2]]
+
+    @staticmethod
+    def update_first_values(to_update: List[float],
+                            guess: List[float]) -> List[float]:
+        """
+        Method for copying the updated values into the first function
+        in the convolution (this determines the value in evaluation).
+        :param to_update: the values to update (due to ties)
+        :param guess: the new guess values for the function being changed
+        :return the updated list
+        """
+        to_update[1] = guess[1]
+        return to_update
```

## quickBayes/fit_functions/qse.py

 * *Ordering differences only*

```diff
@@ -1,93 +1,93 @@
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.functions.qe_function import QEFunction
-from quickBayes.functions.SE import StretchExp
-from numpy import ndarray
-import copy
-from typing import List
-
-
-class QSEFunction(QEFunction):
-    def __init__(self, bg_function: BaseFitFunction, elastic_peak: bool,
-                 r_x: ndarray, r_y: ndarray, start_x: float, end_x: float):
-        """
-        Create a quasi elastic fitting function using stretched exp
-        :param bg_function: background fitting function
-        :param elastic_peak: if to include an elastic peak (True/False)
-        :param res_x: x values for resolution function
-        :param res_y: y values for resolution function
-        :param start_x: the start of the fitting range
-        :param end_x: the end of the fitting range
-        """
-        super().__init__(bg_function, elastic_peak, r_x,
-                         r_y, start_x, end_x)
-
-    def add_single_SE(self) -> None:
-        """
-        Add a single Lorentzian function to the qldata function
-        """
-        se = StretchExp()
-        self.add_single_function(se)
-
-    def _add_params(self, offset: int, x0: float,
-                    args: List[float]) -> List[float]:
-
-        # adds amplitude, peak centre and FWHM
-        return [args[offset], x0, args[offset + 1], args[offset + 2]]
-
-    def _get_func_from_report(self, args: List[float]) -> List[float]:
-        # skip the peak centre
-        return [args[0], args[2], args[3]]
-
-    def _func_guess(self, full_guess: List[float]) -> List[float]:
-        """
-        Get the intial guess values.
-        This takes into account the tied
-        parameters.
-        :return a list of guess parameters for the fit
-        """
-        # skip peak centre
-        return [full_guess[0], full_guess[2], full_guess[3]]
-
-    def get_guess(self) -> List[float]:
-        """
-        Gets the guess for the fit params
-        :result a list of initial values for fit
-        """
-        guess = copy.copy(self.BG.get_guess())
-
-        # want to reduce the guess to remove tied parameters
-        if len(self.conv._funcs) > 0 and self.delta:
-            guess += copy.copy(self.conv._funcs[0].get_guess())
-        elif len(self.conv._funcs) > 0:
-            guess += copy.copy(self.conv._funcs[0].get_guess())
-        if len(self.conv._funcs) > 1:
-            for j in range(1, len(self.conv._funcs)):
-                full_guess = copy.copy(self.conv._funcs[j].get_guess())
-                guess += self._func_guess(full_guess)
-        return guess
-
-    def update_first_values(self, to_update: List[float],
-                            guess: List[float]) -> List[float]:
-        """
-        Method for copying the updated values into the first function
-        in the convolution (this determines the value in evaluation.
-        :param to_update: the values to update (due to ties)
-        :param guess: the new guess values for the function being changed
-        :return the updated list
-        """
-        to_update[1] = guess[1]
-        return to_update
-
-    def set_func_guess_FWHM(self, guess: List[float], index=-1) -> None:
-        """
-        Set the  guess values.
-        :param guess: the guess for the function
-        :param index: the index of the function
-        """
-        if self.N_peaks == 0:
-            return
-        values = guess
-        offset = 1 if self.delta else 0
-
-        values[2] = self.conv._funcs[offset].tau(guess[2])
-        super().set_func_guess(values)
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.functions.qe_function import QEFunction
+from quickBayes.functions.SE import StretchExp
+from numpy import ndarray
+import copy
+from typing import List
+
+
+class QSEFunction(QEFunction):
+    def __init__(self, bg_function: BaseFitFunction, elastic_peak: bool,
+                 r_x: ndarray, r_y: ndarray, start_x: float, end_x: float):
+        """
+        Create a quasi elastic fitting function using stretched exp
+        :param bg_function: background fitting function
+        :param elastic_peak: if to include an elastic peak (True/False)
+        :param res_x: x values for resolution function
+        :param res_y: y values for resolution function
+        :param start_x: the start of the fitting range
+        :param end_x: the end of the fitting range
+        """
+        super().__init__(bg_function, elastic_peak, r_x,
+                         r_y, start_x, end_x)
+
+    def add_single_SE(self) -> None:
+        """
+        Add a single Lorentzian function to the qldata function
+        """
+        se = StretchExp()
+        self.add_single_function(se)
+
+    def _add_params(self, offset: int, x0: float,
+                    args: List[float]) -> List[float]:
+
+        # adds amplitude, peak centre and FWHM
+        return [args[offset], x0, args[offset + 1], args[offset + 2]]
+
+    def _get_func_from_report(self, args: List[float]) -> List[float]:
+        # skip the peak centre
+        return [args[0], args[2], args[3]]
+
+    def _func_guess(self, full_guess: List[float]) -> List[float]:
+        """
+        Get the intial guess values.
+        This takes into account the tied
+        parameters.
+        :return a list of guess parameters for the fit
+        """
+        # skip peak centre
+        return [full_guess[0], full_guess[2], full_guess[3]]
+
+    def get_guess(self) -> List[float]:
+        """
+        Gets the guess for the fit params
+        :result a list of initial values for fit
+        """
+        guess = copy.copy(self.BG.get_guess())
+
+        # want to reduce the guess to remove tied parameters
+        if len(self.conv._funcs) > 0 and self.delta:
+            guess += copy.copy(self.conv._funcs[0].get_guess())
+        elif len(self.conv._funcs) > 0:
+            guess += copy.copy(self.conv._funcs[0].get_guess())
+        if len(self.conv._funcs) > 1:
+            for j in range(1, len(self.conv._funcs)):
+                full_guess = copy.copy(self.conv._funcs[j].get_guess())
+                guess += self._func_guess(full_guess)
+        return guess
+
+    def update_first_values(self, to_update: List[float],
+                            guess: List[float]) -> List[float]:
+        """
+        Method for copying the updated values into the first function
+        in the convolution (this determines the value in evaluation.
+        :param to_update: the values to update (due to ties)
+        :param guess: the new guess values for the function being changed
+        :return the updated list
+        """
+        to_update[1] = guess[1]
+        return to_update
+
+    def set_func_guess_FWHM(self, guess: List[float], index=-1) -> None:
+        """
+        Set the  guess values.
+        :param guess: the guess for the function
+        :param index: the index of the function
+        """
+        if self.N_peaks == 0:
+            return
+        values = guess
+        offset = 1 if self.delta else 0
+
+        values[2] = self.conv._funcs[offset].tau(guess[2])
+        super().set_func_guess(values)
```

## quickBayes/fit_functions/qse_fixed.py

 * *Ordering differences only*

```diff
@@ -1,97 +1,97 @@
-from quickBayes.functions.SE_fix import StretchExpWithFixes
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.functions.qse_function import QSEFunction
-from numpy import ndarray
-from typing import List
-
-
-class QSEFixFunction(QSEFunction):
-
-    def __init__(self, bg_function: BaseFitFunction, elastic_peak: bool,
-                 r_x: ndarray, r_y: ndarray, start_x: float, end_x: float):
-        """
-        Create a quasi elastic fitting function using fixed stretched exp
-        :param bg_function: background fitting function
-        :param elastic_peak: if to include an elastic peak (True/False)
-        :param res_x: x values for resolution function
-        :param res_y: y values for resolution function
-        :param start_x: the start of the fitting range
-        :param end_x: the end of the fitting range
-        """
-        self._se = []
-        super().__init__(bg_function, elastic_peak, r_x,
-                         r_y, start_x, end_x)
-
-    def add_single_SE(self) -> None:
-        """
-        adds a single stretched exp with fixes
-        """
-        self._se.append(StretchExpWithFixes())
-        self.add_single_function(self._se[-1])
-
-    @staticmethod
-    def _get_func_from_report(args: List[float]) -> List[float]:
-        """
-        extracts the relevant info from report (excluding fixes)
-        :param args: the full list of arguments.
-        :return the arguments, skipping the peak centre
-        """
-        return [args[0]]
-
-    @staticmethod
-    def _func_guess(full_guess: List[float]) -> List[float]:
-        """
-        Get the initial guess values.
-        This takes into account the tied
-        parameters.
-        :return a list of guess parameters for the fit
-        """
-        # skip peak centre
-        return [full_guess[0]]
-
-    def set_beta(self, beta: float, index: int = -1) -> None:
-        """
-        sets the beta value for the fix
-        :param beta: the beta value to fix to
-        :param index: the index of the se
-        """
-        if not self._se:
-            return
-        self._se[index].set_beta(beta)
-
-    def set_FWHM(self, FWHM, index: int = -1) -> None:
-        """
-        sets the FWHM value for the fix
-        :param FWHM: the FWHM value to fix to
-        :param index: the index of the se
-        """
-        if not self._se:
-            return
-        self._se[index].set_FWHM(FWHM)
-
-    @staticmethod
-    def _add_params(offset: int, x0: float,
-                    args: List[float]) -> List[float]:
-        """
-        Gets the amplitude and peak centre
-        :param offset: the offset in the index
-        :param x0: the peak centre
-        :param args: the arguments
-        :return a list of parameters for the SE
-        """
-        # adds amplitude, peak centre
-        return [args[offset], x0]
-
-    def set_func_guess_FWHM(self, guess: List[float], index=-1) -> None:
-        """
-        Set the  guess values.
-        :param guess: the guess for the function, assume
-        FWHM is in index 2
-        :param index: the index of the function
-        """
-        if self.N_peaks == 0:
-            return
-
-        self.set_FWHM(guess[2], index)
-
-        super().set_func_guess(guess[0:2], index)
+from quickBayes.functions.SE_fix import StretchExpWithFixes
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.functions.qse_function import QSEFunction
+from numpy import ndarray
+from typing import List
+
+
+class QSEFixFunction(QSEFunction):
+
+    def __init__(self, bg_function: BaseFitFunction, elastic_peak: bool,
+                 r_x: ndarray, r_y: ndarray, start_x: float, end_x: float):
+        """
+        Create a quasi elastic fitting function using fixed stretched exp
+        :param bg_function: background fitting function
+        :param elastic_peak: if to include an elastic peak (True/False)
+        :param res_x: x values for resolution function
+        :param res_y: y values for resolution function
+        :param start_x: the start of the fitting range
+        :param end_x: the end of the fitting range
+        """
+        self._se = []
+        super().__init__(bg_function, elastic_peak, r_x,
+                         r_y, start_x, end_x)
+
+    def add_single_SE(self) -> None:
+        """
+        adds a single stretched exp with fixes
+        """
+        self._se.append(StretchExpWithFixes())
+        self.add_single_function(self._se[-1])
+
+    @staticmethod
+    def _get_func_from_report(args: List[float]) -> List[float]:
+        """
+        extracts the relevant info from report (excluding fixes)
+        :param args: the full list of arguments.
+        :return the arguments, skipping the peak centre
+        """
+        return [args[0]]
+
+    @staticmethod
+    def _func_guess(full_guess: List[float]) -> List[float]:
+        """
+        Get the initial guess values.
+        This takes into account the tied
+        parameters.
+        :return a list of guess parameters for the fit
+        """
+        # skip peak centre
+        return [full_guess[0]]
+
+    def set_beta(self, beta: float, index: int = -1) -> None:
+        """
+        sets the beta value for the fix
+        :param beta: the beta value to fix to
+        :param index: the index of the se
+        """
+        if not self._se:
+            return
+        self._se[index].set_beta(beta)
+
+    def set_FWHM(self, FWHM, index: int = -1) -> None:
+        """
+        sets the FWHM value for the fix
+        :param FWHM: the FWHM value to fix to
+        :param index: the index of the se
+        """
+        if not self._se:
+            return
+        self._se[index].set_FWHM(FWHM)
+
+    @staticmethod
+    def _add_params(offset: int, x0: float,
+                    args: List[float]) -> List[float]:
+        """
+        Gets the amplitude and peak centre
+        :param offset: the offset in the index
+        :param x0: the peak centre
+        :param args: the arguments
+        :return a list of parameters for the SE
+        """
+        # adds amplitude, peak centre
+        return [args[offset], x0]
+
+    def set_func_guess_FWHM(self, guess: List[float], index=-1) -> None:
+        """
+        Set the  guess values.
+        :param guess: the guess for the function, assume
+        FWHM is in index 2
+        :param index: the index of the function
+        """
+        if self.N_peaks == 0:
+            return
+
+        self.set_FWHM(guess[2], index)
+
+        super().set_func_guess(guess[0:2], index)
```

## quickBayes/fit_functions/quasielastic_function.py

 * *Ordering differences only*

```diff
@@ -1,372 +1,372 @@
-from quickBayes.functions.convolution import (
-        ConvolutionWithResolution)
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.functions.delta import Delta
-from numpy import ndarray
-from typing import Dict, List
-from abc import abstractmethod
-import copy
-
-
-"""
-There are no direct tests for this class.
-This is because all of the functionality
-is tested by the classes that inherit
-from it
-"""
-
-
-class QEFunction(BaseFitFunction):
-    def __init__(self, bg_function: BaseFitFunction, elastic_peak: bool,
-                 r_x: ndarray, r_y: ndarray, start_x: float, end_x: float):
-        """
-        Create a quasi elastic fitting function
-
-        ASSUMPTIONS:
-        - The added 'peak' is always the same (e.g. Lorentzian or stretch exp)
-        - The 2nd param for the added function is the 'peak centre'
-        - Will convolve with the resolution function
-        - The fit function has more 'peaks' than the number in a report
-        - The elastic peak can be represented by a 'delta' function
-
-        :param bg_function: background fitting function
-        :param elastic_peak: if to include an elastic peak (True/False)
-        :param res_x: x values for resolution function
-        :param res_y: y values for resolution function
-        :param start_x: the start of the fitting range
-        :param end_x: the end of the fitting range
-        """
-        self._N_peaks = 0
-        self.BG = copy.copy(bg_function)
-        self.BG.add_to_prefix(self.prefix + 'f1')
-        self.conv = ConvolutionWithResolution(r_x, r_y, start_x,
-                                              end_x, self.prefix + 'f2')
-        self.delta = elastic_peak
-        if elastic_peak:
-            delta = Delta('')
-            self.conv.add_function(delta)
-
-        self._N_params = self.BG.N_params + self.conv.N_params,
-        self._prefix = self.prefix
-
-    def update_x_range(self, new_x: ndarray) -> None:
-        """
-        The sampling of the resolution function can make
-        a big difference to the quality of the function.
-        This is because of sampling issues. To solve
-        this problem a user can update the x (and y)
-        ranges using this method.
-        :param new_x: the new x range (y is interpolated)
-        """
-        self.conv.update_x_range(new_x)
-
-    @property
-    def N_params(self) -> int:
-        """
-        :return the number of parameters in the function
-        """
-        # subtract 1 to share the peak position with delta
-        peak_correction = self._N_peaks
-        if not self.delta and self._N_peaks > 0:
-            peak_correction -= 1
-        return self.BG.N_params + self.conv.N_params - 1*peak_correction
-
-    @property
-    def N_peaks(self) -> int:
-        """
-        :return the number of extra functions (e.g. lorentzians, stretch exp)
-        """
-        return self._N_peaks
-
-    @property
-    def prefix(self) -> str:
-        """
-        :return the label for the number of peaks
-        """
-        return str(f'N{self.N_peaks}:')
-
-    def _update_prefixes(self) -> None:
-        """
-        Method for updaing the prefixes for new number of peaks
-        """
-        self.BG.update_prefix(self.prefix)
-        self.conv.update_prefix(self.prefix)
-
-    def add_single_function(self, func: BaseFitFunction) -> None:
-        """
-        :param func: the function (e.g. lorentzian) to add
-        Add a single Lorentzian function to the qldata function
-        """
-        self._N_peaks += 1
-        self.conv.add_function(func)
-        # update the labels/prefixes
-        self._update_prefixes()
-
-    def _add_params(self, offset: int, x0: float,
-                    args: List[float]) -> List[float]:
-        """
-        :param offset: the (index) offset for the function
-        :param x0: the peak centre
-        :param args: the argument list
-        :return the extended (with repeats) parameters to add
-        """
-        return []
-
-    def _get_params(self, args: List[float]) -> List[float]:
-        """
-        For fitting we need to tie the peak centers for the
-        delta and functions. This function creates the
-        extended parameter list (with repeats).
-        :param args: the arguments to the function (no repeats)
-        :return the arguments with repeats for the peak centers
-        in the correct places
-        """
-        params = []
-        N_BG_params = self.BG.N_params
-        x0 = 0
-        N_f0 = 0
-        offset = 0
-        if len(self.conv._funcs) > 0:
-            N_f0 = self.conv._funcs[0].N_params
-            params = [*args[N_BG_params:N_BG_params + N_f0]]
-            x0 = args[N_BG_params + 1]  # same position for both lor and delta
-            if not self.delta:
-                # if not elastic, already done first peak
-                offset = 1
-
-        for j in range(self._N_peaks - offset):
-            params += self._add_params(N_BG_params + N_f0 + j*2, x0, args)
-        return params
-
-    def __call__(self, x: ndarray, *args: float) -> ndarray:
-        """
-        Implement the function evaluation.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for function evaluation
-        :param args: args for functions
-        :return y values for the function evaluation
-        """
-        N_BG_params = self.BG.N_params
-        result = self.BG(x, *args[:N_BG_params])
-
-        params = self._get_params(args)
-        result += self.conv(x, *params)
-        return result
-
-    def _get_func_from_report(self, args: List[float]) -> List[float]:
-        return args
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         N: int, index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param N: the number of peaks
-        :param index: the index to get results from
-        :return the parameters
-        """
-        if N > self._N_peaks:
-            raise ValueError("Too many peaks selected")
-        N_peaks = self._N_peaks
-        # set for number of peaks
-        self._N_peaks = N
-        self._update_prefixes()
-        # get parameters
-        params = self.BG.read_from_report(report_dict, index)
-        num_funcs = N
-        if self.delta:
-            num_funcs += 1
-
-        if num_funcs > 0:
-            # always want the first member in full
-            params += self.conv._funcs[0].read_from_report(report_dict, index)
-
-        for k in range(1, num_funcs):
-            tmp = self.conv._funcs[k].read_from_report(report_dict,
-                                                       index)
-            params += self._get_func_from_report(tmp)
-
-        # reset the number of peaks
-        self._N_peaks = N_peaks
-        self._update_prefixes()
-        return params
-
-    def report(self, report_dict: Dict[str, List[float]],
-               *args: float) -> Dict[str, List[float]]:
-        """
-        Reports the results
-        :param report_dict: dict of results
-        :param args: args for functions
-        :returns updated results dict
-        """
-        N = self.N_params
-        if len(args) != N:
-            raise ValueError(f"Expected {N} args, got {len(args)}")
-        report_dict = self.BG.report(report_dict, *args[:self.BG.N_params])
-
-        params = self._get_params(args)
-        report_dict = self.conv.report(report_dict, *params)
-        return report_dict
-
-    @abstractmethod
-    def update_first_values(self, update: List[float],
-                            guess: List[float], index=-1) -> None:
-        """
-        Update the values due to ties.
-        This will depend on the function
-        :param update: the values to update due to ties
-        :param guess: the guess for the function
-        :param index: the index of the function
-        """
-        raise NotImplementedError()
-
-    def _func_guess(self, full_guess: List[float]) -> List[float]:
-        """
-        Extracts the guess for the function
-        :param full_guess: the full list of guess parameters
-        :return the reduced guess parameters (no repeats for peak centre)
-        """
-        return full_guess
-
-    def get_guess(self) -> List[float]:
-        """
-        Get the intial guess values.
-        This takes into account the tied
-        parameters.
-        :return a list of guess parameters for the fit
-        """
-        # need to copy to prevent incrementing guess by calling this function
-        guess = copy.copy(self.BG.get_guess())
-        # want to reduce the guess to remove tied parameters
-        if len(self.conv._funcs) > 0:
-            guess += copy.copy(self.conv._funcs[0].get_guess())
-            for j in range(1, len(self.conv._funcs)):
-                full_guess = copy.copy(self.conv._funcs[j].get_guess())
-                guess += self._func_guess(full_guess)
-        return guess
-
-    def get_func_guess(self, index=-1):
-        if self.N_peaks == 0:
-            return
-        delta_offset = 1 if self.delta and index != -1 else 0
-        guess = self.conv._funcs[index + delta_offset].get_guess()
-        tie_values = self.conv._funcs[0].get_guess()
-        guess = self.update_first_values(guess, tie_values)
-        return guess
-
-    def set_guess(self, guess: List[float]) -> None:
-        """
-        Override the default guess setting.
-        :param guess: the guess
-        """
-        raise RuntimeError("set_guess is not available for this "
-                           "function. Please use: \n"
-                           "- set_BG_guess \n"
-                           "- set_delta_guess \n"
-                           "- set_func_guess")
-
-    def set_BG_guess(self, guess: List[float]) -> None:
-        """
-        Set the background guess values.
-        :param guess: the guess for the BG
-        """
-        self.BG.set_guess(guess)
-
-    def set_delta_guess(self, guess: List[float]) -> None:
-        """
-        Set the delta guess values.
-        :param guess: the guess for the delta function
-        """
-        if self.delta:
-            self.conv._funcs[0].set_guess(guess)
-
-    def set_func_guess(self, guess: List[float], index=-1) -> None:
-        """
-        Set the  guess values.
-        :param guess: the guess for the function
-        :param index: the index of the function
-        """
-        # no func
-        if self._N_peaks == 0:
-            return
-        delta_offset = 1 if self.delta and index != -1 else 0
-
-        self.conv._funcs[index + delta_offset].set_guess(guess)
-        to_update = self.conv._funcs[0].get_guess()
-        to_update = self.update_first_values(to_update, guess)
-        self.conv._funcs[0].set_guess(to_update)
-
-    def get_bounds(self) -> (List[float], List[float]):
-        """
-        Gets the bounds for the parameters.
-        :return a list of the lower and upper bounds
-        """
-        # need to copy to prevent incrementing bounds by calling this function
-        bounds = self.BG.get_bounds()
-        lower = copy.copy(bounds[0])
-        upper = copy.copy(bounds[1])
-
-        if len(self.conv._funcs) > 0:
-            # want to reduce the guess to remove tied parameters
-            func = self.conv._funcs[0]
-            bounds = func.get_bounds()
-            lower += copy.copy(bounds[0])
-            upper += copy.copy(bounds[1])
-
-            for j in range(1, len(self.conv._funcs)):
-                f = self.conv._funcs[j]
-                bounds = f.get_bounds()
-                tmp = bounds[0]
-                lower += copy.copy(self._func_guess(tmp))
-                tmp = bounds[1]
-                upper += copy.copy(self._func_guess(tmp))
-
-        return lower, upper
-
-    def set_bounds(self, lower: List[float], upper: List[float]) -> None:
-        """
-        Override the default bounds setting.
-        :param lower: the lower bound values
-        :param upper: the upper bound values
-        """
-        raise RuntimeError("set_guess is not available for this "
-                           "function. Please use: \n"
-                           "- set_BG_bounds \n"
-                           "- set_delta_bounds \n"
-                           "- set_func_bounds")
-
-    def set_BG_bounds(self, lower: List[float], upper: List[float]) -> None:
-        """
-        Set the background bounds values.
-        :param lower: the lower bound values
-        :param upper: the upper bound values
-        """
-        self.BG.set_bounds(lower, upper)
-
-    def set_delta_bounds(self, lower: List[float], upper: List[float]) -> None:
-        """
-        Set the delta bounds values.
-        :param lower: the lower bound values
-        :param upper: the upper bound values
-        """
-        if self.delta:
-            self.conv._funcs[0].set_bounds(lower, upper)
-
-    def set_func_bounds(self, lower: List[float],
-                        upper: List[float], index=-1) -> None:
-        """
-        Set the bounds values.
-        :param lower: the lower bound values
-        :param upper: the upper bound values
-        :param index: the index of the function
-        """
-        if self._N_peaks == 0:
-            return
-        delta_offset = 1 if self.delta and index != -1 else 0
-
-        self.conv._funcs[index + delta_offset].set_bounds(lower, upper)
-        update_lower, update_upper = self.conv._funcs[0].get_bounds()
-        update_lower = self.update_first_values(update_lower, lower)
-        update_upper = self.update_first_values(update_upper, upper)
-        self.conv._funcs[0].set_bounds(update_lower, update_upper)
+from quickBayes.functions.convolution import (
+        ConvolutionWithResolution)
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.functions.delta import Delta
+from numpy import ndarray
+from typing import Dict, List
+from abc import abstractmethod
+import copy
+
+
+"""
+There are no direct tests for this class.
+This is because all of the functionality
+is tested by the classes that inherit
+from it
+"""
+
+
+class QEFunction(BaseFitFunction):
+    def __init__(self, bg_function: BaseFitFunction, elastic_peak: bool,
+                 r_x: ndarray, r_y: ndarray, start_x: float, end_x: float):
+        """
+        Create a quasi elastic fitting function
+
+        ASSUMPTIONS:
+        - The added 'peak' is always the same (e.g. Lorentzian or stretch exp)
+        - The 2nd param for the added function is the 'peak centre'
+        - Will convolve with the resolution function
+        - The fit function has more 'peaks' than the number in a report
+        - The elastic peak can be represented by a 'delta' function
+
+        :param bg_function: background fitting function
+        :param elastic_peak: if to include an elastic peak (True/False)
+        :param res_x: x values for resolution function
+        :param res_y: y values for resolution function
+        :param start_x: the start of the fitting range
+        :param end_x: the end of the fitting range
+        """
+        self._N_peaks = 0
+        self.BG = copy.copy(bg_function)
+        self.BG.add_to_prefix(self.prefix + 'f1')
+        self.conv = ConvolutionWithResolution(r_x, r_y, start_x,
+                                              end_x, self.prefix + 'f2')
+        self.delta = elastic_peak
+        if elastic_peak:
+            delta = Delta('')
+            self.conv.add_function(delta)
+
+        self._N_params = self.BG.N_params + self.conv.N_params,
+        self._prefix = self.prefix
+
+    def update_x_range(self, new_x: ndarray) -> None:
+        """
+        The sampling of the resolution function can make
+        a big difference to the quality of the function.
+        This is because of sampling issues. To solve
+        this problem a user can update the x (and y)
+        ranges using this method.
+        :param new_x: the new x range (y is interpolated)
+        """
+        self.conv.update_x_range(new_x)
+
+    @property
+    def N_params(self) -> int:
+        """
+        :return the number of parameters in the function
+        """
+        # subtract 1 to share the peak position with delta
+        peak_correction = self._N_peaks
+        if not self.delta and self._N_peaks > 0:
+            peak_correction -= 1
+        return self.BG.N_params + self.conv.N_params - 1*peak_correction
+
+    @property
+    def N_peaks(self) -> int:
+        """
+        :return the number of extra functions (e.g. lorentzians, stretch exp)
+        """
+        return self._N_peaks
+
+    @property
+    def prefix(self) -> str:
+        """
+        :return the label for the number of peaks
+        """
+        return str(f'N{self.N_peaks}:')
+
+    def _update_prefixes(self) -> None:
+        """
+        Method for updaing the prefixes for new number of peaks
+        """
+        self.BG.update_prefix(self.prefix)
+        self.conv.update_prefix(self.prefix)
+
+    def add_single_function(self, func: BaseFitFunction) -> None:
+        """
+        :param func: the function (e.g. lorentzian) to add
+        Add a single Lorentzian function to the qldata function
+        """
+        self._N_peaks += 1
+        self.conv.add_function(func)
+        # update the labels/prefixes
+        self._update_prefixes()
+
+    def _add_params(self, offset: int, x0: float,
+                    args: List[float]) -> List[float]:
+        """
+        :param offset: the (index) offset for the function
+        :param x0: the peak centre
+        :param args: the argument list
+        :return the extended (with repeats) parameters to add
+        """
+        return []
+
+    def _get_params(self, args: List[float]) -> List[float]:
+        """
+        For fitting we need to tie the peak centers for the
+        delta and functions. This function creates the
+        extended parameter list (with repeats).
+        :param args: the arguments to the function (no repeats)
+        :return the arguments with repeats for the peak centers
+        in the correct places
+        """
+        params = []
+        N_BG_params = self.BG.N_params
+        x0 = 0
+        N_f0 = 0
+        offset = 0
+        if len(self.conv._funcs) > 0:
+            N_f0 = self.conv._funcs[0].N_params
+            params = [*args[N_BG_params:N_BG_params + N_f0]]
+            x0 = args[N_BG_params + 1]  # same position for both lor and delta
+            if not self.delta:
+                # if not elastic, already done first peak
+                offset = 1
+
+        for j in range(self._N_peaks - offset):
+            params += self._add_params(N_BG_params + N_f0 + j*2, x0, args)
+        return params
+
+    def __call__(self, x: ndarray, *args: float) -> ndarray:
+        """
+        Implement the function evaluation.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for function evaluation
+        :param args: args for functions
+        :return y values for the function evaluation
+        """
+        N_BG_params = self.BG.N_params
+        result = self.BG(x, *args[:N_BG_params])
+
+        params = self._get_params(args)
+        result += self.conv(x, *params)
+        return result
+
+    def _get_func_from_report(self, args: List[float]) -> List[float]:
+        return args
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         N: int, index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param N: the number of peaks
+        :param index: the index to get results from
+        :return the parameters
+        """
+        if N > self._N_peaks:
+            raise ValueError("Too many peaks selected")
+        N_peaks = self._N_peaks
+        # set for number of peaks
+        self._N_peaks = N
+        self._update_prefixes()
+        # get parameters
+        params = self.BG.read_from_report(report_dict, index)
+        num_funcs = N
+        if self.delta:
+            num_funcs += 1
+
+        if num_funcs > 0:
+            # always want the first member in full
+            params += self.conv._funcs[0].read_from_report(report_dict, index)
+
+        for k in range(1, num_funcs):
+            tmp = self.conv._funcs[k].read_from_report(report_dict,
+                                                       index)
+            params += self._get_func_from_report(tmp)
+
+        # reset the number of peaks
+        self._N_peaks = N_peaks
+        self._update_prefixes()
+        return params
+
+    def report(self, report_dict: Dict[str, List[float]],
+               *args: float) -> Dict[str, List[float]]:
+        """
+        Reports the results
+        :param report_dict: dict of results
+        :param args: args for functions
+        :returns updated results dict
+        """
+        N = self.N_params
+        if len(args) != N:
+            raise ValueError(f"Expected {N} args, got {len(args)}")
+        report_dict = self.BG.report(report_dict, *args[:self.BG.N_params])
+
+        params = self._get_params(args)
+        report_dict = self.conv.report(report_dict, *params)
+        return report_dict
+
+    @abstractmethod
+    def update_first_values(self, update: List[float],
+                            guess: List[float], index=-1) -> None:
+        """
+        Update the values due to ties.
+        This will depend on the function
+        :param update: the values to update due to ties
+        :param guess: the guess for the function
+        :param index: the index of the function
+        """
+        raise NotImplementedError()
+
+    def _func_guess(self, full_guess: List[float]) -> List[float]:
+        """
+        Extracts the guess for the function
+        :param full_guess: the full list of guess parameters
+        :return the reduced guess parameters (no repeats for peak centre)
+        """
+        return full_guess
+
+    def get_guess(self) -> List[float]:
+        """
+        Get the intial guess values.
+        This takes into account the tied
+        parameters.
+        :return a list of guess parameters for the fit
+        """
+        # need to copy to prevent incrementing guess by calling this function
+        guess = copy.copy(self.BG.get_guess())
+        # want to reduce the guess to remove tied parameters
+        if len(self.conv._funcs) > 0:
+            guess += copy.copy(self.conv._funcs[0].get_guess())
+            for j in range(1, len(self.conv._funcs)):
+                full_guess = copy.copy(self.conv._funcs[j].get_guess())
+                guess += self._func_guess(full_guess)
+        return guess
+
+    def get_func_guess(self, index=-1):
+        if self.N_peaks == 0:
+            return
+        delta_offset = 1 if self.delta and index != -1 else 0
+        guess = self.conv._funcs[index + delta_offset].get_guess()
+        tie_values = self.conv._funcs[0].get_guess()
+        guess = self.update_first_values(guess, tie_values)
+        return guess
+
+    def set_guess(self, guess: List[float]) -> None:
+        """
+        Override the default guess setting.
+        :param guess: the guess
+        """
+        raise RuntimeError("set_guess is not available for this "
+                           "function. Please use: \n"
+                           "- set_BG_guess \n"
+                           "- set_delta_guess \n"
+                           "- set_func_guess")
+
+    def set_BG_guess(self, guess: List[float]) -> None:
+        """
+        Set the background guess values.
+        :param guess: the guess for the BG
+        """
+        self.BG.set_guess(guess)
+
+    def set_delta_guess(self, guess: List[float]) -> None:
+        """
+        Set the delta guess values.
+        :param guess: the guess for the delta function
+        """
+        if self.delta:
+            self.conv._funcs[0].set_guess(guess)
+
+    def set_func_guess(self, guess: List[float], index=-1) -> None:
+        """
+        Set the  guess values.
+        :param guess: the guess for the function
+        :param index: the index of the function
+        """
+        # no func
+        if self._N_peaks == 0:
+            return
+        delta_offset = 1 if self.delta and index != -1 else 0
+
+        self.conv._funcs[index + delta_offset].set_guess(guess)
+        to_update = self.conv._funcs[0].get_guess()
+        to_update = self.update_first_values(to_update, guess)
+        self.conv._funcs[0].set_guess(to_update)
+
+    def get_bounds(self) -> (List[float], List[float]):
+        """
+        Gets the bounds for the parameters.
+        :return a list of the lower and upper bounds
+        """
+        # need to copy to prevent incrementing bounds by calling this function
+        bounds = self.BG.get_bounds()
+        lower = copy.copy(bounds[0])
+        upper = copy.copy(bounds[1])
+
+        if len(self.conv._funcs) > 0:
+            # want to reduce the guess to remove tied parameters
+            func = self.conv._funcs[0]
+            bounds = func.get_bounds()
+            lower += copy.copy(bounds[0])
+            upper += copy.copy(bounds[1])
+
+            for j in range(1, len(self.conv._funcs)):
+                f = self.conv._funcs[j]
+                bounds = f.get_bounds()
+                tmp = bounds[0]
+                lower += copy.copy(self._func_guess(tmp))
+                tmp = bounds[1]
+                upper += copy.copy(self._func_guess(tmp))
+
+        return lower, upper
+
+    def set_bounds(self, lower: List[float], upper: List[float]) -> None:
+        """
+        Override the default bounds setting.
+        :param lower: the lower bound values
+        :param upper: the upper bound values
+        """
+        raise RuntimeError("set_guess is not available for this "
+                           "function. Please use: \n"
+                           "- set_BG_bounds \n"
+                           "- set_delta_bounds \n"
+                           "- set_func_bounds")
+
+    def set_BG_bounds(self, lower: List[float], upper: List[float]) -> None:
+        """
+        Set the background bounds values.
+        :param lower: the lower bound values
+        :param upper: the upper bound values
+        """
+        self.BG.set_bounds(lower, upper)
+
+    def set_delta_bounds(self, lower: List[float], upper: List[float]) -> None:
+        """
+        Set the delta bounds values.
+        :param lower: the lower bound values
+        :param upper: the upper bound values
+        """
+        if self.delta:
+            self.conv._funcs[0].set_bounds(lower, upper)
+
+    def set_func_bounds(self, lower: List[float],
+                        upper: List[float], index=-1) -> None:
+        """
+        Set the bounds values.
+        :param lower: the lower bound values
+        :param upper: the upper bound values
+        :param index: the index of the function
+        """
+        if self._N_peaks == 0:
+            return
+        delta_offset = 1 if self.delta and index != -1 else 0
+
+        self.conv._funcs[index + delta_offset].set_bounds(lower, upper)
+        update_lower, update_upper = self.conv._funcs[0].get_bounds()
+        update_lower = self.update_first_values(update_lower, lower)
+        update_upper = self.update_first_values(update_upper, upper)
+        self.conv._funcs[0].set_bounds(update_lower, update_upper)
```

## quickBayes/fit_functions/stretch_exp.py

 * *Ordering differences only*

```diff
@@ -1,223 +1,223 @@
-from quickBayes.functions.base import BaseFitFunction
-from numpy import ndarray
-import numpy as np
-from typing import Dict, List
-from scipy.fftpack import fft, fftfreq
-from scipy.special import gamma
-from scipy import constants
-
-
-"""
-This code is taken from the open source code
-Mantid.
-https://github.com/mantidproject/mantid/blob/main/Framework/PythonInterface/plugins/functions/StretchedExpFTHelper.py
-"""
-
-
-PLANCK_CONSTANT = constants.Planck / constants.e * 1.e15  # meV*psec
-
-
-def function1Dcommon(xvals: ndarray, tau: float, beta: float,
-                     refine_factor=16,) -> (ndarray, ndarray):
-    """
-    Fourier transform of the symmetrized stretched exponential
-    :param function: instance of StretchedExpFT
-    :param xvals: energy domain
-    :param tau: relaxation time
-    :param beta: stretching exponenet
-    :param refine_factor: divide the natural energy width by this value
-    :return: energies, and function values
-    """
-    N = len(xvals)
-
-    # energy spacing. Assumed xvals is a single-segment grid
-    # of increasing energy values
-    dE = (xvals[-1] - xvals[0]) / (refine_factor * (N - 1))
-    E_range = 2 * max(abs(xvals))
-
-    dt = 0.5 * PLANCK_CONSTANT / E_range  # spacing in time
-    tmax = PLANCK_CONSTANT / dE  # maximum reciprocal time
-    # round to an upper power of two
-    nt = 2 ** (1 + int(np.log(tmax / dt) / np.log(2)))
-    sampled_times = dt * np.arange(-nt, nt)
-
-    decay = np.exp(-(np.abs(sampled_times) / tau)**beta)
-
-    """
-    The Fourier transform introduces an extra factor exp(i*pi*E/dE),
-    which amounts to alternating sign every time E increases by dE,
-    the energy bin width. Thus, we take the absolute value
-    """
-    fourier = np.abs(fft(decay).real)  # notice the reverse of decay array
-
-    fourier /= fourier[0]  # set maximum to unity
-    # Normalize the integral in energies to unity
-    fourier *= 2*tau*gamma(1./beta) / (beta*PLANCK_CONSTANT)
-
-    # symmetrize to negative energies
-    fourier = np.concatenate(
-        [fourier[nt:], fourier[:nt]])  # increasing ordering
-
-    # Find energy values corresponding to the fourier values
-    energies = PLANCK_CONSTANT * fftfreq(2 * nt, d=dt)  # standard ordering
-    energies = np.concatenate(
-        [energies[nt:], energies[:nt]])  # increasing ordering
-    return energies, fourier
-
-
-class StretchExp(BaseFitFunction):
-    def __init__(self, prefix: str = ''):
-        """
-        Create a stretched exponenetial function
-        :param prefix: the prefix for the parameters
-        """
-        super().__init__(4, prefix,
-                         [.1, 0.0, 6.582, 0.7],  # 6.582 -> FWHM = 0.2
-                         [0., -1., 0, 0], [1., 1., 100., 1.])
-
-    @property
-    def amplitude(self) -> str:
-        """
-        :return the string for the amplitude
-        """
-        return str(f"{self._prefix}Amplitude")
-
-    @property
-    def x0(self) -> str:
-        """
-        :return the string for the peak centre
-        """
-        return str(f"{self._prefix}Peak Centre")
-
-    @property
-    def beta(self) -> str:
-        """
-        :return the string for the beta value
-        """
-        return str(f"{self._prefix}beta")
-
-    @property
-    def tau_str(self) -> str:
-        """
-        :return the string value for tau
-        """
-        return str(f"{self._prefix}tau")
-
-    def __call__(self, x: ndarray,
-                 amplitude: float, x0: float,
-                 tau: float, beta: float) -> ndarray:
-        """
-        Implement the stretched exponential.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for function evaluation
-        :param amplitude: amplitude
-        :param x0: the peak centre
-        :param tau: relaxation time
-        :param beta: stretching exponent
-        :return y values for function evaluation
-        """
-
-        energies, fourier = function1Dcommon(x, tau, beta)
-        return amplitude*np.interp(x - x0,
-                                   energies, fourier)
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        return [self._read_report(report_dict, self.amplitude, index),
-                self._read_report(report_dict, self.x0, index),
-                self._read_report(report_dict, self.tau_str, index),
-                self._read_report(report_dict, self.beta, index)]
-
-    @staticmethod
-    def FWHM(tau: float) -> float:
-        """
-        Method to convert tau to FWHM
-        :param tau: tau parameter
-        :return FWHM
-        """
-        return 2.*PLANCK_CONSTANT/(2.*np.pi*tau)
-
-    @staticmethod
-    def tau(FWHM: float) -> float:
-        """
-        Method to get tau from FWHM
-        Used for estimation
-        :param FWHM: full width half maximum
-        :return tau parameter
-        """
-        return 2.*PLANCK_CONSTANT/(2.*np.pi*FWHM)
-
-    def report(self, report_dict: Dict[str, List[float]], a: float, x0: float,
-               tau: float, beta: float) -> Dict[str, List[float]]:
-        """
-        report parameters
-        :param report_dic: dict of results
-        :param a: amplitude
-        :param x0: the peak centre
-        :param tau: relaxation time
-        :param beta: stretching exponent
-        :return update results dict
-        """
-        report_dict = self._add_to_report(self.amplitude,
-                                          a, report_dict)
-        report_dict = self._add_to_report(self.x0,
-                                          x0, report_dict)
-        report_dict = self._add_to_report(self.beta,
-                                          beta, report_dict)
-        report_dict = self._add_to_report(self.tau_str,
-                                          tau, report_dict)
-        report_dict = self._add_to_report(f"{self._prefix}FWHM",
-                                          self.FWHM(tau), report_dict)
-        return report_dict
-
-    def report_errors(self, report_dict: Dict[str, List[float]],
-                      errors: ndarray,
-                      params: ndarray) -> Dict[str, List[float]]:
-        """
-        report parameters
-        :param report_dic: dict of parameter errors
-        :param errors: the errors for the fit parameters
-        :param params: the fit parameters
-        :return update results dict
-        """
-        report_dict = self._add_to_report(self.amplitude,
-                                          errors[0], report_dict)
-        report_dict = self._add_to_report(self.x0,
-                                          errors[1], report_dict)
-        report_dict = self._add_to_report(self.beta,
-                                          errors[3], report_dict)
-        report_dict = self._add_to_report(self.tau_str,
-                                          errors[2], report_dict)
-        """
-        FWHM = 2 hbar /tau
-        sigma_{FWHM} = 2 hbar sigma_tau / tau^2 = FWHM sigma_tau/tau
-        """
-        tmp = errors[2]/params[2]
-        report_dict = self._add_to_report(f"{self._prefix}FWHM",
-                                          self.FWHM(params[2])*tmp,
-                                          report_dict)
-        return report_dict
-
-    def set_guess_FWHM(self, values: List[float]) -> List[float]:
-        """
-        set the starting guess for a fit function
-        :param values: the guess values. The 3rd value is the FWHM
-        """
-        self._check_length(values, 'guess')
-        self._guess = [values[0], values[1],
-                       self.tau(values[2]), values[3]]
-
-    def set_guess(self, values: List[float]) -> List[float]:
-        """
-        set the starting guess for a fit function
-        :param values: the guess values. The 3rd value is the FWHM
-        """
-        self._check_length(values, 'guess')
-        self._guess = values
+from quickBayes.functions.base import BaseFitFunction
+from numpy import ndarray
+import numpy as np
+from typing import Dict, List
+from scipy.fftpack import fft, fftfreq
+from scipy.special import gamma
+from scipy import constants
+
+
+"""
+This code is taken from the open source code
+Mantid.
+https://github.com/mantidproject/mantid/blob/main/Framework/PythonInterface/plugins/functions/StretchedExpFTHelper.py
+"""
+
+
+PLANCK_CONSTANT = constants.Planck / constants.e * 1.e15  # meV*psec
+
+
+def function1Dcommon(xvals: ndarray, tau: float, beta: float,
+                     refine_factor=16,) -> (ndarray, ndarray):
+    """
+    Fourier transform of the symmetrized stretched exponential
+    :param function: instance of StretchedExpFT
+    :param xvals: energy domain
+    :param tau: relaxation time
+    :param beta: stretching exponenet
+    :param refine_factor: divide the natural energy width by this value
+    :return: energies, and function values
+    """
+    N = len(xvals)
+
+    # energy spacing. Assumed xvals is a single-segment grid
+    # of increasing energy values
+    dE = (xvals[-1] - xvals[0]) / (refine_factor * (N - 1))
+    E_range = 2 * max(abs(xvals))
+
+    dt = 0.5 * PLANCK_CONSTANT / E_range  # spacing in time
+    tmax = PLANCK_CONSTANT / dE  # maximum reciprocal time
+    # round to an upper power of two
+    nt = 2 ** (1 + int(np.log(tmax / dt) / np.log(2)))
+    sampled_times = dt * np.arange(-nt, nt)
+
+    decay = np.exp(-(np.abs(sampled_times) / tau)**beta)
+
+    """
+    The Fourier transform introduces an extra factor exp(i*pi*E/dE),
+    which amounts to alternating sign every time E increases by dE,
+    the energy bin width. Thus, we take the absolute value
+    """
+    fourier = np.abs(fft(decay).real)  # notice the reverse of decay array
+
+    fourier /= fourier[0]  # set maximum to unity
+    # Normalize the integral in energies to unity
+    fourier *= 2*tau*gamma(1./beta) / (beta*PLANCK_CONSTANT)
+
+    # symmetrize to negative energies
+    fourier = np.concatenate(
+        [fourier[nt:], fourier[:nt]])  # increasing ordering
+
+    # Find energy values corresponding to the fourier values
+    energies = PLANCK_CONSTANT * fftfreq(2 * nt, d=dt)  # standard ordering
+    energies = np.concatenate(
+        [energies[nt:], energies[:nt]])  # increasing ordering
+    return energies, fourier
+
+
+class StretchExp(BaseFitFunction):
+    def __init__(self, prefix: str = ''):
+        """
+        Create a stretched exponenetial function
+        :param prefix: the prefix for the parameters
+        """
+        super().__init__(4, prefix,
+                         [.1, 0.0, 6.582, 0.7],  # 6.582 -> FWHM = 0.2
+                         [0., -1., 0, 0], [1., 1., 100., 1.])
+
+    @property
+    def amplitude(self) -> str:
+        """
+        :return the string for the amplitude
+        """
+        return str(f"{self._prefix}Amplitude")
+
+    @property
+    def x0(self) -> str:
+        """
+        :return the string for the peak centre
+        """
+        return str(f"{self._prefix}Peak Centre")
+
+    @property
+    def beta(self) -> str:
+        """
+        :return the string for the beta value
+        """
+        return str(f"{self._prefix}beta")
+
+    @property
+    def tau_str(self) -> str:
+        """
+        :return the string value for tau
+        """
+        return str(f"{self._prefix}tau")
+
+    def __call__(self, x: ndarray,
+                 amplitude: float, x0: float,
+                 tau: float, beta: float) -> ndarray:
+        """
+        Implement the stretched exponential.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for function evaluation
+        :param amplitude: amplitude
+        :param x0: the peak centre
+        :param tau: relaxation time
+        :param beta: stretching exponent
+        :return y values for function evaluation
+        """
+
+        energies, fourier = function1Dcommon(x, tau, beta)
+        return amplitude*np.interp(x - x0,
+                                   energies, fourier)
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        return [self._read_report(report_dict, self.amplitude, index),
+                self._read_report(report_dict, self.x0, index),
+                self._read_report(report_dict, self.tau_str, index),
+                self._read_report(report_dict, self.beta, index)]
+
+    @staticmethod
+    def FWHM(tau: float) -> float:
+        """
+        Method to convert tau to FWHM
+        :param tau: tau parameter
+        :return FWHM
+        """
+        return 2.*PLANCK_CONSTANT/(2.*np.pi*tau)
+
+    @staticmethod
+    def tau(FWHM: float) -> float:
+        """
+        Method to get tau from FWHM
+        Used for estimation
+        :param FWHM: full width half maximum
+        :return tau parameter
+        """
+        return 2.*PLANCK_CONSTANT/(2.*np.pi*FWHM)
+
+    def report(self, report_dict: Dict[str, List[float]], a: float, x0: float,
+               tau: float, beta: float) -> Dict[str, List[float]]:
+        """
+        report parameters
+        :param report_dic: dict of results
+        :param a: amplitude
+        :param x0: the peak centre
+        :param tau: relaxation time
+        :param beta: stretching exponent
+        :return update results dict
+        """
+        report_dict = self._add_to_report(self.amplitude,
+                                          a, report_dict)
+        report_dict = self._add_to_report(self.x0,
+                                          x0, report_dict)
+        report_dict = self._add_to_report(self.beta,
+                                          beta, report_dict)
+        report_dict = self._add_to_report(self.tau_str,
+                                          tau, report_dict)
+        report_dict = self._add_to_report(f"{self._prefix}FWHM",
+                                          self.FWHM(tau), report_dict)
+        return report_dict
+
+    def report_errors(self, report_dict: Dict[str, List[float]],
+                      errors: ndarray,
+                      params: ndarray) -> Dict[str, List[float]]:
+        """
+        report parameters
+        :param report_dic: dict of parameter errors
+        :param errors: the errors for the fit parameters
+        :param params: the fit parameters
+        :return update results dict
+        """
+        report_dict = self._add_to_report(self.amplitude,
+                                          errors[0], report_dict)
+        report_dict = self._add_to_report(self.x0,
+                                          errors[1], report_dict)
+        report_dict = self._add_to_report(self.beta,
+                                          errors[3], report_dict)
+        report_dict = self._add_to_report(self.tau_str,
+                                          errors[2], report_dict)
+        """
+        FWHM = 2 hbar /tau
+        sigma_{FWHM} = 2 hbar sigma_tau / tau^2 = FWHM sigma_tau/tau
+        """
+        tmp = errors[2]/params[2]
+        report_dict = self._add_to_report(f"{self._prefix}FWHM",
+                                          self.FWHM(params[2])*tmp,
+                                          report_dict)
+        return report_dict
+
+    def set_guess_FWHM(self, values: List[float]) -> List[float]:
+        """
+        set the starting guess for a fit function
+        :param values: the guess values. The 3rd value is the FWHM
+        """
+        self._check_length(values, 'guess')
+        self._guess = [values[0], values[1],
+                       self.tau(values[2]), values[3]]
+
+    def set_guess(self, values: List[float]) -> List[float]:
+        """
+        set the starting guess for a fit function
+        :param values: the guess values. The 3rd value is the FWHM
+        """
+        self._check_length(values, 'guess')
+        self._guess = values
```

## quickBayes/fit_functions/stretch_exp_fixed.py

 * *Ordering differences only*

```diff
@@ -1,124 +1,124 @@
-from quickBayes.functions.SE import StretchExp
-from numpy import ndarray
-from typing import Dict, List
-
-
-class StretchExpWithFixes(StretchExp):
-    def __init__(self, FWHM: float = 0.2, beta: float = 0.8, prefix: str = ''):
-        """
-        Create a stretched exponential function with 2 fixed parameters.
-        :param FWHM: full width half max value for the fix
-        :param beta: the beta value for the fix
-        :param prefix: the prefix for the parameters
-        """
-        self._func = StretchExp()
-        self.set_beta(beta)
-        self.set_FWHM(FWHM)
-        super().__init__(prefix)
-        # change stuff for 2 free parameters
-        self._N_params = 2
-        self._guess = self._guess[0:2]
-        self._lower = self._lower[0:2]
-        self._upper = self._upper[0:2]
-
-    def set_FWHM(self, FWHM: float) -> None:
-        """
-        Update the FWHM fix value
-        :param FWHM: full width half max for fix
-        """
-        self._tau = self.tau(FWHM)
-
-    def set_beta(self, beta: float) -> None:
-        """
-        Update the beta fix value
-        :param beta: the beta value for fix
-        """
-        self._beta = beta
-
-    @property
-    def get_tau(self) -> float:
-        """
-        Get the tau value being used.
-        tau is related to the FWHM.
-        :return the tau value used in fix
-        """
-        return self._tau
-
-    @property
-    def get_beta(self) -> float:
-        """
-        Gets the beta value being used
-        :return beta value for fix
-        """
-        return self._beta
-
-    def __call__(self, x: ndarray,
-                 amplitude: float, x0: float) -> ndarray:
-        """
-        Implement the stretched exponential.
-        Need to follow the expected
-        form for scipy
-        :param x: x values for function evaluation
-        :param amplitude: amplitude
-        :param x0: the peak centre
-        :return y values for function evaluation
-        """
-        return super().__call__(x, amplitude, x0, self.get_tau, self.get_beta)
-
-    def read_from_report(self, report_dict: Dict[str, List[float]],
-                         index: int = 0) -> List[float]:
-        """
-        Read the parameters from the results dict
-        and sets beta and tau
-        :param report_dict: the dict of results
-        :param index: the index to get results from
-        :return the parameters
-        """
-        self._tau = self._read_report(report_dict, self.tau_str, index)
-        self.set_beta(self._read_report(report_dict, self.beta, index))
-
-        return [self._read_report(report_dict, self.amplitude, index),
-                self._read_report(report_dict, self.x0, index)]
-
-    def set_guess_FWHM(self, value: List[float]) -> None:
-        """
-        This is an inherited function that will not do anything
-        :param value: value to set
-        """
-        raise RuntimeError("this method does not work with fix")
-
-    def report(self, report_dict: Dict[str, List[float]],
-               a: float, x0: float) -> Dict[str, List[float]]:
-        """
-        report parameters, including the fixed ones.
-        :param report_dic: dict of results
-        :param a: amplitude
-        :param x0: the peak centre
-        :return update results dict
-        """
-        return super().report(report_dict, a, x0,
-                              self.get_tau, self.get_beta)
-
-    def report_errors(self, report_dict: Dict[str, List[float]],
-                      errors: ndarray,
-                      params: ndarray) -> Dict[str, List[float]]:
-        """
-        report parameters. The errors are 0 for the
-        fixed parameters.
-        :param report_dic: dict of parameter errors
-        :param errors: the errors for the fit parameters
-        :param params: the fit parameters
-        :return update results dict
-        """
-        report_dict = self._add_to_report(self.amplitude,
-                                          errors[0], report_dict)
-        report_dict = self._add_to_report(self.x0,
-                                          errors[1], report_dict)
-        report_dict = self._add_to_report(self.beta,
-                                          0.0, report_dict)
-        report_dict = self._add_to_report(self.tau_str,
-                                          0.0, report_dict)
-        report_dict = self._add_to_report(f"{self._prefix}FWHM",
-                                          0,
-                                          report_dict)
-        return report_dict
+from quickBayes.functions.SE import StretchExp
+from numpy import ndarray
+from typing import Dict, List
+
+
+class StretchExpWithFixes(StretchExp):
+    def __init__(self, FWHM: float = 0.2, beta: float = 0.8, prefix: str = ''):
+        """
+        Create a stretched exponential function with 2 fixed parameters.
+        :param FWHM: full width half max value for the fix
+        :param beta: the beta value for the fix
+        :param prefix: the prefix for the parameters
+        """
+        self._func = StretchExp()
+        self.set_beta(beta)
+        self.set_FWHM(FWHM)
+        super().__init__(prefix)
+        # change stuff for 2 free parameters
+        self._N_params = 2
+        self._guess = self._guess[0:2]
+        self._lower = self._lower[0:2]
+        self._upper = self._upper[0:2]
+
+    def set_FWHM(self, FWHM: float) -> None:
+        """
+        Update the FWHM fix value
+        :param FWHM: full width half max for fix
+        """
+        self._tau = self.tau(FWHM)
+
+    def set_beta(self, beta: float) -> None:
+        """
+        Update the beta fix value
+        :param beta: the beta value for fix
+        """
+        self._beta = beta
+
+    @property
+    def get_tau(self) -> float:
+        """
+        Get the tau value being used.
+        tau is related to the FWHM.
+        :return the tau value used in fix
+        """
+        return self._tau
+
+    @property
+    def get_beta(self) -> float:
+        """
+        Gets the beta value being used
+        :return beta value for fix
+        """
+        return self._beta
+
+    def __call__(self, x: ndarray,
+                 amplitude: float, x0: float) -> ndarray:
+        """
+        Implement the stretched exponential.
+        Need to follow the expected
+        form for scipy
+        :param x: x values for function evaluation
+        :param amplitude: amplitude
+        :param x0: the peak centre
+        :return y values for function evaluation
+        """
+        return super().__call__(x, amplitude, x0, self.get_tau, self.get_beta)
+
+    def read_from_report(self, report_dict: Dict[str, List[float]],
+                         index: int = 0) -> List[float]:
+        """
+        Read the parameters from the results dict
+        and sets beta and tau
+        :param report_dict: the dict of results
+        :param index: the index to get results from
+        :return the parameters
+        """
+        self._tau = self._read_report(report_dict, self.tau_str, index)
+        self.set_beta(self._read_report(report_dict, self.beta, index))
+
+        return [self._read_report(report_dict, self.amplitude, index),
+                self._read_report(report_dict, self.x0, index)]
+
+    def set_guess_FWHM(self, value: List[float]) -> None:
+        """
+        This is an inherited function that will not do anything
+        :param value: value to set
+        """
+        raise RuntimeError("this method does not work with fix")
+
+    def report(self, report_dict: Dict[str, List[float]],
+               a: float, x0: float) -> Dict[str, List[float]]:
+        """
+        report parameters, including the fixed ones.
+        :param report_dic: dict of results
+        :param a: amplitude
+        :param x0: the peak centre
+        :return update results dict
+        """
+        return super().report(report_dict, a, x0,
+                              self.get_tau, self.get_beta)
+
+    def report_errors(self, report_dict: Dict[str, List[float]],
+                      errors: ndarray,
+                      params: ndarray) -> Dict[str, List[float]]:
+        """
+        report parameters. The errors are 0 for the
+        fixed parameters.
+        :param report_dic: dict of parameter errors
+        :param errors: the errors for the fit parameters
+        :param params: the fit parameters
+        :return update results dict
+        """
+        report_dict = self._add_to_report(self.amplitude,
+                                          errors[0], report_dict)
+        report_dict = self._add_to_report(self.x0,
+                                          errors[1], report_dict)
+        report_dict = self._add_to_report(self.beta,
+                                          0.0, report_dict)
+        report_dict = self._add_to_report(self.tau_str,
+                                          0.0, report_dict)
+        report_dict = self._add_to_report(f"{self._prefix}FWHM",
+                                          0,
+                                          report_dict)
+        return report_dict
```

## quickBayes/utils/crop_data.py

 * *Ordering differences only*

```diff
@@ -1,24 +1,24 @@
-from numpy import ndarray
-import numpy as np
-
-
-def crop(x_data: ndarray, y_data: ndarray, e_data: ndarray,
-         start_x: float, end_x: float) -> (ndarray, ndarray, ndarray):
-    """
-    Simple function for cropping x, y, e data
-    :param x_data: x data to crop
-    :param y_data: y data to crop
-    :param e_data: error data to crop, does nothing if None
-    :param start_x: x value to start cropping from
-    :param end_x: x value to stop cropping at
-    :return cropped values for x, y, e (None if input is None)
-    """
-    start_index = np.searchsorted(x_data, start_x)
-    end_index = np.searchsorted(x_data, end_x)
-
-    x_crop = x_data[start_index:end_index]
-    y_crop = y_data[start_index:end_index]
-    e_crop = None
-    if e_data is not None:
-        e_crop = e_data[start_index:end_index]
-    return x_crop, y_crop, e_crop
+from numpy import ndarray
+import numpy as np
+
+
+def crop(x_data: ndarray, y_data: ndarray, e_data: ndarray,
+         start_x: float, end_x: float) -> (ndarray, ndarray, ndarray):
+    """
+    Simple function for cropping x, y, e data
+    :param x_data: x data to crop
+    :param y_data: y data to crop
+    :param e_data: error data to crop, does nothing if None
+    :param start_x: x value to start cropping from
+    :param end_x: x value to stop cropping at
+    :return cropped values for x, y, e (None if input is None)
+    """
+    start_index = np.searchsorted(x_data, start_x)
+    end_index = np.searchsorted(x_data, end_x)
+
+    x_crop = x_data[start_index:end_index]
+    y_crop = y_data[start_index:end_index]
+    e_crop = None
+    if e_data is not None:
+        e_crop = e_data[start_index:end_index]
+    return x_crop, y_crop, e_crop
```

## quickBayes/utils/general.py

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.functions.BG import (LinearBG,
-                                     FlatBG,
-                                     NoBG)
-from typing import List
-
-
-def get_background_function(BG_type: str) -> (BaseFitFunction):
-    """
-    A simple function for getting the BG type
-    :param BG_type: string of the BG type
-    :return the BG function
-    """
-    if BG_type.lower() == 'linear':
-        return LinearBG()
-    elif BG_type.lower() == "flat":
-        return FlatBG()
-    elif BG_type.lower() == "none":
-        return NoBG()
-    else:
-        raise ValueError("invalid BG function")
-
-
-def update_guess(params: List[float], func: BaseFitFunction) -> List[float]:
-    """
-    Get an updated list of guesses, using the known params
-    :param params: the known parameters
-    :param func: the fitting function
-    :return a list of updated guesses (keeps values from fit)
-    """
-    if len(params) > len(func.get_guess()):
-        raise ValueError("Too many parameters")
-    return params + func.get_guess()[len(params):]
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.functions.BG import (LinearBG,
+                                     FlatBG,
+                                     NoBG)
+from typing import List
+
+
+def get_background_function(BG_type: str) -> (BaseFitFunction):
+    """
+    A simple function for getting the BG type
+    :param BG_type: string of the BG type
+    :return the BG function
+    """
+    if BG_type.lower() == 'linear':
+        return LinearBG()
+    elif BG_type.lower() == "flat":
+        return FlatBG()
+    elif BG_type.lower() == "none":
+        return NoBG()
+    else:
+        raise ValueError("invalid BG function")
+
+
+def update_guess(params: List[float], func: BaseFitFunction) -> List[float]:
+    """
+    Get an updated list of guesses, using the known params
+    :param params: the known parameters
+    :param func: the fitting function
+    :return a list of updated guesses (keeps values from fit)
+    """
+    if len(params) > len(func.get_guess()):
+        raise ValueError("Too many parameters")
+    return params + func.get_guess()[len(params):]
```

## quickBayes/utils/spline.py

 * *Ordering differences only*

```diff
@@ -1,17 +1,17 @@
-from numpy import ndarray
-from scipy.interpolate import interp1d
-
-
-def spline(x_data: ndarray, y_data: ndarray,
-           new_x_values: ndarray) -> ndarray:
-    """
-    Simple function for interpolating and extrapolating
-    (to zero) data.
-    :param x_data: the origianl x data
-    :param y_data: the original y data
-    :param new_x_values: the new x data
-    :return the new y values
-    """
-    func = interp1d(x_data, y_data, bounds_error=False,
-                    fill_value=0., kind='cubic')
-    return func(new_x_values)
+from numpy import ndarray
+from scipy.interpolate import interp1d
+
+
+def spline(x_data: ndarray, y_data: ndarray,
+           new_x_values: ndarray) -> ndarray:
+    """
+    Simple function for interpolating and extrapolating
+    (to zero) data.
+    :param x_data: the origianl x data
+    :param y_data: the original y data
+    :param new_x_values: the new x data
+    :return the new y values
+    """
+    func = interp1d(x_data, y_data, bounds_error=False,
+                    fill_value=0., kind='cubic')
+    return func(new_x_values)
```

## quickBayes/workflows/workflow_template.py

```diff
@@ -1,173 +1,167 @@
-from quickBayes.fitting.scipy_engine import ScipyFitEngine
-from quickBayes.fitting.gofit_engine import GoFitEngine
-from quickBayes.functions.base import BaseFitFunction
-
-from quickBayes.utils.general import update_guess
-
-from numpy import ndarray
-from abc import abstractmethod
-
-
-class WorkflowTemplate(object):
-    """
-    This is a class for the quick bayes workflow.
-    Each method can be overwritten to provide
-    unique functionality for the specific
-    use case.
-
-    The properties are:
-    - fit_engine
-
-    To add a fit engine:
-    - set_scipy_engine (scipy curve fit)
-    - set_gofit_engine (gofit)
-
-    Other methods:
-    - preprocess_data
-    - update_fit_engine
-    - update_function (call this one not the overwritten one)
-    - execute
-    - fix_bounds
-    """
-    def __init__(self):
-        """
-        Set the results and error dicts for reporting
-        """
-        self._engine = None
-        self._data = None
-        self._raw = None
-        self._fix_bounds = False
-
-    @property
-    def get_raw(self):
-        """
-        Returns the original data
-        (i.e. the data fits are interpolated to match)
-        :return a dict of the raw data
-        """
-        return self._raw
-
-    @property
-    def fit_engine(self):
-        """
-        Simple method for getting the fit engine
-        :return the fit engine used
-        """
-        return self._engine
-
-    def preprocess_data(self, x_data: ndarray,
-                        y_data: ndarray, e_data: ndarray,
-                        *args: float) -> None:
-        """
-        The preprocessing needed for the data.
-        This simple case just assigns the data values.
-        This can be overwritten in a derived class to
-        include extra processing (e.g. cropping or
-        interpolating the data).
-        The data and raw data are assumed to be the same here
-        :param x_data: the x data to fit to
-        :param y_data: the y data to fit to
-        :param e_data: the errors for the y data
-        :param *args: additional arguments that might be needed
-        """
-        self._data = {'x': x_data, 'y': y_data, 'e': e_data}
-        self._raw = {'x': x_data, 'y': y_data, 'e': e_data}
-
-    def update_fit_engine(self, func: BaseFitFunction, params: ndarray,
-                          *args: float) -> None:
-        """
-        This updates the fit engine specific properties.
-        e.g. the bounds and guess for scipy
-        :param func: the fitting function
-        :param params: the fitting parameters
-        :param *args: additional arguments
-        """
-        if self._engine.name == 'scipy':
-            self.update_scipy_fit_engine(func, params)
-        elif self._engine.name == 'gofit':
-            self.update_gofit_engine(func)
-        else:
-            raise RuntimeError("The fit engine is "
-                               f"{self._engine.name} "
-                               "please use the appropriate "
-                               "update method")
-        return
-
-    @abstractmethod
-    def execute(self, *args) -> None:
-        """
-        The main part of the analysis.
-        It increments the number of features in the fitting function,
-        does a fit and then records the results.
-        :param args: the arguments
-        """
-        raise NotImplementedError()
-
-    def _check_engine_and_data_set_valid(self) -> None:
-        """
-        A simple check to see if the fit engine
-        has already been set and that data is
-        available for fitting.
-        """
-        if self._engine is not None:
-            raise RuntimeError("Cannot change the fitting engine.")
-        if self._data is None:
-            raise ValueError("self._data must be set, "
-                             "using preprocess_data or "
-                             "an equivalent method")
-
-    def set_scipy_engine(self, guess: ndarray, lower: ndarray,
-                         upper: ndarray) -> None:
-        """
-        Method to set the fit engine to be scipy
-        :param guess: the starting guess for the fit
-        :param lower: the lower bound for the fit
-        :param upper: the upper bound for the fit
-        """
-        self._check_engine_and_data_set_valid()
-        self._engine = ScipyFitEngine(self._raw['x'], self._raw['y'],
-                                      self._raw['e'], lower, upper,
-                                      guess)
-
-    def fix_bounds(self, state: bool) -> None:
-        """
-        A method to preserve the bounds when updating the
-        fitting function. This is for when we just want to
-        change the fitting parameters to a previous guess.
-        Default is False
-        :param state: if to fix the bounds
-        """
-        self._fix_bounds = state
-
-    def update_scipy_fit_engine(self, func: BaseFitFunction, params: ndarray):
-        """
-        This updates the bounds and guess for scipy fit engine
-        :param func: the fitting function
-        :param params: the fitting parameters
-        """
-        if self._fix_bounds:
-            lower, upper = self._engine._lower, self._engine._upper
-        else:
-            lower, upper = func.get_bounds()
-        guess = update_guess(list(params), func)
-        self._engine.set_guess_and_bounds(guess, lower, upper)
-
-    def set_gofit_engine(self, samples: int, lower: ndarray,
-                         upper: ndarray) -> None:
-        """
-        Method to set the fit engine to be gofit
-        :param samples: the number of samples to use
-        :param lower: the lower bound for the fit
-        :param upper: the upper bound for the fit
-        """
-        self._check_engine_and_data_set_valid()
-        self._engine = GoFitEngine(self._raw['x'], self._raw['y'],
-                                   self._raw['e'], lower, upper, samples)
-
-    def update_gofit_engine(self, func: BaseFitFunction):
-        """
-        This updates the bounds for gofit engine
-        :param func: the fitting function
-        """
-        lower, upper = func.get_bounds()
-        self._engine.set_bounds_and_N_params(lower, upper)
+from quickBayes.fitting.scipy_engine import ScipyFitEngine
+from quickBayes.fitting.gofit_engine import GoFitEngine
+from quickBayes.functions.base import BaseFitFunction
+
+from quickBayes.utils.general import update_guess
+
+from numpy import ndarray
+from abc import abstractmethod
+
+
+class WorkflowTemplate(object):
+    """
+    This is a class for the quick bayes workflow.
+    Each method can be overwritten to provide
+    unique functionality for the specific
+    use case.
+
+    The properties are:
+    - fit_engine
+
+    To add a fit engine:
+    - set_scipy_engine (scipy curve fit)
+    - set_gofit_engine (gofit)
+
+    Other methods:
+    - preprocess_data
+    - update_fit_engine
+    - update_function (call this one not the overwritten one)
+    - execute
+    """
+    def __init__(self):
+        """
+        Set the results and error dicts for reporting
+        """
+        self._engine = None
+        self._data = None
+        self._raw = None
+
+    @property
+    def get_raw(self):
+        """
+        Returns the original data
+        (i.e. the data fits are interpolated to match)
+        :return a dict of the raw data
+        """
+        return self._raw
+
+    @property
+    def fit_engine(self):
+        """
+        Simple method for getting the fit engine
+        :return the fit engine used
+        """
+        return self._engine
+
+    def preprocess_data(self, x_data: ndarray,
+                        y_data: ndarray, e_data: ndarray,
+                        *args: float) -> None:
+        """
+        The preprocessing needed for the data.
+        This simple case just assigns the data values.
+        This can be overwritten in a derived class to
+        include extra processing (e.g. cropping or
+        interpolating the data).
+        The data and raw data are assumed to be the same here
+        :param x_data: the x data to fit to
+        :param y_data: the y data to fit to
+        :param e_data: the errors for the y data
+        :param *args: additional arguments that might be needed
+        """
+        self._data = {'x': x_data, 'y': y_data, 'e': e_data}
+        self._raw = {'x': x_data, 'y': y_data, 'e': e_data}
+
+    def update_fit_engine(self, func: BaseFitFunction, params: ndarray,
+                          *args: float) -> None:
+        """
+        This updates the fit engine specific properties.
+        e.g. the bounds and guess for scipy
+        :param func: the fitting function
+        :param params: the fitting parameters
+        :param *args: additional arguments
+        """
+        if self._engine.name == 'scipy':
+            self.update_scipy_fit_engine(func, params)
+        elif self._engine.name == 'gofit':
+            self.update_gofit_engine(func)
+        else:
+            raise RuntimeError("The fit engine is "
+                               f"{self._engine.name} "
+                               "please use the appropriate "
+                               "update method")
+        return
+
+    @abstractmethod
+    def execute(self, *args) -> None:
+        """
+        The main part of the analysis.
+        It increments the number of features in the fitting function,
+        does a fit and then records the results.
+        :param args: the arguments
+        """
+        raise NotImplementedError()
+
+    def _check_engine_and_data_set_valid(self) -> None:
+        """
+        A simple check to see if the fit engine
+        has already been set and that data is
+        available for fitting.
+        """
+        if self._engine is not None:
+            raise RuntimeError("Cannot change the fitting engine.")
+        if self._data is None:
+            raise ValueError("self._data must be set, "
+                             "using preprocess_data or "
+                             "an equivalent method")
+
+    def set_scipy_engine(self, guess: ndarray, lower: ndarray,
+                         upper: ndarray) -> None:
+        """
+        Method to set the fit engine to be scipy
+        :param guess: the starting guess for the fit
+        :param lower: the lower bound for the fit
+        :param upper: the upper bound for the fit
+        """
+        self._check_engine_and_data_set_valid()
+        self._engine = ScipyFitEngine(self._raw['x'], self._raw['y'],
+                                      self._raw['e'], lower, upper,
+                                      guess)
+
+    def _get_bounds(self, func: BaseFitFunction) -> (ndarray, ndarray):
+        """
+        Get the bounds for the fit engine
+        :param func: the fit function
+        :returns the lower and upper bounds
+        """
+        return func.get_bounds()
+
+    def update_scipy_fit_engine(self, func: BaseFitFunction, params: ndarray):
+        """
+        This updates the bounds and guess for scipy fit engine
+        :param func: the fitting function
+        :param params: the fitting parameters
+        """
+        lower, upper = self._get_bounds(func)
+
+        guess = update_guess(list(params), func)
+        self._engine.set_guess_and_bounds(guess, lower, upper)
+
+    def set_gofit_engine(self, samples: int, lower: ndarray,
+                         upper: ndarray) -> None:
+        """
+        Method to set the fit engine to be gofit
+        :param samples: the number of samples to use
+        :param lower: the lower bound for the fit
+        :param upper: the upper bound for the fit
+        """
+        self._check_engine_and_data_set_valid()
+        self._engine = GoFitEngine(self._raw['x'], self._raw['y'],
+                                   self._raw['e'], lower, upper, samples)
+
+    def update_gofit_engine(self, func: BaseFitFunction):
+        """
+        This updates the bounds for gofit engine
+        :param func: the fitting function
+        """
+        lower, upper = func.get_bounds()
+        self._engine.set_bounds_and_N_params(lower, upper)
```

## quickBayes/workflows/grid_search/grid_search_template.py

```diff
@@ -1,260 +1,264 @@
-from quickBayes.workflow.template import WorkflowTemplate
-from quickBayes.log_likelihood import loglikelihood
-from quickBayes.functions.base import BaseFitFunction
-
-from numpy import ndarray
-import numpy as np
-from abc import abstractmethod
-
-
-class Axis(object):
-    """
-    A simple object for holding the information
-    about an axis
-    """
-    def __init__(self, start, end, N, label='x'):
-        """
-        Create an axis
-        :param start: the first value for the axis
-        :param end: the last value for the axis
-        :param N: the number of values along the axis
-        :param label: the name of the axis
-        """
-        self._len = N
-        self._label = label
-        self._vals = np.linspace(start, end, N)
-
-    @property
-    def label(self) -> str:
-        """
-        Get the label for the axis
-        :return the label
-        """
-        return self._label
-
-    @property
-    def len(self):
-        """
-        Get the length of the axis
-        :return the length of the axis
-        """
-        return self._len
-
-    @property
-    def values(self):
-        """
-        Get the values used on the axis
-        :return the values from the axis
-        """
-        return self._vals
-
-
-class GridSearchTemplate(WorkflowTemplate):
-    """
-    A workflow for a grid search.
-    A grid search will do a series of fits for a range of
-    x and y values, that correspond to fixed parameters in
-    the fitting function.
-
-    The inherited class must include:
-    - _set_x_value
-    - _set_y_value
-    - N
-
-    The properties are:
-    - fit_engine
-    - get_grid
-    - get_x_axis
-    - get_y_axis
-
-    To add a fit engine:
-    - set_scipy_engine (scipy curve fit, recommended)
-    - set_gofit_engine (gofit)
-
-    Other methods:
-    - preprocess_data
-    - update_fit_engine
-    - update_function (call this one not the overwritten one)
-    - execute
-    - set_x_axis
-    - set_y_axis
-    - N
-    """
-    def __init__(self):
-        """
-        Set the results and error dicts for reporting
-        """
-        super().__init__()
-        self._x_axis = None
-        self._y_axis = None
-        self._grid = None
-
-    def set_x_axis(self, start: float, end: float,
-                   N: int, label: str) -> None:
-        """
-        Sets the x axis for the workflow
-        :param start: the first value on the x axis
-        :param end: the last value on the x axis
-        :param N: the number of values on the x axis
-        :param label: the x axis label
-        """
-        self._x_axis = Axis(start, end, N, label)
-
-    @property
-    def get_x_axis(self) -> Axis:
-        """
-        Get the x axis
-        :return the x axis object
-        """
-        return self._x_axis
-
-    def set_y_axis(self, start: float, end: float,
-                   N: int, label: str) -> None:
-        """
-        Sets the y axis for the workflow
-        :param start: the first value on the y axis
-        :param end: the last value on the y axis
-        :param N: the number of values on the y axis
-        :param label: the y axis label
-        """
-        self._y_axis = Axis(start, end, N, label)
-
-    @property
-    def get_y_axis(self) -> Axis:
-        """
-        Get the y axis
-        :return the y axis object
-        """
-        return self._y_axis
-
-    def _generate_grid(self) -> (ndarray, ndarray):
-        """
-        Creates a grid from the axis.
-        Need to have set the x and y axis first.
-        :return the X and Y values from np.meshgrid
-        """
-        if self._x_axis is None or self._y_axis is None:
-            raise ValueError("The x and/or y axis has"
-                             " not been set. Please use "
-                             "set_x_axis and set_y_axis.")
-
-        X, Y = np.meshgrid(self._x_axis.values,
-                           self._y_axis.values)
-        self._grid = self._empty_mesh(X)
-        return X, Y
-
-    @staticmethod
-    def _empty_mesh(X: ndarray) -> None:
-        """
-        Creates a grid of the correct size with zeros
-        :param X: one of the meshgrid outputs
-        """
-        return np.zeros(X.shape)
-
-    @property
-    def get_grid(self) -> ndarray:
-        """
-        Get the grid values
-        :return the grid values
-        """
-        return self._grid
-
-    def get_slices(self) -> (ndarray, ndarray):
-        """
-        Gets slices along the x and y axis, such that
-        the peak grid value is in both slices.
-        :return the x and y data slices
-        """
-        indices = np.where(self._grid == self._grid.max())
-        x_slice = self._grid[indices[0], :][0]
-        y_slice = [vec[0] for vec in self._grid[:, indices[1]]]
-        return x_slice, np.array(y_slice)
-
-    @abstractmethod
-    def _set_x_value(self, func: BaseFitFunction,
-                     value: float) -> BaseFitFunction:
-        """
-        Sets the x value (fixed fit parameter)
-        :param func: the function that is being updated
-        :param value: the fix value
-        """
-        raise NotImplementedError()
-
-    @abstractmethod
-    def _set_y_value(self, func: BaseFitFunction,
-                     value: float) -> BaseFitFunction:
-        """
-        Sets the y value (fixed fit parameter)
-        :param func: the function that is being updated
-        :param value: the fix value
-        """
-        raise NotImplementedError()
-
-    def _get_z_value(self, N_p: int, N_f: int, scale: float) -> float:
-        """
-        Gets the loglikelihood value
-        :param N_p: the number of data points being fitted to
-        :param N_f: the number of features being fitted to
-        :param scale: the beta scale factor for loglikelihood
-        :return the loglikelihood
-        """
-        chi2 = self._engine.get_chi_squared()
-        covar = self._engine.get_covariance_matrix()
-        return loglikelihood(N_p, chi2, covar,
-                             N_f, scale)
-
-    def _normalise_grid(self) -> None:
-        """
-        Rescales the grid values so that the max is 1
-        and the min is 0. This should make features clearer
-        """
-        self._grid = np.min(self._grid)/self._grid
-        self._grid -= np.min(self._grid)
-        self._grid /= np.max(self._grid)
-
-    @abstractmethod
-    def N(self, func: BaseFitFunction) -> int:
-        """
-        Gets the number of features in the fit function
-        :param func: the fitting function
-        :return the number of features
-        """
-        raise NotImplementedError()
-
-    def execute(self, func: BaseFitFunction) -> (ndarray, ndarray):
-        """
-        Does the grid search. Needs the x and y axis to be set.
-        Also needs a fitting engine to be set.
-        :param func: the fitting function
-        :return the X and Y values for the grid
-        """
-        if self._engine is None:
-            raise ValueError("please set a fit engine")
-        x_data = self._data['x']
-        y_data = self._data['y']
-        e_data = self._data['e']
-        scale = np.max(y_data)*(np.max(x_data) - np.min(x_data))
-
-        X, Y = self._generate_grid()
-
-        # N = len(self.get_x_axis.values)*len(self.get_y_axis.values)
-        counter = 0
-        self.fix_bounds(True)
-        for i, xx in enumerate(self.get_x_axis.values):
-            func = self._set_x_value(func, xx)
-            params = func.get_guess()
-
-            for j, yy in enumerate(self.get_y_axis.values):
-                func = self._set_y_value(func, yy)
-                self._engine.do_fit(x_data, y_data, e_data, func)
-                params, _ = self._engine.get_fit_parameters()
-
-                num = self.N(func)
-                self._grid[j][i] = self._get_z_value(len(x_data),
-                                                     num,
-                                                     scale)
-                self.update_fit_engine(func, params)
-                counter += 1
-                # print(f'\rPercentage complete: {100*counter/N:2f}')
-        self._normalise_grid()
-        return X, Y
+from quickBayes.workflow.template import WorkflowTemplate
+from quickBayes.log_likelihood import loglikelihood
+from quickBayes.functions.base import BaseFitFunction
+
+from numpy import ndarray
+import numpy as np
+from abc import abstractmethod
+
+
+class Axis(object):
+    """
+    A simple object for holding the information
+    about an axis
+    """
+    def __init__(self, start, end, N, label='x'):
+        """
+        Create an axis
+        :param start: the first value for the axis
+        :param end: the last value for the axis
+        :param N: the number of values along the axis
+        :param label: the name of the axis
+        """
+        self._len = N
+        self._label = label
+        self._vals = np.linspace(start, end, N)
+
+    @property
+    def label(self) -> str:
+        """
+        Get the label for the axis
+        :return the label
+        """
+        return self._label
+
+    @property
+    def len(self):
+        """
+        Get the length of the axis
+        :return the length of the axis
+        """
+        return self._len
+
+    @property
+    def values(self):
+        """
+        Get the values used on the axis
+        :return the values from the axis
+        """
+        return self._vals
+
+
+class GridSearchTemplate(WorkflowTemplate):
+    """
+    A workflow for a grid search.
+    A grid search will do a series of fits for a range of
+    x and y values, that correspond to fixed parameters in
+    the fitting function.
+
+    The inherited class must include:
+    - _set_x_value
+    - _set_y_value
+    - N
+
+    The properties are:
+    - fit_engine
+    - get_grid
+    - get_x_axis
+    - get_y_axis
+
+    To add a fit engine:
+    - set_scipy_engine (scipy curve fit, recommended)
+    - set_gofit_engine (gofit)
+
+    Other methods:
+    - preprocess_data
+    - update_fit_engine
+    - update_function (call this one not the overwritten one)
+    - execute
+    - set_x_axis
+    - set_y_axis
+    - N
+    """
+    def __init__(self):
+        """
+        Set the results and error dicts for reporting
+        """
+        super().__init__()
+        self._x_axis = None
+        self._y_axis = None
+        self._grid = None
+
+    def set_x_axis(self, start: float, end: float,
+                   N: int, label: str) -> None:
+        """
+        Sets the x axis for the workflow
+        :param start: the first value on the x axis
+        :param end: the last value on the x axis
+        :param N: the number of values on the x axis
+        :param label: the x axis label
+        """
+        self._x_axis = Axis(start, end, N, label)
+
+    @property
+    def get_x_axis(self) -> Axis:
+        """
+        Get the x axis
+        :return the x axis object
+        """
+        return self._x_axis
+
+    def set_y_axis(self, start: float, end: float,
+                   N: int, label: str) -> None:
+        """
+        Sets the y axis for the workflow
+        :param start: the first value on the y axis
+        :param end: the last value on the y axis
+        :param N: the number of values on the y axis
+        :param label: the y axis label
+        """
+        self._y_axis = Axis(start, end, N, label)
+
+    @property
+    def get_y_axis(self) -> Axis:
+        """
+        Get the y axis
+        :return the y axis object
+        """
+        return self._y_axis
+
+    def _generate_grid(self) -> (ndarray, ndarray):
+        """
+        Creates a grid from the axis.
+        Need to have set the x and y axis first.
+        :return the X and Y values from np.meshgrid
+        """
+        if self._x_axis is None or self._y_axis is None:
+            raise ValueError("The x and/or y axis has"
+                             " not been set. Please use "
+                             "set_x_axis and set_y_axis.")
+
+        X, Y = np.meshgrid(self._x_axis.values,
+                           self._y_axis.values)
+        self._grid = self._empty_mesh(X)
+        return X, Y
+
+    @staticmethod
+    def _empty_mesh(X: ndarray) -> None:
+        """
+        Creates a grid of the correct size with zeros
+        :param X: one of the meshgrid outputs
+        """
+        return np.zeros(X.shape)
+
+    @property
+    def get_grid(self) -> ndarray:
+        """
+        Get the grid values
+        :return the grid values
+        """
+        return self._grid
+
+    def get_slices(self) -> (ndarray, ndarray):
+        """
+        Gets slices along the x and y axis, such that
+        the peak grid value is in both slices.
+        :return the x and y data slices
+        """
+        indices = np.where(self._grid == self._grid.max())
+        x_slice = self._grid[indices[0], :][0]
+        y_slice = [vec[0] for vec in self._grid[:, indices[1]]]
+        return x_slice, np.array(y_slice)
+
+    @abstractmethod
+    def _set_x_value(self, func: BaseFitFunction,
+                     value: float) -> BaseFitFunction:
+        """
+        Sets the x value (fixed fit parameter)
+        :param func: the function that is being updated
+        :param value: the fix value
+        """
+        raise NotImplementedError()
+
+    @abstractmethod
+    def _set_y_value(self, func: BaseFitFunction,
+                     value: float) -> BaseFitFunction:
+        """
+        Sets the y value (fixed fit parameter)
+        :param func: the function that is being updated
+        :param value: the fix value
+        """
+        raise NotImplementedError()
+
+    def _get_z_value(self, N_p: int, N_f: int, scale: float) -> float:
+        """
+        Gets the loglikelihood value
+        :param N_p: the number of data points being fitted to
+        :param N_f: the number of features being fitted to
+        :param scale: the beta scale factor for loglikelihood
+        :return the loglikelihood
+        """
+        chi2 = self._engine.get_chi_squared()
+        covar = self._engine.get_covariance_matrix()
+        return loglikelihood(N_p, chi2, covar,
+                             N_f, scale)
+
+    def _normalise_grid(self) -> None:
+        """
+        Rescales the grid values so that the max is 1
+        and the min is 0. This should make features clearer
+        """
+        self._grid = np.min(self._grid)/self._grid
+        self._grid -= np.min(self._grid)
+        self._grid /= np.max(self._grid)
+
+    @abstractmethod
+    def N(self, func: BaseFitFunction) -> int:
+        """
+        Gets the number of features in the fit function
+        :param func: the fitting function
+        :return the number of features
+        """
+        raise NotImplementedError()
+
+    def _get_bounds(self, func: BaseFitFunction) -> (ndarray, ndarray):
+        """
+        Get the bounds for the fit engine
+        For a grid search we want the original
+        bounds
+        :param func: the fit function
+        :returns the lower and upper bounds
+        """
+        return self._engine._lower, self._engine._upper
+
+    def execute(self, func: BaseFitFunction) -> (ndarray, ndarray):
+        """
+        Does the grid search. Needs the x and y axis to be set.
+        Also needs a fitting engine to be set.
+        :param func: the fitting function
+        :return the X and Y values for the grid
+        """
+        if self._engine is None:
+            raise ValueError("please set a fit engine")
+        x_data = self._data['x']
+        y_data = self._data['y']
+        e_data = self._data['e']
+        scale = np.max(y_data)*(np.max(x_data) - np.min(x_data))
+
+        X, Y = self._generate_grid()
+        for i, xx in enumerate(self.get_x_axis.values):
+            func = self._set_x_value(func, xx)
+            params = func.get_guess()
+
+            for j, yy in enumerate(self.get_y_axis.values):
+                func = self._set_y_value(func, yy)
+                self._engine.do_fit(x_data, y_data, e_data, func)
+                params, _ = self._engine.get_fit_parameters()
+
+                num = self.N(func)
+                self._grid[j][i] = self._get_z_value(len(x_data),
+                                                     num,
+                                                     scale)
+                self.update_fit_engine(func, params)
+        self._normalise_grid()
+        return X, Y
```

## quickBayes/workflows/grid_search/qse_grid_search.py

 * *Ordering differences only*

```diff
@@ -1,94 +1,94 @@
-from quickBayes.workflow.grid_template import GridSearchTemplate
-from quickBayes.functions.qse_fixed import QSEFixFunction
-from quickBayes.utils.spline import spline
-from numpy import ndarray
-from typing import Dict
-import numpy as np
-
-
-class QSEGridSearch(GridSearchTemplate):
-    """
-    A workflow for doing a grid search of quasielastic
-    data to fit a stretch exponential for different
-    (fixed) beta and FWHM values.
-
-    The properties are:
-    - fit_engine
-    - get_grid
-    - get_x_axis
-    - get_y_axis
-    - N
-
-    To add a fit engine:
-    - set_scipy_engine (scipy curve fit, recommended)
-    - set_gofit_engine (gofit)
-
-    Other methods:
-    - preprocess_data
-    - update_fit_engine
-    - update_function (call this one not the overwritten one)
-    - execute
-    - set_x_axis
-    - set_y_axis
-    """
-    def preprocess_data(self, x_data: ndarray,
-                        y_data: ndarray, e_data: ndarray,
-                        start_x: float, end_x: float,
-                        res: Dict[str, ndarray]) -> (ndarray, ndarray):
-        """
-        The preprocessing needed for the data.
-        It splines the sample and resolution data
-        to the same uniform grid.
-        This is designed for a fixed stretched exp.
-        :param x_data: the sample x data to fit to
-        :param y_data: the sample y data to fit to
-        :param e_data: the sample errors for the y data
-        :param start_x: the start x value
-        :param end_x: the end x value
-        :param res: a dict of the resolution data (keys =x, y, e)
-        :return the new x range and the new resolution y values
-        """
-        dx = x_data[1] - x_data[0]
-        new_x = np.linspace(start_x, end_x, int((end_x - start_x)/dx))
-
-        sy = spline(x_data, y_data, new_x)
-        se = spline(x_data, e_data, new_x)
-        ry = spline(res['x'], res['y'], new_x)
-        super().preprocess_data(new_x, sy, se)
-
-        return new_x, ry
-
-    @staticmethod
-    def _set_x_value(func: QSEFixFunction,
-                     value: float) -> QSEFixFunction:
-        """
-        Sets the beta value for the fit
-        function (x axis)
-        :param func: the stretch exp with fixes function
-        :param value: the value to fix beta to
-        :return the updated fit function
-        """
-        func.set_beta(value)
-        return func
-
-    @staticmethod
-    def _set_y_value(func: QSEFixFunction,
-                     value: float) -> QSEFixFunction:
-        """
-        Sets the FWHM (tau) value for the fit
-        function (y axis)
-        :param func: the stretch exp with fixes function
-        :param value: the value to fix FWHM (tau) to
-        :return the updated fit function
-        """
-        func.set_FWHM(value)
-        return func
-
-    @staticmethod
-    def N(func: QSEFixFunction) -> int:
-        """
-        Get the number of features from fit
-        :param func: the fitting function
-        :return the number of features
-        """
-        return func.N_peaks
+from quickBayes.workflow.grid_template import GridSearchTemplate
+from quickBayes.functions.qse_fixed import QSEFixFunction
+from quickBayes.utils.spline import spline
+from numpy import ndarray
+from typing import Dict
+import numpy as np
+
+
+class QSEGridSearch(GridSearchTemplate):
+    """
+    A workflow for doing a grid search of quasielastic
+    data to fit a stretch exponential for different
+    (fixed) beta and FWHM values.
+
+    The properties are:
+    - fit_engine
+    - get_grid
+    - get_x_axis
+    - get_y_axis
+    - N
+
+    To add a fit engine:
+    - set_scipy_engine (scipy curve fit, recommended)
+    - set_gofit_engine (gofit)
+
+    Other methods:
+    - preprocess_data
+    - update_fit_engine
+    - update_function (call this one not the overwritten one)
+    - execute
+    - set_x_axis
+    - set_y_axis
+    """
+    def preprocess_data(self, x_data: ndarray,
+                        y_data: ndarray, e_data: ndarray,
+                        start_x: float, end_x: float,
+                        res: Dict[str, ndarray]) -> (ndarray, ndarray):
+        """
+        The preprocessing needed for the data.
+        It splines the sample and resolution data
+        to the same uniform grid.
+        This is designed for a fixed stretched exp.
+        :param x_data: the sample x data to fit to
+        :param y_data: the sample y data to fit to
+        :param e_data: the sample errors for the y data
+        :param start_x: the start x value
+        :param end_x: the end x value
+        :param res: a dict of the resolution data (keys =x, y, e)
+        :return the new x range and the new resolution y values
+        """
+        dx = x_data[1] - x_data[0]
+        new_x = np.linspace(start_x, end_x, int((end_x - start_x)/dx))
+
+        sy = spline(x_data, y_data, new_x)
+        se = spline(x_data, e_data, new_x)
+        ry = spline(res['x'], res['y'], new_x)
+        super().preprocess_data(new_x, sy, se)
+
+        return new_x, ry
+
+    @staticmethod
+    def _set_x_value(func: QSEFixFunction,
+                     value: float) -> QSEFixFunction:
+        """
+        Sets the beta value for the fit
+        function (x axis)
+        :param func: the stretch exp with fixes function
+        :param value: the value to fix beta to
+        :return the updated fit function
+        """
+        func.set_beta(value)
+        return func
+
+    @staticmethod
+    def _set_y_value(func: QSEFixFunction,
+                     value: float) -> QSEFixFunction:
+        """
+        Sets the FWHM (tau) value for the fit
+        function (y axis)
+        :param func: the stretch exp with fixes function
+        :param value: the value to fix FWHM (tau) to
+        :return the updated fit function
+        """
+        func.set_FWHM(value)
+        return func
+
+    @staticmethod
+    def N(func: QSEFixFunction) -> int:
+        """
+        Get the number of features from fit
+        :param func: the fitting function
+        :return the number of features
+        """
+        return func.N_peaks
```

## quickBayes/workflows/model_selection/model_template.py

 * *Ordering differences only*

```diff
@@ -1,146 +1,146 @@
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.workflow.template import WorkflowTemplate
-
-from quickBayes.log_likelihood import loglikelihood
-
-from numpy import ndarray
-import numpy as np
-from typing import Dict
-from abc import abstractmethod
-
-
-class ModelSelectionWorkflow(WorkflowTemplate):
-    """
-    This is a class for the quick bayes model selection workflow.
-    Each method can be overwritten to provide
-    unique functionality for the specific
-    use case.
-
-    The inherited class must include:
-    - _update_function method to increment the fit function
-
-    The properties are:
-    - fit_engine
-    - get_parameters_and_errors
-
-    To add a fit engine:
-    - set_scipy_engine (scipy curve fit)
-    - set_gofit_engine (gofit)
-
-    Other methods:
-    - preprocess_data
-    - update_fit_engine
-    - update_function (call this one not the overwritten one)
-    - report
-    - execute
-    """
-
-    def __init__(self, results: Dict[str, ndarray],
-                 results_errors: Dict[str, ndarray]):
-        """
-        Set the results and error dicts for reporting
-        :param results: dict of parameter values
-        :param results_errors: dict of parameter errors
-        """
-        self._results_dict = results
-        self._errors_dict = results_errors
-        super().__init__()
-
-    @property
-    def get_parameters_and_errors(self) -> (Dict[str, float],
-                                            Dict[str, float]):
-        """
-        Method to get the dict's of the fit parameters and errors.
-        :return dict of fit parameters, dict of fit parameter errors
-        """
-        return self._results_dict, self._errors_dict
-
-    @abstractmethod
-    def _update_function(self, func: BaseFitFunction) -> BaseFitFunction:
-        """
-        This method updates the fitting function when the number of
-        features has been incremented.
-        It will be unique to the workflow.
-        :param func: the fitting function that needs modifying
-        :return the modified fitting function
-        """
-        raise NotImplementedError()
-
-    def update_function(self, func: BaseFitFunction,
-                        N: int) -> BaseFitFunction:
-        """
-        This method updates the fitting function when the number of
-        features has been incremented.
-        It will be unique to the workflow.
-        :param func: the fitting function that needs modifying
-        :return the modified fitting function
-        """
-        function = self._update_function(func)
-        function.update_prefix(f'N{N}:')
-        return function
-
-    def report(self, func: BaseFitFunction, N: int, beta: float) -> ndarray:
-        """
-        Reports the latest fit parameters and records the fit
-        parameters and their errors into dicts.
-        :param func: the fitting function used
-        :param N: the number of features used
-        :param beta: the beta scaling factor
-        :return the fit parameters
-        """
-        params, errors = self._engine.get_fit_parameters()
-
-        self._results_dict = func.report(self._results_dict, *params)
-        self._errors_dict = func.report_errors(self._errors_dict,
-                                               errors, params)
-
-        prob_name = f'N{N}:loglikelihood'
-        n_data = len(self._data['y'])
-        chi2 = self._engine.get_chi_squared()
-        covar = self._engine.get_covariance_matrix()
-
-        if prob_name in self._results_dict.keys():
-            self._results_dict[prob_name].append(loglikelihood(n_data,
-                                                               chi2,
-                                                               covar,
-                                                               N, beta))
-        else:
-            self._results_dict[prob_name] = [loglikelihood(n_data,
-                                                           chi2,
-                                                           covar,
-                                                           N, beta)]
-
-        return params
-
-    def execute(self, max_num_features: int,
-                func: BaseFitFunction,
-                params: ndarray = []) -> BaseFitFunction:
-        """
-        The main part of the analysis.
-        It increments the number of features in the fitting function,
-        does a fit and then records the results.
-        :param max_num_features: the maximum number of features
-        :param func: the fitting function
-        :param params: the (optional) initial fit parameters
-        :return the update fitting function
-        """
-        if self._data is None:
-            raise ValueError("self._data must be set, "
-                             "using preprocess_data or "
-                             "an equivalent method")
-        elif self._engine is None:
-            raise ValueError("A fitting engine must be set, "
-                             "by calling one of: \n"
-                             "set_scipy_engine")
-
-        beta = np.max(self._data['y'])*(np.max(self._data['x']) -
-                                        np.min(self._data['x']))
-
-        for N in range(1, max_num_features + 1):
-            func = self.update_function(func, N)
-            self.update_fit_engine(func, params)
-
-            self._engine.do_fit(self._data['x'], self._data['y'],
-                                self._data['e'], func)
-
-            params = self.report(func, N, beta)
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.workflow.template import WorkflowTemplate
+
+from quickBayes.log_likelihood import loglikelihood
+
+from numpy import ndarray
+import numpy as np
+from typing import Dict
+from abc import abstractmethod
+
+
+class ModelSelectionWorkflow(WorkflowTemplate):
+    """
+    This is a class for the quick bayes model selection workflow.
+    Each method can be overwritten to provide
+    unique functionality for the specific
+    use case.
+
+    The inherited class must include:
+    - _update_function method to increment the fit function
+
+    The properties are:
+    - fit_engine
+    - get_parameters_and_errors
+
+    To add a fit engine:
+    - set_scipy_engine (scipy curve fit)
+    - set_gofit_engine (gofit)
+
+    Other methods:
+    - preprocess_data
+    - update_fit_engine
+    - update_function (call this one not the overwritten one)
+    - report
+    - execute
+    """
+
+    def __init__(self, results: Dict[str, ndarray],
+                 results_errors: Dict[str, ndarray]):
+        """
+        Set the results and error dicts for reporting
+        :param results: dict of parameter values
+        :param results_errors: dict of parameter errors
+        """
+        self._results_dict = results
+        self._errors_dict = results_errors
+        super().__init__()
+
+    @property
+    def get_parameters_and_errors(self) -> (Dict[str, float],
+                                            Dict[str, float]):
+        """
+        Method to get the dict's of the fit parameters and errors.
+        :return dict of fit parameters, dict of fit parameter errors
+        """
+        return self._results_dict, self._errors_dict
+
+    @abstractmethod
+    def _update_function(self, func: BaseFitFunction) -> BaseFitFunction:
+        """
+        This method updates the fitting function when the number of
+        features has been incremented.
+        It will be unique to the workflow.
+        :param func: the fitting function that needs modifying
+        :return the modified fitting function
+        """
+        raise NotImplementedError()
+
+    def update_function(self, func: BaseFitFunction,
+                        N: int) -> BaseFitFunction:
+        """
+        This method updates the fitting function when the number of
+        features has been incremented.
+        It will be unique to the workflow.
+        :param func: the fitting function that needs modifying
+        :return the modified fitting function
+        """
+        function = self._update_function(func)
+        function.update_prefix(f'N{N}:')
+        return function
+
+    def report(self, func: BaseFitFunction, N: int, beta: float) -> ndarray:
+        """
+        Reports the latest fit parameters and records the fit
+        parameters and their errors into dicts.
+        :param func: the fitting function used
+        :param N: the number of features used
+        :param beta: the beta scaling factor
+        :return the fit parameters
+        """
+        params, errors = self._engine.get_fit_parameters()
+
+        self._results_dict = func.report(self._results_dict, *params)
+        self._errors_dict = func.report_errors(self._errors_dict,
+                                               errors, params)
+
+        prob_name = f'N{N}:loglikelihood'
+        n_data = len(self._data['y'])
+        chi2 = self._engine.get_chi_squared()
+        covar = self._engine.get_covariance_matrix()
+
+        if prob_name in self._results_dict.keys():
+            self._results_dict[prob_name].append(loglikelihood(n_data,
+                                                               chi2,
+                                                               covar,
+                                                               N, beta))
+        else:
+            self._results_dict[prob_name] = [loglikelihood(n_data,
+                                                           chi2,
+                                                           covar,
+                                                           N, beta)]
+
+        return params
+
+    def execute(self, max_num_features: int,
+                func: BaseFitFunction,
+                params: ndarray = []) -> BaseFitFunction:
+        """
+        The main part of the analysis.
+        It increments the number of features in the fitting function,
+        does a fit and then records the results.
+        :param max_num_features: the maximum number of features
+        :param func: the fitting function
+        :param params: the (optional) initial fit parameters
+        :return the update fitting function
+        """
+        if self._data is None:
+            raise ValueError("self._data must be set, "
+                             "using preprocess_data or "
+                             "an equivalent method")
+        elif self._engine is None:
+            raise ValueError("A fitting engine must be set, "
+                             "by calling one of: \n"
+                             "set_scipy_engine")
+
+        beta = np.max(self._data['y'])*(np.max(self._data['x']) -
+                                        np.min(self._data['x']))
+
+        for N in range(1, max_num_features + 1):
+            func = self.update_function(func, N)
+            self.update_fit_engine(func, params)
+
+            self._engine.do_fit(self._data['x'], self._data['y'],
+                                self._data['e'], func)
+
+            params = self.report(func, N, beta)
```

## quickBayes/workflows/model_selection/muon_exp_decay_main.py

 * *Ordering differences only*

```diff
@@ -1,94 +1,94 @@
-from quickBayes.functions.composite import CompositeFunction
-from quickBayes.functions.exp_decay import ExpDecay
-from quickBayes.utils.general import get_background_function
-from quickBayes.utils.crop_data import crop
-from quickBayes.workflow.model_template import ModelSelectionWorkflow
-from quickBayes.functions.base import BaseFitFunction
-from numpy import ndarray
-from typing import Dict, List
-
-
-class MuonExpDecay(ModelSelectionWorkflow):
-    """
-    A class for the muon exponential decay workflow
-    """
-    def preprocess_data(self, x_data: ndarray,
-                        y_data: ndarray, e_data: ndarray,
-                        start_x: float, end_x: float) -> None:
-        """
-        The preprocessing needed for the data.
-        This crops and stores the data.
-        :param x_data: the x data to fit to
-        :param y_data: the y data to fit to
-        :param e_data: the errors for the y data
-        :param start_x: the start x value
-        :param end_x: the end x value
-        """
-        sx, sy, se = crop(x_data, y_data, e_data,
-                          start_x, end_x)
-        super().preprocess_data(sx, sy, se)
-
-    @staticmethod
-    def _update_function(func: BaseFitFunction) -> BaseFitFunction:
-        """
-        This method adds a exponential decay to the fitting
-        function.
-        :param func: the fitting function that needs modifying
-        :return the modified fitting function
-        """
-
-        exp_function = ExpDecay()
-        func.add_function(exp_function)
-        return func
-
-
-def muon_expdecay_main(sample: Dict[str, ndarray],
-                       BG_type: str, start_x: float, end_x: float,
-                       results: Dict[str, ndarray],
-                       results_errors: Dict[str, ndarray],
-                       init_params: List[float] = None) -> (Dict[str, ndarray],
-                                                            Dict[str, ndarray],
-                                                            ndarray,
-                                                            List[ndarray],
-                                                            List[ndarray]):
-    """
-    The main function for calculating muon decay rates.
-    Uses the muon exp decay workflow
-    :param sample: dict containing the sample x, y and e data (keys = x, y, e)
-    :param BG_type: the type of BG ("none", "flat", "linear")
-    :param start_x: the start x for the calculation
-    :param end_x: the end x for the calculation
-    :param results: dict of results
-    :param results_errors: dict of errors for results
-    :param init_params: initial values, if None a guess will be made
-    :result dict of the fit parameters, their errors, the x range used, list of
-    fit values and their errors.
-    """
-    # construct fitting function
-    BG = get_background_function(BG_type)
-    func = CompositeFunction()
-    func.add_function(BG)
-    lower, upper = func.get_bounds()
-
-    # setup workflow
-    workflow = MuonExpDecay(results, results_errors)
-    workflow.preprocess_data(sample['x'], sample['y'], sample['e'],
-                             start_x, end_x)
-    params = init_params if init_params is not None else func.get_guess()
-    workflow.set_scipy_engine(params, lower, upper)
-
-    # do the calculation
-    max_features = 4
-    func = workflow.execute(max_features, func, params)
-    results, results_errors = workflow.get_parameters_and_errors
-
-    engine = workflow.fit_engine
-    fits = []
-    errors_fit = []
-    x_data = []
-    for j in range(max_features):
-        x_data, y, e, df, de = engine.get_fit_values(j)
-        fits.append(y)
-        errors_fit.append(e)
-
-    return results, results_errors, x_data, fits, errors_fit
+from quickBayes.functions.composite import CompositeFunction
+from quickBayes.functions.exp_decay import ExpDecay
+from quickBayes.utils.general import get_background_function
+from quickBayes.utils.crop_data import crop
+from quickBayes.workflow.model_template import ModelSelectionWorkflow
+from quickBayes.functions.base import BaseFitFunction
+from numpy import ndarray
+from typing import Dict, List
+
+
+class MuonExpDecay(ModelSelectionWorkflow):
+    """
+    A class for the muon exponential decay workflow
+    """
+    def preprocess_data(self, x_data: ndarray,
+                        y_data: ndarray, e_data: ndarray,
+                        start_x: float, end_x: float) -> None:
+        """
+        The preprocessing needed for the data.
+        This crops and stores the data.
+        :param x_data: the x data to fit to
+        :param y_data: the y data to fit to
+        :param e_data: the errors for the y data
+        :param start_x: the start x value
+        :param end_x: the end x value
+        """
+        sx, sy, se = crop(x_data, y_data, e_data,
+                          start_x, end_x)
+        super().preprocess_data(sx, sy, se)
+
+    @staticmethod
+    def _update_function(func: BaseFitFunction) -> BaseFitFunction:
+        """
+        This method adds a exponential decay to the fitting
+        function.
+        :param func: the fitting function that needs modifying
+        :return the modified fitting function
+        """
+
+        exp_function = ExpDecay()
+        func.add_function(exp_function)
+        return func
+
+
+def muon_expdecay_main(sample: Dict[str, ndarray],
+                       BG_type: str, start_x: float, end_x: float,
+                       results: Dict[str, ndarray],
+                       results_errors: Dict[str, ndarray],
+                       init_params: List[float] = None) -> (Dict[str, ndarray],
+                                                            Dict[str, ndarray],
+                                                            ndarray,
+                                                            List[ndarray],
+                                                            List[ndarray]):
+    """
+    The main function for calculating muon decay rates.
+    Uses the muon exp decay workflow
+    :param sample: dict containing the sample x, y and e data (keys = x, y, e)
+    :param BG_type: the type of BG ("none", "flat", "linear")
+    :param start_x: the start x for the calculation
+    :param end_x: the end x for the calculation
+    :param results: dict of results
+    :param results_errors: dict of errors for results
+    :param init_params: initial values, if None a guess will be made
+    :result dict of the fit parameters, their errors, the x range used, list of
+    fit values and their errors.
+    """
+    # construct fitting function
+    BG = get_background_function(BG_type)
+    func = CompositeFunction()
+    func.add_function(BG)
+    lower, upper = func.get_bounds()
+
+    # setup workflow
+    workflow = MuonExpDecay(results, results_errors)
+    workflow.preprocess_data(sample['x'], sample['y'], sample['e'],
+                             start_x, end_x)
+    params = init_params if init_params is not None else func.get_guess()
+    workflow.set_scipy_engine(params, lower, upper)
+
+    # do the calculation
+    max_features = 4
+    func = workflow.execute(max_features, func, params)
+    results, results_errors = workflow.get_parameters_and_errors
+
+    engine = workflow.fit_engine
+    fits = []
+    errors_fit = []
+    x_data = []
+    for j in range(max_features):
+        x_data, y, e, df, de = engine.get_fit_values(j)
+        fits.append(y)
+        errors_fit.append(e)
+
+    return results, results_errors, x_data, fits, errors_fit
```

## quickBayes/workflows/model_selection/qldata_main.py

 * *Ordering differences only*

```diff
@@ -1,114 +1,114 @@
-from quickBayes.functions.qldata_function import QlDataFunction
-from quickBayes.utils.spline import spline
-from quickBayes.utils.general import get_background_function
-from quickBayes.workflow.model_template import ModelSelectionWorkflow
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.utils.crop_data import crop
-
-
-from numpy import ndarray
-import numpy as np
-from typing import Dict, List
-
-
-class QLData(ModelSelectionWorkflow):
-    """
-    A class for the quasielastic lorentzian workflow
-    """
-    def preprocess_data(self, x_data: ndarray,
-                        y_data: ndarray, e_data: ndarray,
-                        start_x: float, end_x: float,
-                        res: Dict[str, ndarray]) -> (ndarray, ndarray):
-        """
-        The preprocessing needed for the data.
-        It splines the sample and resolution data
-        to the same uniform grid.
-        :param x_data: the sample x data to fit to
-        :param y_data: the sample y data to fit to
-        :param e_data: the sample errors for the y data
-        :param start_x: the start x value
-        :param end_x: the end x value
-        :param res: a dict of the resolution data (keys =x, y, e)
-        :return the new x range and the new resolution y values
-        """
-        dx = x_data[1] - x_data[0]
-        new_x = np.linspace(start_x, end_x, int((end_x - start_x)/dx))
-
-        sy = spline(x_data, y_data, new_x)
-        se = spline(x_data, e_data, new_x)
-        ry = spline(res['x'], res['y'], new_x)
-        super().preprocess_data(new_x, sy, se)
-
-        # Set the raw data
-        raw_x, raw_y, raw_e = crop(x_data, y_data, e_data,
-                                   start_x, end_x)
-        self._raw = {'x': raw_x, 'y': raw_y, 'e': raw_e}
-
-        return new_x, ry
-
-    @staticmethod
-    def _update_function(func: BaseFitFunction) -> BaseFitFunction:
-        """
-        This method adds a single lorentzian to the fitting function
-        :param func: the fitting function that needs modifying
-        :return the modified fitting function
-        """
-        func.add_single_lorentzian()
-        return func
-
-
-def ql_data_main(sample: Dict[str, ndarray], res: Dict[str, ndarray],
-                 BG_type: str, start_x: float, end_x: float,
-                 elastic: bool,
-                 results: Dict[str, ndarray],
-                 results_errors: Dict[str, ndarray],
-                 init_params: List[float] = None) -> (Dict[str, ndarray],
-                                                      Dict[str, ndarray],
-                                                      ndarray,
-                                                      List[ndarray],
-                                                      List[ndarray]):
-    """
-    Method for wrapping the qldata workflow.
-    :param sample: dict containing the sample x, y and e data (keys = x, y, e)
-    :param res: dict containing the resolution x, y data (keys = x, y)
-    :param BG_type: the type of BG ("none", "flat", "linear")
-    :param start_x: the start x for the calculation
-    :param end_x: the end x for the calculation
-    :param elastic: if to include the elastic peak
-    :param results: dict of results
-    :param results_errors: dict of errors for results
-    :param init_params: initial values, if None a guess will be made
-    :result dict of the fit parameters, their errors, the x range used, list of
-    fit values and their errors.
-    """
-
-    # setup workflow
-    workflow = QLData(results, results_errors)
-    new_x, ry = workflow.preprocess_data(sample['x'], sample['y'],
-                                         sample['e'],
-                                         start_x, end_x, res)
-
-    max_num_peaks = 3
-
-    # setup fit function
-    BG = get_background_function(BG_type)
-    func = QlDataFunction(BG, elastic, new_x, ry, start_x, end_x)
-    lower, upper = func.get_bounds()
-
-    params = init_params if init_params is not None else func.get_guess()
-    # just want a guess the same length as lower, it is not used
-    workflow.set_scipy_engine(func.get_guess(), lower, upper)
-
-    # do the calculation
-    func = workflow.execute(max_num_peaks, func, params)
-    results, results_errors = workflow.get_parameters_and_errors
-
-    engine = workflow.fit_engine
-    fits = []
-    errors_fit = []
-    x_data = []
-    for j in range(max_num_peaks):
-        x_data, y, e, df, de = engine.get_fit_values(j)
-        fits.append(y)
-        errors_fit.append(e)
-    return results, results_errors, x_data, fits, errors_fit
+from quickBayes.functions.qldata_function import QlDataFunction
+from quickBayes.utils.spline import spline
+from quickBayes.utils.general import get_background_function
+from quickBayes.workflow.model_template import ModelSelectionWorkflow
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.utils.crop_data import crop
+
+
+from numpy import ndarray
+import numpy as np
+from typing import Dict, List
+
+
+class QLData(ModelSelectionWorkflow):
+    """
+    A class for the quasielastic lorentzian workflow
+    """
+    def preprocess_data(self, x_data: ndarray,
+                        y_data: ndarray, e_data: ndarray,
+                        start_x: float, end_x: float,
+                        res: Dict[str, ndarray]) -> (ndarray, ndarray):
+        """
+        The preprocessing needed for the data.
+        It splines the sample and resolution data
+        to the same uniform grid.
+        :param x_data: the sample x data to fit to
+        :param y_data: the sample y data to fit to
+        :param e_data: the sample errors for the y data
+        :param start_x: the start x value
+        :param end_x: the end x value
+        :param res: a dict of the resolution data (keys =x, y, e)
+        :return the new x range and the new resolution y values
+        """
+        dx = x_data[1] - x_data[0]
+        new_x = np.linspace(start_x, end_x, int((end_x - start_x)/dx))
+
+        sy = spline(x_data, y_data, new_x)
+        se = spline(x_data, e_data, new_x)
+        ry = spline(res['x'], res['y'], new_x)
+        super().preprocess_data(new_x, sy, se)
+
+        # Set the raw data
+        raw_x, raw_y, raw_e = crop(x_data, y_data, e_data,
+                                   start_x, end_x)
+        self._raw = {'x': raw_x, 'y': raw_y, 'e': raw_e}
+
+        return new_x, ry
+
+    @staticmethod
+    def _update_function(func: BaseFitFunction) -> BaseFitFunction:
+        """
+        This method adds a single lorentzian to the fitting function
+        :param func: the fitting function that needs modifying
+        :return the modified fitting function
+        """
+        func.add_single_lorentzian()
+        return func
+
+
+def ql_data_main(sample: Dict[str, ndarray], res: Dict[str, ndarray],
+                 BG_type: str, start_x: float, end_x: float,
+                 elastic: bool,
+                 results: Dict[str, ndarray],
+                 results_errors: Dict[str, ndarray],
+                 init_params: List[float] = None) -> (Dict[str, ndarray],
+                                                      Dict[str, ndarray],
+                                                      ndarray,
+                                                      List[ndarray],
+                                                      List[ndarray]):
+    """
+    Method for wrapping the qldata workflow.
+    :param sample: dict containing the sample x, y and e data (keys = x, y, e)
+    :param res: dict containing the resolution x, y data (keys = x, y)
+    :param BG_type: the type of BG ("none", "flat", "linear")
+    :param start_x: the start x for the calculation
+    :param end_x: the end x for the calculation
+    :param elastic: if to include the elastic peak
+    :param results: dict of results
+    :param results_errors: dict of errors for results
+    :param init_params: initial values, if None a guess will be made
+    :result dict of the fit parameters, their errors, the x range used, list of
+    fit values and their errors.
+    """
+
+    # setup workflow
+    workflow = QLData(results, results_errors)
+    new_x, ry = workflow.preprocess_data(sample['x'], sample['y'],
+                                         sample['e'],
+                                         start_x, end_x, res)
+
+    max_num_peaks = 3
+
+    # setup fit function
+    BG = get_background_function(BG_type)
+    func = QlDataFunction(BG, elastic, new_x, ry, start_x, end_x)
+    lower, upper = func.get_bounds()
+
+    params = init_params if init_params is not None else func.get_guess()
+    # just want a guess the same length as lower, it is not used
+    workflow.set_scipy_engine(func.get_guess(), lower, upper)
+
+    # do the calculation
+    func = workflow.execute(max_num_peaks, func, params)
+    results, results_errors = workflow.get_parameters_and_errors
+
+    engine = workflow.fit_engine
+    fits = []
+    errors_fit = []
+    x_data = []
+    for j in range(max_num_peaks):
+        x_data, y, e, df, de = engine.get_fit_values(j)
+        fits.append(y)
+        errors_fit.append(e)
+    return results, results_errors, x_data, fits, errors_fit
```

## quickBayes/workflows/model_selection/qse_main.py

 * *Ordering differences only*

```diff
@@ -1,141 +1,141 @@
-from quickBayes.functions.qse_function import QSEFunction
-from quickBayes.utils.spline import spline
-from quickBayes.utils.general import get_background_function
-from quickBayes.workflow.model_template import ModelSelectionWorkflow
-from quickBayes.functions.base import BaseFitFunction
-from quickBayes.utils.crop_data import crop
-
-
-from numpy import ndarray
-import numpy as np
-from typing import Dict, List
-
-
-class QlStretchedExp(ModelSelectionWorkflow):
-    """
-    A class for the quasielastic stretched exponential workflow
-    """
-    def preprocess_data(self, x_data: ndarray,
-                        y_data: ndarray, e_data: ndarray,
-                        start_x: float, end_x: float,
-                        res: Dict[str, ndarray]) -> (ndarray, ndarray):
-        """
-        The preprocessing needed for the data.
-        It splines the sample and resolution data
-        to the same uniform grid.
-        :param x_data: the sample x data to fit to
-        :param y_data: the sample y data to fit to
-        :param e_data: the sample errors for the y data
-        :param start_x: the start x value
-        :param end_x: the end x value
-        :param res: a dict of the resolution data (keys =x, y, e)
-        :return the new x range and the new resolution y values
-        """
-        dx = x_data[1] - x_data[0]
-        new_x = np.linspace(start_x, end_x, int((end_x - start_x)/dx))
-
-        sy = spline(x_data, y_data, new_x)
-        se = spline(x_data, e_data, new_x)
-        ry = spline(res['x'], res['y'], new_x)
-        super().preprocess_data(new_x, sy, se)
-
-        # Set the raw data
-        raw_x, raw_y, raw_e = crop(x_data, y_data, e_data,
-                                   start_x, end_x)
-        self._raw = {'x': raw_x, 'y': raw_y, 'e': raw_e}
-
-        return new_x, ry
-
-    @staticmethod
-    def _update_function(func: BaseFitFunction) -> BaseFitFunction:
-        """
-        Adds a single stretched exponential to the fitting function.
-        :param func: the fitting function that needs modifing
-        :return the modified fitting function
-        """
-        func.add_single_SE()
-        return func
-
-    def update_scipy_fit_engine(self, func: BaseFitFunction, params: ndarray):
-        """
-        This updates the bounds and guess for scipy
-        fit engine.
-        :param func: the fitting function
-        :param params: the fitting parameters
-        """
-
-        lower, upper = func.get_bounds()
-        # get estimate for FWHM -> tau
-        new_x = self._data['x']
-        y_max = np.max(self._data['y'])
-        tmp = np.where(self._data['y'] > y_max/2.)
-        est_FWHM = new_x[tmp[0][-1]] - new_x[tmp[0][0]]
-        guess = []
-        if len(params) == len(upper):
-            guess = params
-        else:
-            guess = func.get_func_guess()
-            guess[2] = est_FWHM
-            func.set_func_guess_FWHM(guess)
-            guess = func.get_guess()
-        self._engine.set_guess_and_bounds(guess, lower, upper)
-
-
-def qse_data_main(sample: Dict[str, ndarray], res: Dict[str, ndarray],
-                  BG_type: str, start_x: float, end_x: float,
-                  elastic: bool,
-                  results: Dict[str, ndarray],
-                  results_errors: Dict[str, ndarray],
-                  init_params: List[float] = None) -> (Dict[str, ndarray],
-                                                       Dict[str, ndarray],
-                                                       ndarray,
-                                                       List[ndarray],
-                                                       List[ndarray]):
-    """
-    The main function for calculating QSEdata.
-    This uses the stretch exponential workflow
-    :param sample: dict containing the sample x, y and e data (keys = x, y, e)
-    :param res: dict containing the resolution x, y data (keys = x, y)
-    :param BG_type: the type of BG ("none", "flat", "linear")
-    :param start_x: the start x for the calculation
-    :param end_x: the end x for the calculation
-    :param elastic: if to include the elastic peak
-    :param results: dict of results
-    :param results_errors: the dict of parameter errors
-    :param init_params: initial values, if None (default) a guess will be made
-    :result dict of the fit parameters, their errors, the x range used, list
-    of fit values and their errors.
-    """
-    # setup workflow
-    workflow = QlStretchedExp(results, results_errors)
-    new_x, ry = workflow.preprocess_data(sample['x'], sample['y'],
-                                         sample['e'],
-                                         start_x, end_x, res)
-
-    max_num_peaks = 1
-
-    # setup fit function
-    BG = get_background_function(BG_type)
-    func = QSEFunction(BG, elastic, new_x, ry, start_x, end_x)
-    lower, upper = func.get_bounds()
-    """
-    if the parameters have come in from another calculation bounds won't match
-    because it will be missing the stretched exp terms
-    """
-
-    params = init_params if init_params is not None else func.get_guess()
-    workflow.set_scipy_engine(func.get_guess(), lower, upper)
-
-    # do the calculation
-    func = workflow.execute(max_num_peaks, func, params)
-    results, results_errors = workflow.get_parameters_and_errors
-
-    engine = workflow.fit_engine
-    fits = []
-    errors_fit = []
-    x_data = []
-    for j in range(max_num_peaks):
-        x_data, y, e, df, de = engine.get_fit_values(j)
-        fits.append(y)
-        errors_fit.append(e)
-    return results, results_errors, x_data, fits, errors_fit
+from quickBayes.functions.qse_function import QSEFunction
+from quickBayes.utils.spline import spline
+from quickBayes.utils.general import get_background_function
+from quickBayes.workflow.model_template import ModelSelectionWorkflow
+from quickBayes.functions.base import BaseFitFunction
+from quickBayes.utils.crop_data import crop
+
+
+from numpy import ndarray
+import numpy as np
+from typing import Dict, List
+
+
+class QlStretchedExp(ModelSelectionWorkflow):
+    """
+    A class for the quasielastic stretched exponential workflow
+    """
+    def preprocess_data(self, x_data: ndarray,
+                        y_data: ndarray, e_data: ndarray,
+                        start_x: float, end_x: float,
+                        res: Dict[str, ndarray]) -> (ndarray, ndarray):
+        """
+        The preprocessing needed for the data.
+        It splines the sample and resolution data
+        to the same uniform grid.
+        :param x_data: the sample x data to fit to
+        :param y_data: the sample y data to fit to
+        :param e_data: the sample errors for the y data
+        :param start_x: the start x value
+        :param end_x: the end x value
+        :param res: a dict of the resolution data (keys =x, y, e)
+        :return the new x range and the new resolution y values
+        """
+        dx = x_data[1] - x_data[0]
+        new_x = np.linspace(start_x, end_x, int((end_x - start_x)/dx))
+
+        sy = spline(x_data, y_data, new_x)
+        se = spline(x_data, e_data, new_x)
+        ry = spline(res['x'], res['y'], new_x)
+        super().preprocess_data(new_x, sy, se)
+
+        # Set the raw data
+        raw_x, raw_y, raw_e = crop(x_data, y_data, e_data,
+                                   start_x, end_x)
+        self._raw = {'x': raw_x, 'y': raw_y, 'e': raw_e}
+
+        return new_x, ry
+
+    @staticmethod
+    def _update_function(func: BaseFitFunction) -> BaseFitFunction:
+        """
+        Adds a single stretched exponential to the fitting function.
+        :param func: the fitting function that needs modifing
+        :return the modified fitting function
+        """
+        func.add_single_SE()
+        return func
+
+    def update_scipy_fit_engine(self, func: BaseFitFunction, params: ndarray):
+        """
+        This updates the bounds and guess for scipy
+        fit engine.
+        :param func: the fitting function
+        :param params: the fitting parameters
+        """
+
+        lower, upper = func.get_bounds()
+        # get estimate for FWHM -> tau
+        new_x = self._data['x']
+        y_max = np.max(self._data['y'])
+        tmp = np.where(self._data['y'] > y_max/2.)
+        est_FWHM = new_x[tmp[0][-1]] - new_x[tmp[0][0]]
+        guess = []
+        if len(params) == len(upper):
+            guess = params
+        else:
+            guess = func.get_func_guess()
+            guess[2] = est_FWHM
+            func.set_func_guess_FWHM(guess)
+            guess = func.get_guess()
+        self._engine.set_guess_and_bounds(guess, lower, upper)
+
+
+def qse_data_main(sample: Dict[str, ndarray], res: Dict[str, ndarray],
+                  BG_type: str, start_x: float, end_x: float,
+                  elastic: bool,
+                  results: Dict[str, ndarray],
+                  results_errors: Dict[str, ndarray],
+                  init_params: List[float] = None) -> (Dict[str, ndarray],
+                                                       Dict[str, ndarray],
+                                                       ndarray,
+                                                       List[ndarray],
+                                                       List[ndarray]):
+    """
+    The main function for calculating QSEdata.
+    This uses the stretch exponential workflow
+    :param sample: dict containing the sample x, y and e data (keys = x, y, e)
+    :param res: dict containing the resolution x, y data (keys = x, y)
+    :param BG_type: the type of BG ("none", "flat", "linear")
+    :param start_x: the start x for the calculation
+    :param end_x: the end x for the calculation
+    :param elastic: if to include the elastic peak
+    :param results: dict of results
+    :param results_errors: the dict of parameter errors
+    :param init_params: initial values, if None (default) a guess will be made
+    :result dict of the fit parameters, their errors, the x range used, list
+    of fit values and their errors.
+    """
+    # setup workflow
+    workflow = QlStretchedExp(results, results_errors)
+    new_x, ry = workflow.preprocess_data(sample['x'], sample['y'],
+                                         sample['e'],
+                                         start_x, end_x, res)
+
+    max_num_peaks = 1
+
+    # setup fit function
+    BG = get_background_function(BG_type)
+    func = QSEFunction(BG, elastic, new_x, ry, start_x, end_x)
+    lower, upper = func.get_bounds()
+    """
+    if the parameters have come in from another calculation bounds won't match
+    because it will be missing the stretched exp terms
+    """
+
+    params = init_params if init_params is not None else func.get_guess()
+    workflow.set_scipy_engine(func.get_guess(), lower, upper)
+
+    # do the calculation
+    func = workflow.execute(max_num_peaks, func, params)
+    results, results_errors = workflow.get_parameters_and_errors
+
+    engine = workflow.fit_engine
+    fits = []
+    errors_fit = []
+    x_data = []
+    for j in range(max_num_peaks):
+        x_data, y, e, df, de = engine.get_fit_values(j)
+        fits.append(y)
+        errors_fit.append(e)
+    return results, results_errors, x_data, fits, errors_fit
```

## Comparing `quickBayes-1.0.0b8.dist-info/LICENSE.txt` & `quickBayes-1.0.0b9.dist-info/LICENSE.txt`

 * *Ordering differences only*

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,11 @@
-Copyright 2021, Mantid Developers
-
-Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
-
-1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
-
-2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
-
-3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
-
+Copyright 2021, Mantid Developers
+
+Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
+
+1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
+
+2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
+
+3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
+
 THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
```

## Comparing `quickBayes-1.0.0b8.dist-info/METADATA` & `quickBayes-1.0.0b9.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: quickBayes
-Version: 1.0.0b8
+Version: 1.0.0b9
 Summary: A Bayesian fitting package used for model selection and grid searches of fits for neutron and muon data.
 Home-page: https://www.mantidproject.org
 Author: Anthony Lim
 Author-email: anthony.lim@stfc.ac.uk
 License: BSD
 Requires: numpy
 License-File: LICENSE.txt
```

## Comparing `quickBayes-1.0.0b8.dist-info/RECORD` & `quickBayes-1.0.0b9.dist-info/RECORD`

 * *Files 22% similar despite different names*

```diff
@@ -1,74 +1,74 @@
 quickBayes/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-quickBayes/log_likelihood.cp38-win_amd64.pyd,sha256=BfLhoBxAhdFCZG6-X5KOQFvJw37FjVRyuXifKEPW2uA,43520
-quickBayes/log_likelihood.py,sha256=kwld1j1_U6XI9J7hvo83zQIfLtndbg8kULQxrLy48uY,2542
+quickBayes/log_likelihood.cpython-39-darwin.so,sha256=YBo52JjjguKKoBC6w5Y07HSLs1jEWc3SCjktSvy7c28,74056
+quickBayes/log_likelihood.py,sha256=qhKjB4D9aaRhWPROFdNK2lSs2v1ijkfFr2GQnyaS0d8,2477
 quickBayes/fit_engines/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-quickBayes/fit_engines/fit_engine.py,sha256=i0p9fCM8Na2A4bBTdWubyVjta5pQjAETDxnqstefSt0,7049
-quickBayes/fit_engines/fit_utils.py,sha256=fh4I-t-n9onjJHobH9_GQMcICWcVkhcaFhTRt3imiqU,3714
-quickBayes/fit_engines/gofit_engine.py,sha256=IEYNC_2g3crzP-7apRpEyfo4o1FvNpxlSjfp-T4BumU,4074
-quickBayes/fit_engines/scipy_fit_engine.py,sha256=hbVFqsm0UjZcvzmLcCzuHyj8Sm5lGIsCq-sMzqpWwmk,3691
-quickBayes/fit_functions/BG.py,sha256=wiD3CF58Y3nmpdgI2dhBrSIutWmyLOhhK4rxupSAprw,4586
+quickBayes/fit_engines/fit_engine.py,sha256=8hkYV-wPoMURFd1nS8XQoBnkf_kt3fxE9DSCO4Ildoo,6873
+quickBayes/fit_engines/fit_utils.py,sha256=p8gjY5QYvRr3CDUtxJI9YPsHM_JuA72Ns8P-CEdll9Y,3590
+quickBayes/fit_engines/gofit_engine.py,sha256=1Xr87fAOt5JVe6-gfF98TEUIAD1Dgqi_fA8bAleKibM,3968
+quickBayes/fit_engines/scipy_fit_engine.py,sha256=zdLHkbdhehTVeF5zxb5_EMHoJLuO06neKm7N5oc47BI,3487
+quickBayes/fit_functions/BG.py,sha256=_qMCk6gqOZleHRnUPGV4YBSx3I2rxVKiEEwifp1WgxU,4446
 quickBayes/fit_functions/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-quickBayes/fit_functions/base.py,sha256=CfhgWnEAd5DR7C1Nkq3dNhLBvUhwisqsjd9BKiYDH9c,6666
-quickBayes/fit_functions/composite_fun.py,sha256=Leo5GksFp363vNo1kV49SIOFWb0iFnvkh6DdKo3bqiU,4875
-quickBayes/fit_functions/conv_with_res.py,sha256=WHW25jpkoBcc9KQCC4ttVR93mug2tUxwip7t2wGL1XU,2839
-quickBayes/fit_functions/delta_function.py,sha256=wx3n9ddVzYzSiBdiVKQaQViDHyDJnX1FuYWZxJN3gNE,2761
-quickBayes/fit_functions/exp_decay.py,sha256=uEAssAX6EOEifJXjXpuxGG1H3CWSLyVhPlPrORs7ACI,2349
-quickBayes/fit_functions/gaussian.py,sha256=HeizI-6JnoSqJle9ZzP7CLYlUo-OID1oOa8P44lRKHU,2889
-quickBayes/fit_functions/lorentz.py,sha256=oNUUruzD6f93qMXnDQgoqlU2go6WPBKqA8JSTd0H9Xk,2826
-quickBayes/fit_functions/qldata_function.py,sha256=AvlxtQnLcz3V6p8p0Z5ccE1hjo0uO5x5NNN7tHP0SCg,5025
-quickBayes/fit_functions/qse.py,sha256=saqExKjVKu6pvhc3ppQ2uSXuViKXqb3uYkaN5c3h4wM,3598
-quickBayes/fit_functions/qse_fixed.py,sha256=1rTED62ZoiFt-sPv6NqTKkeJlxuR4kbq8KBRZabq3wY,3307
-quickBayes/fit_functions/quasielastic_function.py,sha256=hr5UxNgkJc6ZKgPzf1XC6FH03K9ntASjVz6o1fli7CQ,13849
-quickBayes/fit_functions/stretch_exp.py,sha256=WkSDWBguWrScxhvld8Jym0DYpEiBBWYM8sLtQHRmkrU,8219
-quickBayes/fit_functions/stretch_exp_fixed.py,sha256=RfSrLH0-gGkO0919Uqumo4H8DIlbeIA-c_gL2NntTWg,4595
-quickBayes/fitting/fit_engine.cp38-win_amd64.pyd,sha256=G4kJ86n22LWk853ARURqYfWTIshXUj-gDCFy_Yq341s,88064
-quickBayes/fitting/fit_utils.cp38-win_amd64.pyd,sha256=tDFHggp6RY4C6BbFT43rrPYy3OFKBOAsN2XNZWr1vgI,63488
-quickBayes/fitting/gofit_engine.cp38-win_amd64.pyd,sha256=r8gzjOcvhwAgVL_u9C_9ThXSZx5eXHPm5irCr1D-WfU,57856
-quickBayes/fitting/scipy_engine.cp38-win_amd64.pyd,sha256=fSHWGcr8zcE4yAvTNmt2jiiF_iON0-rqO21caLzRJOk,57344
-quickBayes/functions/BG.cp38-win_amd64.pyd,sha256=smGKooOOFG0MwI7KWe5imU24ZnDihIt-xEPuL77WqPo,77824
-quickBayes/functions/SE.cp38-win_amd64.pyd,sha256=iIJ205EykWAG43i5E_g-dyGdWxPDg653rFJSuJsyPmM,99840
-quickBayes/functions/SE_fix.cp38-win_amd64.pyd,sha256=wsHvb0D6PcLByZTDaxx6GDS_ZjSgYQLXHxHDHozPw9M,69632
-quickBayes/functions/base.cp38-win_amd64.pyd,sha256=oRhY6ZLHu0U5L6EjT3ROKuj9cinsESxGDaL6kToTqUM,84480
-quickBayes/functions/composite.cp38-win_amd64.pyd,sha256=w2nb93oTWtqQTnwOrsKJY_HpKDwopbESKRmEW66oFGc,79360
-quickBayes/functions/convolution.cp38-win_amd64.pyd,sha256=E5vk1KKhkn3BVMipEx9HNrsXHi51f4p7CKLzqj5rWMA,56320
-quickBayes/functions/delta.cp38-win_amd64.pyd,sha256=rWoPNVPLoT018oEhaYIuGrDkh0FCouTTb9OHbZrQAkI,55808
-quickBayes/functions/exp_decay.cp38-win_amd64.pyd,sha256=cGWGJmb1gdqOmKIcAibb1nVhuTBojH7xz4FbDGRlbLA,52736
-quickBayes/functions/gaussian.cp38-win_amd64.pyd,sha256=Cs2m8byDTqcDQ_OZZcmC9Vv5GMqN7dUW6s2BtkdR-ng,58880
-quickBayes/functions/lorentz.cp38-win_amd64.pyd,sha256=ty5eTQ3tvi52McUn7Fv9fVjeLdPTRZnnawU4qwaBHLo,55808
-quickBayes/functions/qe_function.cp38-win_amd64.pyd,sha256=JWeqj3btEHTa28HEgZiWaMw4DpYrHNAvg66EN9VS5lg,138240
-quickBayes/functions/qldata_function.cp38-win_amd64.pyd,sha256=6GPB0p-BRs0ycO7GxoLmSPAlBH3UH06OlldBFH-AgEA,71168
-quickBayes/functions/qse_fixed.cp38-win_amd64.pyd,sha256=GanmDamVXGKScO-NxLCKxTR553rMmvqWRHlpLnL1YAQ,57856
-quickBayes/functions/qse_function.cp38-win_amd64.pyd,sha256=uqpzMguhar9PFhy7Lidl4VTA4WmraxbpO1aOdj-x88k,63488
-quickBayes/test_helpers/fitting_data.cp38-win_amd64.pyd,sha256=BIMHIM68jW7f5HMSQSIrN5vvsDwVMHvXXHzAfpLw5ck,41472
-quickBayes/test_helpers/template_fit_test.cp38-win_amd64.pyd,sha256=R3PhsU04dHnTLrg7ESg9b_aWjoTEyL7_fORCA2T-eV4,137216
-quickBayes/test_helpers/template_scipy_fit.cp38-win_amd64.pyd,sha256=VIyXXkfjms9H0uY-qxEt2jqXSMaObiNE305gy53sAWs,49664
-quickBayes/test_helpers/workflows.cp38-win_amd64.pyd,sha256=Pt9M_WBS4BmUjMA9UA2W7NQEvMJH9nXVkGJM13nJX84,54784
+quickBayes/fit_functions/base.py,sha256=euBYXnG260C_GYbH2yHnczr2_xdOE-YPpU5L3iyCiYY,6478
+quickBayes/fit_functions/composite_fun.py,sha256=Lh7WvUZpM4tY5YNcZTDJIeXE66FZ_l1S8Dx0c9l6fsk,4734
+quickBayes/fit_functions/conv_with_res.py,sha256=JxrJxCZuUw7Blii3Mk1EixPQbNzjzKpRlBeFknQ7e7k,2767
+quickBayes/fit_functions/delta_function.py,sha256=u_7Hj4GysWTVLyH_fBaZgm4Ed2TzPPmKYef1BVepSu4,2682
+quickBayes/fit_functions/exp_decay.py,sha256=A0s8X4SAcKK-ewrpX3qw6p1cDifDCsv7nb-IR4Ogdhc,2283
+quickBayes/fit_functions/gaussian.py,sha256=Jc-MYJYPZOc7cp8hGTAIUGY2ELzrldZeApotZPCbqxY,2809
+quickBayes/fit_functions/lorentz.py,sha256=2ZwkFEUEHyO4uTZ_Sx1qleqnr6tiI0UdYcWeXX2sU2A,2747
+quickBayes/fit_functions/qldata_function.py,sha256=vaKQ14fGlinuJwKiRqb-9nysJCvLWMtJg4AicL3Vss8,4905
+quickBayes/fit_functions/qse.py,sha256=xirJ63m-fkapSdhO_hoSWvLH09q6l1G8xH61PRz478I,3505
+quickBayes/fit_functions/qse_fixed.py,sha256=qnU6dk-QmxyMK4k_bGxlyy3qSDUq-y1Oxxe2qQvP2yo,3210
+quickBayes/fit_functions/quasielastic_function.py,sha256=ok5pv5nxDtmMS8qmEvFAgA2hCWldMpR31_Z9Ui5OaGY,13477
+quickBayes/fit_functions/stretch_exp.py,sha256=3pNxwsDwh4egdAR2SjA4s0YLlZTfpNO_xFqpb9NGfy4,7996
+quickBayes/fit_functions/stretch_exp_fixed.py,sha256=O7V6y5o_X1pXUjUlhqPxyiB60ieEbT-WDgK2ZgYmniw,4471
+quickBayes/fitting/fit_engine.cpython-39-darwin.so,sha256=LuvhFSBexOcjL9unhfImJGsxbhrkIUjL_5DfJrytLQI,169744
+quickBayes/fitting/fit_utils.cpython-39-darwin.so,sha256=U8c_03jMBepyyLXRBNDOduJFktZyaNuewSmfgAftqFw,121288
+quickBayes/fitting/gofit_engine.cpython-39-darwin.so,sha256=S6rCxGBM22VQ3LpWkKFP4atx-izbIGG6UVoIBEuj2dc,100768
+quickBayes/fitting/scipy_engine.cpython-39-darwin.so,sha256=8yVUbn9TJQaz8w2aiJ8VG75PWDWa46eHahH2xkaFP34,99344
+quickBayes/functions/BG.cpython-39-darwin.so,sha256=RkoS4EXfqszfYwTnnTvKp84VvGefOCfrxihwz6HGNME,141880
+quickBayes/functions/SE.cpython-39-darwin.so,sha256=Nn1Ax4sPYYCcRCD27OSdAc6mOR43uCSG__r7Sw6AOjc,187632
+quickBayes/functions/SE_fix.cpython-39-darwin.so,sha256=kRMc46KKnHZ4LYym9Imb3BbdtBTi5Q2sczPjOfHu3T8,121432
+quickBayes/functions/base.cpython-39-darwin.so,sha256=jOCdckTLTcLLLE3Wxk8pAD0Nby6Dyjs0LAVX-B1Z9eA,150520
+quickBayes/functions/composite.cpython-39-darwin.so,sha256=TG6aCthjuMyzXEnGXNS8dCVfSoP9v24wk7ZuxIR6Hl8,142912
+quickBayes/functions/convolution.cpython-39-darwin.so,sha256=LrN6CGIPnqXVZcDgb33y7vTMhU5oIDNAZ5WhsXrgeko,99248
+quickBayes/functions/delta.cpython-39-darwin.so,sha256=VQHgTK7R8l-3OeBcedy-RgOfERDmamPPwR3pKj7-6ug,96272
+quickBayes/functions/exp_decay.cpython-39-darwin.so,sha256=_qeqjnxjG2TtPxbuCWpuZKdyTmfSVNSMO1EedIZTiE0,95152
+quickBayes/functions/gaussian.cpython-39-darwin.so,sha256=M4eeLVwFRssXBhxd54mDQNbK-7bJWHJ5WzIg2i90DXI,98760
+quickBayes/functions/lorentz.cpython-39-darwin.so,sha256=bxF69L-lbWFfQ17l4T5R6mZHh0WflrxPhb0nky6wsio,96688
+quickBayes/functions/qe_function.cpython-39-darwin.so,sha256=J3qaQ7Yg5jD6Nl5h4QLsyEm0MgRmA6-02YQVq7dF6qY,258608
+quickBayes/functions/qldata_function.cpython-39-darwin.so,sha256=KYW_qNYqH5yqiGju3oKNYOZsVShifXywnayZfCeJXcs,141112
+quickBayes/functions/qse_fixed.cpython-39-darwin.so,sha256=9UqemhmuAJmuyhe-uCwK39sXhIazKXTr5iSNUZYbTb8,100496
+quickBayes/functions/qse_function.cpython-39-darwin.so,sha256=vLPmp6dHQbxbWdW0ASumEdGhQ08SouRvbdP7UvD2Cpk,120704
+quickBayes/test_helpers/fitting_data.cpython-39-darwin.so,sha256=oNN7G1IIBVnWndIzXXOMZxzo9FaLN0eTBdEQvkhP2v4,75816
+quickBayes/test_helpers/template_fit_test.cpython-39-darwin.so,sha256=AFhGQNdAEJ7uM_n38hHWcRVO5JhfM6vZ6QpHKcdnphE,259016
+quickBayes/test_helpers/template_scipy_fit.cpython-39-darwin.so,sha256=k2EvzO8o9rn4KTgjGPAE15g6JuRy-VG0HL2cU2W76m4,102696
+quickBayes/test_helpers/workflows.cpython-39-darwin.so,sha256=ZpujIMTUfyRhiwq2uqtu21JlqYGsoOQvYov1sGnmUU8,99104
 quickBayes/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-quickBayes/utils/crop_data.cp38-win_amd64.pyd,sha256=XQzItiC2VnSW6TP2JybjGlflR2R3HLkvj84fG4xfG3c,34304
-quickBayes/utils/crop_data.py,sha256=H4ops-ypbIJBKy1FHp3f3JI3yQ1IK7zxHdiXb9rflmE,863
-quickBayes/utils/general.cp38-win_amd64.pyd,sha256=G2n3zL3aSLfHsuepxxe0lIIbjecB6DDud26N9mZtg2g,39424
-quickBayes/utils/general.py,sha256=6VmsXfEbKiJzI3XkXe9hG3u2Ti1eMr0IM0kgjONY6W8,1119
-quickBayes/utils/spline.cp38-win_amd64.pyd,sha256=1i8vJxf1KTTbkTC-_HdywU6F23NGjN5rlf61g-KuNv4,32256
-quickBayes/utils/spline.py,sha256=4Sxft4zlKIJ5fgUbYk8FforbUJowGJoEqhvQX-mz6Vg,549
-quickBayes/workflow/MuonExpDecay.cp38-win_amd64.pyd,sha256=PR0msAgSrODvAL1TOaTWBGhAa1CaFBYXWrUQk5_OU38,63488
-quickBayes/workflow/QSE.cp38-win_amd64.pyd,sha256=qErzZYHe1FKxZ5xncc9nVT9irDH5jZ7llXZq3lmYcL4,80384
-quickBayes/workflow/QlData.cp38-win_amd64.pyd,sha256=5E2IUYL6pEM5EQNAgGUUe9qG1XfaBmgDG-6-8OpU0ss,72192
-quickBayes/workflow/grid_template.cp38-win_amd64.pyd,sha256=jjT80u_umvWxgCDR4cUG4--peXLutovUK12b-rqbG2U,97792
-quickBayes/workflow/model_template.cp38-win_amd64.pyd,sha256=nEDc6cPQnaxteMNzH6WKlxaX2YYjdk4SaO10etX_ePo,72704
-quickBayes/workflow/qse_search.cp38-win_amd64.pyd,sha256=9jARYJ0y01E7m1ioL4LbGYNfwVbY5AokTdNTb0-6wkc,51712
-quickBayes/workflow/template.cp38-win_amd64.pyd,sha256=iwG97T_-GFWOPKpYLhZ1IP9AW9RYLQS1m_U3PcIq-Kc,72192
+quickBayes/utils/crop_data.cpython-39-darwin.so,sha256=AH8qctBq8_0aC6mwtR_SaVe5zIIjTlsamxrtcxZFmuw,67864
+quickBayes/utils/crop_data.py,sha256=2afvko06Qi_D2WRO50Lq-n-Y8SnYLsaISBcEThYrC70,839
+quickBayes/utils/general.cpython-39-darwin.so,sha256=bwWNXQ-HQiUOutlrG9_qkGA7gn2bGIHBjZvrWYs57Lk,71984
+quickBayes/utils/general.py,sha256=DX1gfWdTZucCUh9zB6p_vJ7QoBSEyU2IYvb1GDDfkUk,1086
+quickBayes/utils/spline.cpython-39-darwin.so,sha256=jDNAyyQ94RvHTIDoiqhdliQXatQf8J-iN_GzyDmvud0,66424
+quickBayes/utils/spline.py,sha256=67NFbhwdshZH3NipLAXD-BavAzi_mik3SNWlDdPweuo,532
+quickBayes/workflow/MuonExpDecay.cpython-39-darwin.so,sha256=b8h5HhhLm16xgWi7cdiK2lKh4IvE2gz6pwnqoKbDkKw,120160
+quickBayes/workflow/QSE.cpython-39-darwin.so,sha256=CmpU0qz4hxMI_lSllYosA5LRHkOLt-T1pqZy_pt387w,144256
+quickBayes/workflow/QlData.cpython-39-darwin.so,sha256=slh8U-l1izWozQjCCKBOdaJUHYzX7lRT60MNTsg38tA,139768
+quickBayes/workflow/grid_template.cpython-39-darwin.so,sha256=7KO6Z-b9tn7dRLgpS2_gpMtTw7goiBJC2-bsGqiALPs,197968
+quickBayes/workflow/model_template.cpython-39-darwin.so,sha256=mgMGLehhBNahdyQ0x-1tgWxuxl_mMOSDwhR7FsgPnBs,125024
+quickBayes/workflow/qse_search.cpython-39-darwin.so,sha256=zG61i9KKGNM5oL1vxr_O9U9RX9-abgeK-xKJia887Ck,97344
+quickBayes/workflow/template.cpython-39-darwin.so,sha256=VQPujZUooOKEJUpZRLdXpC-hbrwTTit3yIX2dNwBMFE,127472
 quickBayes/workflows/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-quickBayes/workflows/workflow_template.py,sha256=ytVWpjNWKgtaLb9Hmb51lmq8sGkBhzbAfIAGTeVoQz8,6229
+quickBayes/workflows/workflow_template.py,sha256=qqQwG2pBFrls9910dgk719SE6kVSu0uEJvk7kI5HVss,5802
 quickBayes/workflows/grid_search/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-quickBayes/workflows/grid_search/grid_search_template.py,sha256=6mXPV8egl7CFRmHkQCtW0Br3HlUvGJ7cUMqFpQ-_weI,8208
-quickBayes/workflows/grid_search/qse_grid_search.py,sha256=UgCrxG9GcEwvndXy79VMVhxmb8HKu_tOZjFf5ierx6A,3082
+quickBayes/workflows/grid_search/grid_search_template.py,sha256=WOV9TWfYCuUc3QaADmYtg8jR2jgjSXe6rh-azCw4zIM,8067
+quickBayes/workflows/grid_search/qse_grid_search.py,sha256=2likOawnB6rwoy2iU-xmVa0LRGqWrgxWCSea9izAD8A,2988
 quickBayes/workflows/model_selection/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-quickBayes/workflows/model_selection/model_template.py,sha256=2ptFsV9aTN3FFFs99nM7rfWfSst9udacVs1yVpmpVo8,5583
-quickBayes/workflows/model_selection/muon_exp_decay_main.py,sha256=jwtsL08U8DVSPzNJCBkh5QliEAi1ekNicdPryJMwioA,3803
-quickBayes/workflows/model_selection/qldata_main.py,sha256=jefHk_FCgmRf0M2GIc7gy_uX34t3cY8wUCLPmQKu5cM,4638
-quickBayes/workflows/model_selection/qse_main.py,sha256=DzzDx8nfd9ewn82IW0lrIFxhb_qRIquTrRJYpgq4qyY,5669
-quickBayes-1.0.0b8.dist-info/LICENSE.txt,sha256=byREVSClMpnwlNISq2kdKO_9zeDSiBJPMtg5tmdpQtQ,1472
-quickBayes-1.0.0b8.dist-info/METADATA,sha256=NcnONqh23TAP7vDn7qEa_XFno11C_VsC4D4bfMnx34Y,663
-quickBayes-1.0.0b8.dist-info/WHEEL,sha256=M2GQ3lde8oJhlQPj2wbRvnqE3cuovPJasri5X5aCmck,100
-quickBayes-1.0.0b8.dist-info/top_level.txt,sha256=lX54OMtqpIAvLjHlWmMJlWqRsfiwEecVokNtE3tjK9c,11
-quickBayes-1.0.0b8.dist-info/RECORD,,
+quickBayes/workflows/model_selection/model_template.py,sha256=inhih0D-W7o_pwZ7Mj0Kg871LfnSKYJYsycdz9If8gg,5437
+quickBayes/workflows/model_selection/muon_exp_decay_main.py,sha256=LWKYIV4W363yXNCkoeE065Ba9MJfBJoaNhvdzSpcRSY,3709
+quickBayes/workflows/model_selection/qldata_main.py,sha256=2_cu7YpTkb_XumF3hKzqXzpkynGLjqx0ucjwVLwlUdg,4524
+quickBayes/workflows/model_selection/qse_main.py,sha256=Aiv2SyGiA47hGK4iC2dpAPxDFGUSpDJnqO4rrIsqIqs,5528
+quickBayes-1.0.0b9.dist-info/LICENSE.txt,sha256=UobD18Fw9i4uiBPGun1ha5ApddXDXwqPMNiIJ_Y5LEc,1462
+quickBayes-1.0.0b9.dist-info/METADATA,sha256=eYjNTGamwKHn_lzBuRv4TOv5GKTygn2L91nXpXtehq8,663
+quickBayes-1.0.0b9.dist-info/WHEEL,sha256=pfjXB0CCNW4PSSqQc2t4Up6p3o0jxBnHy_2o38FQkyE,109
+quickBayes-1.0.0b9.dist-info/top_level.txt,sha256=lX54OMtqpIAvLjHlWmMJlWqRsfiwEecVokNtE3tjK9c,11
+quickBayes-1.0.0b9.dist-info/RECORD,,
```

