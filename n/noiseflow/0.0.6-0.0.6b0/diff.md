# Comparing `tmp/noiseflow-0.0.6-cp311-cp311-win_amd64.whl.zip` & `tmp/noiseflow-0.0.6b0-cp39-cp39-manylinux_2_35_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,50 +1,52 @@
-Zip file size: 64696 bytes, number of entries: 48
--rw-r--r--  2.0 fat      739 b- defN 80-Jan-01 00:00 .gitmodules
--rw-r--r--  2.0 fat     6149 b- defN 80-Jan-01 00:00 CMakeLists.txt
--rw-r--r--  2.0 fat     1311 b- defN 80-Jan-01 00:00 noiseflow/__init__.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/app/__init__.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/cc/__init__.py
--rw-r--r--  2.0 fat    12030 b- defN 80-Jan-01 00:00 noiseflow/cc/corrdata.py
--rw-r--r--  2.0 fat    10467 b- defN 80-Jan-01 00:00 noiseflow/cc/include/corr.hpp
--rw-r--r--  2.0 fat    10398 b- defN 80-Jan-01 00:00 noiseflow/cc/include/rfft.hpp
--rw-r--r--  2.0 fat    11339 b- defN 80-Jan-01 00:00 noiseflow/cc/include/stack.hpp
--rw-r--r--  2.0 fat     8665 b- defN 80-Jan-01 00:00 noiseflow/cc/include/utils.hpp
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/cc/python/__init__.py
--rw-r--r--  2.0 fat     6251 b- defN 80-Jan-01 00:00 noiseflow/cc/python/corr.py
--rw-r--r--  2.0 fat     5455 b- defN 80-Jan-01 00:00 noiseflow/cc/python/rfft.py
--rw-r--r--  2.0 fat    28068 b- defN 80-Jan-01 00:00 noiseflow/cc/python/stack.py
--rw-r--r--  2.0 fat     3417 b- defN 80-Jan-01 00:00 noiseflow/cc/python/utils.py
--rw-r--r--  2.0 fat     8312 b- defN 80-Jan-01 00:00 noiseflow/cc/rfftdata.py
--rw-r--r--  2.0 fat     5626 b- defN 80-Jan-01 00:00 noiseflow/cc/src/pybind11.cpp
--rw-r--r--  2.0 fat    38192 b- defN 80-Jan-01 00:00 noiseflow/cc/stackdata.py
--rw-r--r--  2.0 fat    11000 b- defN 80-Jan-01 00:00 noiseflow/cc/utils_load.py
--rw-r--r--  2.0 fat     1410 b- defN 80-Jan-01 00:00 noiseflow/cc/utils_time.py
--rw-r--r--  2.0 fat     9085 b- defN 80-Jan-01 00:00 noiseflow/cc/wrapper.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/client/__init__.py
--rw-r--r--  2.0 fat     8055 b- defN 80-Jan-01 00:00 noiseflow/client/client.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/dispersion/__init__.py
--rw-r--r--  2.0 fat       32 b- defN 80-Jan-01 00:00 noiseflow/dispersion/app_dispersion.py
--rw-r--r--  2.0 fat       30 b- defN 80-Jan-01 00:00 noiseflow/dispersion/test.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/dvv/__init__.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/dvv/monitoring.py
--rw-r--r--  2.0 fat      205 b- defN 80-Jan-01 00:00 noiseflow/real_time/watch_dog.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/signal/__init__.py
--rw-r--r--  2.0 fat     2978 b- defN 80-Jan-01 00:00 noiseflow/signal/include/decimate.hpp
--rw-r--r--  2.0 fat     3379 b- defN 80-Jan-01 00:00 noiseflow/signal/include/detrend.hpp
--rw-r--r--  2.0 fat    13019 b- defN 80-Jan-01 00:00 noiseflow/signal/include/filter.hpp
--rw-r--r--  2.0 fat     4873 b- defN 80-Jan-01 00:00 noiseflow/signal/include/taper.hpp
--rw-r--r--  2.0 fat     1326 b- defN 80-Jan-01 00:00 noiseflow/signal/include/utils.hpp
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/signal/python/__init__.py
--rw-r--r--  2.0 fat      780 b- defN 80-Jan-01 00:00 noiseflow/signal/python/decimate.py
--rw-r--r--  2.0 fat     2075 b- defN 80-Jan-01 00:00 noiseflow/signal/python/detrend.py
--rw-r--r--  2.0 fat     7008 b- defN 80-Jan-01 00:00 noiseflow/signal/python/filter.py
--rw-r--r--  2.0 fat     3002 b- defN 80-Jan-01 00:00 noiseflow/signal/python/taper.py
--rw-r--r--  2.0 fat     3343 b- defN 80-Jan-01 00:00 noiseflow/signal/rawdata.py
--rw-r--r--  2.0 fat     7532 b- defN 80-Jan-01 00:00 noiseflow/signal/src/pybind11.cpp
--rw-r--r--  2.0 fat    10485 b- defN 80-Jan-01 00:00 noiseflow/signal/wrapper.py
--rw-r--r--  2.0 fat        0 b- defN 80-Jan-01 00:00 noiseflow/tests/__init__.py
--rw-r--r--  2.0 fat    11558 b- defN 80-Jan-01 00:00 noiseflow-0.0.6.dist-info/LICENSE
--rw-r--r--  2.0 fat     4558 b- defN 80-Jan-01 00:00 noiseflow-0.0.6.dist-info/METADATA
--rw-r--r--  2.0 fat       98 b- defN 80-Jan-01 00:00 noiseflow-0.0.6.dist-info/WHEEL
-?rw-r--r--  2.0 fat     4037 b- defN 16-Jan-01 00:00 noiseflow-0.0.6.dist-info/RECORD
-48 files, 266287 bytes uncompressed, 58258 bytes compressed:  78.1%
+Zip file size: 894966 bytes, number of entries: 50
+-rw-r--r--  2.0 unx      196 b- defN 80-Jan-01 00:00 .gitmodules
+-rw-r--r--  2.0 unx     6015 b- defN 80-Jan-01 00:00 CMakeLists.txt
+-rw-r--r--  2.0 unx     1270 b- defN 80-Jan-01 00:00 noiseflow/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/app/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/cc/__init__.py
+-rw-r--r--  2.0 unx    11738 b- defN 80-Jan-01 00:00 noiseflow/cc/corrdata.py
+-rw-r--r--  2.0 unx    10160 b- defN 80-Jan-01 00:00 noiseflow/cc/include/corr.hpp
+-rw-r--r--  2.0 unx    10099 b- defN 80-Jan-01 00:00 noiseflow/cc/include/rfft.hpp
+-rw-r--r--  2.0 unx    11023 b- defN 80-Jan-01 00:00 noiseflow/cc/include/stack.hpp
+-rw-r--r--  2.0 unx     8396 b- defN 80-Jan-01 00:00 noiseflow/cc/include/utils.hpp
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/cc/python/__init__.py
+-rw-r--r--  2.0 unx     6071 b- defN 80-Jan-01 00:00 noiseflow/cc/python/corr.py
+-rw-r--r--  2.0 unx     5299 b- defN 80-Jan-01 00:00 noiseflow/cc/python/rfft.py
+-rw-r--r--  2.0 unx    27277 b- defN 80-Jan-01 00:00 noiseflow/cc/python/stack.py
+-rw-r--r--  2.0 unx     3310 b- defN 80-Jan-01 00:00 noiseflow/cc/python/utils.py
+-rw-r--r--  2.0 unx     8127 b- defN 80-Jan-01 00:00 noiseflow/cc/rfftdata.py
+-rw-r--r--  2.0 unx     5512 b- defN 80-Jan-01 00:00 noiseflow/cc/src/pybind11.cpp
+-rw-r--r--  2.0 unx    37323 b- defN 80-Jan-01 00:00 noiseflow/cc/stackdata.py
+-rw-r--r--  2.0 unx    10646 b- defN 80-Jan-01 00:00 noiseflow/cc/utils_load.py
+-rw-r--r--  2.0 unx     1368 b- defN 80-Jan-01 00:00 noiseflow/cc/utils_time.py
+-rw-r--r--  2.0 unx     8858 b- defN 80-Jan-01 00:00 noiseflow/cc/wrapper.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/client/__init__.py
+-rw-r--r--  2.0 unx     7776 b- defN 80-Jan-01 00:00 noiseflow/client/client.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/dispersion/__init__.py
+-rw-r--r--  2.0 unx       29 b- defN 80-Jan-01 00:00 noiseflow/dispersion/app_dispersion.py
+-rw-r--r--  2.0 unx       27 b- defN 80-Jan-01 00:00 noiseflow/dispersion/test.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/dvv/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/dvv/monitoring.py
+-rw-r--r--  2.0 unx      193 b- defN 80-Jan-01 00:00 noiseflow/real_time/watch_dog.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/signal/__init__.py
+-rw-r--r--  2.0 unx     2899 b- defN 80-Jan-01 00:00 noiseflow/signal/include/decimate.hpp
+-rw-r--r--  2.0 unx     3291 b- defN 80-Jan-01 00:00 noiseflow/signal/include/detrend.hpp
+-rw-r--r--  2.0 unx    12708 b- defN 80-Jan-01 00:00 noiseflow/signal/include/filter.hpp
+-rw-r--r--  2.0 unx     4737 b- defN 80-Jan-01 00:00 noiseflow/signal/include/taper.hpp
+-rw-r--r--  2.0 unx     1284 b- defN 80-Jan-01 00:00 noiseflow/signal/include/utils.hpp
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/signal/python/__init__.py
+-rw-r--r--  2.0 unx      747 b- defN 80-Jan-01 00:00 noiseflow/signal/python/decimate.py
+-rw-r--r--  2.0 unx     2004 b- defN 80-Jan-01 00:00 noiseflow/signal/python/detrend.py
+-rw-r--r--  2.0 unx     6813 b- defN 80-Jan-01 00:00 noiseflow/signal/python/filter.py
+-rw-r--r--  2.0 unx     2917 b- defN 80-Jan-01 00:00 noiseflow/signal/python/taper.py
+-rw-r--r--  2.0 unx     3263 b- defN 80-Jan-01 00:00 noiseflow/signal/rawdata.py
+-rw-r--r--  2.0 unx     7355 b- defN 80-Jan-01 00:00 noiseflow/signal/src/pybind11.cpp
+-rw-r--r--  2.0 unx    10225 b- defN 80-Jan-01 00:00 noiseflow/signal/wrapper.py
+-rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 noiseflow/tests/__init__.py
+-rwxr-xr-x  2.0 unx  1257600 b- defN 80-Jan-01 00:00 noiseflow/lib/cc_share.cpython-39-x86_64-linux-gnu.so
+-rwxr-xr-x  2.0 unx   786144 b- defN 80-Jan-01 00:00 noiseflow/lib/signal_share.cpython-39-x86_64-linux-gnu.so
+-rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 noiseflow-0.0.6b0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     5002 b- defN 80-Jan-01 00:00 noiseflow-0.0.6b0.dist-info/METADATA
+-rw-r--r--  2.0 unx      108 b- defN 80-Jan-01 00:00 noiseflow-0.0.6b0.dist-info/WHEEL
+?rw-r--r--  2.0 unx     4275 b- defN 16-Jan-01 00:00 noiseflow-0.0.6b0.dist-info/RECORD
+50 files, 2303442 bytes uncompressed, 888140 bytes compressed:  61.5%
```

## zipnote {}

```diff
@@ -126,20 +126,26 @@
 
 Filename: noiseflow/signal/wrapper.py
 Comment: 
 
 Filename: noiseflow/tests/__init__.py
 Comment: 
 
-Filename: noiseflow-0.0.6.dist-info/LICENSE
+Filename: noiseflow/lib/cc_share.cpython-39-x86_64-linux-gnu.so
 Comment: 
 
-Filename: noiseflow-0.0.6.dist-info/METADATA
+Filename: noiseflow/lib/signal_share.cpython-39-x86_64-linux-gnu.so
 Comment: 
 
-Filename: noiseflow-0.0.6.dist-info/WHEEL
+Filename: noiseflow-0.0.6b0.dist-info/LICENSE
 Comment: 
 
-Filename: noiseflow-0.0.6.dist-info/RECORD
+Filename: noiseflow-0.0.6b0.dist-info/METADATA
+Comment: 
+
+Filename: noiseflow-0.0.6b0.dist-info/WHEEL
+Comment: 
+
+Filename: noiseflow-0.0.6b0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## .gitmodules

```diff
@@ -1,21 +1,6 @@
-[submodule "extern/xtensor"]
-	path = extern/xtensor
-	url = https://github.com/xtensor-stack/xtensor
-[submodule "extern/xtl"]
-	path = extern/xtl
-	url = https://github.com/xtensor-stack/xtl
-[submodule "extern/xsimd"]
-	path = extern/xsimd
-	url = https://github.com/xtensor-stack/xsimd
-[submodule "extern/xtensor-python"]
-	path = extern/xtensor-python
-	url = https://github.com/xtensor-stack/xtensor-python
-[submodule "extern/xtensor-blas"]
-	path = extern/xtensor-blas
-	url = https://github.com/xtensor-stack/xtensor-blas
-[submodule "extern/xtensor-fftw"]
-	path = extern/xtensor-fftw
-	url = https://github.com/xtensor-stack/xtensor-fftw
-[submodule "extern/kfr"]
-	path = extern/kfr
-	url = https://github.com/kfrlib/kfr.git
+[submodule "extern/xtensor-fftw"]
+	path = extern/xtensor-fftw
+	url = https://github.com/xtensor-stack/xtensor-fftw
+[submodule "extern/kfr"]
+	path = extern/kfr
+	url = https://github.com/kfrlib/kfr
```

## CMakeLists.txt

```diff
@@ -1,137 +1,136 @@
-###################################################################  
-#   Optimization Parameters
-################################################################### 
-cmake_minimum_required(VERSION 3.18)
-set(CMAKE_CXX_STANDARD 17)
-set(CMAKE_CXX_FLAGS "-Wall -g -fPIC -O3")
-set(XTENSOR_USE_XSIMD 1) # set xtensor to use xsimd for SIMD optimization
-set(CMAKE_PREFIX_PATH $ENV{CONDA_PREFIX}) # set conda env path, so that cmake can find those libraries in conda env
-
-
-
-
-###################################################################  
-#   Project Info & Compiler Detection
-###################################################################  
-project(noiseflow_share VERSION 0.1.0 LANGUAGES CXX)
-message("Check C++ compiler: ${CMAKE_CXX_COMPILER_ID}")
-if ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
-    if (MINGW)
-        message("Using MinGW-w64")
-        set(COMPILER "MinGW-w64")
-    else()
-        message("Using GCC")
-        set(COMPILER "GCC")
-    endif()
-elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang")
-    message("Using Clang")
-    set(COMPILER "Clang")
-elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "AppleClang")
-    message("Using AppleClang")
-    set(COMPILER "AppleClang")
-elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "MSVC")
-    message("Using MSVC")
-    set(COMPILER "MSVC")
-elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Intel")
-    message("Using Intel Compiler")
-    set(COMPILER "Intel")
-elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "IntelLLVM")
-    message("Using Intel oneAPI Compiler")
-    set(COMPILER "Intel oneAPI")
-else()
-    message(FATAL_ERROR "Unrecognized compiler: ${CMAKE_CXX_COMPILER_ID}")
-endif()
-
-
-
-
-###################################################################  
-#   Find Libraries
-###################################################################  
-### [a]. use find_package for numpy
-find_package(Python REQUIRED COMPONENTS Interpreter Development NumPy)
-### [b]. use execute_process for numpy
-# execute_process(
-#   COMMAND "${PYTHON_EXECUTABLE}"
-#   -c "import numpy; print(numpy.get_include())"
-#   OUTPUT_VARIABLE NumPy_INCLUDE_DIRS
-#   OUTPUT_STRIP_TRAILING_WHITESPACE
-# )
-
-
-### pybind11 xtensor xtl xsimd xtensor-blas xtensor-python
-find_package(pybind11 REQUIRED CONFIG)
-find_package(xtensor REQUIRED)
-find_package(xtl REQUIRED)
-find_package(xsimd REQUIRED)
-find_package(xtensor-blas REQUIRED)
-find_package(xtensor-python REQUIRED)
-
-
-### xtensor-fftw
-set(FFTW_USE_FLOAT ON CACHE BOOL "Use float precision") # set fftw3 to use float precision
-set(FFTW_USE_DOUBLE ON CACHE BOOL "Use double precision") # set fftw3 to use double precision
-set(FFTW_USE_LONG_DOUBLE OFF CACHE BOOL "Use long double precision") # set fftw3 to use long double precision
-# find_package(xtensor-fftw REQUIRED) # this command must be after set(FFTW_USE_FLOAT ON CACHE BOOL "Use double precision")
-include_directories("./extern/xtensor-fftw/include")
-
-
-### FFTW3 using FindFFTW.cmake (note this command will seach some default path to find fftw3, for example the conda env path)
-set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} "${CMAKE_CURRENT_SOURCE_DIR}/extern/xtensor-fftw/cmake/Modules/findFFTW") # use FindFFTW.cmake to find fftw3
-find_package(FFTW REQUIRED COMPONENTS ${REQUIRE_FLOAT_LIB} ${REQUIRE_DOUBLE_LIB} ${REQUIRE_LONG_DOUBLE_LIB})
-if(FFTW_FOUND)
-    message(STATUS "FFTW Found!")
-endif()
-
-
-### BLAS/LAPACK, which is xtensor-blas' dependencies
-add_definitions(-DHAVE_CBLAS=1)
-find_package(BLAS REQUIRED)
-find_package(LAPACK REQUIRED)
-message(STATUS "BLAS VENDOR:    " ${BLA_VENDOR})
-message(STATUS "BLAS LIBRARIES: " ${BLAS_LIBRARIES})
-
-
-### OpenMP (clang doesn't bring openmp, you need to install it by brew, and find_package can't find it, you need to set the PATH as below. refer to https://www.kancloud.cn/csyangbinbin/cmake-cookbook1/2157938  https://iscinumpy.gitlab.io/post/omp-on-high-sierra/)
-if(APPLE AND "${CMAKE_CXX_COMPILER_ID}" MATCHES "AppleClang")
-    message(STATUS "Using AppleClang in mac will set brew lib path for OpenMP")
-    execute_process(COMMAND brew --prefix OUTPUT_VARIABLE BREW_PREFIX OUTPUT_STRIP_TRAILING_WHITESPACE)
-    set(OpenMP_CXX_FLAGS "-Xpreprocessor -fopenmp -I${BREW_PREFIX}/opt/libomp/include")
-    set(OpenMP_CXX_LIB_NAMES "omp")
-    set(OpenMP_omp_LIBRARY "${BREW_PREFIX}/opt/libomp/lib")
-    find_package(OpenMP REQUIRED)
-else()
-    find_package(OpenMP REQUIRED)
-endif()
-
-
-### KFR 
-include_directories("./extern/kfr/include")
-
-
-
-
-###################################################################  
-#   Target -- Python Package Module
-################################################################### 
-pybind11_add_module(cc_share ${CMAKE_SOURCE_DIR}/noiseflow/cc/src/pybind11.cpp)
-target_include_directories(cc_share PRIVATE ${CMAKE_SOURCE_DIR}/noiseflow/cc/src ${CMAKE_SOURCE_DIR}/noiseflow/cc/include)
-if(OPENMP_FOUND)
-    target_link_libraries(cc_share PUBLIC ${BLAS_LIBRARIES} ${LAPACK_LIBRARIES} ${FFTW_LIBRARIES} pybind11::module xtensor xtensor::optimize xtensor::use_xsimd xtensor-python Python::NumPy OpenMP::OpenMP_CXX) 
-else()
-    target_link_libraries(cc_share PUBLIC ${BLAS_LIBRARIES} ${LAPACK_LIBRARIES} ${FFTW_LIBRARIES} pybind11::module xtensor xtensor::optimize xtensor::use_xsimd xtensor-python)
-endif()
-
-
-pybind11_add_module(signal_share ${CMAKE_SOURCE_DIR}/noiseflow/signal/src/pybind11.cpp)
-target_include_directories(signal_share PRIVATE ${CMAKE_SOURCE_DIR}/noiseflow/signal/src ${CMAKE_SOURCE_DIR}/noiseflow/signal/include)
-if(OPENMP_FOUND)
-    target_link_libraries(signal_share PUBLIC ${BLAS_LIBRARIES} ${LAPACK_LIBRARIES} ${FFTW_LIBRARIES} pybind11::module xtensor xtensor::optimize xtensor::use_xsimd xtensor-python Python::NumPy OpenMP::OpenMP_CXX)
-else()
-    target_link_libraries(signal_share PUBLIC ${BLAS_LIBRARIES} ${LAPACK_LIBRARIES} ${FFTW_LIBRARIES} pybind11::module xtensor xtensor::optimize xtensor::use_xsimd xtensor-python)
-endif()
-
-
-### setup.py will install the module to the python site-packages
-# install(TARGETS cc_share DESTINATION lib)
+###################################################################  
+#   Optimization Parameters
+################################################################### 
+cmake_minimum_required(VERSION 3.18)
+set(CMAKE_CXX_STANDARD 17)
+set(CMAKE_CXX_FLAGS "-Wall -g -fPIC -O3")
+set(XTENSOR_USE_XSIMD 1) # set xtensor to use xsimd for SIMD optimization
+set(CMAKE_PREFIX_PATH $ENV{CONDA_PREFIX}) # set conda env path, so that cmake can find those libraries in conda env
+
+
+
+
+###################################################################  
+#   Project Info & Compiler Detection
+###################################################################  
+project(noiseflow_share VERSION 0.1.0 LANGUAGES CXX)
+message("Check C++ compiler: ${CMAKE_CXX_COMPILER_ID}")
+if ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "GNU")
+    if (MINGW)
+        message("Using MinGW-w64")
+        set(COMPILER "MinGW-w64")
+    else()
+        message("Using GCC")
+        set(COMPILER "GCC")
+    endif()
+elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Clang")
+    message("Using Clang")
+    set(COMPILER "Clang")
+elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "AppleClang")
+    message("Using AppleClang")
+    set(COMPILER "AppleClang")
+elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "MSVC")
+    message("Using MSVC")
+    set(COMPILER "MSVC")
+elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "Intel")
+    message("Using Intel Compiler")
+    set(COMPILER "Intel")
+elseif ("${CMAKE_CXX_COMPILER_ID}" STREQUAL "IntelLLVM")
+    message("Using Intel oneAPI Compiler")
+    set(COMPILER "Intel oneAPI")
+else()
+    message(FATAL_ERROR "Unrecognized compiler: ${CMAKE_CXX_COMPILER_ID}")
+endif()
+
+
+
+
+###################################################################  
+#   Find Libraries
+###################################################################  
+### [a]. use find_package for numpy
+find_package(Python REQUIRED COMPONENTS Interpreter Development NumPy)
+### [b]. use execute_process for numpy
+# execute_process(
+#   COMMAND "${PYTHON_EXECUTABLE}"
+#   -c "import numpy; print(numpy.get_include())"
+#   OUTPUT_VARIABLE NumPy_INCLUDE_DIRS
+#   OUTPUT_STRIP_TRAILING_WHITESPACE
+# )
+
+
+### pybind11 xtensor xtl xsimd xtensor-blas xtensor-python
+find_package(pybind11 REQUIRED CONFIG)
+find_package(xtensor REQUIRED)
+find_package(xtl REQUIRED)
+find_package(xsimd REQUIRED)
+find_package(xtensor-blas REQUIRED)
+find_package(xtensor-python REQUIRED)
+
+
+### xtensor-fftw
+set(FFTW_USE_FLOAT ON CACHE BOOL "Use float precision") # set fftw3 to use float precision
+set(FFTW_USE_DOUBLE ON CACHE BOOL "Use double precision") # set fftw3 to use double precision
+set(FFTW_USE_LONG_DOUBLE OFF CACHE BOOL "Use long double precision") # set fftw3 to use long double precision
+# find_package(xtensor-fftw REQUIRED) # this command must be after set(FFTW_USE_FLOAT ON CACHE BOOL "Use double precision")
+include_directories("./extern/xtensor-fftw/include")
+
+
+### FFTW3 using FindFFTW.cmake (note this command will seach some default path to find fftw3, for example the conda env path)
+set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} "${CMAKE_CURRENT_SOURCE_DIR}/extern/xtensor-fftw/cmake/Modules/findFFTW") # use FindFFTW.cmake to find fftw3
+find_package(FFTW REQUIRED COMPONENTS ${REQUIRE_FLOAT_LIB} ${REQUIRE_DOUBLE_LIB} ${REQUIRE_LONG_DOUBLE_LIB})
+if(FFTW_FOUND)
+    message(STATUS "FFTW Found!")
+endif()
+
+
+### BLAS/LAPACK, which is xtensor-blas' dependencies
+add_definitions(-DHAVE_CBLAS=1)
+find_package(BLAS REQUIRED)
+find_package(LAPACK REQUIRED)
+message(STATUS "BLAS VENDOR:    " ${BLA_VENDOR})
+message(STATUS "BLAS LIBRARIES: " ${BLAS_LIBRARIES})
+
+
+### OpenMP (clang doesn't bring openmp, you need to install it by brew, and find_package can't find it, you need to set the PATH as below. refer to https://www.kancloud.cn/csyangbinbin/cmake-cookbook1/2157938  https://iscinumpy.gitlab.io/post/omp-on-high-sierra/)
+if(APPLE AND "${CMAKE_CXX_COMPILER_ID}" MATCHES "AppleClang" OR "${CMAKE_CXX_COMPILER_ID}" MATCHES "Clang")
+    message(STATUS "Using AppleClang in mac will set brew lib path for OpenMP")
+    execute_process(COMMAND brew --prefix OUTPUT_VARIABLE BREW_PREFIX OUTPUT_STRIP_TRAILING_WHITESPACE)
+    set(OpenMP_CXX_FLAGS "-Xpreprocessor -fopenmp -I${BREW_PREFIX}/opt/libomp/include")
+    set(OpenMP_CXX_LIB_NAMES "omp")
+    set(OpenMP_omp_LIBRARY "${BREW_PREFIX}/opt/libomp/lib")
+endif()
+find_package(OpenMP REQUIRED)
+
+
+
+### KFR 
+include_directories("./extern/kfr/include")
+
+
+
+
+###################################################################  
+#   Target -- Python Package Module
+################################################################### 
+pybind11_add_module(cc_share ${CMAKE_SOURCE_DIR}/noiseflow/cc/src/pybind11.cpp)
+target_include_directories(cc_share PRIVATE ${CMAKE_SOURCE_DIR}/noiseflow/cc/src ${CMAKE_SOURCE_DIR}/noiseflow/cc/include)
+if(OPENMP_FOUND)
+    target_link_libraries(cc_share PUBLIC ${BLAS_LIBRARIES} ${LAPACK_LIBRARIES} ${FFTW_LIBRARIES} pybind11::module xtensor xtensor::optimize xtensor::use_xsimd xtensor-python Python::NumPy OpenMP::OpenMP_CXX) 
+else()
+    target_link_libraries(cc_share PUBLIC ${BLAS_LIBRARIES} ${LAPACK_LIBRARIES} ${FFTW_LIBRARIES} pybind11::module xtensor xtensor::optimize xtensor::use_xsimd xtensor-python)
+endif()
+
+
+pybind11_add_module(signal_share ${CMAKE_SOURCE_DIR}/noiseflow/signal/src/pybind11.cpp)
+target_include_directories(signal_share PRIVATE ${CMAKE_SOURCE_DIR}/noiseflow/signal/src ${CMAKE_SOURCE_DIR}/noiseflow/signal/include)
+if(OPENMP_FOUND)
+    target_link_libraries(signal_share PUBLIC ${BLAS_LIBRARIES} ${LAPACK_LIBRARIES} ${FFTW_LIBRARIES} pybind11::module xtensor xtensor::optimize xtensor::use_xsimd xtensor-python Python::NumPy OpenMP::OpenMP_CXX)
+else()
+    target_link_libraries(signal_share PUBLIC ${BLAS_LIBRARIES} ${LAPACK_LIBRARIES} ${FFTW_LIBRARIES} pybind11::module xtensor xtensor::optimize xtensor::use_xsimd xtensor-python)
+endif()
+
+
+### setup.py will install the module to the python site-packages
+# install(TARGETS cc_share DESTINATION lib)
 # install(TARGETS signal_share DESTINATION lib)
```

## noiseflow/__init__.py

 * *Ordering differences only*

```diff
@@ -1,42 +1,42 @@
-import os
-import re
-import json
-
-
-env = os.environ.get('CONDA_DEFAULT_ENV')
-env = re.sub('[^a-zA-Z0-9_]', '', env)[0:50]
-config_path = os.path.abspath(os.path.expanduser(f'~/.noiseflow/config_{env}.json'))    
-
-try:
-    from noiseflow.lib import cc_share
-    from noiseflow.lib import signal_share
-    NOISEFLOW_USE_CPP = True
-except:
-    NOISEFLOW_USE_CPP = False
-
-os.makedirs(os.path.expanduser('~/.noiseflow'), exist_ok=True)
-compile_time_env = {"NOISEFLOW_USE_CPP": NOISEFLOW_USE_CPP}
-with open(config_path, 'w') as f:
-    json.dump(compile_time_env, f)
-
-
-from noiseflow.cc.wrapper import rfft, corr, stack
-from noiseflow.cc.rfftdata import RFFTData_Class
-from noiseflow.cc.corrdata import CorrData_Class
-from noiseflow.cc.stackdata import StackData_Class
-from noiseflow.cc.utils_time import time_linspace, get_timestamp, get_stack_timestamp
-from noiseflow.cc.utils_load import load_raw, load_rfft, load_corr, load_stack
-
-from noiseflow.signal.rawdata import RawData_Class
-from noiseflow.signal.wrapper import bandpass, bandstop, lowpass, highpass, detrend, decimate, taper
-
-from noiseflow.client.client import downloader, downloader_https
-
-from noiseflow.dispersion import app_dispersion, test
-
-__all__ = ["wrapper", "dispersion", "tests"]
-
-
-
-
+import os
+import re
+import json
+
+
+env = os.environ.get('CONDA_DEFAULT_ENV')
+env = re.sub('[^a-zA-Z0-9_]', '', env)[0:50]
+config_path = os.path.abspath(os.path.expanduser(f'~/.noiseflow/config_{env}.json'))    
+
+try:
+    from noiseflow.lib import cc_share
+    from noiseflow.lib import signal_share
+    NOISEFLOW_USE_CPP = True
+except:
+    NOISEFLOW_USE_CPP = False
+
+os.makedirs(os.path.expanduser('~/.noiseflow'), exist_ok=True)
+compile_time_env = {"NOISEFLOW_USE_CPP": NOISEFLOW_USE_CPP}
+with open(config_path, 'w') as f:
+    json.dump(compile_time_env, f)
+
+
+from noiseflow.cc.wrapper import rfft, corr, stack
+from noiseflow.cc.rfftdata import RFFTData_Class
+from noiseflow.cc.corrdata import CorrData_Class
+from noiseflow.cc.stackdata import StackData_Class
+from noiseflow.cc.utils_time import time_linspace, get_timestamp, get_stack_timestamp
+from noiseflow.cc.utils_load import load_raw, load_rfft, load_corr, load_stack
+
+from noiseflow.signal.rawdata import RawData_Class
+from noiseflow.signal.wrapper import bandpass, bandstop, lowpass, highpass, detrend, decimate, taper
+
+from noiseflow.client.client import downloader, downloader_https
+
+from noiseflow.dispersion import app_dispersion, test
+
+__all__ = ["wrapper", "dispersion", "tests"]
+
+
+
+
 __version__ = "0.0.1"
```

## noiseflow/cc/corrdata.py

 * *Ordering differences only*

```diff
@@ -1,292 +1,292 @@
-import os
-import h5py
-import numpy as np
-import matplotlib.pyplot as plt
-
-from scipy.io import savemat
-from obspy.core import UTCDateTime
-from obspy.signal.filter import bandpass
-from noiseflow.cc.utils_time import time_linspace, get_timestamp
-
-
-class CorrData_Class(object):
-    def __init__(self, corr_data, dt, 
-                 corr_method, corr_pair, maxlag,smoothspect_N,
-                flag, flag_gap, threads, jobs, py):
-        self.corr_data = corr_data
-        self.dt = dt
-        self.corr_method = corr_method
-        self.corr_pair = corr_pair
-        self.maxlag = maxlag
-        self.smoothspect_N=smoothspect_N
-        self.flag=flag
-        self.flag_gap=flag_gap
-        self.threads=threads
-        self.jobs=jobs
-        self.py=py
-
-    def save(self, save_path, format='npz', compression=False, h5_compression_format='gzip', h5_compression_opts=3):
-        if format == 'npz':
-            if compression:
-                np.savez_compressed(save_path,
-                                    corr_data=self.corr_data,
-                                    dt=self.dt,
-                                    corr_method = self.corr_method,
-                                    corr_pair = self.corr_pair,
-                                    maxlag = self.maxlag,
-                                    smoothspect_N = self.smoothspect_N,
-                                    flag = self.flag,
-                                    flag_gap = self.flag_gap,
-                                    threads = self.threads,
-                                    jobs = self.jobs,
-                                    py = self.py)
-            else:
-                np.savez(save_path,
-                        corr_data=self.corr_data,
-                        dt=self.dt,
-                        corr_method = self.corr_method,
-                        corr_pair = self.corr_pair,
-                        maxlag = self.maxlag,
-                        smoothspect_N = self.smoothspect_N,
-                        flag = self.flag,
-                        flag_gap = self.flag_gap,
-                        threads = self.threads,
-                        jobs = self.jobs,
-                        py = self.py)
-                
-        elif format == 'h5':
-            with h5py.File(save_path, 'w') as f:
-                group = f.create_group('noiseflow_group')
-                group.attrs['dt'] = self.dt
-                group.attrs['corr_method'] = self.corr_method
-                group.attrs['corr_pair'] = self.corr_pair
-                group.attrs['maxlag'] = self.maxlag
-                group.attrs['smoothspect_N'] = self.smoothspect_N
-                group.attrs['flag'] = self.flag
-                group.attrs['flag_gap'] = self.flag_gap
-                group.attrs['threads'] = self.threads
-                group.attrs['jobs'] = self.jobs
-                group.attrs['py'] = self.py
-                group.create_dataset('corr_pair', data=self.corr_pair)
-                if compression:
-                    group.create_dataset('corr_data', data=self.corr_data, compression=h5_compression_format, compression_opts=h5_compression_opts)
-                else:
-                    group.create_dataset('corr_data', data=self.corr_data)
-
-        elif format == 'mat':
-            savemat(save_path,
-                {'corr_data': self.corr_data,
-                 'dt': self.dt,
-                 'corr_method': self.corr_method,
-                 'corr_pair': self.corr_pair,
-                 'maxlag': self.maxlag,
-                 'smoothspect_N': self.smoothspect_N,
-                 'flag': self.flag,
-                 'flag_gap': self.flag_gap,
-                 'threads': self.threads,
-                 'jobs': self.jobs,
-                 'py': self.py},
-                do_compression=compression) 
-        else:
-            raise ValueError("format must be 'npz', 'h5' or 'mat'")
-        
-
-    # plot
-    def plot(self, 
-             pair_indx=0, 
-             t_min=UTCDateTime("1970-01-01T00:00:00.0"), 
-             cc_len=None, 
-             cc_step=None, 
-             win_start=None, 
-             win_end=None, 
-             lag_start=None, 
-             lag_end=None, 
-             amp_normalize=True, 
-             amp_scale=1, 
-             filter=False, 
-             f1=None, 
-             f2=None, 
-             corners=4, 
-             zerophase=True, 
-             win_interval=None, 
-             mode='waveform', 
-             cmap='seismic',
-             linewidth=0.8, 
-             yticklabel_num=5, 
-             figsize=(10, 6),
-             save=False, 
-             save_path=None, 
-             dpi=100):
-        
-        # check pair_indx
-        if pair_indx >= self.corr_data.shape[0]:
-            raise ValueError("pair_indx must be <= (corr_data.shape[0]=%d)" % self.corr_data.shape[0])
-        
-        # init cc_len cc_step
-        if cc_len == None:
-            cc_len = self.corr_data.shape[2]*self.dt
-        if cc_step == None:
-            cc_step = 0.0
-
-        # init timestamp
-        t_max, win_interval_raw, win_vector = get_timestamp(win_num=self.corr_data.shape[1], 
-                                                        cc_len=cc_len, 
-                                                        cc_step=cc_step, 
-                                                        t_min=t_min)
-
-        # init win_start
-        if win_start == None:
-            win_start = t_min
-        if win_start < t_min:
-            raise ValueError("win_start must be >= (t_min=%s)" % str(t_min))
-
-        # init win_end
-        if win_end == None:
-            win_end = t_max
-        if win_end > t_max:
-            raise ValueError("win_end must be <= (t_max=%s)" % str(t_max))
-
-        # init win_interval
-        if win_interval == None:
-            win_interval = win_interval_raw      
-        if win_interval < win_interval_raw:
-            raise ValueError("win_interval must be >= %f" % win_interval_raw)
-        if win_interval > t_max-t_min-cc_len:
-            raise ValueError("win_interval must be <= %f" % (t_max-t_min-cc_len))
-
-        # init lag_start 
-        if lag_start == None:
-            lag_start = -self.maxlag
-        if lag_start < -self.maxlag:
-            raise ValueError("lag_start must be >= (-maxlag=-%f)" % self.maxlag)
-        
-        # init lag_end
-        if lag_end == None:
-            lag_end = self.maxlag
-        if lag_end > self.maxlag:
-            raise ValueError("lag_end must be <= (maxlag=%f)" % self.maxlag)
-        
-        # lag vector
-        tt = np.arange(lag_start, lag_end+self.dt, self.dt)
-        tp_start = round((lag_start+self.maxlag)/self.dt)
-        tp_end = tp_start+len(tt)  # make sure same length, so do not use round((lag_end+self.maxlag+self.dt)/self.dt)
-
-        # select and filter data according to win_start, win_end
-        win_indx = np.where((win_vector >= win_start) & (win_vector <= win_end))[0]
-        if filter:
-            data=np.empty((len(win_indx), len(tt)))
-            for i in range(0, len(win_indx)):
-                data[i,:] = bandpass(self.corr_data[pair_indx, win_indx[i], tp_start:tp_end], f1, f2, int(1/self.dt), corners=corners, zerophase=zerophase)
-        else:
-            data = self.corr_data[pair_indx, win_indx, tp_start:tp_end]
-
-        # plot
-        if mode == 'waveform':
-            # init fig
-            fig, ax = plt.subplots(figsize=figsize)
-
-            # normalize
-            if amp_normalize:
-                scale = np.max(np.abs(data), axis=1)[:,None]
-                if np.min(scale) != 0:
-                    data_plot = amp_scale*data/scale
-                else:
-                    raise ValueError("data is all zeros in amp_normalize=True")
-            else:
-                scale = np.max(np.abs(data))
-                if scale != 0:
-                    data_plot = amp_scale*data/scale
-                else:
-                    raise ValueError("data is all zeros in amp_normalize=False")
-
-            # get win_interval index
-            ydist_n=[]
-            win_interval_n = round(win_interval/win_interval_raw)
-            for i in range(0, len(win_indx), win_interval_n):
-                ydist_n.append(i)
-            ydist_n = np.int64(np.array(ydist_n))
-
-            # plot wavefrom
-            for i in range(0, len(ydist_n)):
-                ax.plot(tt, data_plot[ydist_n[i]]+ydist_n[i], 'k', linewidth=linewidth)
-
-            # set x axis
-            ax.set_title("CorrData: pair_indx=%d, filter=[%.2f, %.2f] hz" % (pair_indx, f1, f2))
-            ax.set_xlim(tt[0], tt[-1])
-            ax.set_xlabel('Time(s)')
-            
-            # set y axis
-            yy_tick = np.linspace(0, len(win_indx)-1, num=yticklabel_num)
-            yy_label_UTC = time_linspace(win_start, win_end, num=yticklabel_num)
-            yy_label = np.array([i.strftime('%Y-%m-%dT%H:%M:%S') for i in yy_label_UTC])
-            ax.set_yticks(yy_tick)
-            ax.set_yticklabels(yy_label, rotation=45)
-
-            # save or show
-            if save:
-                if save_path is None:
-                    raise ValueError("save_path must be specified")
-                fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight')
-                plt.close(fig)
-            else:
-                plt.show()
-
-        elif mode == 'mat':
-            # init fig
-            fig, ax = plt.subplots(figsize=figsize)
-
-            # average all data
-            cc_mean = np.mean(data, axis=0)/np.max(np.mean(data, axis=0))
-
-            # average win_interval data
-            ntrace = int((win_end-win_start)/win_interval)
-            ndata  = np.zeros(shape=(ntrace,len(tt)))
-            for i in range(0,ntrace):
-                tindx = np.where(((win_vector-win_start)>=i*win_interval) & ((win_vector-win_start)<(i+1)*win_interval))[0]
-                ndata[i] = np.mean(data[tindx],axis=0)
-
-            # normalize waveforms
-            if amp_normalize:
-                scale = np.max(np.abs(ndata), axis=1)[:,None]
-                if np.min(scale) != 0:
-                    ndata_plot = ndata/scale
-                else:
-                    raise ValueError("data is all zeros in amp_normalize=True")
-            else:
-                scale = np.max(np.abs(ndata))
-                if scale != 0:
-                    ndata_plot = ndata/scale
-                else:
-                    raise ValueError("data is all zeros in amp_normalize=False")
-                
-            # plot mat
-            cax=ax.matshow(ndata_plot, extent=[lag_start, lag_end, ntrace, 0], aspect='auto', cmap=cmap)
-            ax.plot(tt, ntrace/10*cc_mean+ntrace/2, 'k', linewidth=linewidth)
-            
-            # set x axis
-            ax.set_title("CorrData: pair_indx=%d, filter=[%.2f, %.2f] hz" % (pair_indx, f1, f2))
-            ax.set_xlim(tt[0], tt[-1])
-            ax.set_xlabel('Time(s)')
-            ax.xaxis.set_ticks_position('bottom')
-            
-            # set y axis
-            ax.invert_yaxis()
-            ax.set_ylim(0, ntrace)
-            yy_tick=np.linspace(0, ntrace, num=yticklabel_num)
-            yy_label_UTC=time_linspace(win_start, win_end, num=yticklabel_num)
-            yy_label = np.array([i.strftime('%Y-%m-%dT%H:%M:%S') for i in yy_label_UTC])
-            ax.set_yticks(yy_tick)
-            ax.set_yticklabels(yy_label, rotation=45)
-
-            # save or show
-            if save:
-                if save_path is None:
-                    raise ValueError("save_path must be specified")
-                fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches = 'tight') 
-                plt.close(fig)
-            else:
-                plt.show()
-
-        else:
-            raise ValueError("mode must be 'waveform' or 'mat'")
-        
+import os
+import h5py
+import numpy as np
+import matplotlib.pyplot as plt
+
+from scipy.io import savemat
+from obspy.core import UTCDateTime
+from obspy.signal.filter import bandpass
+from noiseflow.cc.utils_time import time_linspace, get_timestamp
+
+
+class CorrData_Class(object):
+    def __init__(self, corr_data, dt, 
+                 corr_method, corr_pair, maxlag,smoothspect_N,
+                flag, flag_gap, threads, jobs, py):
+        self.corr_data = corr_data
+        self.dt = dt
+        self.corr_method = corr_method
+        self.corr_pair = corr_pair
+        self.maxlag = maxlag
+        self.smoothspect_N=smoothspect_N
+        self.flag=flag
+        self.flag_gap=flag_gap
+        self.threads=threads
+        self.jobs=jobs
+        self.py=py
+
+    def save(self, save_path, format='npz', compression=False, h5_compression_format='gzip', h5_compression_opts=3):
+        if format == 'npz':
+            if compression:
+                np.savez_compressed(save_path,
+                                    corr_data=self.corr_data,
+                                    dt=self.dt,
+                                    corr_method = self.corr_method,
+                                    corr_pair = self.corr_pair,
+                                    maxlag = self.maxlag,
+                                    smoothspect_N = self.smoothspect_N,
+                                    flag = self.flag,
+                                    flag_gap = self.flag_gap,
+                                    threads = self.threads,
+                                    jobs = self.jobs,
+                                    py = self.py)
+            else:
+                np.savez(save_path,
+                        corr_data=self.corr_data,
+                        dt=self.dt,
+                        corr_method = self.corr_method,
+                        corr_pair = self.corr_pair,
+                        maxlag = self.maxlag,
+                        smoothspect_N = self.smoothspect_N,
+                        flag = self.flag,
+                        flag_gap = self.flag_gap,
+                        threads = self.threads,
+                        jobs = self.jobs,
+                        py = self.py)
+                
+        elif format == 'h5':
+            with h5py.File(save_path, 'w') as f:
+                group = f.create_group('noiseflow_group')
+                group.attrs['dt'] = self.dt
+                group.attrs['corr_method'] = self.corr_method
+                group.attrs['corr_pair'] = self.corr_pair
+                group.attrs['maxlag'] = self.maxlag
+                group.attrs['smoothspect_N'] = self.smoothspect_N
+                group.attrs['flag'] = self.flag
+                group.attrs['flag_gap'] = self.flag_gap
+                group.attrs['threads'] = self.threads
+                group.attrs['jobs'] = self.jobs
+                group.attrs['py'] = self.py
+                group.create_dataset('corr_pair', data=self.corr_pair)
+                if compression:
+                    group.create_dataset('corr_data', data=self.corr_data, compression=h5_compression_format, compression_opts=h5_compression_opts)
+                else:
+                    group.create_dataset('corr_data', data=self.corr_data)
+
+        elif format == 'mat':
+            savemat(save_path,
+                {'corr_data': self.corr_data,
+                 'dt': self.dt,
+                 'corr_method': self.corr_method,
+                 'corr_pair': self.corr_pair,
+                 'maxlag': self.maxlag,
+                 'smoothspect_N': self.smoothspect_N,
+                 'flag': self.flag,
+                 'flag_gap': self.flag_gap,
+                 'threads': self.threads,
+                 'jobs': self.jobs,
+                 'py': self.py},
+                do_compression=compression) 
+        else:
+            raise ValueError("format must be 'npz', 'h5' or 'mat'")
+        
+
+    # plot
+    def plot(self, 
+             pair_indx=0, 
+             t_min=UTCDateTime("1970-01-01T00:00:00.0"), 
+             cc_len=None, 
+             cc_step=None, 
+             win_start=None, 
+             win_end=None, 
+             lag_start=None, 
+             lag_end=None, 
+             amp_normalize=True, 
+             amp_scale=1, 
+             filter=False, 
+             f1=None, 
+             f2=None, 
+             corners=4, 
+             zerophase=True, 
+             win_interval=None, 
+             mode='waveform', 
+             cmap='seismic',
+             linewidth=0.8, 
+             yticklabel_num=5, 
+             figsize=(10, 6),
+             save=False, 
+             save_path=None, 
+             dpi=100):
+        
+        # check pair_indx
+        if pair_indx >= self.corr_data.shape[0]:
+            raise ValueError("pair_indx must be <= (corr_data.shape[0]=%d)" % self.corr_data.shape[0])
+        
+        # init cc_len cc_step
+        if cc_len == None:
+            cc_len = self.corr_data.shape[2]*self.dt
+        if cc_step == None:
+            cc_step = 0.0
+
+        # init timestamp
+        t_max, win_interval_raw, win_vector = get_timestamp(win_num=self.corr_data.shape[1], 
+                                                        cc_len=cc_len, 
+                                                        cc_step=cc_step, 
+                                                        t_min=t_min)
+
+        # init win_start
+        if win_start == None:
+            win_start = t_min
+        if win_start < t_min:
+            raise ValueError("win_start must be >= (t_min=%s)" % str(t_min))
+
+        # init win_end
+        if win_end == None:
+            win_end = t_max
+        if win_end > t_max:
+            raise ValueError("win_end must be <= (t_max=%s)" % str(t_max))
+
+        # init win_interval
+        if win_interval == None:
+            win_interval = win_interval_raw      
+        if win_interval < win_interval_raw:
+            raise ValueError("win_interval must be >= %f" % win_interval_raw)
+        if win_interval > t_max-t_min-cc_len:
+            raise ValueError("win_interval must be <= %f" % (t_max-t_min-cc_len))
+
+        # init lag_start 
+        if lag_start == None:
+            lag_start = -self.maxlag
+        if lag_start < -self.maxlag:
+            raise ValueError("lag_start must be >= (-maxlag=-%f)" % self.maxlag)
+        
+        # init lag_end
+        if lag_end == None:
+            lag_end = self.maxlag
+        if lag_end > self.maxlag:
+            raise ValueError("lag_end must be <= (maxlag=%f)" % self.maxlag)
+        
+        # lag vector
+        tt = np.arange(lag_start, lag_end+self.dt, self.dt)
+        tp_start = round((lag_start+self.maxlag)/self.dt)
+        tp_end = tp_start+len(tt)  # make sure same length, so do not use round((lag_end+self.maxlag+self.dt)/self.dt)
+
+        # select and filter data according to win_start, win_end
+        win_indx = np.where((win_vector >= win_start) & (win_vector <= win_end))[0]
+        if filter:
+            data=np.empty((len(win_indx), len(tt)))
+            for i in range(0, len(win_indx)):
+                data[i,:] = bandpass(self.corr_data[pair_indx, win_indx[i], tp_start:tp_end], f1, f2, int(1/self.dt), corners=corners, zerophase=zerophase)
+        else:
+            data = self.corr_data[pair_indx, win_indx, tp_start:tp_end]
+
+        # plot
+        if mode == 'waveform':
+            # init fig
+            fig, ax = plt.subplots(figsize=figsize)
+
+            # normalize
+            if amp_normalize:
+                scale = np.max(np.abs(data), axis=1)[:,None]
+                if np.min(scale) != 0:
+                    data_plot = amp_scale*data/scale
+                else:
+                    raise ValueError("data is all zeros in amp_normalize=True")
+            else:
+                scale = np.max(np.abs(data))
+                if scale != 0:
+                    data_plot = amp_scale*data/scale
+                else:
+                    raise ValueError("data is all zeros in amp_normalize=False")
+
+            # get win_interval index
+            ydist_n=[]
+            win_interval_n = round(win_interval/win_interval_raw)
+            for i in range(0, len(win_indx), win_interval_n):
+                ydist_n.append(i)
+            ydist_n = np.int64(np.array(ydist_n))
+
+            # plot wavefrom
+            for i in range(0, len(ydist_n)):
+                ax.plot(tt, data_plot[ydist_n[i]]+ydist_n[i], 'k', linewidth=linewidth)
+
+            # set x axis
+            ax.set_title("CorrData: pair_indx=%d, filter=[%.2f, %.2f] hz" % (pair_indx, f1, f2))
+            ax.set_xlim(tt[0], tt[-1])
+            ax.set_xlabel('Time(s)')
+            
+            # set y axis
+            yy_tick = np.linspace(0, len(win_indx)-1, num=yticklabel_num)
+            yy_label_UTC = time_linspace(win_start, win_end, num=yticklabel_num)
+            yy_label = np.array([i.strftime('%Y-%m-%dT%H:%M:%S') for i in yy_label_UTC])
+            ax.set_yticks(yy_tick)
+            ax.set_yticklabels(yy_label, rotation=45)
+
+            # save or show
+            if save:
+                if save_path is None:
+                    raise ValueError("save_path must be specified")
+                fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight')
+                plt.close(fig)
+            else:
+                plt.show()
+
+        elif mode == 'mat':
+            # init fig
+            fig, ax = plt.subplots(figsize=figsize)
+
+            # average all data
+            cc_mean = np.mean(data, axis=0)/np.max(np.mean(data, axis=0))
+
+            # average win_interval data
+            ntrace = int((win_end-win_start)/win_interval)
+            ndata  = np.zeros(shape=(ntrace,len(tt)))
+            for i in range(0,ntrace):
+                tindx = np.where(((win_vector-win_start)>=i*win_interval) & ((win_vector-win_start)<(i+1)*win_interval))[0]
+                ndata[i] = np.mean(data[tindx],axis=0)
+
+            # normalize waveforms
+            if amp_normalize:
+                scale = np.max(np.abs(ndata), axis=1)[:,None]
+                if np.min(scale) != 0:
+                    ndata_plot = ndata/scale
+                else:
+                    raise ValueError("data is all zeros in amp_normalize=True")
+            else:
+                scale = np.max(np.abs(ndata))
+                if scale != 0:
+                    ndata_plot = ndata/scale
+                else:
+                    raise ValueError("data is all zeros in amp_normalize=False")
+                
+            # plot mat
+            cax=ax.matshow(ndata_plot, extent=[lag_start, lag_end, ntrace, 0], aspect='auto', cmap=cmap)
+            ax.plot(tt, ntrace/10*cc_mean+ntrace/2, 'k', linewidth=linewidth)
+            
+            # set x axis
+            ax.set_title("CorrData: pair_indx=%d, filter=[%.2f, %.2f] hz" % (pair_indx, f1, f2))
+            ax.set_xlim(tt[0], tt[-1])
+            ax.set_xlabel('Time(s)')
+            ax.xaxis.set_ticks_position('bottom')
+            
+            # set y axis
+            ax.invert_yaxis()
+            ax.set_ylim(0, ntrace)
+            yy_tick=np.linspace(0, ntrace, num=yticklabel_num)
+            yy_label_UTC=time_linspace(win_start, win_end, num=yticklabel_num)
+            yy_label = np.array([i.strftime('%Y-%m-%dT%H:%M:%S') for i in yy_label_UTC])
+            ax.set_yticks(yy_tick)
+            ax.set_yticklabels(yy_label, rotation=45)
+
+            # save or show
+            if save:
+                if save_path is None:
+                    raise ValueError("save_path must be specified")
+                fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches = 'tight') 
+                plt.close(fig)
+            else:
+                plt.show()
+
+        else:
+            raise ValueError("mode must be 'waveform' or 'mat'")
+
```

## noiseflow/cc/include/corr.hpp

 * *Ordering differences only*

```diff
@@ -1,308 +1,308 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-
-#ifndef CORR_HPP
-#define CORR_HPP
-
-#include "utils.hpp"
-
-namespace CC {
-
-// Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
-template <typename T1, typename T2, typename T3> 
-class CorrClass{
-  private:
-    T2 _fft_data; // input data
-    float _dt;
-    std::string _corr_method;
-    xt::xtensor<int, 2> _corr_pair;
-    float _maxlag;
-    int _smoothspect_N;
-    bool _flag;
-    int _flag_gap;
-    int _threads;
-
-  public:
-    int _npts;
-    int _maxlag_npts; 
-    int _fft_npts; // number of points for each channel in the fftdata
-    int _channel_num; // number of channels in the fftdata 
-    int _win_num; // number of windows for each channel in the fftdata
-    int _pair_num; // number of pairs in the corr_pair
-    int _maxlag_start; // start index of maxlag
-    int _maxlag_end; // end index of maxlag
-    T3 _output_data; // output data
-
-    // constructor
-    CorrClass(T2& fft_data, float dt, std::string corr_method, xt::xtensor<int, 2> corr_pair, float maxlag, int smoothspect_N, bool flag, int flag_gap, int threads);
-
-    // copy constructor
-    // CorrClass(CorrClass & A);
-
-    // destructor
-    ~CorrClass();
-
-    // corr  deconv, coherence
-    xt::xarray<std::complex<T1>>  xcorr(int pair_id);
-    xt::xarray<std::complex<T1>>  deconv(int pair_id);
-    xt::xarray<std::complex<T1>>  coherency(int pair_id);
-
-    // irfft
-    xt::xarray<T1> irfft(xt::xarray<std::complex<T1>>& fft_corr_data);
-
-    // cut with maxlag
-    xt::xarray<T1> cut_maxlag(xt::xarray<T1>& corr_data);
-
-    // run workflow
-    void run();
-
-    // return
-    T3& get_corrdata() {return _output_data;};
-};
-
-
-
-
-
-// **************************************************************************
-// *                        constructor
-// **************************************************************************
-// parameter constructor                                                                                                                                                      
-template <typename T1, typename T2, typename T3> 
-CorrClass<T1, T2, T3>::CorrClass(T2& fft_data, float dt, std::string corr_method, xt::xtensor<int, 2> corr_pair, float maxlag, int smoothspect_N, bool flag, int flag_gap, int threads) 
-{
-    _fft_data = fft_data;
-    _dt = dt;
-    _corr_method = corr_method;
-    _corr_pair = corr_pair;
-    _maxlag = maxlag;
-    _smoothspect_N = smoothspect_N;
-    _flag = flag;
-    _flag_gap = flag_gap;
-    _threads = threads;
-
-    _pair_num = corr_pair.shape(0);
-    _channel_num = fft_data.shape(0);
-    _win_num = fft_data.shape(1);
-    _fft_npts = fft_data.shape(2);  
-    _npts = 2*(_fft_npts-1);
-
-    xt::xarray<T1> t = xt::arange(-_fft_npts+1, _fft_npts) * _dt;
-    auto ind = xt::where(xt::abs(t) <= _maxlag)[0];
-    _maxlag_npts = ind.size();
-    _maxlag_start = ind[0]; 
-    _maxlag_end = ind[ind.size()-1]+1;
-}
-
-
-// virtual destructor                                                                                                                                                       
-template <typename T1, typename T2, typename T3> 
-CorrClass<T1, T2, T3>::~CorrClass() {}
-
-
-
-
-
-
-// **************************************************************************
-// *                        corr
-// **************************************************************************
-// xcorr
-template <typename T1, typename T2, typename T3> 
-xt::xarray<std::complex<T1>> CorrClass<T1, T2, T3>::xcorr(int pair_id)
-{
-    int source_id = _corr_pair(pair_id,0);
-    int receiver_id = _corr_pair(pair_id,1);
-    xt::xarray<std::complex<T1>> fft_corr_data = xt::conj(xt::view(_fft_data, source_id, xt::all(), xt::all())) * xt::view(_fft_data, receiver_id, xt::all(), xt::all());
-
-    return fft_corr_data;
-}
-
-
-// deconv
-template <typename T1, typename T2, typename T3>
-xt::xarray<std::complex<T1>> CorrClass<T1, T2, T3>::deconv(int pair_id)
-{
-    std::complex<T1> _i0 {0, 0};
-    int source_id = _corr_pair(pair_id,0);
-    int receiver_id = _corr_pair(pair_id,1);  
-
-    auto rr_data = xt::view(_fft_data, receiver_id, xt::all(), xt::all());
-    xt::xarray<std::complex<T1>> ss_data = xt::empty<std::complex<T1>>({_win_num, _fft_npts});
-
-    for (int i=0; i<_win_num; i++){
-        auto ss = xt::view(_fft_data, source_id, i, xt::all());
-        auto temp = CC::moving_ave<T1>(xt::abs(ss), _smoothspect_N);
-        xt::view(ss_data, i, xt::all()) = ss/temp;
-    }
-
-    // convert nan to 0+0j
-    for(auto it=ss_data.begin(); it!=ss_data.end(); ++it){
-        if (*it != *it){
-            *it = _i0;
-        }
-    }
-
-    xt::xarray<std::complex<T1>> fft_corr_data = xt::conj(ss_data) * rr_data;
-
-  return fft_corr_data;
-}
-
-
-// coherency
-template <typename T1, typename T2, typename T3>
-xt::xarray<std::complex<T1>> CorrClass<T1, T2, T3>::coherency(int pair_id)
-{
-    std::complex<T1> _i0 {0, 0};
-    int source_id = _corr_pair(pair_id,0);
-    int receiver_id = _corr_pair(pair_id,1);   
-
-    xt::xarray<std::complex<T1>> ss_data = xt::empty<std::complex<T1>>({_win_num, _fft_npts});
-    xt::xarray<std::complex<T1>> rr_data = xt::empty<std::complex<T1>>({_win_num, _fft_npts});
-
-    for (int i=0; i<_win_num; i++){
-        auto ss = xt::view(_fft_data, source_id, i, xt::all());
-        auto rr = xt::view(_fft_data, receiver_id, i, xt::all());
-        auto ss_temp = CC::moving_ave<T1>(xt::abs(ss), _smoothspect_N);
-        auto rr_temp = CC::moving_ave<T1>(xt::abs(rr), _smoothspect_N);
-        xt::view(ss_data, i, xt::all()) = ss / ss_temp;
-        xt::view(rr_data, i, xt::all()) = rr / rr_temp;
-    }
-
-    // convert nan to 0+0j
-    for(auto it=ss_data.begin(); it!=ss_data.end(); ++it){
-        if (*it!=*it){
-            *it = _i0;
-        }
-    }
-
-    // convert nan to 0+0j
-    for(auto it=rr_data.begin(); it!=rr_data.end(); ++it){
-        if (*it!=*it){
-            *it = _i0;
-        }
-    }
-
-    xt::xarray<std::complex<T1>> fft_corr_data = xt::conj(ss_data) * rr_data;
-
-    return fft_corr_data;
-}
-
-
-
-
-
-// **************************************************************************
-// *                        irfft
-// **************************************************************************
-template <typename T1, typename T2, typename T3>
-xt::xarray<T1> CorrClass<T1, T2, T3>::irfft(xt::xarray<std::complex<T1>>& fft_corr_data)
-{
-    xt::xarray<T1> corr_data = xt::empty<T1>({_win_num, _npts});
-
-    for (int i=0; i<_win_num; i++){
-        auto ss = xt::view(fft_corr_data, i, xt::all());
-        xt::view(corr_data, i, xt::all()) = xt::roll(xt::fftw::irfft(xt::eval(ss)), int(_fft_npts-1));
-    }
-
-    return corr_data;
-}
-
-
-
-
-// **************************************************************************
-// *                        cut_maxlag
-// **************************************************************************
-template <typename T1, typename T2, typename T3>
-xt::xarray<T1> CorrClass<T1, T2, T3>::cut_maxlag(xt::xarray<T1>& corr_data)
-{
-    auto maxlag_corr_data = xt::view(corr_data, xt::all(), xt::range(_maxlag_start, _maxlag_end));
-
-    return maxlag_corr_data;
-}
-
-
-
-
-
-// **************************************************************************
-// *                        run
-// **************************************************************************
-template <typename T1, typename T2, typename T3> 
-void CorrClass<T1, T2, T3>::run()
-{
-  auto start_time = std::chrono::high_resolution_clock::now();
-  auto end_time = start_time;
-  _output_data = xt::empty<T1>({_pair_num, _win_num, _maxlag_npts});
-  
-#ifdef _OPENMP
-  omp_set_num_threads(_threads);
-  std::cout << "Start corr with " << _threads  << " threads using openmp..." << std::endl;
-  #pragma omp parallel for
-#else
-  std::cout << "Start corr with " << 1 << " threads without openmp..." << std::endl;
-#endif
-
-  for(int i = 0; i < _pair_num; i++){
-// flag
-#ifdef _OPENMP
-    if (_flag && omp_get_thread_num()==0 && i%_flag_gap==0) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process pair " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (_flag && i%_flag_gap==0) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process pair " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-
-    // corr
-    xt::xarray<std::complex<T1>> fft_corr_data;
-    if (_corr_method == "xcorr") {
-      fft_corr_data = xcorr(i);
-    } 
-    else if (_corr_method == "deconv"){
-      fft_corr_data = deconv(i);
-    } 
-    else if (_corr_method == "coherency") {
-      fft_corr_data = coherency(i);
-    } 
-    else {
-      std::cout << "error: please input the correct corr method." << std::endl;
-    }
-
-    // irfft
-    xt::xarray<T1> corr_data = irfft(fft_corr_data);
-
-    // cut maxlag
-    xt::xarray<T1> maxlag_corr_data = cut_maxlag(corr_data);
-    
-    // fill with maxlag-data
-    xt::view(_output_data, i, xt::all()) = maxlag_corr_data;
-  }
-
-  end_time = std::chrono::high_resolution_clock::now();
-  auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-  std::cout << "End corr with total time " << elapsed_time.count() << "s" <<std::endl;
-
-}
-
-
-
-// **************************************************************************
-// *                        end
-// **************************************************************************
-
-}
-
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+
+#ifndef CORR_HPP
+#define CORR_HPP
+
+#include "utils.hpp"
+
+namespace CC {
+
+// Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
+template <typename T1, typename T2, typename T3> 
+class CorrClass{
+  private:
+    T2 _fft_data; // input data
+    float _dt;
+    std::string _corr_method;
+    xt::xtensor<int, 2> _corr_pair;
+    float _maxlag;
+    int _smoothspect_N;
+    bool _flag;
+    int _flag_gap;
+    int _threads;
+
+  public:
+    int _npts;
+    int _maxlag_npts; 
+    int _fft_npts; // number of points for each channel in the fftdata
+    int _channel_num; // number of channels in the fftdata 
+    int _win_num; // number of windows for each channel in the fftdata
+    int _pair_num; // number of pairs in the corr_pair
+    int _maxlag_start; // start index of maxlag
+    int _maxlag_end; // end index of maxlag
+    T3 _output_data; // output data
+
+    // constructor
+    CorrClass(T2& fft_data, float dt, std::string corr_method, xt::xtensor<int, 2> corr_pair, float maxlag, int smoothspect_N, bool flag, int flag_gap, int threads);
+
+    // copy constructor
+    // CorrClass(CorrClass & A);
+
+    // destructor
+    ~CorrClass();
+
+    // corr  deconv, coherence
+    xt::xarray<std::complex<T1>>  xcorr(int pair_id);
+    xt::xarray<std::complex<T1>>  deconv(int pair_id);
+    xt::xarray<std::complex<T1>>  coherency(int pair_id);
+
+    // irfft
+    xt::xarray<T1> irfft(xt::xarray<std::complex<T1>>& fft_corr_data);
+
+    // cut with maxlag
+    xt::xarray<T1> cut_maxlag(xt::xarray<T1>& corr_data);
+
+    // run workflow
+    void run();
+
+    // return
+    T3& get_corrdata() {return _output_data;};
+};
+
+
+
+
+
+// **************************************************************************
+// *                        constructor
+// **************************************************************************
+// parameter constructor                                                                                                                                                      
+template <typename T1, typename T2, typename T3> 
+CorrClass<T1, T2, T3>::CorrClass(T2& fft_data, float dt, std::string corr_method, xt::xtensor<int, 2> corr_pair, float maxlag, int smoothspect_N, bool flag, int flag_gap, int threads) 
+{
+    _fft_data = fft_data;
+    _dt = dt;
+    _corr_method = corr_method;
+    _corr_pair = corr_pair;
+    _maxlag = maxlag;
+    _smoothspect_N = smoothspect_N;
+    _flag = flag;
+    _flag_gap = flag_gap;
+    _threads = threads;
+
+    _pair_num = corr_pair.shape(0);
+    _channel_num = fft_data.shape(0);
+    _win_num = fft_data.shape(1);
+    _fft_npts = fft_data.shape(2);  
+    _npts = 2*(_fft_npts-1);
+
+    xt::xarray<T1> t = xt::arange(-_fft_npts+1, _fft_npts) * _dt;
+    auto ind = xt::where(xt::abs(t) <= _maxlag)[0];
+    _maxlag_npts = ind.size();
+    _maxlag_start = ind[0]; 
+    _maxlag_end = ind[ind.size()-1]+1;
+}
+
+
+// virtual destructor                                                                                                                                                       
+template <typename T1, typename T2, typename T3> 
+CorrClass<T1, T2, T3>::~CorrClass() {}
+
+
+
+
+
+
+// **************************************************************************
+// *                        corr
+// **************************************************************************
+// xcorr
+template <typename T1, typename T2, typename T3> 
+xt::xarray<std::complex<T1>> CorrClass<T1, T2, T3>::xcorr(int pair_id)
+{
+    int source_id = _corr_pair(pair_id,0);
+    int receiver_id = _corr_pair(pair_id,1);
+    xt::xarray<std::complex<T1>> fft_corr_data = xt::conj(xt::view(_fft_data, source_id, xt::all(), xt::all())) * xt::view(_fft_data, receiver_id, xt::all(), xt::all());
+
+    return fft_corr_data;
+}
+
+
+// deconv
+template <typename T1, typename T2, typename T3>
+xt::xarray<std::complex<T1>> CorrClass<T1, T2, T3>::deconv(int pair_id)
+{
+    std::complex<T1> _i0 {0, 0};
+    int source_id = _corr_pair(pair_id,0);
+    int receiver_id = _corr_pair(pair_id,1);  
+
+    auto rr_data = xt::view(_fft_data, receiver_id, xt::all(), xt::all());
+    xt::xarray<std::complex<T1>> ss_data = xt::empty<std::complex<T1>>({_win_num, _fft_npts});
+
+    for (int i=0; i<_win_num; i++){
+        auto ss = xt::view(_fft_data, source_id, i, xt::all());
+        auto temp = CC::moving_ave<T1>(xt::abs(ss), _smoothspect_N);
+        xt::view(ss_data, i, xt::all()) = ss/temp;
+    }
+
+    // convert nan to 0+0j
+    for(auto it=ss_data.begin(); it!=ss_data.end(); ++it){
+        if (*it != *it){
+            *it = _i0;
+        }
+    }
+
+    xt::xarray<std::complex<T1>> fft_corr_data = xt::conj(ss_data) * rr_data;
+
+  return fft_corr_data;
+}
+
+
+// coherency
+template <typename T1, typename T2, typename T3>
+xt::xarray<std::complex<T1>> CorrClass<T1, T2, T3>::coherency(int pair_id)
+{
+    std::complex<T1> _i0 {0, 0};
+    int source_id = _corr_pair(pair_id,0);
+    int receiver_id = _corr_pair(pair_id,1);   
+
+    xt::xarray<std::complex<T1>> ss_data = xt::empty<std::complex<T1>>({_win_num, _fft_npts});
+    xt::xarray<std::complex<T1>> rr_data = xt::empty<std::complex<T1>>({_win_num, _fft_npts});
+
+    for (int i=0; i<_win_num; i++){
+        auto ss = xt::view(_fft_data, source_id, i, xt::all());
+        auto rr = xt::view(_fft_data, receiver_id, i, xt::all());
+        auto ss_temp = CC::moving_ave<T1>(xt::abs(ss), _smoothspect_N);
+        auto rr_temp = CC::moving_ave<T1>(xt::abs(rr), _smoothspect_N);
+        xt::view(ss_data, i, xt::all()) = ss / ss_temp;
+        xt::view(rr_data, i, xt::all()) = rr / rr_temp;
+    }
+
+    // convert nan to 0+0j
+    for(auto it=ss_data.begin(); it!=ss_data.end(); ++it){
+        if (*it!=*it){
+            *it = _i0;
+        }
+    }
+
+    // convert nan to 0+0j
+    for(auto it=rr_data.begin(); it!=rr_data.end(); ++it){
+        if (*it!=*it){
+            *it = _i0;
+        }
+    }
+
+    xt::xarray<std::complex<T1>> fft_corr_data = xt::conj(ss_data) * rr_data;
+
+    return fft_corr_data;
+}
+
+
+
+
+
+// **************************************************************************
+// *                        irfft
+// **************************************************************************
+template <typename T1, typename T2, typename T3>
+xt::xarray<T1> CorrClass<T1, T2, T3>::irfft(xt::xarray<std::complex<T1>>& fft_corr_data)
+{
+    xt::xarray<T1> corr_data = xt::empty<T1>({_win_num, _npts});
+
+    for (int i=0; i<_win_num; i++){
+        auto ss = xt::view(fft_corr_data, i, xt::all());
+        xt::view(corr_data, i, xt::all()) = xt::roll(xt::fftw::irfft(xt::eval(ss)), int(_fft_npts-1));
+    }
+
+    return corr_data;
+}
+
+
+
+
+// **************************************************************************
+// *                        cut_maxlag
+// **************************************************************************
+template <typename T1, typename T2, typename T3>
+xt::xarray<T1> CorrClass<T1, T2, T3>::cut_maxlag(xt::xarray<T1>& corr_data)
+{
+    auto maxlag_corr_data = xt::view(corr_data, xt::all(), xt::range(_maxlag_start, _maxlag_end));
+
+    return maxlag_corr_data;
+}
+
+
+
+
+
+// **************************************************************************
+// *                        run
+// **************************************************************************
+template <typename T1, typename T2, typename T3> 
+void CorrClass<T1, T2, T3>::run()
+{
+  auto start_time = std::chrono::high_resolution_clock::now();
+  auto end_time = start_time;
+  _output_data = xt::empty<T1>({_pair_num, _win_num, _maxlag_npts});
+  
+#ifdef _OPENMP
+  omp_set_num_threads(_threads);
+  std::cout << "Start corr with " << _threads  << " threads using openmp..." << std::endl;
+  #pragma omp parallel for
+#else
+  std::cout << "Start corr with " << 1 << " threads without openmp..." << std::endl;
+#endif
+
+  for(int i = 0; i < _pair_num; i++){
+// flag
+#ifdef _OPENMP
+    if (_flag && omp_get_thread_num()==0 && i%_flag_gap==0) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process pair " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (_flag && i%_flag_gap==0) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process pair " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+
+    // corr
+    xt::xarray<std::complex<T1>> fft_corr_data;
+    if (_corr_method == "xcorr") {
+      fft_corr_data = xcorr(i);
+    } 
+    else if (_corr_method == "deconv"){
+      fft_corr_data = deconv(i);
+    } 
+    else if (_corr_method == "coherency") {
+      fft_corr_data = coherency(i);
+    } 
+    else {
+      std::cout << "error: please input the correct corr method." << std::endl;
+    }
+
+    // irfft
+    xt::xarray<T1> corr_data = irfft(fft_corr_data);
+
+    // cut maxlag
+    xt::xarray<T1> maxlag_corr_data = cut_maxlag(corr_data);
+    
+    // fill with maxlag-data
+    xt::view(_output_data, i, xt::all()) = maxlag_corr_data;
+  }
+
+  end_time = std::chrono::high_resolution_clock::now();
+  auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+  std::cout << "End corr with total time " << elapsed_time.count() << "s" <<std::endl;
+
+}
+
+
+
+// **************************************************************************
+// *                        end
+// **************************************************************************
+
+}
+
 #endif
```

## noiseflow/cc/include/rfft.hpp

 * *Ordering differences only*

```diff
@@ -1,300 +1,300 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-
-#ifndef RFFT_HPP
-#define RFFT_HPP
-
-#include "utils.hpp"
-
-namespace CC {
-
-// Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
-template <typename T1, typename T2, typename T3> 
-class RFFTClass{
-  private:
-    T2 _raw_data; // input data
-    float _dt;
-    float _cc_len;
-    float _cc_step;
-    std::string _time_norm;
-    float _clip_std;
-    int _smooth_N;
-    std::string _freq_norm; 
-    float _freqmin;
-    float _freqmax;
-    int _whiten_npad;
-    int _smoothspect_N;
-    bool _flag;
-    int _flag_gap;
-    int _threads;
-    
-  public:
-    int _cc_len_points;
-    int _cc_step_points;
-    int _npts; // number of points for each channel in the rawdata 
-    int _rfft_npts; // number of points for each channel in the rfftdata
-    int _channel_num; // number of channels in the rawdata 
-    int _win_num; // number of windows for each channel in the rawdata
-    xt::xtensor<int, 2> _win_info; // slice window
-    T3 _output_data; // output data
-
-    // constructor
-    RFFTClass(T2& raw_data, float dt, float cc_len, float cc_step, std::string time_norm, float clip_std, int smooth_N, std::string freq_norm, float freqmin, float freqmax, int whiten_npad, int smoothspect_N, bool flag, int flag_gap, int threads);
-
-    // copy constructor
-    // RFFTClass(RFFTClass & A);
-
-    // destructor
-    ~RFFTClass();
-
-    // time_norm --> time_norm_data 
-    xt::xarray<T1>  time_norm_no(int channel);
-    xt::xarray<T1>  time_norm_onebit(int channel);
-    xt::xarray<T1>  time_norm_clip(int channel);
-    xt::xarray<T1>  time_norm_smooth(int channel);
-
-    // rfft --> rfft_data
-    xt::xarray<std::complex<T1>> rfft(xt::xarray<T1>& time_norm_data);
-
-    // freq_norm --> rfft_norm_data
-    xt::xarray<std::complex<T1>> freq_norm_no(xt::xarray<std::complex<T1>>& rfft_data);
-    xt::xarray<std::complex<T1>> freq_norm_whiten(xt::xarray<std::complex<T1>>& rfft_data);
-
-    // run workflow
-    void run();
-
-    // return
-    T3& get_rfftdata() {return _output_data;};
-};
-
-
-
-
-// **************************************************************************
-// *                        constructor
-// **************************************************************************
-// parameter constructor                                                                                                                                                      
-template <typename T1, typename T2, typename T3> 
-RFFTClass<T1, T2, T3>::RFFTClass(T2& raw_data, float dt, float cc_len, float cc_step, std::string time_norm, float clip_std, int smooth_N, std::string freq_norm, float freqmin, float freqmax, int whiten_npad, int smoothspect_N, bool flag, int flag_gap, int threads) 
-{
-  _raw_data = raw_data;
-  _dt = dt;
-  _cc_len = cc_len;
-  _cc_step = cc_step;
-  _time_norm = time_norm;
-  _clip_std = clip_std;
-  _smooth_N = smooth_N;
-  _freq_norm = freq_norm;
-  _freqmin = freqmin;
-  _freqmax = freqmax;
-  _whiten_npad = whiten_npad;
-  _smoothspect_N = smoothspect_N;
-  _flag = flag;
-  _flag_gap = flag_gap;
-  _threads = threads;
-
-  // convert time to points
-  _cc_len_points = int(_cc_len/_dt);
-  _cc_step_points = int(_cc_step/_dt);
-  _npts = raw_data.shape(1);
-  _rfft_npts = _cc_len_points/2+1;
-  _channel_num = raw_data.shape(0);
-  
-  // slice_window --> _win_num, _win_info
-  _win_info = CC::slice_window(_npts, _cc_len_points, _cc_step_points);
-  _win_num = _win_info.shape(0);
-}
-
-                                                                                                                                                       
-// virtual destructor                                                                                                                                                       
-template <typename T1, typename T2, typename T3> 
-RFFTClass<T1, T2, T3>::~RFFTClass() {}
-
-
-
-
-// **************************************************************************
-// *                        time_norm
-// **************************************************************************
-// no
-template <typename T1, typename T2, typename T3> 
-inline xt::xarray<T1> RFFTClass<T1, T2, T3>::time_norm_no(int channel)
-{
-  xt::xarray<T1> time_norm_data = xt::view(_raw_data, channel, xt::all());
-
-  return time_norm_data;
-}
-
-
-// onebit
-template <typename T1, typename T2, typename T3> 
-inline xt::xarray<T1> RFFTClass<T1, T2, T3>::time_norm_onebit(int channel)
-{
-  xt::xarray<T1> time_norm_data = xt::sign(xt::view(_raw_data, channel, xt::all()));
-  
-  return time_norm_data;
-}
-
-
-// clip
-template <typename T1, typename T2, typename T3> 
-inline xt::xarray<T1> RFFTClass<T1, T2, T3>::time_norm_clip(int channel)
-{
-  xt::xarray<T1> time_norm_data = xt::view(_raw_data, channel, xt::all());
-  T1 lim = _clip_std * xt::stddev(time_norm_data)(0);
-  filtration(time_norm_data, time_norm_data>lim) = lim;
-  filtration(time_norm_data, time_norm_data<(-lim)) = -lim;
-
-  return time_norm_data;
-}
-
-
-// smooth
-template <typename T1, typename T2, typename T3> 
-inline xt::xarray<T1> RFFTClass<T1, T2, T3>::time_norm_smooth(int channel)
-{
-  xt::xarray<T1> data = xt::view(_raw_data, channel, xt::all());
-  xt::xarray<T1> time_norm_data = data / CC::moving_ave<T1>(xt::abs(data), _smooth_N);
-
-  return time_norm_data;
-}
-
-
-
-
-
-// **************************************************************************
-// *                        rfft
-// **************************************************************************
-template <typename T1, typename T2, typename T3> 
-inline xt::xarray<std::complex<T1>> RFFTClass<T1, T2, T3>::rfft(xt::xarray<T1>& time_norm_data)
-{
-  xt::xarray<std::complex<T1>> rfft_data= xt::empty<T1>({_win_num, _rfft_npts});
-
-  for(int i=0; i<_win_num; i++){
-    auto segment = xt::view(time_norm_data, xt::range(_win_info(i,0), _win_info(i,1)), xt::all());
-    auto segment_rfft = xt::fftw::rfft(xt::eval(segment));
-    xt::view(rfft_data, i, xt::all()) = segment_rfft; 
-  }
-
-  return rfft_data;
-}
-
-
-
-
-
-// **************************************************************************
-// *                        freq_norm
-// **************************************************************************
-template <typename T1, typename T2, typename T3> 
-inline xt::xarray<std::complex<T1>> RFFTClass<T1, T2, T3>::freq_norm_no(xt::xarray<std::complex<T1>>& rfft_data)
-{
-  auto freq_norm_data = rfft_data;
-
-  return freq_norm_data;
-}
-
-
-template <typename T1, typename T2, typename T3> 
-inline xt::xarray<std::complex<T1>> RFFTClass<T1, T2, T3>::freq_norm_whiten(xt::xarray<std::complex<T1>>& rfft_data)
-{
-  xt::xarray<std::complex<T1>> rfft_norm_data = CC::whiten<T1>(rfft_data, _dt, _freq_norm, _freqmin, _freqmax, _smoothspect_N, _whiten_npad);
-  
-  return rfft_norm_data;
-}
-
-
-
-
-
-
-// **************************************************************************
-// *                        run
-// **************************************************************************
-template <typename T1, typename T2, typename T3> 
-void RFFTClass<T1, T2, T3>::run()
-{
-  auto start_time = std::chrono::high_resolution_clock::now();
-  auto end_time = start_time;
-  _output_data = xt::empty<std::complex<T1>>({_channel_num, _win_num, _rfft_npts});
-  
-#ifdef _OPENMP
-  omp_set_num_threads(_threads);
-  std::cout << "Start rfft with " << _threads  << " threads using openmp..." << std::endl;
-  #pragma omp parallel for
-#else
-  std::cout << "Start rfft with " << 1 << " threads without openmp..." << std::endl;
-#endif
-
-  for(int i = 0; i < _channel_num; i++){
-// flag
-#ifdef _OPENMP
-    if (_flag && omp_get_thread_num()==0 && i%_flag_gap==0) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (_flag && i%_flag_gap==0) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-
-    // time_norm
-    xt::xarray<T1> time_norm_data;
-    if (_time_norm == "no") {
-      time_norm_data = time_norm_no(i);
-    } 
-    else if (_time_norm == "clip"){
-      time_norm_data = time_norm_clip(i);
-    } 
-    else if (_time_norm == "onebit") {
-      time_norm_data = time_norm_onebit(i);
-    } 
-    else if (_time_norm == "smooth") {
-      time_norm_data = time_norm_smooth(i);
-    } 
-    else {
-      std::cout << "error: please input the correct time_norm method." << std::endl;
-      exit(1);
-    }
-
-    // rfft
-    xt::xarray<std::complex<T1>> rfft_data = rfft(time_norm_data);
-
-    // freq_norm
-    xt::xarray<std::complex<T1>> rfft_norm_data;
-    if (_freq_norm == "no") {
-      rfft_norm_data = freq_norm_no(rfft_data);
-    } else {
-      rfft_norm_data = freq_norm_whiten(rfft_data);
-    }
-
-    // fill _output_data
-    xt::view(_output_data, i, xt::all()) = rfft_norm_data; 
-  }
-
-  end_time = std::chrono::high_resolution_clock::now();
-  auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-  std::cout << "End rfft with total time " << elapsed_time.count() << "s" <<std::endl;
-
-}
-
-
-
-// **************************************************************************
-// *                        end
-// **************************************************************************
-
-}
-
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+
+#ifndef RFFT_HPP
+#define RFFT_HPP
+
+#include "utils.hpp"
+
+namespace CC {
+
+// Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
+template <typename T1, typename T2, typename T3> 
+class RFFTClass{
+  private:
+    T2 _raw_data; // input data
+    float _dt;
+    float _cc_len;
+    float _cc_step;
+    std::string _time_norm;
+    float _clip_std;
+    int _smooth_N;
+    std::string _freq_norm; 
+    float _freqmin;
+    float _freqmax;
+    int _whiten_npad;
+    int _smoothspect_N;
+    bool _flag;
+    int _flag_gap;
+    int _threads;
+    
+  public:
+    int _cc_len_points;
+    int _cc_step_points;
+    int _npts; // number of points for each channel in the rawdata 
+    int _rfft_npts; // number of points for each channel in the rfftdata
+    int _channel_num; // number of channels in the rawdata 
+    int _win_num; // number of windows for each channel in the rawdata
+    xt::xtensor<int, 2> _win_info; // slice window
+    T3 _output_data; // output data
+
+    // constructor
+    RFFTClass(T2& raw_data, float dt, float cc_len, float cc_step, std::string time_norm, float clip_std, int smooth_N, std::string freq_norm, float freqmin, float freqmax, int whiten_npad, int smoothspect_N, bool flag, int flag_gap, int threads);
+
+    // copy constructor
+    // RFFTClass(RFFTClass & A);
+
+    // destructor
+    ~RFFTClass();
+
+    // time_norm --> time_norm_data 
+    xt::xarray<T1>  time_norm_no(int channel);
+    xt::xarray<T1>  time_norm_onebit(int channel);
+    xt::xarray<T1>  time_norm_clip(int channel);
+    xt::xarray<T1>  time_norm_smooth(int channel);
+
+    // rfft --> rfft_data
+    xt::xarray<std::complex<T1>> rfft(xt::xarray<T1>& time_norm_data);
+
+    // freq_norm --> rfft_norm_data
+    xt::xarray<std::complex<T1>> freq_norm_no(xt::xarray<std::complex<T1>>& rfft_data);
+    xt::xarray<std::complex<T1>> freq_norm_whiten(xt::xarray<std::complex<T1>>& rfft_data);
+
+    // run workflow
+    void run();
+
+    // return
+    T3& get_rfftdata() {return _output_data;};
+};
+
+
+
+
+// **************************************************************************
+// *                        constructor
+// **************************************************************************
+// parameter constructor                                                                                                                                                      
+template <typename T1, typename T2, typename T3> 
+RFFTClass<T1, T2, T3>::RFFTClass(T2& raw_data, float dt, float cc_len, float cc_step, std::string time_norm, float clip_std, int smooth_N, std::string freq_norm, float freqmin, float freqmax, int whiten_npad, int smoothspect_N, bool flag, int flag_gap, int threads) 
+{
+  _raw_data = raw_data;
+  _dt = dt;
+  _cc_len = cc_len;
+  _cc_step = cc_step;
+  _time_norm = time_norm;
+  _clip_std = clip_std;
+  _smooth_N = smooth_N;
+  _freq_norm = freq_norm;
+  _freqmin = freqmin;
+  _freqmax = freqmax;
+  _whiten_npad = whiten_npad;
+  _smoothspect_N = smoothspect_N;
+  _flag = flag;
+  _flag_gap = flag_gap;
+  _threads = threads;
+
+  // convert time to points
+  _cc_len_points = int(_cc_len/_dt);
+  _cc_step_points = int(_cc_step/_dt);
+  _npts = raw_data.shape(1);
+  _rfft_npts = _cc_len_points/2+1;
+  _channel_num = raw_data.shape(0);
+  
+  // slice_window --> _win_num, _win_info
+  _win_info = CC::slice_window(_npts, _cc_len_points, _cc_step_points);
+  _win_num = _win_info.shape(0);
+}
+
+                                                                                                                                                       
+// virtual destructor                                                                                                                                                       
+template <typename T1, typename T2, typename T3> 
+RFFTClass<T1, T2, T3>::~RFFTClass() {}
+
+
+
+
+// **************************************************************************
+// *                        time_norm
+// **************************************************************************
+// no
+template <typename T1, typename T2, typename T3> 
+inline xt::xarray<T1> RFFTClass<T1, T2, T3>::time_norm_no(int channel)
+{
+  xt::xarray<T1> time_norm_data = xt::view(_raw_data, channel, xt::all());
+
+  return time_norm_data;
+}
+
+
+// onebit
+template <typename T1, typename T2, typename T3> 
+inline xt::xarray<T1> RFFTClass<T1, T2, T3>::time_norm_onebit(int channel)
+{
+  xt::xarray<T1> time_norm_data = xt::sign(xt::view(_raw_data, channel, xt::all()));
+  
+  return time_norm_data;
+}
+
+
+// clip
+template <typename T1, typename T2, typename T3> 
+inline xt::xarray<T1> RFFTClass<T1, T2, T3>::time_norm_clip(int channel)
+{
+  xt::xarray<T1> time_norm_data = xt::view(_raw_data, channel, xt::all());
+  T1 lim = _clip_std * xt::stddev(time_norm_data)(0);
+  filtration(time_norm_data, time_norm_data>lim) = lim;
+  filtration(time_norm_data, time_norm_data<(-lim)) = -lim;
+
+  return time_norm_data;
+}
+
+
+// smooth
+template <typename T1, typename T2, typename T3> 
+inline xt::xarray<T1> RFFTClass<T1, T2, T3>::time_norm_smooth(int channel)
+{
+  xt::xarray<T1> data = xt::view(_raw_data, channel, xt::all());
+  xt::xarray<T1> time_norm_data = data / CC::moving_ave<T1>(xt::abs(data), _smooth_N);
+
+  return time_norm_data;
+}
+
+
+
+
+
+// **************************************************************************
+// *                        rfft
+// **************************************************************************
+template <typename T1, typename T2, typename T3> 
+inline xt::xarray<std::complex<T1>> RFFTClass<T1, T2, T3>::rfft(xt::xarray<T1>& time_norm_data)
+{
+  xt::xarray<std::complex<T1>> rfft_data= xt::empty<T1>({_win_num, _rfft_npts});
+
+  for(int i=0; i<_win_num; i++){
+    auto segment = xt::view(time_norm_data, xt::range(_win_info(i,0), _win_info(i,1)), xt::all());
+    auto segment_rfft = xt::fftw::rfft(xt::eval(segment));
+    xt::view(rfft_data, i, xt::all()) = segment_rfft; 
+  }
+
+  return rfft_data;
+}
+
+
+
+
+
+// **************************************************************************
+// *                        freq_norm
+// **************************************************************************
+template <typename T1, typename T2, typename T3> 
+inline xt::xarray<std::complex<T1>> RFFTClass<T1, T2, T3>::freq_norm_no(xt::xarray<std::complex<T1>>& rfft_data)
+{
+  auto freq_norm_data = rfft_data;
+
+  return freq_norm_data;
+}
+
+
+template <typename T1, typename T2, typename T3> 
+inline xt::xarray<std::complex<T1>> RFFTClass<T1, T2, T3>::freq_norm_whiten(xt::xarray<std::complex<T1>>& rfft_data)
+{
+  xt::xarray<std::complex<T1>> rfft_norm_data = CC::whiten<T1>(rfft_data, _dt, _freq_norm, _freqmin, _freqmax, _smoothspect_N, _whiten_npad);
+  
+  return rfft_norm_data;
+}
+
+
+
+
+
+
+// **************************************************************************
+// *                        run
+// **************************************************************************
+template <typename T1, typename T2, typename T3> 
+void RFFTClass<T1, T2, T3>::run()
+{
+  auto start_time = std::chrono::high_resolution_clock::now();
+  auto end_time = start_time;
+  _output_data = xt::empty<std::complex<T1>>({_channel_num, _win_num, _rfft_npts});
+  
+#ifdef _OPENMP
+  omp_set_num_threads(_threads);
+  std::cout << "Start rfft with " << _threads  << " threads using openmp..." << std::endl;
+  #pragma omp parallel for
+#else
+  std::cout << "Start rfft with " << 1 << " threads without openmp..." << std::endl;
+#endif
+
+  for(int i = 0; i < _channel_num; i++){
+// flag
+#ifdef _OPENMP
+    if (_flag && omp_get_thread_num()==0 && i%_flag_gap==0) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (_flag && i%_flag_gap==0) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+
+    // time_norm
+    xt::xarray<T1> time_norm_data;
+    if (_time_norm == "no") {
+      time_norm_data = time_norm_no(i);
+    } 
+    else if (_time_norm == "clip"){
+      time_norm_data = time_norm_clip(i);
+    } 
+    else if (_time_norm == "onebit") {
+      time_norm_data = time_norm_onebit(i);
+    } 
+    else if (_time_norm == "smooth") {
+      time_norm_data = time_norm_smooth(i);
+    } 
+    else {
+      std::cout << "error: please input the correct time_norm method." << std::endl;
+      exit(1);
+    }
+
+    // rfft
+    xt::xarray<std::complex<T1>> rfft_data = rfft(time_norm_data);
+
+    // freq_norm
+    xt::xarray<std::complex<T1>> rfft_norm_data;
+    if (_freq_norm == "no") {
+      rfft_norm_data = freq_norm_no(rfft_data);
+    } else {
+      rfft_norm_data = freq_norm_whiten(rfft_data);
+    }
+
+    // fill _output_data
+    xt::view(_output_data, i, xt::all()) = rfft_norm_data; 
+  }
+
+  end_time = std::chrono::high_resolution_clock::now();
+  auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+  std::cout << "End rfft with total time " << elapsed_time.count() << "s" <<std::endl;
+
+}
+
+
+
+// **************************************************************************
+// *                        end
+// **************************************************************************
+
+}
+
 #endif
```

## noiseflow/cc/include/stack.hpp

 * *Ordering differences only*

```diff
@@ -1,317 +1,317 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-
-#ifndef STACK_HPP
-#define STACK_HPP
-
-#include "utils.hpp"
-
-namespace CC {
-
-// Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
-template <typename T1, typename T2, typename T3> 
-class StackClass{
-  private:
-    T2 _corr_data; // input data
-    std::string _stack_method;
-    bool _stack_all;
-    float _stack_len;
-    float _stack_step;
-    bool _pick;
-    float _median_high;
-    float _median_low;
-    bool _flag;
-    int _flag_gap;
-    int _threads;
-
-  public:
-    int _npts;
-    int _pair_num; 
-    int _corr_win_num;
-    int _stack_win_num;
-    xt::xtensor<int, 2> _win_info;
-    T3 _ngood_all;
-    T3 _output_data;
-
-    // constructor
-    StackClass(T2& corr_data, std::string stack_method, bool stack_all, float stack_len, float stack_step, bool pick, float median_high, float median_low, bool flag, int flag_gap, int threads);
-
-    // copy constructor
-    // StackClass(StackClass & A);
-
-    // destructor
-    ~StackClass();
-
-    // pick --> _nindex, _ngood
-    xt::xarray<int> pick(int pair_id);
-    xt::xarray<T1> check_ngood(xt::xarray<int> & nindex);
-
-    // linear, pws, robust
-    xt::xarray<T1>  linear(int pair_id, xt::xarray<int> & nindex);
-    xt::xarray<T1>  pws(int pair_id, xt::xarray<int> & nindex);
-    xt::xarray<T1>  robust(int pair_id, xt::xarray<int> & nindex);
-
-    // run workflow
-    void run();
-
-    // return
-    T3& get_ngood() {return _ngood_all;};
-    T3& get_stackdata() {return _output_data;};
-    
-};
-
-
-// **************************************************************************
-// *                        constructor
-// **************************************************************************
-// parameter constructor                                                                                                                                                      
-template <typename T1, typename T2, typename T3> 
-StackClass<T1, T2, T3>::StackClass(T2& corr_data, std::string stack_method, bool stack_all, float stack_len, float stack_step, bool pick, float median_high, float median_low, bool flag, int flag_gap, int threads) 
-{ 
-    _corr_data = corr_data;
-    _stack_method = stack_method;
-    _stack_all = stack_all;
-    _stack_len = stack_len;
-    _stack_step = stack_step;
-    _pick = pick;
-    _median_high = median_high;
-    _median_low = median_low;
-    _flag = flag;
-    _flag_gap = flag_gap;
-    _threads = threads;
-
-    _pair_num = corr_data.shape(0);
-    _corr_win_num = corr_data.shape(1);
-    _npts = corr_data.shape(2);  
-
-    // slice_window --> _stack_win_num, _win_info
-    if (_stack_all){
-        _win_info = xt::xtensor<int, 2> {{0, _corr_win_num}};
-        _stack_win_num = 1;
-    }
-    else{
-        _win_info = CC::slice_window(_corr_win_num, _stack_len, _stack_step);
-        _stack_win_num = _win_info.shape(0);
-    }
-}
-
-                                                                                                                                                       
-// virtual destructor                                                                                                                                                          
-template <typename T1, typename T2, typename T3> 
-StackClass<T1, T2, T3>::~StackClass() {}
-
-
-
-
-// **************************************************************************
-// *                        pick
-// **************************************************************************
-template <typename T1, typename T2, typename T3> 
-xt::xarray<int> StackClass<T1, T2, T3>::pick(int pair_id)
-{
-    xt::xarray<int> nindex;
-    if (_pick){
-        // SOME WARNING HERE!!!
-        auto ampmax = xt::amax(xt::view(_corr_data, pair_id, xt::all(), xt::all()), 1);
-        auto index = xt::where((ampmax >_median_low*xt::median(ampmax)) && (ampmax<_median_high*xt::median(ampmax)))[0]; // index: std::vector<long unsigned int>
-        
-        std::vector<int> index_i;
-        for (auto& elem : index) {
-            index_i.push_back(elem);
-        }
-        nindex = xt::adapt(index_i);   
-    } 
-    else{
-        nindex = xt::arange<int>(0, _corr_win_num);
-    }
-
-    return nindex;  
-}
-
-
-
-
-// **************************************************************************
-// *                        check_ngood
-// **************************************************************************
-template <typename T1, typename T2, typename T3> 
-xt::xarray<T1> StackClass<T1, T2, T3>::check_ngood(xt::xarray<int> & nindex)
-{
-    xt::xarray<T1> ngood = xt::empty<T1>({_stack_win_num});
-    if (_pick){
-        for(int i=0; i<_stack_win_num; i++){
-            ngood(i) = xt::sum(nindex >= _win_info(i,0) && nindex < _win_info(i,1))(0);
-        }
-    } 
-    else {
-        ngood = _stack_len*xt::ones<T1>({_stack_win_num});
-    }
-
-    return ngood;
-}
-
-
-
-
-
-// **************************************************************************
-// *                        stack
-// **************************************************************************
-// linear
-template <typename T1, typename T2, typename T3> 
-xt::xarray<T1> StackClass<T1, T2, T3>::linear(int pair_id, xt::xarray<int> & nindex)
-{
-    xt::xarray<T1> stack_data = xt::empty<T1>({_stack_win_num, _npts});
-
-    for(int i=0; i<_stack_win_num; i++){
-        std::vector<int> pick_index;
-        xt::xarray<T1> each_index = xt::arange(_win_info(i,0), _win_info(i,1));
-        std::set_intersection(nindex.begin(), nindex.end(), each_index.begin(), each_index.end(), std::back_inserter(pick_index));
-
-        auto pick_corr_data = xt::view(_corr_data, pair_id, xt::keep(pick_index), xt::all());
-        if (pick_corr_data.shape(0) == 0){
-            xt::view(stack_data,i, xt::all()) = xt::zeros<T1>({_npts});
-        } 
-        else{
-            xt::view(stack_data,i, xt::all()) = xt::mean(pick_corr_data,0); // xt::sum(pick_corr_data,0) / static_cast<T1>pick_corr_data.shape(0);
-        }
-   }
-
-    return stack_data;
-}
-
-
-// pws
-template <typename T1, typename T2, typename T3> 
-xt::xarray<T1> StackClass<T1, T2, T3>::pws(int pair_id, xt::xarray<int> & nindex)
-{
-    xt::xarray<T1> stack_data = xt::empty<T1>({_stack_win_num, _npts});
-
-    for(int i=0; i<_stack_win_num; i++){
-        std::vector<int> pick_index;
-        xt::xarray<T1> each_index = xt::arange(_win_info(i,0), _win_info(i,1));
-        std::set_intersection(nindex.begin(), nindex.end(), each_index.begin(), each_index.end(), std::back_inserter(pick_index));
-
-        auto pick_corr_data = xt::view(_corr_data, pair_id, xt::keep(pick_index), xt::all());
-        if (pick_corr_data.shape(0) == 0){
-            xt::view(stack_data,i, xt::all()) = xt::zeros<T1>({_npts});
-        } 
-        else{
-            xt::view(stack_data,i, xt::all()) = CC::pws<T1>(pick_corr_data);
-        }
-    }
-
-    return stack_data;
-}
-
-
-// robust
-template <typename T1, typename T2, typename T3> 
-xt::xarray<T1> StackClass<T1, T2, T3>::robust(int pair_id, xt::xarray<int> & nindex)
-{
-    xt::xarray<T1> stack_data = xt::empty<T1>({_stack_win_num, _npts});
-    
-    for(int i=0; i<_stack_win_num; i++){
-        std::vector<int> pick_index;
-        xt::xarray<T1> each_index = xt::arange(_win_info(i,0), _win_info(i,1));
-        std::set_intersection(nindex.begin(), nindex.end(), each_index.begin(), each_index.end(), std::back_inserter(pick_index));
-        
-        auto pick_corr_data = xt::view(_corr_data, pair_id, xt::keep(pick_index), xt::all());
-        if (pick_corr_data.shape(0) == 0){
-            xt::view(stack_data,i, xt::all()) = xt::zeros<T1>({_npts});
-        } 
-        else{
-            xt::view(stack_data,i, xt::all()) = CC::robust<T1>(pick_corr_data);
-        }
-    }
-
-    return stack_data;
-}
-
-
-
-
-
-
-// **************************************************************************
-// *                        run
-// **************************************************************************
-template <typename T1, typename T2, typename T3> 
-void StackClass<T1, T2, T3>::run()
-{
-    auto start_time = std::chrono::high_resolution_clock::now();
-    auto end_time = start_time;
-    _ngood_all = xt::empty<T1>({_pair_num, _stack_win_num});
-    _output_data = xt::empty<T1>({_pair_num, _stack_win_num, _npts});
-    
-#ifdef _OPENMP
-  omp_set_num_threads(_threads);
-  std::cout << "Start stack with " << _threads  << " threads using openmp..." << std::endl;
-  #pragma omp parallel for
-#else
-  std::cout << "Start stack with " << 1 << " threads without openmp..." << std::endl;
-#endif
-
-    for(int i = 0; i < _pair_num; i++){
-// flag
-#ifdef _OPENMP
-        if (_flag && omp_get_thread_num()==0 && i%_flag_gap==0) {
-            end_time = std::chrono::high_resolution_clock::now();
-            auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-            std::cout << "Thread " << omp_get_thread_num() << " starts to process pair " << i << " || " << elapsed_time.count() << "s" << std::endl;
-        }
-#else
-        if (_flag && i%_flag_gap==0) {
-            end_time = std::chrono::high_resolution_clock::now();
-            auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-            std::cout << "Thread " << 0 << " starts to process pair " << i << " || " << elapsed_time.count() << "s" << std::endl;
-        }
-#endif
-
-        // pick --> _nindex
-        xt::xarray<int> nindex = pick(i);
-
-        // ngood
-        xt::xarray<T1> ngood = check_ngood(nindex);
-
-        // corr
-        xt::xarray<T1> stack_data;
-        if (_stack_method == "linear") {
-            stack_data = linear(i, nindex);
-        } 
-        else if (_stack_method == "pws"){
-            stack_data = pws(i, nindex);
-        } 
-        else if (_stack_method == "robust") {
-            stack_data = robust(i, nindex);
-        } 
-        else {
-            std::cout << "error: please input the correct stack method." << std::endl;
-        }
-    
-        // fill with maxlag-data
-        xt::view(_ngood_all, i, xt::all()) = ngood;
-        xt::view(_output_data, i, xt::all()) = stack_data;
-    }
-
-  end_time = std::chrono::high_resolution_clock::now();
-  auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-  std::cout << "End stack with total time " << elapsed_time.count() << "s" <<std::endl;
-}
-
-
-
-
-// **************************************************************************
-// *                        end
-// **************************************************************************
-
-} 
-
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+
+#ifndef STACK_HPP
+#define STACK_HPP
+
+#include "utils.hpp"
+
+namespace CC {
+
+// Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
+template <typename T1, typename T2, typename T3> 
+class StackClass{
+  private:
+    T2 _corr_data; // input data
+    std::string _stack_method;
+    bool _stack_all;
+    float _stack_len;
+    float _stack_step;
+    bool _pick;
+    float _median_high;
+    float _median_low;
+    bool _flag;
+    int _flag_gap;
+    int _threads;
+
+  public:
+    int _npts;
+    int _pair_num; 
+    int _corr_win_num;
+    int _stack_win_num;
+    xt::xtensor<int, 2> _win_info;
+    T3 _ngood_all;
+    T3 _output_data;
+
+    // constructor
+    StackClass(T2& corr_data, std::string stack_method, bool stack_all, float stack_len, float stack_step, bool pick, float median_high, float median_low, bool flag, int flag_gap, int threads);
+
+    // copy constructor
+    // StackClass(StackClass & A);
+
+    // destructor
+    ~StackClass();
+
+    // pick --> _nindex, _ngood
+    xt::xarray<int> pick(int pair_id);
+    xt::xarray<T1> check_ngood(xt::xarray<int> & nindex);
+
+    // linear, pws, robust
+    xt::xarray<T1>  linear(int pair_id, xt::xarray<int> & nindex);
+    xt::xarray<T1>  pws(int pair_id, xt::xarray<int> & nindex);
+    xt::xarray<T1>  robust(int pair_id, xt::xarray<int> & nindex);
+
+    // run workflow
+    void run();
+
+    // return
+    T3& get_ngood() {return _ngood_all;};
+    T3& get_stackdata() {return _output_data;};
+    
+};
+
+
+// **************************************************************************
+// *                        constructor
+// **************************************************************************
+// parameter constructor                                                                                                                                                      
+template <typename T1, typename T2, typename T3> 
+StackClass<T1, T2, T3>::StackClass(T2& corr_data, std::string stack_method, bool stack_all, float stack_len, float stack_step, bool pick, float median_high, float median_low, bool flag, int flag_gap, int threads) 
+{ 
+    _corr_data = corr_data;
+    _stack_method = stack_method;
+    _stack_all = stack_all;
+    _stack_len = stack_len;
+    _stack_step = stack_step;
+    _pick = pick;
+    _median_high = median_high;
+    _median_low = median_low;
+    _flag = flag;
+    _flag_gap = flag_gap;
+    _threads = threads;
+
+    _pair_num = corr_data.shape(0);
+    _corr_win_num = corr_data.shape(1);
+    _npts = corr_data.shape(2);  
+
+    // slice_window --> _stack_win_num, _win_info
+    if (_stack_all){
+        _win_info = xt::xtensor<int, 2> {{0, _corr_win_num}};
+        _stack_win_num = 1;
+    }
+    else{
+        _win_info = CC::slice_window(_corr_win_num, _stack_len, _stack_step);
+        _stack_win_num = _win_info.shape(0);
+    }
+}
+
+                                                                                                                                                       
+// virtual destructor                                                                                                                                                          
+template <typename T1, typename T2, typename T3> 
+StackClass<T1, T2, T3>::~StackClass() {}
+
+
+
+
+// **************************************************************************
+// *                        pick
+// **************************************************************************
+template <typename T1, typename T2, typename T3> 
+xt::xarray<int> StackClass<T1, T2, T3>::pick(int pair_id)
+{
+    xt::xarray<int> nindex;
+    if (_pick){
+        // SOME WARNING HERE!!!
+        auto ampmax = xt::amax(xt::view(_corr_data, pair_id, xt::all(), xt::all()), 1);
+        auto index = xt::where((ampmax >_median_low*xt::median(ampmax)) && (ampmax<_median_high*xt::median(ampmax)))[0]; // index: std::vector<long unsigned int>
+        
+        std::vector<int> index_i;
+        for (auto& elem : index) {
+            index_i.push_back(elem);
+        }
+        nindex = xt::adapt(index_i);   
+    } 
+    else{
+        nindex = xt::arange<int>(0, _corr_win_num);
+    }
+
+    return nindex;  
+}
+
+
+
+
+// **************************************************************************
+// *                        check_ngood
+// **************************************************************************
+template <typename T1, typename T2, typename T3> 
+xt::xarray<T1> StackClass<T1, T2, T3>::check_ngood(xt::xarray<int> & nindex)
+{
+    xt::xarray<T1> ngood = xt::empty<T1>({_stack_win_num});
+    if (_pick){
+        for(int i=0; i<_stack_win_num; i++){
+            ngood(i) = xt::sum(nindex >= _win_info(i,0) && nindex < _win_info(i,1))(0);
+        }
+    } 
+    else {
+        ngood = _stack_len*xt::ones<T1>({_stack_win_num});
+    }
+
+    return ngood;
+}
+
+
+
+
+
+// **************************************************************************
+// *                        stack
+// **************************************************************************
+// linear
+template <typename T1, typename T2, typename T3> 
+xt::xarray<T1> StackClass<T1, T2, T3>::linear(int pair_id, xt::xarray<int> & nindex)
+{
+    xt::xarray<T1> stack_data = xt::empty<T1>({_stack_win_num, _npts});
+
+    for(int i=0; i<_stack_win_num; i++){
+        std::vector<int> pick_index;
+        xt::xarray<T1> each_index = xt::arange(_win_info(i,0), _win_info(i,1));
+        std::set_intersection(nindex.begin(), nindex.end(), each_index.begin(), each_index.end(), std::back_inserter(pick_index));
+
+        auto pick_corr_data = xt::view(_corr_data, pair_id, xt::keep(pick_index), xt::all());
+        if (pick_corr_data.shape(0) == 0){
+            xt::view(stack_data,i, xt::all()) = xt::zeros<T1>({_npts});
+        } 
+        else{
+            xt::view(stack_data,i, xt::all()) = xt::mean(pick_corr_data,0); // xt::sum(pick_corr_data,0) / static_cast<T1>pick_corr_data.shape(0);
+        }
+   }
+
+    return stack_data;
+}
+
+
+// pws
+template <typename T1, typename T2, typename T3> 
+xt::xarray<T1> StackClass<T1, T2, T3>::pws(int pair_id, xt::xarray<int> & nindex)
+{
+    xt::xarray<T1> stack_data = xt::empty<T1>({_stack_win_num, _npts});
+
+    for(int i=0; i<_stack_win_num; i++){
+        std::vector<int> pick_index;
+        xt::xarray<T1> each_index = xt::arange(_win_info(i,0), _win_info(i,1));
+        std::set_intersection(nindex.begin(), nindex.end(), each_index.begin(), each_index.end(), std::back_inserter(pick_index));
+
+        auto pick_corr_data = xt::view(_corr_data, pair_id, xt::keep(pick_index), xt::all());
+        if (pick_corr_data.shape(0) == 0){
+            xt::view(stack_data,i, xt::all()) = xt::zeros<T1>({_npts});
+        } 
+        else{
+            xt::view(stack_data,i, xt::all()) = CC::pws<T1>(pick_corr_data);
+        }
+    }
+
+    return stack_data;
+}
+
+
+// robust
+template <typename T1, typename T2, typename T3> 
+xt::xarray<T1> StackClass<T1, T2, T3>::robust(int pair_id, xt::xarray<int> & nindex)
+{
+    xt::xarray<T1> stack_data = xt::empty<T1>({_stack_win_num, _npts});
+    
+    for(int i=0; i<_stack_win_num; i++){
+        std::vector<int> pick_index;
+        xt::xarray<T1> each_index = xt::arange(_win_info(i,0), _win_info(i,1));
+        std::set_intersection(nindex.begin(), nindex.end(), each_index.begin(), each_index.end(), std::back_inserter(pick_index));
+        
+        auto pick_corr_data = xt::view(_corr_data, pair_id, xt::keep(pick_index), xt::all());
+        if (pick_corr_data.shape(0) == 0){
+            xt::view(stack_data,i, xt::all()) = xt::zeros<T1>({_npts});
+        } 
+        else{
+            xt::view(stack_data,i, xt::all()) = CC::robust<T1>(pick_corr_data);
+        }
+    }
+
+    return stack_data;
+}
+
+
+
+
+
+
+// **************************************************************************
+// *                        run
+// **************************************************************************
+template <typename T1, typename T2, typename T3> 
+void StackClass<T1, T2, T3>::run()
+{
+    auto start_time = std::chrono::high_resolution_clock::now();
+    auto end_time = start_time;
+    _ngood_all = xt::empty<T1>({_pair_num, _stack_win_num});
+    _output_data = xt::empty<T1>({_pair_num, _stack_win_num, _npts});
+    
+#ifdef _OPENMP
+  omp_set_num_threads(_threads);
+  std::cout << "Start stack with " << _threads  << " threads using openmp..." << std::endl;
+  #pragma omp parallel for
+#else
+  std::cout << "Start stack with " << 1 << " threads without openmp..." << std::endl;
+#endif
+
+    for(int i = 0; i < _pair_num; i++){
+// flag
+#ifdef _OPENMP
+        if (_flag && omp_get_thread_num()==0 && i%_flag_gap==0) {
+            end_time = std::chrono::high_resolution_clock::now();
+            auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+            std::cout << "Thread " << omp_get_thread_num() << " starts to process pair " << i << " || " << elapsed_time.count() << "s" << std::endl;
+        }
+#else
+        if (_flag && i%_flag_gap==0) {
+            end_time = std::chrono::high_resolution_clock::now();
+            auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+            std::cout << "Thread " << 0 << " starts to process pair " << i << " || " << elapsed_time.count() << "s" << std::endl;
+        }
+#endif
+
+        // pick --> _nindex
+        xt::xarray<int> nindex = pick(i);
+
+        // ngood
+        xt::xarray<T1> ngood = check_ngood(nindex);
+
+        // corr
+        xt::xarray<T1> stack_data;
+        if (_stack_method == "linear") {
+            stack_data = linear(i, nindex);
+        } 
+        else if (_stack_method == "pws"){
+            stack_data = pws(i, nindex);
+        } 
+        else if (_stack_method == "robust") {
+            stack_data = robust(i, nindex);
+        } 
+        else {
+            std::cout << "error: please input the correct stack method." << std::endl;
+        }
+    
+        // fill with maxlag-data
+        xt::view(_ngood_all, i, xt::all()) = ngood;
+        xt::view(_output_data, i, xt::all()) = stack_data;
+    }
+
+  end_time = std::chrono::high_resolution_clock::now();
+  auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+  std::cout << "End stack with total time " << elapsed_time.count() << "s" <<std::endl;
+}
+
+
+
+
+// **************************************************************************
+// *                        end
+// **************************************************************************
+
+} 
+
 #endif
```

## noiseflow/cc/include/utils.hpp

 * *Ordering differences only*

```diff
@@ -1,270 +1,270 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-#ifndef UTILS_HPP
-#define UTILS_HPP
-
-#ifdef _OPENMP
-#include <omp.h>
-#endif
-
-#include <iostream>
-#include <vector>
-#include <string>
-// #include <ctime>
-#include <chrono>
-#include <complex>
-#include <exception>
-
-#include <xtensor/xarray.hpp>
-#include <xtensor/xtensor.hpp>
-#include <xtensor/xbuilder.hpp>
-#include <xtensor/xview.hpp>
-#include <xtensor/xmath.hpp>
-#include <xtensor/xcomplex.hpp>
-#include <xtensor/xmanipulation.hpp> // for xt::roll
-#include <xtensor/xadapt.hpp>
-#include <xtensor/xsort.hpp>
-#include <xtensor/xoperation.hpp>
-#include <xtensor/xindex_view.hpp>
-#include <xsimd/xsimd.hpp>
-#include <xtensor-blas/xlinalg.hpp>
-#include <xtensor-fftw/basic.hpp>
-#include <xtensor-fftw/helper.hpp>
-#include <xtensor-python/pyarray.hpp>
-#include <xtensor-python/pytensor.hpp>
-
-
-namespace CC {
-
-inline xt::xtensor<int, 2> slice_window(int npts, int segment_points, int step_points)
-{
-    int win_num;
-    xt::xtensor<int, 2> win_info;
-
-    if (segment_points < npts){
-        int slide_points = segment_points - step_points;
-        win_num = 0;
-        for (int i=0; i<(npts/slide_points); i++){
-            if ((i * slide_points + segment_points) <= npts){
-                win_num++;
-            } 
-            else {
-                break;
-            }
-        }
-        win_info = xt::empty<int>({win_num, 2});
-        for (int i=0; i<win_num; i++){
-            win_info(i,0) = i * slide_points;
-            win_info(i,1) = i * slide_points + segment_points;
-        }
-    }
-    else if (segment_points == npts){
-        win_num = 1;
-        win_info = xt::xtensor<int, 2> {{0, npts}};
-    } 
-    else if (segment_points > npts){
-        std::cout << "error: segment-points length is larger than npts when slicing windows!" << std::endl;
-        exit(1);
-    } 
-    else {
-        std::cout << "error: segment-points length is small than 0!" << std::endl; 
-        exit(1);
-    }
-
-    return win_info;
-}
-
-  
-
-// A: 1D xarray
-template <class T>
-inline xt::xarray<T> moving_ave(const xt::xarray<T>& A, int N)
-{
-    xt::xarray<T> temp = xt::zeros<T>({A.shape(0)+2*N});
-    
-    int temp_len = temp.shape(0);
-    xt::view(temp, xt::range(N, temp_len-N)) = A;
-    xt::view(temp, xt::range(0, N)) = temp(N);
-    xt::view(temp, xt::range(temp_len-N, temp_len)) = temp(temp_len-N-1);
-
-    xt::xarray<T> nn = xt::ones<T>({N}) / T(N);
-    auto b1 = xt::convolve(temp, nn, xt::convolve_mode::full());
-
-    int n1 = N+(N-1)/2;
-    int n2 = N+(N-1-(N-1)/2);
-    auto B1 = xt::view(b1, xt::range(n1, b1.shape(0)-n2));
-
-    return B1;
-}
-
-
-// rfft_data: 2D xarray, shape: (win_num, rfft_npts)
-template <class T>
-inline xt::xarray<std::complex<T>> whiten(const xt::xarray<std::complex<T>>& rfft_data, float dt, std::string freq_norm, float freqmin, float freqmax, int smoothspect_N, int whiten_npad)
-{
-    std::complex<T> _i {0, 1};
-    std::complex<T> _i0 {0, 0};
-    T _pi = xt::numeric_constants<T>::PI;
-
-    int win_num = rfft_data.shape(0);
-    int rfft_npts = rfft_data.shape(1);
-
-    xt::xarray<T> freq_array = xt::arange(rfft_npts) / dt / 2.0 / T(rfft_npts-1); // note: must divide by 2.0, because rfft_npts is not _npts.
-    auto J = xt::where((freq_array>=freqmin) & (freq_array<=freqmax))[0];
-
-    int low = J[0] - whiten_npad;
-    if (low <= 0)
-        low = 0;
-    int left = J[0];
-    int right = J[J.size()-1];
-    int high = J[J.size()-1] + whiten_npad;
-    if (high > rfft_npts)
-        high = rfft_npts;
-
-    xt::xarray<std::complex<T>> rfft_norm_data = _i0*xt::ones<std::complex<T>>({win_num, rfft_npts});
-
-    for(int i=0; i<win_num; i++){
-        // left zero cut-off
-        // xt::view(rfft_norm_data, i, xt::range(0, low)) = _i0*xt::view(rfft_data, i, xt::range(0, low));
-
-        // left tapering
-        auto smo1 = xt::pow(xt::cos( xt::linspace<T>(_pi/2, _pi, left-low)), 2);
-        auto exp1 = xt::exp(_i*xt::arg(xt::view(rfft_data, i, xt::range(low, left))));
-        xt::view(rfft_norm_data, i, xt::range(low, left)) = smo1*exp1;
- 
-        // pass band
-        if (freq_norm == "whiten"){
-            auto smo2 = xt::ones<T>({right-left});
-            auto exp2 = xt::exp(_i*xt::arg(xt::view(rfft_data, i, xt::range(left, right))));
-            xt::view(rfft_norm_data, i, xt::range(left, right)) = smo2*exp2;
-        } 
-        else if(freq_norm == "smooth_whiten"){
-            auto data = xt::view(rfft_data, i, xt::range(left, right));
-            xt::view(rfft_norm_data, i, xt::range(left, right)) = data / moving_ave<std::complex<T>>(xt::abs(data), smoothspect_N);
-        } 
-        else {
-            std::cout << "freq_norm is not defined" << std::endl;
-            exit(1);
-        }
-    
-        // right tapering
-        auto smo3 = xt::pow(xt::cos( xt::linspace<T>(0, _pi/2, high-right)), 2);
-        auto exp3 = xt::exp(_i*xt::arg(xt::view(rfft_data, i, xt::range(right, high))));
-        xt::view(rfft_norm_data, i, xt::range(right, high)) = smo3*exp3;
-
-        // right zero cut-off
-        // xt::view(rfft_norm_data, i, xt::range(high, -1)) = _i0*xt::view(rfft_data, i, xt::range(high, -1));
-    }
-
-    return rfft_norm_data;
-}
-
-
-
-// data: (nchannel, npts) 2D array
-template <class T>
-xt::xarray<T> robust(const xt::xarray<T>& data)
-{
-    int nstep = 0;
-    int maxstep = 10;
-    int channel_num = data.shape(0);
-
-    T res = 9e9;
-    T epsilon = 1e-5;
-    
-    xt::xarray<T> w = xt::ones<T>({channel_num});
-    xt::xarray<T> newstack = xt::median(data,0);
-    xt::xarray<T> crap;
-    xt::xarray<T> crap_dot;
-    xt::xarray<T> di_norm;
-    xt::xarray<T> ri;
-    xt::xarray<T> ri_norm;
-    xt::xarray<T> stack;
-
-    while (res>epsilon && nstep <=maxstep){
-        stack = newstack;
-
-        for(int i=0; i<channel_num;i++){
-            crap = stack * xt::transpose(xt::view(data, i, xt::all()));
-            crap_dot = xt::sum(crap);
-            di_norm = xt::linalg::norm(xt::view(data, i, xt::all()));
-            ri = xt::view(data, i, xt::all()) - crap_dot*stack;
-            ri_norm = xt::linalg::norm(ri);
-            xt::view(w, i) = xt::abs(crap_dot)/di_norm/ri_norm;
-        }
-
-        w = w/xt::sum(w);
-        newstack = xt::sum(xt::transpose(w*xt::transpose(data)), 0);
-        res = xt::linalg::norm(newstack-stack, 1)/xt::linalg::norm(newstack)/T(channel_num);
-        nstep += 1;
-    }
-
-    return newstack;
-}
-
-
-
-// x: (npts) 1D complex-array
-template <class T>
-inline xt::xarray<std::complex<T>> hilbert_transform(const xt::xarray<std::complex<T>>& x)
-{
-    int N = x.shape(0);
-    xt::xarray<std::complex<T>> Xf = xt::fftw::fft(x);
-    xt::xarray<T> h = xt::zeros<T>({N});
-
-    if ((N%2) == 0){
-        h(0) = 1.0;
-        h(N/2) = 1.0;
-        xt::view(h, xt::range(1,N/2)) = 2.0;
-    } 
-    else{
-        h(0) = 1.0;
-        xt::view(h, xt::range(1,(N+1)/2)) = 2.0;
-    }
-        
-    return xt::fftw::ifft(xt::eval(Xf * h));
-}
-
-
-
-// x: (nchannel, npts) 2D array
-template <class T>
-inline xt::xarray<T> pws(const xt::xarray<T>& x)
-{   
-    int channel_num = x.shape(0);
-
-    if (channel_num == 0){
-        xt::xarray<T> newstack;
-        return newstack;
-    } 
-    else{
-        int row_num = x.shape(0);
-        int colume_num = x.shape(1);
-        std::complex<float> _i {0, 1};
-        xt::xarray<std::complex<T>> analytic = xt::empty<std::complex<T>>({row_num, colume_num});
-
-        for (int i=0; i<row_num; i++){
-            xt::view(analytic, i, xt::all()) = hilbert_transform<T>(xt::view(x, i, xt::all())); 
-        }
-
-        auto phase = xt::angle(analytic);
-        auto phase_stack = xt::mean(xt::exp(_i*phase), 0); 
-        // auto phase_stack = xt::sum(xt::exp(_i*phase),0) / static_cast<T>(row_num);
-
-        auto phase_stack_new = xt::pow(xt::abs(phase_stack), 2);
-        xt::xarray<T> weighted = xt::mean(x*phase_stack_new, 0);
-        // xt::xarray<T> weighted = xt::sum(x*phase_stack_new, 0) / static_cast<T>(row_num);
-
-        return weighted;
-    }
-}
-
-
-} 
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+#ifndef UTILS_HPP
+#define UTILS_HPP
+
+#ifdef _OPENMP
+#include <omp.h>
+#endif
+
+#include <iostream>
+#include <vector>
+#include <string>
+// #include <ctime>
+#include <chrono>
+#include <complex>
+#include <exception>
+
+#include <xtensor/xarray.hpp>
+#include <xtensor/xtensor.hpp>
+#include <xtensor/xbuilder.hpp>
+#include <xtensor/xview.hpp>
+#include <xtensor/xmath.hpp>
+#include <xtensor/xcomplex.hpp>
+#include <xtensor/xmanipulation.hpp> // for xt::roll
+#include <xtensor/xadapt.hpp>
+#include <xtensor/xsort.hpp>
+#include <xtensor/xoperation.hpp>
+#include <xtensor/xindex_view.hpp>
+#include <xsimd/xsimd.hpp>
+#include <xtensor-blas/xlinalg.hpp>
+#include <xtensor-fftw/basic.hpp>
+#include <xtensor-fftw/helper.hpp>
+#include <xtensor-python/pyarray.hpp>
+#include <xtensor-python/pytensor.hpp>
+
+
+namespace CC {
+
+inline xt::xtensor<int, 2> slice_window(int npts, int segment_points, int step_points)
+{
+    int win_num;
+    xt::xtensor<int, 2> win_info;
+
+    if (segment_points < npts){
+        int slide_points = segment_points - step_points;
+        win_num = 0;
+        for (int i=0; i<(npts/slide_points); i++){
+            if ((i * slide_points + segment_points) <= npts){
+                win_num++;
+            } 
+            else {
+                break;
+            }
+        }
+        win_info = xt::empty<int>({win_num, 2});
+        for (int i=0; i<win_num; i++){
+            win_info(i,0) = i * slide_points;
+            win_info(i,1) = i * slide_points + segment_points;
+        }
+    }
+    else if (segment_points == npts){
+        win_num = 1;
+        win_info = xt::xtensor<int, 2> {{0, npts}};
+    } 
+    else if (segment_points > npts){
+        std::cout << "error: segment-points length is larger than npts when slicing windows!" << std::endl;
+        exit(1);
+    } 
+    else {
+        std::cout << "error: segment-points length is small than 0!" << std::endl; 
+        exit(1);
+    }
+
+    return win_info;
+}
+
+  
+
+// A: 1D xarray
+template <class T>
+inline xt::xarray<T> moving_ave(const xt::xarray<T>& A, int N)
+{
+    xt::xarray<T> temp = xt::zeros<T>({A.shape(0)+2*N});
+    
+    int temp_len = temp.shape(0);
+    xt::view(temp, xt::range(N, temp_len-N)) = A;
+    xt::view(temp, xt::range(0, N)) = temp(N);
+    xt::view(temp, xt::range(temp_len-N, temp_len)) = temp(temp_len-N-1);
+
+    xt::xarray<T> nn = xt::ones<T>({N}) / T(N);
+    auto b1 = xt::convolve(temp, nn, xt::convolve_mode::full());
+
+    int n1 = N+(N-1)/2;
+    int n2 = N+(N-1-(N-1)/2);
+    auto B1 = xt::view(b1, xt::range(n1, b1.shape(0)-n2));
+
+    return B1;
+}
+
+
+// rfft_data: 2D xarray, shape: (win_num, rfft_npts)
+template <class T>
+inline xt::xarray<std::complex<T>> whiten(const xt::xarray<std::complex<T>>& rfft_data, float dt, std::string freq_norm, float freqmin, float freqmax, int smoothspect_N, int whiten_npad)
+{
+    std::complex<T> _i {0, 1};
+    std::complex<T> _i0 {0, 0};
+    T _pi = xt::numeric_constants<T>::PI;
+
+    int win_num = rfft_data.shape(0);
+    int rfft_npts = rfft_data.shape(1);
+
+    xt::xarray<T> freq_array = xt::arange(rfft_npts) / dt / 2.0 / T(rfft_npts-1); // note: must divide by 2.0, because rfft_npts is not _npts.
+    auto J = xt::where((freq_array>=freqmin) & (freq_array<=freqmax))[0];
+
+    int low = J[0] - whiten_npad;
+    if (low <= 0)
+        low = 0;
+    int left = J[0];
+    int right = J[J.size()-1];
+    int high = J[J.size()-1] + whiten_npad;
+    if (high > rfft_npts)
+        high = rfft_npts;
+
+    xt::xarray<std::complex<T>> rfft_norm_data = _i0*xt::ones<std::complex<T>>({win_num, rfft_npts});
+
+    for(int i=0; i<win_num; i++){
+        // left zero cut-off
+        // xt::view(rfft_norm_data, i, xt::range(0, low)) = _i0*xt::view(rfft_data, i, xt::range(0, low));
+
+        // left tapering
+        auto smo1 = xt::pow(xt::cos( xt::linspace<T>(_pi/2, _pi, left-low)), 2);
+        auto exp1 = xt::exp(_i*xt::arg(xt::view(rfft_data, i, xt::range(low, left))));
+        xt::view(rfft_norm_data, i, xt::range(low, left)) = smo1*exp1;
+ 
+        // pass band
+        if (freq_norm == "whiten"){
+            auto smo2 = xt::ones<T>({right-left});
+            auto exp2 = xt::exp(_i*xt::arg(xt::view(rfft_data, i, xt::range(left, right))));
+            xt::view(rfft_norm_data, i, xt::range(left, right)) = smo2*exp2;
+        } 
+        else if(freq_norm == "smooth_whiten"){
+            auto data = xt::view(rfft_data, i, xt::range(left, right));
+            xt::view(rfft_norm_data, i, xt::range(left, right)) = data / moving_ave<std::complex<T>>(xt::abs(data), smoothspect_N);
+        } 
+        else {
+            std::cout << "freq_norm is not defined" << std::endl;
+            exit(1);
+        }
+    
+        // right tapering
+        auto smo3 = xt::pow(xt::cos( xt::linspace<T>(0, _pi/2, high-right)), 2);
+        auto exp3 = xt::exp(_i*xt::arg(xt::view(rfft_data, i, xt::range(right, high))));
+        xt::view(rfft_norm_data, i, xt::range(right, high)) = smo3*exp3;
+
+        // right zero cut-off
+        // xt::view(rfft_norm_data, i, xt::range(high, -1)) = _i0*xt::view(rfft_data, i, xt::range(high, -1));
+    }
+
+    return rfft_norm_data;
+}
+
+
+
+// data: (nchannel, npts) 2D array
+template <class T>
+xt::xarray<T> robust(const xt::xarray<T>& data)
+{
+    int nstep = 0;
+    int maxstep = 10;
+    int channel_num = data.shape(0);
+
+    T res = 9e9;
+    T epsilon = 1e-5;
+    
+    xt::xarray<T> w = xt::ones<T>({channel_num});
+    xt::xarray<T> newstack = xt::median(data,0);
+    xt::xarray<T> crap;
+    xt::xarray<T> crap_dot;
+    xt::xarray<T> di_norm;
+    xt::xarray<T> ri;
+    xt::xarray<T> ri_norm;
+    xt::xarray<T> stack;
+
+    while (res>epsilon && nstep <=maxstep){
+        stack = newstack;
+
+        for(int i=0; i<channel_num;i++){
+            crap = stack * xt::transpose(xt::view(data, i, xt::all()));
+            crap_dot = xt::sum(crap);
+            di_norm = xt::linalg::norm(xt::view(data, i, xt::all()));
+            ri = xt::view(data, i, xt::all()) - crap_dot*stack;
+            ri_norm = xt::linalg::norm(ri);
+            xt::view(w, i) = xt::abs(crap_dot)/di_norm/ri_norm;
+        }
+
+        w = w/xt::sum(w);
+        newstack = xt::sum(xt::transpose(w*xt::transpose(data)), 0);
+        res = xt::linalg::norm(newstack-stack, 1)/xt::linalg::norm(newstack)/T(channel_num);
+        nstep += 1;
+    }
+
+    return newstack;
+}
+
+
+
+// x: (npts) 1D complex-array
+template <class T>
+inline xt::xarray<std::complex<T>> hilbert_transform(const xt::xarray<std::complex<T>>& x)
+{
+    int N = x.shape(0);
+    xt::xarray<std::complex<T>> Xf = xt::fftw::fft(x);
+    xt::xarray<T> h = xt::zeros<T>({N});
+
+    if ((N%2) == 0){
+        h(0) = 1.0;
+        h(N/2) = 1.0;
+        xt::view(h, xt::range(1,N/2)) = 2.0;
+    } 
+    else{
+        h(0) = 1.0;
+        xt::view(h, xt::range(1,(N+1)/2)) = 2.0;
+    }
+        
+    return xt::fftw::ifft(xt::eval(Xf * h));
+}
+
+
+
+// x: (nchannel, npts) 2D array
+template <class T>
+inline xt::xarray<T> pws(const xt::xarray<T>& x)
+{   
+    int channel_num = x.shape(0);
+
+    if (channel_num == 0){
+        xt::xarray<T> newstack;
+        return newstack;
+    } 
+    else{
+        int row_num = x.shape(0);
+        int colume_num = x.shape(1);
+        std::complex<float> _i {0, 1};
+        xt::xarray<std::complex<T>> analytic = xt::empty<std::complex<T>>({row_num, colume_num});
+
+        for (int i=0; i<row_num; i++){
+            xt::view(analytic, i, xt::all()) = hilbert_transform<T>(xt::view(x, i, xt::all())); 
+        }
+
+        auto phase = xt::angle(analytic);
+        auto phase_stack = xt::mean(xt::exp(_i*phase), 0); 
+        // auto phase_stack = xt::sum(xt::exp(_i*phase),0) / static_cast<T>(row_num);
+
+        auto phase_stack_new = xt::pow(xt::abs(phase_stack), 2);
+        xt::xarray<T> weighted = xt::mean(x*phase_stack_new, 0);
+        // xt::xarray<T> weighted = xt::sum(x*phase_stack_new, 0) / static_cast<T>(row_num);
+
+        return weighted;
+    }
+}
+
+
+} 
 #endif
```

## noiseflow/cc/python/corr.py

 * *Ordering differences only*

```diff
@@ -1,180 +1,180 @@
-import time
-import scipy
-import numpy as np
-
-from tqdm import tqdm 
-from joblib import Parallel, delayed
-from noiseflow.cc.python.utils import moving_ave, split
-
-
-def xcorr(source_data, receiver_data):
-    rfft_corr_data = np.conj(source_data) * receiver_data
-
-    return rfft_corr_data
-
-
-def deconv(source_data, receiver_data, smoothspect_N):
-    win_num = int(source_data.shape[0])
-    rfft_npts = int(source_data.shape[1])
-    ss_data = np.empty((win_num, rfft_npts), dtype=source_data.dtype)
-
-    for i in range(win_num):
-        ss = source_data[i, :]
-        temp = moving_ave(np.abs(ss), smoothspect_N)
-        ss_data[i] = np.divide(ss, 
-                               temp, 
-                               out=np.zeros_like(ss, dtype=ss.dtype), 
-                               where=temp!=0)
-
-    rfft_corr_data = np.conj(ss_data) * receiver_data
-
-    return rfft_corr_data
-
-
-def coherency(source_data, receiver_data, smoothspect_N):
-    win_num = int(source_data.shape[0])
-    rfft_npts = int(source_data.shape[1])
-
-    ss_data = np.empty((win_num, rfft_npts), dtype=source_data.dtype)
-    rr_data = np.empty((win_num, rfft_npts), dtype=source_data.dtype)
-
-    for i in range(win_num):
-        ss = source_data[i, :]
-        rr = receiver_data[i, :]
-        ss_temp = moving_ave(np.abs(ss), smoothspect_N)
-        rr_temp = moving_ave(np.abs(rr), smoothspect_N)
-        ss_data[i] = np.divide(ss, 
-                                ss_temp, 
-                                out=np.zeros_like(ss, dtype=ss.dtype), 
-                                where=ss_temp!=0)
-        
-        rr_data[i] = np.divide(rr,
-                                rr_temp,
-                                out=np.zeros_like(rr, dtype=rr.dtype),
-                                where=rr_temp!=0)
-
-
-    rfft_corr_data = np.conj(ss_data) * rr_data
-
-    return rfft_corr_data
-
-
-class CorrClass_python(object):
-    def __init__(self, rfft_data, dt, corr_method, corr_pair, maxlag,
-                smoothspect_N, flag, jobs):
-        
-        self.rfft_data = rfft_data
-        self.dt = dt
-        self.corr_method = corr_method
-        self.corr_pair = corr_pair
-        self.maxlag = maxlag
-        self.smoothspect_N = smoothspect_N
-        self.flag = flag
-        self.jobs = jobs
-
-        self.pair_num = int(corr_pair.shape[0])
-        self.channel_num = int(rfft_data.shape[0])
-        self.win_num = int(rfft_data.shape[1])
-        self.rfft_npts = int(rfft_data.shape[2])
-        self.npts = int(2*(self.rfft_npts-1))
-
-        t = np.arange(-self.rfft_npts + 1, self.rfft_npts) * dt
-        ind = np.where(np.abs(t) <= maxlag)[0]
-        self.maxlag_npts = int(ind.size)
-        self.maxlag_start = int(ind[0])
-        self.maxlag_end = int(ind[-1] + 1)
-
-        # initialize output_data
-        if self.rfft_data.dtype == np.dtype(np.complex64):
-            self.output_data = np.empty((self.pair_num, self.win_num, self.maxlag_npts), dtype=np.float32)
-            self.time_dtype = np.float32
-            self.freq_dtype = np.complex64
-        elif self.rfft_data.dtype == np.dtype(np.complex128):
-            self.output_data = np.empty((self.pair_num, self.win_num, self.maxlag_npts), dtype=np.float64)
-            self.time_dtype = np.float64
-            self.freq_dtype = np.complex128
-        else:
-            print("error: please input the correct data type.")
-            exit(1)
-
-
-    def corr(self, source_data, receiver_data):
-        if self.corr_method == "xcorr":
-            rfft_corr_data = xcorr(source_data, receiver_data)
-        elif self.corr_method == "deconv":
-            rfft_corr_data = deconv(source_data, receiver_data, self.smoothspect_N)
-        elif self.corr_method == "coherency":
-            rfft_corr_data = coherency(source_data, receiver_data, self.smoothspect_N)
-        else:
-            print("error: please input the correct corr method.")
-            exit(1)
-        
-        return rfft_corr_data
-
-
-    def irfft(self, rfft_corr_data):
-        corr_data = np.empty((self.win_num, self.npts), dtype=self.time_dtype)
-
-
-        for i in range(self.win_num):
-            ss = rfft_corr_data[i]
-            corr_data[i] = np.roll(scipy.fft.irfft(ss), int(self.rfft_npts - 1))
-
-        return corr_data
-
-
-    def cut_maxlag(self, corr_data):
-        maxlag_corr_data = corr_data[:, self.maxlag_start:self.maxlag_end]
-
-        return maxlag_corr_data
-
-
-    def process_chunk(self, chunk_start, chunk_end):
-        results = []
-        if self.flag and chunk_start == 0:
-            bar = tqdm(range(chunk_start, chunk_end))
-        else:
-            bar = range(chunk_start, chunk_end)
-
-        for i in bar:
-            # corr
-            source_data = self.rfft_data[self.corr_pair[i, 0], :, :]
-            receiver_data = self.rfft_data[self.corr_pair[i, 1], :, :]
-            rfft_corr_data = self.corr(source_data, receiver_data)
-
-            # irfft
-            corr_data = self.irfft(rfft_corr_data)
-
-            # cut maxlag
-            maxlag_corr_data = self.cut_maxlag(corr_data)
-
-            results.append(maxlag_corr_data)
-
-        return results
-
-
-    def run(self):
-        if self.flag:
-            start_time = time.time()
-            print(f"Start corr with {self.jobs} jobs in python...")
-        
-        # parallel processing
-        if self.jobs > 1:
-            chunk_list = split(num=self.pair_num, n_jobs=self.jobs)
-            results = Parallel(n_jobs=self.jobs, backend="loky")(delayed(self.process_chunk)(chunk_start, chunk_end) for chunk_start, chunk_end in chunk_list)
-
-            for i, chunk_results in enumerate(results):
-                chunk_start = chunk_list[i][0]
-                for j, result in enumerate(chunk_results):
-                    self.output_data[chunk_start + j] = result
-        else:
-            results = self.process_chunk(0, self.pair_num)
-            self.output_data = np.array(results, dtype=self.time_dtype)
-
-        if self.flag:
-            end_time = time.time()
-            elapsed_time = end_time - start_time
-            print(f"End corr with total time {elapsed_time}s")
-
-
-
+import time
+import scipy
+import numpy as np
+
+from tqdm import tqdm 
+from joblib import Parallel, delayed
+from noiseflow.cc.python.utils import moving_ave, split
+
+
+def xcorr(source_data, receiver_data):
+    rfft_corr_data = np.conj(source_data) * receiver_data
+
+    return rfft_corr_data
+
+
+def deconv(source_data, receiver_data, smoothspect_N):
+    win_num = int(source_data.shape[0])
+    rfft_npts = int(source_data.shape[1])
+    ss_data = np.empty((win_num, rfft_npts), dtype=source_data.dtype)
+
+    for i in range(win_num):
+        ss = source_data[i, :]
+        temp = moving_ave(np.abs(ss), smoothspect_N)
+        ss_data[i] = np.divide(ss, 
+                               temp, 
+                               out=np.zeros_like(ss, dtype=ss.dtype), 
+                               where=temp!=0)
+
+    rfft_corr_data = np.conj(ss_data) * receiver_data
+
+    return rfft_corr_data
+
+
+def coherency(source_data, receiver_data, smoothspect_N):
+    win_num = int(source_data.shape[0])
+    rfft_npts = int(source_data.shape[1])
+
+    ss_data = np.empty((win_num, rfft_npts), dtype=source_data.dtype)
+    rr_data = np.empty((win_num, rfft_npts), dtype=source_data.dtype)
+
+    for i in range(win_num):
+        ss = source_data[i, :]
+        rr = receiver_data[i, :]
+        ss_temp = moving_ave(np.abs(ss), smoothspect_N)
+        rr_temp = moving_ave(np.abs(rr), smoothspect_N)
+        ss_data[i] = np.divide(ss, 
+                                ss_temp, 
+                                out=np.zeros_like(ss, dtype=ss.dtype), 
+                                where=ss_temp!=0)
+        
+        rr_data[i] = np.divide(rr,
+                                rr_temp,
+                                out=np.zeros_like(rr, dtype=rr.dtype),
+                                where=rr_temp!=0)
+
+
+    rfft_corr_data = np.conj(ss_data) * rr_data
+
+    return rfft_corr_data
+
+
+class CorrClass_python(object):
+    def __init__(self, rfft_data, dt, corr_method, corr_pair, maxlag,
+                smoothspect_N, flag, jobs):
+        
+        self.rfft_data = rfft_data
+        self.dt = dt
+        self.corr_method = corr_method
+        self.corr_pair = corr_pair
+        self.maxlag = maxlag
+        self.smoothspect_N = smoothspect_N
+        self.flag = flag
+        self.jobs = jobs
+
+        self.pair_num = int(corr_pair.shape[0])
+        self.channel_num = int(rfft_data.shape[0])
+        self.win_num = int(rfft_data.shape[1])
+        self.rfft_npts = int(rfft_data.shape[2])
+        self.npts = int(2*(self.rfft_npts-1))
+
+        t = np.arange(-self.rfft_npts + 1, self.rfft_npts) * dt
+        ind = np.where(np.abs(t) <= maxlag)[0]
+        self.maxlag_npts = int(ind.size)
+        self.maxlag_start = int(ind[0])
+        self.maxlag_end = int(ind[-1] + 1)
+
+        # initialize output_data
+        if self.rfft_data.dtype == np.dtype(np.complex64):
+            self.output_data = np.empty((self.pair_num, self.win_num, self.maxlag_npts), dtype=np.float32)
+            self.time_dtype = np.float32
+            self.freq_dtype = np.complex64
+        elif self.rfft_data.dtype == np.dtype(np.complex128):
+            self.output_data = np.empty((self.pair_num, self.win_num, self.maxlag_npts), dtype=np.float64)
+            self.time_dtype = np.float64
+            self.freq_dtype = np.complex128
+        else:
+            print("error: please input the correct data type.")
+            exit(1)
+
+
+    def corr(self, source_data, receiver_data):
+        if self.corr_method == "xcorr":
+            rfft_corr_data = xcorr(source_data, receiver_data)
+        elif self.corr_method == "deconv":
+            rfft_corr_data = deconv(source_data, receiver_data, self.smoothspect_N)
+        elif self.corr_method == "coherency":
+            rfft_corr_data = coherency(source_data, receiver_data, self.smoothspect_N)
+        else:
+            print("error: please input the correct corr method.")
+            exit(1)
+        
+        return rfft_corr_data
+
+
+    def irfft(self, rfft_corr_data):
+        corr_data = np.empty((self.win_num, self.npts), dtype=self.time_dtype)
+
+
+        for i in range(self.win_num):
+            ss = rfft_corr_data[i]
+            corr_data[i] = np.roll(scipy.fft.irfft(ss), int(self.rfft_npts - 1))
+
+        return corr_data
+
+
+    def cut_maxlag(self, corr_data):
+        maxlag_corr_data = corr_data[:, self.maxlag_start:self.maxlag_end]
+
+        return maxlag_corr_data
+
+
+    def process_chunk(self, chunk_start, chunk_end):
+        results = []
+        if self.flag and chunk_start == 0:
+            bar = tqdm(range(chunk_start, chunk_end))
+        else:
+            bar = range(chunk_start, chunk_end)
+
+        for i in bar:
+            # corr
+            source_data = self.rfft_data[self.corr_pair[i, 0], :, :]
+            receiver_data = self.rfft_data[self.corr_pair[i, 1], :, :]
+            rfft_corr_data = self.corr(source_data, receiver_data)
+
+            # irfft
+            corr_data = self.irfft(rfft_corr_data)
+
+            # cut maxlag
+            maxlag_corr_data = self.cut_maxlag(corr_data)
+
+            results.append(maxlag_corr_data)
+
+        return results
+
+
+    def run(self):
+        if self.flag:
+            start_time = time.time()
+            print(f"Start corr with {self.jobs} jobs in python...")
+        
+        # parallel processing
+        if self.jobs > 1:
+            chunk_list = split(num=self.pair_num, n_jobs=self.jobs)
+            results = Parallel(n_jobs=self.jobs, backend="loky")(delayed(self.process_chunk)(chunk_start, chunk_end) for chunk_start, chunk_end in chunk_list)
+
+            for i, chunk_results in enumerate(results):
+                chunk_start = chunk_list[i][0]
+                for j, result in enumerate(chunk_results):
+                    self.output_data[chunk_start + j] = result
+        else:
+            results = self.process_chunk(0, self.pair_num)
+            self.output_data = np.array(results, dtype=self.time_dtype)
+
+        if self.flag:
+            end_time = time.time()
+            elapsed_time = end_time - start_time
+            print(f"End corr with total time {elapsed_time}s")
+
+
+
```

## noiseflow/cc/python/rfft.py

 * *Ordering differences only*

```diff
@@ -1,156 +1,156 @@
-import time
-import scipy
-import numpy as np
-
-from tqdm import tqdm
-from joblib import Parallel, delayed
-from noiseflow.cc.python.utils import slice_window, moving_ave, whiten, split
-
-
-def time_norm_clip(data, clip_std):
-    lim = clip_std * np.std(data)
-    time_norm_data = np.clip(data, -lim, lim)
-
-    return time_norm_data
-
-
-def time_norm_smooth(data, smooth_N):
-    temp = moving_ave(np.abs(data), smooth_N)
-    time_norm_data = np.divide(data, 
-                               temp, 
-                               out=np.zeros_like(data, dtype=data.dtype), 
-                               where=temp!=0)
-
-    return time_norm_data
-
-
-class RFFTClass_python(object):
-    def __init__(self, raw_data, dt, 
-                cc_len, cc_step, 
-                time_norm, clip_std, smooth_N,
-                freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
-                flag, jobs):
-        
-        self.raw_data = raw_data
-        self.dt = dt
-        self.cc_len = cc_len
-        self.cc_step = cc_step
-        self.time_norm_method = time_norm
-        self.clip_std = clip_std
-        self.smooth_N = smooth_N
-        self.freq_norm_method = freq_norm
-        self.freqmin = freqmin
-        self.freqmax = freqmax
-        self.whiten_npad = whiten_npad
-        self.smoothspect_N = smoothspect_N
-        self.flag = flag
-        self.jobs = jobs
-
-        # convert time to points
-        self.cc_len_points = int(cc_len/dt)
-        self.cc_step_points = int(cc_step/dt)
-        self.npts = int(raw_data.shape[1])
-        self.rfft_npts = int(self.cc_len_points/2+1)
-        self.channel_num = int(raw_data.shape[0])
-  
-        # slice_window --> _win_num, _win_info
-        self.win_info = slice_window(self.npts, self.cc_len_points, self.cc_step_points)
-        self.win_num = int(self.win_info.shape[0])
-
-        # initialize output_data
-        if self.raw_data.dtype == np.dtype(np.float32):
-            self.output_data = np.empty((self.channel_num, self.win_num, self.rfft_npts), dtype=np.complex64)
-            self.time_dtype = np.float32
-            self.freq_dtype = np.complex64
-        elif self.raw_data.dtype == np.dtype(np.float64):
-            self.output_data = np.empty((self.channel_num, self.win_num, self.rfft_npts), dtype=np.complex128)
-            self.time_dtype = np.float64
-            self.freq_dtype = np.complex128
-        else:
-            print("error: please input the correct data type.")
-            exit(1)
-
-
-    def time_norm(self, data):
-        time_norm_data = None
-        if self.time_norm_method == "no":
-            time_norm_data = data
-        elif self.time_norm_method == "clip":
-            time_norm_data = time_norm_clip(data, self.clip_std)
-        elif self.time_norm_method == "onebit":
-            time_norm_data = np.sign(data)
-        elif self.time_norm_method == "smooth":
-            time_norm_data = time_norm_smooth(data, self.smooth_N)
-        else:
-            print("error: please input the correct time_norm method.")
-            exit(1)
-
-        return time_norm_data
-    
-
-    def rfft(self, time_norm_data):
-        rfft_data = np.empty((self.win_num, self.rfft_npts), dtype=self.freq_dtype)
-
-        for i in range(self.win_num):
-            segment = time_norm_data[self.win_info[i, 0]:self.win_info[i, 1]]
-            segment_rfft = scipy.fft.rfft(segment)
-            rfft_data[i] = segment_rfft
-
-        return rfft_data
-
-
-    def freq_norm(self, rfft_data):
-        freq_norm_data = None
-        if self.freq_norm_method == "no":
-            freq_norm_data = rfft_data
-        else:
-            freq_norm_data = whiten(rfft_data, self.dt, self.freq_norm_method, self.freqmin, self.freqmax, self.smoothspect_N, self.whiten_npad)
-
-        return freq_norm_data
-
-
-    def process_chunk(self, chunk_start, chunk_end):
-        results = []
-        if self.flag and chunk_start == 0:
-            bar = tqdm(range(chunk_start, chunk_end))
-        else:
-            bar = range(chunk_start, chunk_end)
-
-        for i in bar:
-            # time_norm
-            time_norm_data = self.time_norm(self.raw_data[i, :])
-
-            # rfft
-            rfft_data = self.rfft(time_norm_data)
-
-            # freq_norm
-            rfft_norm_data = self.freq_norm(rfft_data)
-
-            results.append(rfft_norm_data)
-
-        return results
-
-
-    def run(self):
-        if self.flag:
-            start_time = time.time()
-            print(f"Start rfft with {self.jobs} jobs in python...")
-        
-        # parallel processing
-        if self.jobs > 1:
-            chunk_list = split(num=self.channel_num, n_jobs=self.jobs)
-            results = Parallel(n_jobs=self.jobs, backend="loky")(delayed(self.process_chunk)(chunk_start, chunk_end) for chunk_start, chunk_end in chunk_list)
-
-            for i, chunk_results in enumerate(results):
-                chunk_start = chunk_list[i][0]
-                for j, result in enumerate(chunk_results):
-                    self.output_data[chunk_start + j] = result
-        else:
-            results = self.process_chunk(0, self.channel_num)
-            self.output_data = np.array(results, dtype=self.freq_dtype)
-
-        if self.flag:
-            end_time = time.time()
-            elapsed_time = end_time - start_time
-            print(f"End rfft with total time {elapsed_time}s")
-
+import time
+import scipy
+import numpy as np
+
+from tqdm import tqdm
+from joblib import Parallel, delayed
+from noiseflow.cc.python.utils import slice_window, moving_ave, whiten, split
+
+
+def time_norm_clip(data, clip_std):
+    lim = clip_std * np.std(data)
+    time_norm_data = np.clip(data, -lim, lim)
+
+    return time_norm_data
+
+
+def time_norm_smooth(data, smooth_N):
+    temp = moving_ave(np.abs(data), smooth_N)
+    time_norm_data = np.divide(data, 
+                               temp, 
+                               out=np.zeros_like(data, dtype=data.dtype), 
+                               where=temp!=0)
+
+    return time_norm_data
+
+
+class RFFTClass_python(object):
+    def __init__(self, raw_data, dt, 
+                cc_len, cc_step, 
+                time_norm, clip_std, smooth_N,
+                freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
+                flag, jobs):
+        
+        self.raw_data = raw_data
+        self.dt = dt
+        self.cc_len = cc_len
+        self.cc_step = cc_step
+        self.time_norm_method = time_norm
+        self.clip_std = clip_std
+        self.smooth_N = smooth_N
+        self.freq_norm_method = freq_norm
+        self.freqmin = freqmin
+        self.freqmax = freqmax
+        self.whiten_npad = whiten_npad
+        self.smoothspect_N = smoothspect_N
+        self.flag = flag
+        self.jobs = jobs
+
+        # convert time to points
+        self.cc_len_points = int(cc_len/dt)
+        self.cc_step_points = int(cc_step/dt)
+        self.npts = int(raw_data.shape[1])
+        self.rfft_npts = int(self.cc_len_points/2+1)
+        self.channel_num = int(raw_data.shape[0])
+  
+        # slice_window --> _win_num, _win_info
+        self.win_info = slice_window(self.npts, self.cc_len_points, self.cc_step_points)
+        self.win_num = int(self.win_info.shape[0])
+
+        # initialize output_data
+        if self.raw_data.dtype == np.dtype(np.float32):
+            self.output_data = np.empty((self.channel_num, self.win_num, self.rfft_npts), dtype=np.complex64)
+            self.time_dtype = np.float32
+            self.freq_dtype = np.complex64
+        elif self.raw_data.dtype == np.dtype(np.float64):
+            self.output_data = np.empty((self.channel_num, self.win_num, self.rfft_npts), dtype=np.complex128)
+            self.time_dtype = np.float64
+            self.freq_dtype = np.complex128
+        else:
+            print("error: please input the correct data type.")
+            exit(1)
+
+
+    def time_norm(self, data):
+        time_norm_data = None
+        if self.time_norm_method == "no":
+            time_norm_data = data
+        elif self.time_norm_method == "clip":
+            time_norm_data = time_norm_clip(data, self.clip_std)
+        elif self.time_norm_method == "onebit":
+            time_norm_data = np.sign(data)
+        elif self.time_norm_method == "smooth":
+            time_norm_data = time_norm_smooth(data, self.smooth_N)
+        else:
+            print("error: please input the correct time_norm method.")
+            exit(1)
+
+        return time_norm_data
+    
+
+    def rfft(self, time_norm_data):
+        rfft_data = np.empty((self.win_num, self.rfft_npts), dtype=self.freq_dtype)
+
+        for i in range(self.win_num):
+            segment = time_norm_data[self.win_info[i, 0]:self.win_info[i, 1]]
+            segment_rfft = scipy.fft.rfft(segment)
+            rfft_data[i] = segment_rfft
+
+        return rfft_data
+
+
+    def freq_norm(self, rfft_data):
+        freq_norm_data = None
+        if self.freq_norm_method == "no":
+            freq_norm_data = rfft_data
+        else:
+            freq_norm_data = whiten(rfft_data, self.dt, self.freq_norm_method, self.freqmin, self.freqmax, self.smoothspect_N, self.whiten_npad)
+
+        return freq_norm_data
+
+
+    def process_chunk(self, chunk_start, chunk_end):
+        results = []
+        if self.flag and chunk_start == 0:
+            bar = tqdm(range(chunk_start, chunk_end))
+        else:
+            bar = range(chunk_start, chunk_end)
+
+        for i in bar:
+            # time_norm
+            time_norm_data = self.time_norm(self.raw_data[i, :])
+
+            # rfft
+            rfft_data = self.rfft(time_norm_data)
+
+            # freq_norm
+            rfft_norm_data = self.freq_norm(rfft_data)
+
+            results.append(rfft_norm_data)
+
+        return results
+
+
+    def run(self):
+        if self.flag:
+            start_time = time.time()
+            print(f"Start rfft with {self.jobs} jobs in python...")
+        
+        # parallel processing
+        if self.jobs > 1:
+            chunk_list = split(num=self.channel_num, n_jobs=self.jobs)
+            results = Parallel(n_jobs=self.jobs, backend="loky")(delayed(self.process_chunk)(chunk_start, chunk_end) for chunk_start, chunk_end in chunk_list)
+
+            for i, chunk_results in enumerate(results):
+                chunk_start = chunk_list[i][0]
+                for j, result in enumerate(chunk_results):
+                    self.output_data[chunk_start + j] = result
+        else:
+            results = self.process_chunk(0, self.channel_num)
+            self.output_data = np.array(results, dtype=self.freq_dtype)
+
+        if self.flag:
+            end_time = time.time()
+            elapsed_time = end_time - start_time
+            print(f"End rfft with total time {elapsed_time}s")
+
```

## noiseflow/cc/python/stack.py

 * *Ordering differences only*

```diff
@@ -1,791 +1,791 @@
-# The stack functions are from https://github.com/xtyangpsp/StackMaster
-
-import time
-import numpy as np
-import matplotlib.pyplot as plt
-
-from tqdm import tqdm 
-from joblib import Parallel, delayed
-from itertools import compress
-from scipy.signal import hilbert
-from scipy.fftpack import fft,ifft,next_fast_len
-from noiseflow.cc.python.utils import slice_window, split
-
-try:
-    from stockwell import st
-    from tslearn.utils import to_time_series_dataset
-    from tslearn.clustering import TimeSeriesKMeans
-except:
-    pass
-
-
-
-def rms(d):
-    return np.sqrt(np.mean(d**2))
-
-
-def power2pad(data):
-	"""Zero pad data such that its length is a power of 2"""
-	N=int(2**np.ceil(np.log2(len(data))))
-	pad_end=np.zeros(int(N-len(data)))
-
-	return np.concatenate((data,pad_end))
-
-
-def stack(d,method,par=None):
-    """
-    this is a wrapper for calling individual stacking functions.
-    d: data. 2-d array
-    method: stacking method, one of "linear","pws","robust","acf","nroot","selective",
-            "cluster"
-    par: dictionary containing all parameters for each stacking method. defaults will
-        be used if not specified.
-
-    RETURNS:
-    ds: stacked data, which may be a list depending on the method.
-    """
-    method_list=["linear","pws","robust","acf","nroot","selective",
-            "cluster","tfpws"]
-    if method not in method_list:
-        raise ValueError("$s not recoganized. use one of $s"%(method,str(method_list)))
-    
-    par0={"axis":0,"p":2,"g":1,"cc_min":0.0,"epsilon":1E-5,"maxstep":10,
-            "win":None,"stat":False,"h":0.75,'plot':False,'normalize':True,'ref':None}  #stat: if true, will return statistics.
-    
-    if par is None:
-        par=par0
-    else:
-        par={**par0,**par} #use par values if specified. otherwise, use defaults.
-
-    if method.lower() == 'linear':
-        ds = np.mean(d,axis=par["axis"])
-    elif method.lower() == 'pws':
-        ds = pws(d,p=par['p'])
-    elif method.lower() == 'tfpws':
-        ds = tfpws(d,p=par['p'])
-    # elif method.lower() == 'tfpws-dost':
-    #     ds = tfpws_dost(d,p=par['p'])
-    elif method.lower() == 'robust':
-        ds = robust(d,epsilon=par['epsilon'],maxstep=par['maxstep'],win=par["win"],
-                stat=par['stat'],ref=par['ref'])
-    elif method.lower() == 'acf':
-        ds = adaptive_filter(d,g=par['g'])
-    elif method.lower() == 'nroot':
-        ds = nroot(d,p=par['p'])
-    elif method.lower() == 'selective':
-        ds = selective(d,cc_min=par['cc_min'],epsilon=par['epsilon'],maxstep=par['maxstep'],
-                stat=par['stat'],ref=par['ref'],win=par["win"])
-    elif method.lower() == 'cluster':
-        ds = clusterstack(d,h=par['h'],axis=par['axis'],win=par["win"],
-        normalize=par['normalize'],plot=par['plot'])
-    #
-    return ds
-
-def seisstack(d,method,par=None):
-    """
-    This is the same as stack(), to be compatible with old usage.
-    """
-    return stack(d,method=method,par=par)
-
-def robust(d,epsilon=1E-5,maxstep=10,win=None,stat=False,ref=None):
-    """
-    this is a robust stacking algorithm described in Pavlis and Vernon 2010. Generalized
-    by Xiaotao Yang.
-
-    PARAMETERS:
-    ----------------------
-    d: numpy.ndarray contains the 2D cross correlation matrix
-    epsilon: residual threhold to quit the iteration (a small number). Default 1E-5
-    maxstep: maximum iterations. default 10.
-    win: [start_index,end_index] used to compute the weight, instead of the entire trace. Default None.
-            When None, use the entire trace.
-    ref: reference stack, with the same length as individual data. Default: None. Use median().
-    RETURNS:
-    ----------------------
-    newstack: numpy vector contains the stacked cross correlation
-
-    Written by Marine Denolle
-    Modified by Xiaotao Yang
-    """
-    if d.ndim == 1:
-        print('2D matrix is needed')
-        return d
-    N,M = d.shape
-    res  = 9E9  # residuals
-    w = np.ones(d.shape[0])
-    small_number=1E-15
-    nstep=0
-    if N >=2:
-        if ref is None:
-            newstack = np.median(d,axis=0)
-        else:
-            newstack = ref
-        if win is None:
-            win=[0,-1]
-        while res > epsilon and nstep <=maxstep:
-            stack = newstack
-            for i in range(d.shape[0]):
-                dtemp=d[i,win[0]:win[1]]
-                crap = np.multiply(stack[win[0]:win[1]],dtemp.T)
-                crap_dot = np.sum(crap)
-                di_norm = np.linalg.norm(dtemp)
-                ri_norm = np.linalg.norm(dtemp -  crap_dot*stack[win[0]:win[1]])
-                if ri_norm < small_number:
-                    w[i]=0
-                else:
-                    w[i]  = np.abs(crap_dot) /di_norm/ri_norm
-            w =w /np.sum(w)
-            newstack =np.sum( (w*d.T).T,axis=0)#/len(cc_array[:,1])
-            res = np.linalg.norm(newstack-stack,ord=1)/np.linalg.norm(newstack)/len(d[:,1])
-            nstep +=1
-    else:
-        newstack=d[0].copy()
-    if stat:
-        return newstack, w, nstep
-    else:
-        return newstack
-
-def adaptive_filter(d,g=1):
-    '''
-    the adaptive covariance filter to enhance coherent signals. Fellows the method of
-    Nakata et al., 2015 (Appendix B)
-
-    the filtered signal [x1] is given by x1 = ifft(P*x1(w)) where x1 is the ffted spectra
-    and P is the filter. P is constructed by using the temporal covariance matrix.
-
-    PARAMETERS:
-    ----------------------
-    d: numpy.ndarray contains the 2D traces of daily/hourly cross-correlation functions
-    g: a positive number to adjust the filter harshness [default is 1]
-    RETURNS:
-    ----------------------
-    newstack: numpy vector contains the stacked cross correlation function
-    '''
-    if d.ndim == 1:
-        print('2D matrix is needed')
-        return d
-    N,M = d.shape
-    if N>=2:
-        Nfft = next_fast_len(M)
-
-        # fft the 2D array
-        spec = fft(d,axis=1,n=Nfft)[:,:M]
-
-        # make cross-spectrm matrix
-        cspec = np.zeros(shape=(N*N,M),dtype=np.complex64)
-        for ii in range(N):
-            for jj in range(N):
-                kk = ii*N+jj
-                cspec[kk] = spec[ii]*np.conjugate(spec[jj])
-
-        S1 = np.zeros(M,dtype=np.complex64)
-        S2 = np.zeros(M,dtype=np.complex64)
-        # construct the filter P
-        for ii in range(N):
-            mm = ii*N+ii
-            S2 += cspec[mm]
-            for jj in range(N):
-                kk = ii*N+jj
-                S1 += cspec[kk]
-
-        p = np.power((S1-S2)/(S2*(N-1)),g)
-
-        # make ifft
-        narr = np.real(ifft(np.multiply(p,spec),Nfft,axis=1)[:,:M])
-        newstack=np.mean(narr,axis=0)
-    else:
-        newstack=d[0].copy()
-    #
-    return newstack
-
-def pws(d,p=2):
-    '''
-    Performs phase-weighted stack on array of time series. Modified on the noise function by Tim Climents.
-    Follows methods of Schimmel and Paulssen, 1997.
-    If s(t) is time series data (seismogram, or cross-correlation),
-    S(t) = s(t) + i*H(s(t)), where H(s(t)) is Hilbert transform of s(t)
-    S(t) = s(t) + i*H(s(t)) = A(t)*exp(i*phi(t)), where
-    A(t) is envelope of s(t) and phi(t) is phase of s(t)
-    Phase-weighted stack, g(t), is then:
-    g(t) = 1/N sum j = 1:N s_j(t) * | 1/N sum k = 1:N exp[i * phi_k(t)]|^v
-    where N is number of traces used, v is sharpness of phase-weighted stack
-
-    PARAMETERS:
-    ---------------------
-    d: N length array of time series data (numpy.ndarray)
-    p: exponent for phase stack (int). default is 2
-
-    RETURNS:
-    ---------------------
-    newstack: Phase weighted stack of time series data (numpy.ndarray)
-    '''
-
-    if d.ndim == 1:
-        print('2D matrix is needed')
-        return d
-    N,M = d.shape
-    if N >=2:
-        analytic = hilbert(d,axis=1, N=next_fast_len(M))[:,:M]
-        phase = np.angle(analytic)
-        phase_stack = np.mean(np.exp(1j*phase),axis=0)
-        phase_stack = np.abs(phase_stack)**(p)
-
-        weighted = np.multiply(d,phase_stack)
-
-        newstack=np.mean(weighted,axis=0)
-    else:
-        newstack=d[0].copy()
-    return newstack
-
-def nroot(d,p=2):
-    '''
-    this is nth-root stacking algorithm translated based on the matlab function
-    from https://github.com/xtyangpsp/SeisStack (by Xiaotao Yang; follows the
-    reference of Millet, F et al., 2019 JGR)
-
-    Parameters:
-    ------------
-    d: numpy.ndarray contains the 2D cross correlation matrix
-    p: np.int, nth root for the stacking. Default is 2.
-
-    Returns:
-    ------------
-    newstack: np.ndarray, final stacked waveforms
-
-    Written by Chengxin Jiang @ANU (May2020)
-    '''
-    if d.ndim == 1:
-        print('2D matrix is needed for nroot_stack')
-        return d
-    N,M = d.shape
-    if N >=2:
-        dout = np.zeros(M,dtype=np.float32)
-
-        # construct y
-        for ii in range(N):
-            dat = d[ii,:]
-            dout += np.sign(dat)*np.abs(dat)**(1/p)
-        dout /= N
-
-        # the final stacked waveform
-        newstack = dout*np.abs(dout)**(p-1)
-    else:
-        newstack=d[0].copy()
-
-    return newstack
-
-
-def selective(d,cc_min,epsilon=1E-5,maxstep=10,win=None,stat=False,ref=None):
-    '''
-    this is a selective stacking algorithm developed by Jared Bryan/Kurama Okubo.
-
-    PARAMETERS:
-    ----------------------
-    d: numpy.ndarray contains the 2D cross correlation matrix
-    epsilon: residual threhold to quit the iteration
-    cc_min: numpy.float, threshold of correlation coefficient to be selected
-    epsilon: residual threhold to quit the iteration (a small number). Default 1E-5
-    maxstep: maximum iterations. default 10.
-    win: [start_index,end_index] used to compute the weight, instead of the entire trace. Default None.
-            When None, use the entire trace.
-    ref: reference stack, with the same length as individual data. Default: None. Use mean().
-    RETURNS:
-    ----------------------
-    newstack: numpy vector contains the stacked cross correlation
-    nstep: np.int, total number of iterations for the stacking
-
-    Originally ritten by Marine Denolle
-    Modified by Chengxin Jiang @Harvard (Oct2020)
-    '''
-    if d.ndim == 1:
-        print('2D matrix is needed for selective stacking')
-        return d
-    N,M = d.shape
-    if N>=2:
-        res  = 9E9  # residuals
-        cof  = np.zeros(N,dtype=np.float32)
-        if ref is None:
-            newstack = np.mean(d,axis=0)
-        else:
-            newstack = ref
-
-        nstep = 0
-        if win is None:
-            win=[0,-1]
-        # start iteration
-        while res>epsilon and nstep<=maxstep:
-            for ii in range(N):
-                cof[ii] = np.corrcoef(newstack[win[0]:win[1]], d[ii,win[0]:win[1]])[0, 1]
-
-            # find good waveforms
-            indx = np.where(cof>=cc_min)[0]
-            nstep +=1
-            if not len(indx):
-                newstack=np.ndarray((d.shape[1],))
-                newstack.fill(np.nan)
-                print('cannot find good waveforms inside selective stacking')
-                break
-            else:
-                oldstack = newstack
-                newstack = np.mean(d[indx],axis=0)
-                res = np.linalg.norm(newstack-oldstack)/(np.linalg.norm(newstack)*M)
-    else:
-        newstack=d[0].copy()
-    if stat:
-        return newstack, nstep
-    else:
-        return newstack
-#
-def clusterstack(d,h=0.75,win=None,axis=0,normalize=True,plot=False):
-    '''
-    Performs stack after clustering. The data will be clustered into two groups.
-    If the two centers of the clusters are similar (defined by corrcoef >= "t"), the original
-    traces associated with both clusters will be used to produce the final linear stack, weighted by
-    normalized SNR (phase clarity) of each cluster. Otherwise, the one with larger phase clarity
-    (defined as max(abs(amplitudes))/rms(abs(amplitudes))) will be used to get the final stack.
-
-    PARAMETERS:
-    ---------------------
-    d: N length array of time series data (numpy.ndarray)
-    h: corrcoeff threshold to decide which group/cluster to use. Default 0.75.
-    win: [start_index,end_index] used to compute the weight, instead of the entire trace. Default None.
-            When None, use the entire trace.
-    axis: which axis to stack. default 0.
-    normalize: Normalize the traces before clustering. This will only influence the cluster.
-            The final stack will be produced using the original data.
-    plot: plot clustering results. default False.
-
-    RETURNS:
-    ---------------------
-    newstack: final stack.
-    '''
-    ncluster=2 #DO NOT change this value.
-    min_trace=2 #minimum of two traces.
-    metric="euclidean" #matric to compute the distance in kmeans clustering.
-    if d.ndim == 1:
-        print('2D matrix is needed')
-        return d
-    N,M = d.shape
-    if N >= min_trace:
-        dataN=d.copy()
-        if normalize:
-            for i in range(N):
-                dataN[i]=d[i]/np.max(np.abs(d[i]),axis=0)
-
-        ts = to_time_series_dataset(dataN)
-
-        km = TimeSeriesKMeans(n_clusters=ncluster, n_jobs=1,metric=metric, verbose=False,
-                              max_iter_barycenter=100, random_state=0)
-        y_pred = km.fit_predict(ts)
-        snr_all=[]
-        centers_all=[]
-        cidx=[]
-        if win is None:
-            win=[0,-1]
-        for yi in range(ncluster):
-            cidx.append(np.where((y_pred==yi))[0])
-            center=km.cluster_centers_[yi].ravel()#np.squeeze(np.mean(ts[y_pred == yi].T,axis=2))
-            centers_all.append(center)
-            snr=np.max(np.abs(center[win[0]:win[1]]))/rms(np.abs(center))
-            snr_all.append(snr)
-
-        #
-        if plot:
-            plt.figure(figsize=(12,4))
-            for yi in range(ncluster):
-                plt.subplot(1,ncluster,yi+1)
-                plt.plot(np.squeeze(ts[cidx[yi]].T),'k-',alpha=0.3)
-                plt.plot(centers_all[yi],'r-')
-                plt.title('Cluster %d: %d'%(yi+1,len(cidx[yi])))
-            plt.show()
-        cc=np.corrcoef(centers_all[0],centers_all[1])[0,1]
-        if cc>= h: #use all data
-            snr_normalize=snr_all/np.sum(snr_all)
-            newstack=np.zeros((M))
-            for yi in range(ncluster):
-                newstack += snr_normalize[yi]*np.mean(d[cidx[yi]],axis=0)
-        else:
-            goodidx=np.argmax(snr_all)
-            newstack=np.mean(d[cidx[goodidx]],axis=0)
-        del dataN,ts,y_pred
-    else:
-        newstack=d[0].copy()
-    #
-    return newstack
-
-def tfpws(d,p=2,axis=0):
-    '''
-    Performs time-frequency domain phase-weighted stack on array of time series.
-
-    $C_{ps} = |(\sum{S*e^{i2\pi}/|S|})/M|^p$, where $C_{ps}$ is the phase weight. Then
-    $S_{pws} = C_{ps}*S_{ls}$, where $S_{ls}$ is the S transform of the linea stack
-    of the whole data.
-
-    Reference:
-    Schimmel, M., Stutzmann, E., & Gallart, J. (2011). Using instantaneous phase
-    coherence for signal extraction from ambient noise data at a local to a
-    global scale. Geophysical Journal International, 184(1), 494–506.
-    https://doi.org/10.1111/j.1365-246X.2010.04861.x
-
-    PARAMETERS:
-    ---------------------
-    d: N length array of time series data (numpy.ndarray)
-    p: exponent for phase stack (int). default is 2
-    axis: axis to stack, default is 0.
-
-    RETURNS:
-    ---------------------
-    newstack: Phase weighted stack of time series data (numpy.ndarray)
-    '''
-    if d.ndim == 1:
-        print('2D matrix is needed')
-        return d
-    N,M = d.shape
-    if N >=2:
-        lstack=np.mean(d,axis=axis)
-        #get the ST of the linear stack first
-        stock_ls=st.st(power2pad(lstack))
-
-        #run a ST to get the dimension of ST result
-        stock_temp=st.st(power2pad(d[0]))
-        phase_stack=np.zeros((stock_temp.shape[0],stock_temp.shape[1]),dtype='complex128')
-        for i in range(N):
-            if i>0: #zero index has been computed.
-                stock_temp=st.st(power2pad(d[i]))
-            phase_stack += np.multiply(stock_temp,np.angle(stock_temp))/np.abs(stock_temp)
-        #
-        phase_stack = np.abs(phase_stack/N)**p
-
-        pwstock=np.multiply(phase_stack,stock_ls)
-        recdostIn=np.real(st.ist(pwstock))
-        newstack=recdostIn[:M] # trim padding
-    else:
-        newstack=d[0].copy()
-    #
-    return newstack
-
-# def tfpws_dost(d,p=2,axis=0):
-#     '''
-#     Performs time-frequency domain phase-weighted stack on array of time series using DOST (Discrete
-#     orthogonal stockwell transform).
-#     $C_{ps} = |(\sum{S*e^{i2\pi}/|S|})/M|^p$, where $C_{ps}$ is the phase weight. Then
-# 	$S_{pws} = C_{ps}*S_{ls}$, where $S_{ls}$ is the Discrete Orthonormal S transform
-# 	of the linear stack of the whole data.
-
-#     DOST stacking was implemented by Jared Bryan.
-
-#     Reference for tf-PWS:
-#     Schimmel, M., Stutzmann, E., & Gallart, J. (2011). Using instantaneous phase
-#     coherence for signal extraction from ambient noise data at a local to a
-#     global scale. Geophysical Journal International, 184(1), 494–506.
-#     https://doi.org/10.1111/j.1365-246X.2010.04861.x
-
-#     Reference for DOST:
-#     U. Battisti, L. Riba, "Window-dependent bases for efficient representations of the
-# 	Stockwell transform", Applied and Computational Harmonic Analysis, 23 February 2015,
-# 	http://dx.doi.org/10.1016/j.acha.2015.02.002.
-
-#     PARAMETERS:
-#     ---------------------
-#     d: N length array of time series data (numpy.ndarray)
-#     p: exponent for phase stack (int). default is 2
-#     axis: axis to stack, default is 0.
-
-#     RETURNS:
-#     ---------------------
-#     newstack: Phase weighted stack of time series data (numpy.ndarray)
-#     '''
-#     if d.ndim == 1:
-#         print('2D matrix is needed')
-#         return d
-#     N,M = d.shape
-#     if N >=2:
-#         lstack=np.mean(d,axis=axis)
-#         #get the dost of the linear stack first
-#         stock_ls_dost=DOST(lstack) # initialize dost object
-#         stock_ls=stock_ls_dost.dost(stock_ls_dost.data) # calculate the dost
-
-#     	# calculate dost for first trace to know its shape
-#         stock_dost=DOST(d[0])
-#         stock_temp=stock_dost.dost(stock_dost.data)
-#     	# initialize stack
-#         phase_stack=np.zeros(len(stock_temp),dtype='complex128')
-#     	# calculate the dost for each trace to be stacked
-#         for i in range(d.shape[0]):
-#         	if i>0: # zero index has been computed
-#         	    stock_dost=DOST(d[i])
-#         	    stock_temp=stock_dost.dost(stock_dost.data)
-                    
-#             phase_stack+=np.multiply(stock_temp,np.angle(stock_temp))/np.abs(stock_temp)
-
-#         phase_stack = np.abs(phase_stack/N)**p
-
-#         pwstock=np.multiply(phase_stack,stock_ls)
-#         recdostIn = np.real(stock_dost.idost(pwstock))
-#         newstack = recdostIn[:M] # trim padding
-#     else:
-#         newstack=d[0].copy()
-#     #
-#     return newstack
-
-class DOST:
-    def __init__(self, data):
-        # make sure data length is a power of 2
-        if np.ceil(np.log2(len(data)))==np.floor(np.log2(len(data))):
-            # length of data already a power of 2
-            self.data=data
-        else:
-            # pad data to nearest power of 2
-            self.data=self.pad(data)
-
-    def pad(self,data):
-        """Zero pad data such that its length is a power of 2
-
-        PARAMETERS:
-        ---------------------
-        data: array of time series data (numpy.ndarray)
-
-        RETURNS:
-        ---------------------
-        data: zero-padded array of time series data (numpy.ndarray)
-        """
-        N=int(2**np.ceil(np.log2(len(data))))
-        pad_end=np.zeros(int(N-len(data)))
-        data=np.concatenate((data,pad_end))
-
-        return data
-
-    def fourier(self, d):
-        """Normalized and centered fft
-
-        PARAMETERS:
-        ---------------------
-        d: array of time series data (numpy.ndarray)
-
-        RETURNS:
-        ---------------------
-        fftIn: array of frequency-domain data (numpy.ndarray)
-        """
-        fftIn=(1/np.sqrt(len(d))) * np.fft.fftshift(np.fft.fft(np.fft.ifftshift(d)))
-        return fftIn
-
-    def ifourier(self,d):
-        """Normalized and centered ifft
-
-        PARAMETERS:
-        ---------------------
-        d: array of frequency-domain data (numpy.ndarray)
-
-        RETURNS:
-        ---------------------
-        ifftIn: array of time series data (numpy.ndarray)
-        """
-        ifftIn=np.sqrt(len(d)) * np.fft.fftshift(np.fft.ifft(np.fft.ifftshift(d)))
-        return ifftIn
-
-    def dostbw(self,D):
-        """Calculate size of the DOST bandwidths
-
-        PARAMETERS:
-        ---------------------
-        D: length of time-series data (int)
-
-        RETURNS:
-        ---------------------
-        bw: list of DOST bandwidths
-        """
-        bw=[0]
-        bw.extend(np.arange(np.log2(D)-2, -1e-9, -1))
-        bw.extend([0])
-        bw.extend(np.arange(0, np.log2(D)-2+1e-9))
-        bw=2**np.array(bw)
-        return bw
-
-    def dost(self,d):
-        """Discrete Orthonormal Stockwell Transform
-
-        PARAMETERS:
-        ---------------------
-        d: array of time-series data (numpy.ndarray)
-
-        RETURNS:
-        ---------------------
-        d_dost: array of DOST coefficients (numpy.ndarray)
-        """
-        d_dost=self.fourier(d)
-        D=len(d)
-        bw=self.dostbw(D)
-        k=0
-        # heuristically, this is a short-time fourier transform with a frequency-dependent bandwidth
-        for i in bw:
-            i=int(i)
-            if i==1:
-                k=k+i
-            else:
-                d_dost[k:k+i] = self.ifourier(d_dost[k:k+i])
-                k=k+i
-        return d_dost
-
-    def idost(self,d):
-        """Inverse Discrete Orthonormal Stockwell Transform
-
-        PARAMETERS:
-        ---------------------
-        d: array of DOST coefficients (numpy.ndarray)
-
-        RETURNS:
-        ---------------------
-        d_idost: array of time-series data (numpy.ndarray)
-        """
-        d_idost=d
-        D=len(d)
-        bw=self.dostbw(D)
-        k=0
-        for i in bw:
-            i=int(i)
-            if i==1:
-                k=k+i
-            else:
-                d_idost[k:k+i] = self.fourier(d_idost[k:k+i])
-                k=k+i
-        d_idost = self.ifourier(d_idost)
-        return d_idost
-
-
-class StackClass_python(object):
-    def __init__(self, corr_data, stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, jobs):
-        self.corr_data = corr_data
-        self.stack_method = stack_method
-        self.par = par
-        self.stack_all = stack_all
-        self.stack_len = stack_len
-        self.stack_step = stack_step
-        self.pick_m = pick
-        self.median_high = median_high
-        self.median_low = median_low
-        self.flag = flag
-        self.jobs = jobs
-
-        self.pair_num = int(corr_data.shape[0])
-        self.corr_win_num = int(corr_data.shape[1])
-        self.npts = int(corr_data.shape[2])
-
-        # slice_window --> _stack_win_num, _win_info
-        if stack_all:
-            self.win_info = np.array([[0, self.corr_win_num]])
-            self.stack_win_num = 1
-        else:
-            self.win_info = slice_window(self.corr_win_num, stack_len, stack_step)
-            self.stack_win_num = int(self.win_info.shape[0])
-
-        # initialize output_data
-        self.ngood_all = np.empty((self.pair_num, self.stack_win_num))
-        if self.corr_data.dtype == np.dtype(np.float32):
-            self.output_data = np.empty((self.pair_num, self.stack_win_num, self.npts), dtype=np.float32)
-            self.time_dtype = np.float32
-            self.freq_dtype = np.complex64
-        elif self.corr_data.dtype == np.dtype(np.float64):
-            self.output_data = np.empty((self.pair_num, self.stack_win_num, self.npts), dtype=np.float64)
-            self.time_dtype = np.float64
-            self.freq_dtype = np.complex128
-        else:
-            print("error: please input the correct data type.")
-            exit(1)
-
-
-    def pick(self, pair_id):
-        nindex = None
-        if self.pick_m:
-            # SOME WARNING HERE!!!
-            ampmax = np.amax(self.corr_data[pair_id, :, :], axis=1)
-            median_ampmax = np.median(ampmax)
-            index = np.where((ampmax > self.median_low * median_ampmax) & (ampmax < self.median_high * median_ampmax))[0]
-        
-            nindex = np.array(index, dtype=int)
-        else:
-            nindex = np.arange(0, self.corr_win_num, dtype=int)
-
-        return nindex
-
-
-    def check_ngood(self, nindex):
-        ngood = np.empty(self.stack_win_num)
-        if self.pick_m:
-            for i in range(0, self.stack_win_num):
-                ngood[i] = np.sum((nindex >= self.win_info[i, 0]) & (nindex < self.win_info[i, 1]))
-        else:
-            ngood = self.stack_len * np.ones(self.stack_win_num)
-
-        return ngood
-
-
-    def stack(self, pair_id, nindex):
-        stack_data = np.empty((self.stack_win_num, self.npts), dtype=self.time_dtype)
-
-        for i in range(0, self.stack_win_num):
-            each_index = np.arange(self.win_info[i, 0], self.win_info[i, 1])
-            pick_index = list(compress(each_index, np.isin(each_index, nindex)))
-
-            if len(pick_index) == 0:
-                stack_data[i, :] = np.zeros(self.npts)
-            else:
-                pick_corr_data = self.corr_data[pair_id, pick_index, :]
-                stack_data[i, :] = stack(pick_corr_data, self.stack_method, self.par)    
-
-        return stack_data
-
-
-    def process_chunk(self, chunk_start, chunk_end):
-        ngood_results = []
-        stack_data_results = []
-
-        if self.flag and chunk_start == 0:
-            bar = tqdm(range(chunk_start, chunk_end))
-        else:
-            bar = range(chunk_start, chunk_end)
-
-        for i in bar:
-            # pick --> _nindex
-            nindex = self.pick(i)
-
-            # ngood
-            ngood = self.check_ngood(nindex)
-
-            # corr
-            stack_data = self.stack(i, nindex) # "linear", "pws", "robust"
-
-            ngood_results.append(ngood)
-            stack_data_results.append(stack_data)
-
-        return ngood_results, stack_data_results
-
-
-    def run(self):
-        if self.flag:
-            start_time = time.time()
-            print(f"Start stack with {self.jobs} jobs in python...")
-        
-        # parallel processing
-        if self.jobs > 1:
-            chunk_list = split(num=self.pair_num, n_jobs=self.jobs)
-            results = Parallel(n_jobs=self.jobs, backend="loky")(delayed(self.process_chunk)(chunk_start, chunk_end) for chunk_start, chunk_end in chunk_list)
-
-            ngood_all_results = []
-            output_data_results = []
-
-            for chunk_results in results:
-                ngood_all_chunk, output_data_chunk = chunk_results
-                ngood_all_results.extend(ngood_all_chunk)
-                output_data_results.extend(output_data_chunk)
-
-            self.ngood_all = np.array(ngood_all_results)
-            self.output_data = np.array(output_data_results, dtype=self.time_dtype)
-        else:
-            ngood_all_results, output_data_results = self.process_chunk(0, self.pair_num)
-            self.ngood_all, self.output_data = np.array(ngood_all_results), np.array(output_data_results, dtype=self.time_dtype)
-
-        if self.flag:
-            end_time = time.time()
-            elapsed_time = end_time - start_time
-            print(f"End stack with total time {elapsed_time}s")
-
+# The stack functions are from https://github.com/xtyangpsp/StackMaster
+
+import time
+import numpy as np
+import matplotlib.pyplot as plt
+
+from tqdm import tqdm 
+from joblib import Parallel, delayed
+from itertools import compress
+from scipy.signal import hilbert
+from scipy.fftpack import fft,ifft,next_fast_len
+from noiseflow.cc.python.utils import slice_window, split
+
+try:
+    from stockwell import st
+    from tslearn.utils import to_time_series_dataset
+    from tslearn.clustering import TimeSeriesKMeans
+except:
+    pass
+
+
+
+def rms(d):
+    return np.sqrt(np.mean(d**2))
+
+
+def power2pad(data):
+	"""Zero pad data such that its length is a power of 2"""
+	N=int(2**np.ceil(np.log2(len(data))))
+	pad_end=np.zeros(int(N-len(data)))
+
+	return np.concatenate((data,pad_end))
+
+
+def stack(d,method,par=None):
+    """
+    this is a wrapper for calling individual stacking functions.
+    d: data. 2-d array
+    method: stacking method, one of "linear","pws","robust","acf","nroot","selective",
+            "cluster"
+    par: dictionary containing all parameters for each stacking method. defaults will
+        be used if not specified.
+
+    RETURNS:
+    ds: stacked data, which may be a list depending on the method.
+    """
+    method_list=["linear","pws","robust","acf","nroot","selective",
+            "cluster","tfpws"]
+    if method not in method_list:
+        raise ValueError("$s not recoganized. use one of $s"%(method,str(method_list)))
+    
+    par0={"axis":0,"p":2,"g":1,"cc_min":0.0,"epsilon":1E-5,"maxstep":10,
+            "win":None,"stat":False,"h":0.75,'plot':False,'normalize':True,'ref':None}  #stat: if true, will return statistics.
+    
+    if par is None:
+        par=par0
+    else:
+        par={**par0,**par} #use par values if specified. otherwise, use defaults.
+
+    if method.lower() == 'linear':
+        ds = np.mean(d,axis=par["axis"])
+    elif method.lower() == 'pws':
+        ds = pws(d,p=par['p'])
+    elif method.lower() == 'tfpws':
+        ds = tfpws(d,p=par['p'])
+    # elif method.lower() == 'tfpws-dost':
+    #     ds = tfpws_dost(d,p=par['p'])
+    elif method.lower() == 'robust':
+        ds = robust(d,epsilon=par['epsilon'],maxstep=par['maxstep'],win=par["win"],
+                stat=par['stat'],ref=par['ref'])
+    elif method.lower() == 'acf':
+        ds = adaptive_filter(d,g=par['g'])
+    elif method.lower() == 'nroot':
+        ds = nroot(d,p=par['p'])
+    elif method.lower() == 'selective':
+        ds = selective(d,cc_min=par['cc_min'],epsilon=par['epsilon'],maxstep=par['maxstep'],
+                stat=par['stat'],ref=par['ref'],win=par["win"])
+    elif method.lower() == 'cluster':
+        ds = clusterstack(d,h=par['h'],axis=par['axis'],win=par["win"],
+        normalize=par['normalize'],plot=par['plot'])
+    #
+    return ds
+
+def seisstack(d,method,par=None):
+    """
+    This is the same as stack(), to be compatible with old usage.
+    """
+    return stack(d,method=method,par=par)
+
+def robust(d,epsilon=1E-5,maxstep=10,win=None,stat=False,ref=None):
+    """
+    this is a robust stacking algorithm described in Pavlis and Vernon 2010. Generalized
+    by Xiaotao Yang.
+
+    PARAMETERS:
+    ----------------------
+    d: numpy.ndarray contains the 2D cross correlation matrix
+    epsilon: residual threhold to quit the iteration (a small number). Default 1E-5
+    maxstep: maximum iterations. default 10.
+    win: [start_index,end_index] used to compute the weight, instead of the entire trace. Default None.
+            When None, use the entire trace.
+    ref: reference stack, with the same length as individual data. Default: None. Use median().
+    RETURNS:
+    ----------------------
+    newstack: numpy vector contains the stacked cross correlation
+
+    Written by Marine Denolle
+    Modified by Xiaotao Yang
+    """
+    if d.ndim == 1:
+        print('2D matrix is needed')
+        return d
+    N,M = d.shape
+    res  = 9E9  # residuals
+    w = np.ones(d.shape[0])
+    small_number=1E-15
+    nstep=0
+    if N >=2:
+        if ref is None:
+            newstack = np.median(d,axis=0)
+        else:
+            newstack = ref
+        if win is None:
+            win=[0,-1]
+        while res > epsilon and nstep <=maxstep:
+            stack = newstack
+            for i in range(d.shape[0]):
+                dtemp=d[i,win[0]:win[1]]
+                crap = np.multiply(stack[win[0]:win[1]],dtemp.T)
+                crap_dot = np.sum(crap)
+                di_norm = np.linalg.norm(dtemp)
+                ri_norm = np.linalg.norm(dtemp -  crap_dot*stack[win[0]:win[1]])
+                if ri_norm < small_number:
+                    w[i]=0
+                else:
+                    w[i]  = np.abs(crap_dot) /di_norm/ri_norm
+            w =w /np.sum(w)
+            newstack =np.sum( (w*d.T).T,axis=0)#/len(cc_array[:,1])
+            res = np.linalg.norm(newstack-stack,ord=1)/np.linalg.norm(newstack)/len(d[:,1])
+            nstep +=1
+    else:
+        newstack=d[0].copy()
+    if stat:
+        return newstack, w, nstep
+    else:
+        return newstack
+
+def adaptive_filter(d,g=1):
+    '''
+    the adaptive covariance filter to enhance coherent signals. Fellows the method of
+    Nakata et al., 2015 (Appendix B)
+
+    the filtered signal [x1] is given by x1 = ifft(P*x1(w)) where x1 is the ffted spectra
+    and P is the filter. P is constructed by using the temporal covariance matrix.
+
+    PARAMETERS:
+    ----------------------
+    d: numpy.ndarray contains the 2D traces of daily/hourly cross-correlation functions
+    g: a positive number to adjust the filter harshness [default is 1]
+    RETURNS:
+    ----------------------
+    newstack: numpy vector contains the stacked cross correlation function
+    '''
+    if d.ndim == 1:
+        print('2D matrix is needed')
+        return d
+    N,M = d.shape
+    if N>=2:
+        Nfft = next_fast_len(M)
+
+        # fft the 2D array
+        spec = fft(d,axis=1,n=Nfft)[:,:M]
+
+        # make cross-spectrm matrix
+        cspec = np.zeros(shape=(N*N,M),dtype=np.complex64)
+        for ii in range(N):
+            for jj in range(N):
+                kk = ii*N+jj
+                cspec[kk] = spec[ii]*np.conjugate(spec[jj])
+
+        S1 = np.zeros(M,dtype=np.complex64)
+        S2 = np.zeros(M,dtype=np.complex64)
+        # construct the filter P
+        for ii in range(N):
+            mm = ii*N+ii
+            S2 += cspec[mm]
+            for jj in range(N):
+                kk = ii*N+jj
+                S1 += cspec[kk]
+
+        p = np.power((S1-S2)/(S2*(N-1)),g)
+
+        # make ifft
+        narr = np.real(ifft(np.multiply(p,spec),Nfft,axis=1)[:,:M])
+        newstack=np.mean(narr,axis=0)
+    else:
+        newstack=d[0].copy()
+    #
+    return newstack
+
+def pws(d,p=2):
+    '''
+    Performs phase-weighted stack on array of time series. Modified on the noise function by Tim Climents.
+    Follows methods of Schimmel and Paulssen, 1997.
+    If s(t) is time series data (seismogram, or cross-correlation),
+    S(t) = s(t) + i*H(s(t)), where H(s(t)) is Hilbert transform of s(t)
+    S(t) = s(t) + i*H(s(t)) = A(t)*exp(i*phi(t)), where
+    A(t) is envelope of s(t) and phi(t) is phase of s(t)
+    Phase-weighted stack, g(t), is then:
+    g(t) = 1/N sum j = 1:N s_j(t) * | 1/N sum k = 1:N exp[i * phi_k(t)]|^v
+    where N is number of traces used, v is sharpness of phase-weighted stack
+
+    PARAMETERS:
+    ---------------------
+    d: N length array of time series data (numpy.ndarray)
+    p: exponent for phase stack (int). default is 2
+
+    RETURNS:
+    ---------------------
+    newstack: Phase weighted stack of time series data (numpy.ndarray)
+    '''
+
+    if d.ndim == 1:
+        print('2D matrix is needed')
+        return d
+    N,M = d.shape
+    if N >=2:
+        analytic = hilbert(d,axis=1, N=next_fast_len(M))[:,:M]
+        phase = np.angle(analytic)
+        phase_stack = np.mean(np.exp(1j*phase),axis=0)
+        phase_stack = np.abs(phase_stack)**(p)
+
+        weighted = np.multiply(d,phase_stack)
+
+        newstack=np.mean(weighted,axis=0)
+    else:
+        newstack=d[0].copy()
+    return newstack
+
+def nroot(d,p=2):
+    '''
+    this is nth-root stacking algorithm translated based on the matlab function
+    from https://github.com/xtyangpsp/SeisStack (by Xiaotao Yang; follows the
+    reference of Millet, F et al., 2019 JGR)
+
+    Parameters:
+    ------------
+    d: numpy.ndarray contains the 2D cross correlation matrix
+    p: np.int, nth root for the stacking. Default is 2.
+
+    Returns:
+    ------------
+    newstack: np.ndarray, final stacked waveforms
+
+    Written by Chengxin Jiang @ANU (May2020)
+    '''
+    if d.ndim == 1:
+        print('2D matrix is needed for nroot_stack')
+        return d
+    N,M = d.shape
+    if N >=2:
+        dout = np.zeros(M,dtype=np.float32)
+
+        # construct y
+        for ii in range(N):
+            dat = d[ii,:]
+            dout += np.sign(dat)*np.abs(dat)**(1/p)
+        dout /= N
+
+        # the final stacked waveform
+        newstack = dout*np.abs(dout)**(p-1)
+    else:
+        newstack=d[0].copy()
+
+    return newstack
+
+
+def selective(d,cc_min,epsilon=1E-5,maxstep=10,win=None,stat=False,ref=None):
+    '''
+    this is a selective stacking algorithm developed by Jared Bryan/Kurama Okubo.
+
+    PARAMETERS:
+    ----------------------
+    d: numpy.ndarray contains the 2D cross correlation matrix
+    epsilon: residual threhold to quit the iteration
+    cc_min: numpy.float, threshold of correlation coefficient to be selected
+    epsilon: residual threhold to quit the iteration (a small number). Default 1E-5
+    maxstep: maximum iterations. default 10.
+    win: [start_index,end_index] used to compute the weight, instead of the entire trace. Default None.
+            When None, use the entire trace.
+    ref: reference stack, with the same length as individual data. Default: None. Use mean().
+    RETURNS:
+    ----------------------
+    newstack: numpy vector contains the stacked cross correlation
+    nstep: np.int, total number of iterations for the stacking
+
+    Originally ritten by Marine Denolle
+    Modified by Chengxin Jiang @Harvard (Oct2020)
+    '''
+    if d.ndim == 1:
+        print('2D matrix is needed for selective stacking')
+        return d
+    N,M = d.shape
+    if N>=2:
+        res  = 9E9  # residuals
+        cof  = np.zeros(N,dtype=np.float32)
+        if ref is None:
+            newstack = np.mean(d,axis=0)
+        else:
+            newstack = ref
+
+        nstep = 0
+        if win is None:
+            win=[0,-1]
+        # start iteration
+        while res>epsilon and nstep<=maxstep:
+            for ii in range(N):
+                cof[ii] = np.corrcoef(newstack[win[0]:win[1]], d[ii,win[0]:win[1]])[0, 1]
+
+            # find good waveforms
+            indx = np.where(cof>=cc_min)[0]
+            nstep +=1
+            if not len(indx):
+                newstack=np.ndarray((d.shape[1],))
+                newstack.fill(np.nan)
+                print('cannot find good waveforms inside selective stacking')
+                break
+            else:
+                oldstack = newstack
+                newstack = np.mean(d[indx],axis=0)
+                res = np.linalg.norm(newstack-oldstack)/(np.linalg.norm(newstack)*M)
+    else:
+        newstack=d[0].copy()
+    if stat:
+        return newstack, nstep
+    else:
+        return newstack
+#
+def clusterstack(d,h=0.75,win=None,axis=0,normalize=True,plot=False):
+    '''
+    Performs stack after clustering. The data will be clustered into two groups.
+    If the two centers of the clusters are similar (defined by corrcoef >= "t"), the original
+    traces associated with both clusters will be used to produce the final linear stack, weighted by
+    normalized SNR (phase clarity) of each cluster. Otherwise, the one with larger phase clarity
+    (defined as max(abs(amplitudes))/rms(abs(amplitudes))) will be used to get the final stack.
+
+    PARAMETERS:
+    ---------------------
+    d: N length array of time series data (numpy.ndarray)
+    h: corrcoeff threshold to decide which group/cluster to use. Default 0.75.
+    win: [start_index,end_index] used to compute the weight, instead of the entire trace. Default None.
+            When None, use the entire trace.
+    axis: which axis to stack. default 0.
+    normalize: Normalize the traces before clustering. This will only influence the cluster.
+            The final stack will be produced using the original data.
+    plot: plot clustering results. default False.
+
+    RETURNS:
+    ---------------------
+    newstack: final stack.
+    '''
+    ncluster=2 #DO NOT change this value.
+    min_trace=2 #minimum of two traces.
+    metric="euclidean" #matric to compute the distance in kmeans clustering.
+    if d.ndim == 1:
+        print('2D matrix is needed')
+        return d
+    N,M = d.shape
+    if N >= min_trace:
+        dataN=d.copy()
+        if normalize:
+            for i in range(N):
+                dataN[i]=d[i]/np.max(np.abs(d[i]),axis=0)
+
+        ts = to_time_series_dataset(dataN)
+
+        km = TimeSeriesKMeans(n_clusters=ncluster, n_jobs=1,metric=metric, verbose=False,
+                              max_iter_barycenter=100, random_state=0)
+        y_pred = km.fit_predict(ts)
+        snr_all=[]
+        centers_all=[]
+        cidx=[]
+        if win is None:
+            win=[0,-1]
+        for yi in range(ncluster):
+            cidx.append(np.where((y_pred==yi))[0])
+            center=km.cluster_centers_[yi].ravel()#np.squeeze(np.mean(ts[y_pred == yi].T,axis=2))
+            centers_all.append(center)
+            snr=np.max(np.abs(center[win[0]:win[1]]))/rms(np.abs(center))
+            snr_all.append(snr)
+
+        #
+        if plot:
+            plt.figure(figsize=(12,4))
+            for yi in range(ncluster):
+                plt.subplot(1,ncluster,yi+1)
+                plt.plot(np.squeeze(ts[cidx[yi]].T),'k-',alpha=0.3)
+                plt.plot(centers_all[yi],'r-')
+                plt.title('Cluster %d: %d'%(yi+1,len(cidx[yi])))
+            plt.show()
+        cc=np.corrcoef(centers_all[0],centers_all[1])[0,1]
+        if cc>= h: #use all data
+            snr_normalize=snr_all/np.sum(snr_all)
+            newstack=np.zeros((M))
+            for yi in range(ncluster):
+                newstack += snr_normalize[yi]*np.mean(d[cidx[yi]],axis=0)
+        else:
+            goodidx=np.argmax(snr_all)
+            newstack=np.mean(d[cidx[goodidx]],axis=0)
+        del dataN,ts,y_pred
+    else:
+        newstack=d[0].copy()
+    #
+    return newstack
+
+def tfpws(d,p=2,axis=0):
+    '''
+    Performs time-frequency domain phase-weighted stack on array of time series.
+
+    $C_{ps} = |(\sum{S*e^{i2\pi}/|S|})/M|^p$, where $C_{ps}$ is the phase weight. Then
+    $S_{pws} = C_{ps}*S_{ls}$, where $S_{ls}$ is the S transform of the linea stack
+    of the whole data.
+
+    Reference:
+    Schimmel, M., Stutzmann, E., & Gallart, J. (2011). Using instantaneous phase
+    coherence for signal extraction from ambient noise data at a local to a
+    global scale. Geophysical Journal International, 184(1), 494–506.
+    https://doi.org/10.1111/j.1365-246X.2010.04861.x
+
+    PARAMETERS:
+    ---------------------
+    d: N length array of time series data (numpy.ndarray)
+    p: exponent for phase stack (int). default is 2
+    axis: axis to stack, default is 0.
+
+    RETURNS:
+    ---------------------
+    newstack: Phase weighted stack of time series data (numpy.ndarray)
+    '''
+    if d.ndim == 1:
+        print('2D matrix is needed')
+        return d
+    N,M = d.shape
+    if N >=2:
+        lstack=np.mean(d,axis=axis)
+        #get the ST of the linear stack first
+        stock_ls=st.st(power2pad(lstack))
+
+        #run a ST to get the dimension of ST result
+        stock_temp=st.st(power2pad(d[0]))
+        phase_stack=np.zeros((stock_temp.shape[0],stock_temp.shape[1]),dtype='complex128')
+        for i in range(N):
+            if i>0: #zero index has been computed.
+                stock_temp=st.st(power2pad(d[i]))
+            phase_stack += np.multiply(stock_temp,np.angle(stock_temp))/np.abs(stock_temp)
+        #
+        phase_stack = np.abs(phase_stack/N)**p
+
+        pwstock=np.multiply(phase_stack,stock_ls)
+        recdostIn=np.real(st.ist(pwstock))
+        newstack=recdostIn[:M] # trim padding
+    else:
+        newstack=d[0].copy()
+    #
+    return newstack
+
+# def tfpws_dost(d,p=2,axis=0):
+#     '''
+#     Performs time-frequency domain phase-weighted stack on array of time series using DOST (Discrete
+#     orthogonal stockwell transform).
+#     $C_{ps} = |(\sum{S*e^{i2\pi}/|S|})/M|^p$, where $C_{ps}$ is the phase weight. Then
+# 	$S_{pws} = C_{ps}*S_{ls}$, where $S_{ls}$ is the Discrete Orthonormal S transform
+# 	of the linear stack of the whole data.
+
+#     DOST stacking was implemented by Jared Bryan.
+
+#     Reference for tf-PWS:
+#     Schimmel, M., Stutzmann, E., & Gallart, J. (2011). Using instantaneous phase
+#     coherence for signal extraction from ambient noise data at a local to a
+#     global scale. Geophysical Journal International, 184(1), 494–506.
+#     https://doi.org/10.1111/j.1365-246X.2010.04861.x
+
+#     Reference for DOST:
+#     U. Battisti, L. Riba, "Window-dependent bases for efficient representations of the
+# 	Stockwell transform", Applied and Computational Harmonic Analysis, 23 February 2015,
+# 	http://dx.doi.org/10.1016/j.acha.2015.02.002.
+
+#     PARAMETERS:
+#     ---------------------
+#     d: N length array of time series data (numpy.ndarray)
+#     p: exponent for phase stack (int). default is 2
+#     axis: axis to stack, default is 0.
+
+#     RETURNS:
+#     ---------------------
+#     newstack: Phase weighted stack of time series data (numpy.ndarray)
+#     '''
+#     if d.ndim == 1:
+#         print('2D matrix is needed')
+#         return d
+#     N,M = d.shape
+#     if N >=2:
+#         lstack=np.mean(d,axis=axis)
+#         #get the dost of the linear stack first
+#         stock_ls_dost=DOST(lstack) # initialize dost object
+#         stock_ls=stock_ls_dost.dost(stock_ls_dost.data) # calculate the dost
+
+#     	# calculate dost for first trace to know its shape
+#         stock_dost=DOST(d[0])
+#         stock_temp=stock_dost.dost(stock_dost.data)
+#     	# initialize stack
+#         phase_stack=np.zeros(len(stock_temp),dtype='complex128')
+#     	# calculate the dost for each trace to be stacked
+#         for i in range(d.shape[0]):
+#         	if i>0: # zero index has been computed
+#         	    stock_dost=DOST(d[i])
+#         	    stock_temp=stock_dost.dost(stock_dost.data)
+                    
+#             phase_stack+=np.multiply(stock_temp,np.angle(stock_temp))/np.abs(stock_temp)
+
+#         phase_stack = np.abs(phase_stack/N)**p
+
+#         pwstock=np.multiply(phase_stack,stock_ls)
+#         recdostIn = np.real(stock_dost.idost(pwstock))
+#         newstack = recdostIn[:M] # trim padding
+#     else:
+#         newstack=d[0].copy()
+#     #
+#     return newstack
+
+class DOST:
+    def __init__(self, data):
+        # make sure data length is a power of 2
+        if np.ceil(np.log2(len(data)))==np.floor(np.log2(len(data))):
+            # length of data already a power of 2
+            self.data=data
+        else:
+            # pad data to nearest power of 2
+            self.data=self.pad(data)
+
+    def pad(self,data):
+        """Zero pad data such that its length is a power of 2
+
+        PARAMETERS:
+        ---------------------
+        data: array of time series data (numpy.ndarray)
+
+        RETURNS:
+        ---------------------
+        data: zero-padded array of time series data (numpy.ndarray)
+        """
+        N=int(2**np.ceil(np.log2(len(data))))
+        pad_end=np.zeros(int(N-len(data)))
+        data=np.concatenate((data,pad_end))
+
+        return data
+
+    def fourier(self, d):
+        """Normalized and centered fft
+
+        PARAMETERS:
+        ---------------------
+        d: array of time series data (numpy.ndarray)
+
+        RETURNS:
+        ---------------------
+        fftIn: array of frequency-domain data (numpy.ndarray)
+        """
+        fftIn=(1/np.sqrt(len(d))) * np.fft.fftshift(np.fft.fft(np.fft.ifftshift(d)))
+        return fftIn
+
+    def ifourier(self,d):
+        """Normalized and centered ifft
+
+        PARAMETERS:
+        ---------------------
+        d: array of frequency-domain data (numpy.ndarray)
+
+        RETURNS:
+        ---------------------
+        ifftIn: array of time series data (numpy.ndarray)
+        """
+        ifftIn=np.sqrt(len(d)) * np.fft.fftshift(np.fft.ifft(np.fft.ifftshift(d)))
+        return ifftIn
+
+    def dostbw(self,D):
+        """Calculate size of the DOST bandwidths
+
+        PARAMETERS:
+        ---------------------
+        D: length of time-series data (int)
+
+        RETURNS:
+        ---------------------
+        bw: list of DOST bandwidths
+        """
+        bw=[0]
+        bw.extend(np.arange(np.log2(D)-2, -1e-9, -1))
+        bw.extend([0])
+        bw.extend(np.arange(0, np.log2(D)-2+1e-9))
+        bw=2**np.array(bw)
+        return bw
+
+    def dost(self,d):
+        """Discrete Orthonormal Stockwell Transform
+
+        PARAMETERS:
+        ---------------------
+        d: array of time-series data (numpy.ndarray)
+
+        RETURNS:
+        ---------------------
+        d_dost: array of DOST coefficients (numpy.ndarray)
+        """
+        d_dost=self.fourier(d)
+        D=len(d)
+        bw=self.dostbw(D)
+        k=0
+        # heuristically, this is a short-time fourier transform with a frequency-dependent bandwidth
+        for i in bw:
+            i=int(i)
+            if i==1:
+                k=k+i
+            else:
+                d_dost[k:k+i] = self.ifourier(d_dost[k:k+i])
+                k=k+i
+        return d_dost
+
+    def idost(self,d):
+        """Inverse Discrete Orthonormal Stockwell Transform
+
+        PARAMETERS:
+        ---------------------
+        d: array of DOST coefficients (numpy.ndarray)
+
+        RETURNS:
+        ---------------------
+        d_idost: array of time-series data (numpy.ndarray)
+        """
+        d_idost=d
+        D=len(d)
+        bw=self.dostbw(D)
+        k=0
+        for i in bw:
+            i=int(i)
+            if i==1:
+                k=k+i
+            else:
+                d_idost[k:k+i] = self.fourier(d_idost[k:k+i])
+                k=k+i
+        d_idost = self.ifourier(d_idost)
+        return d_idost
+
+
+class StackClass_python(object):
+    def __init__(self, corr_data, stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, jobs):
+        self.corr_data = corr_data
+        self.stack_method = stack_method
+        self.par = par
+        self.stack_all = stack_all
+        self.stack_len = stack_len
+        self.stack_step = stack_step
+        self.pick_m = pick
+        self.median_high = median_high
+        self.median_low = median_low
+        self.flag = flag
+        self.jobs = jobs
+
+        self.pair_num = int(corr_data.shape[0])
+        self.corr_win_num = int(corr_data.shape[1])
+        self.npts = int(corr_data.shape[2])
+
+        # slice_window --> _stack_win_num, _win_info
+        if stack_all:
+            self.win_info = np.array([[0, self.corr_win_num]])
+            self.stack_win_num = 1
+        else:
+            self.win_info = slice_window(self.corr_win_num, stack_len, stack_step)
+            self.stack_win_num = int(self.win_info.shape[0])
+
+        # initialize output_data
+        self.ngood_all = np.empty((self.pair_num, self.stack_win_num))
+        if self.corr_data.dtype == np.dtype(np.float32):
+            self.output_data = np.empty((self.pair_num, self.stack_win_num, self.npts), dtype=np.float32)
+            self.time_dtype = np.float32
+            self.freq_dtype = np.complex64
+        elif self.corr_data.dtype == np.dtype(np.float64):
+            self.output_data = np.empty((self.pair_num, self.stack_win_num, self.npts), dtype=np.float64)
+            self.time_dtype = np.float64
+            self.freq_dtype = np.complex128
+        else:
+            print("error: please input the correct data type.")
+            exit(1)
+
+
+    def pick(self, pair_id):
+        nindex = None
+        if self.pick_m:
+            # SOME WARNING HERE!!!
+            ampmax = np.amax(self.corr_data[pair_id, :, :], axis=1)
+            median_ampmax = np.median(ampmax)
+            index = np.where((ampmax > self.median_low * median_ampmax) & (ampmax < self.median_high * median_ampmax))[0]
+        
+            nindex = np.array(index, dtype=int)
+        else:
+            nindex = np.arange(0, self.corr_win_num, dtype=int)
+
+        return nindex
+
+
+    def check_ngood(self, nindex):
+        ngood = np.empty(self.stack_win_num)
+        if self.pick_m:
+            for i in range(0, self.stack_win_num):
+                ngood[i] = np.sum((nindex >= self.win_info[i, 0]) & (nindex < self.win_info[i, 1]))
+        else:
+            ngood = self.stack_len * np.ones(self.stack_win_num)
+
+        return ngood
+
+
+    def stack(self, pair_id, nindex):
+        stack_data = np.empty((self.stack_win_num, self.npts), dtype=self.time_dtype)
+
+        for i in range(0, self.stack_win_num):
+            each_index = np.arange(self.win_info[i, 0], self.win_info[i, 1])
+            pick_index = list(compress(each_index, np.isin(each_index, nindex)))
+
+            if len(pick_index) == 0:
+                stack_data[i, :] = np.zeros(self.npts)
+            else:
+                pick_corr_data = self.corr_data[pair_id, pick_index, :]
+                stack_data[i, :] = stack(pick_corr_data, self.stack_method, self.par)    
+
+        return stack_data
+
+
+    def process_chunk(self, chunk_start, chunk_end):
+        ngood_results = []
+        stack_data_results = []
+
+        if self.flag and chunk_start == 0:
+            bar = tqdm(range(chunk_start, chunk_end))
+        else:
+            bar = range(chunk_start, chunk_end)
+
+        for i in bar:
+            # pick --> _nindex
+            nindex = self.pick(i)
+
+            # ngood
+            ngood = self.check_ngood(nindex)
+
+            # corr
+            stack_data = self.stack(i, nindex) # "linear", "pws", "robust"
+
+            ngood_results.append(ngood)
+            stack_data_results.append(stack_data)
+
+        return ngood_results, stack_data_results
+
+
+    def run(self):
+        if self.flag:
+            start_time = time.time()
+            print(f"Start stack with {self.jobs} jobs in python...")
+        
+        # parallel processing
+        if self.jobs > 1:
+            chunk_list = split(num=self.pair_num, n_jobs=self.jobs)
+            results = Parallel(n_jobs=self.jobs, backend="loky")(delayed(self.process_chunk)(chunk_start, chunk_end) for chunk_start, chunk_end in chunk_list)
+
+            ngood_all_results = []
+            output_data_results = []
+
+            for chunk_results in results:
+                ngood_all_chunk, output_data_chunk = chunk_results
+                ngood_all_results.extend(ngood_all_chunk)
+                output_data_results.extend(output_data_chunk)
+
+            self.ngood_all = np.array(ngood_all_results)
+            self.output_data = np.array(output_data_results, dtype=self.time_dtype)
+        else:
+            ngood_all_results, output_data_results = self.process_chunk(0, self.pair_num)
+            self.ngood_all, self.output_data = np.array(ngood_all_results), np.array(output_data_results, dtype=self.time_dtype)
+
+        if self.flag:
+            end_time = time.time()
+            elapsed_time = end_time - start_time
+            print(f"End stack with total time {elapsed_time}s")
+
```

## noiseflow/cc/python/utils.py

 * *Ordering differences only*

```diff
@@ -1,107 +1,107 @@
-import numpy as np
-
-
-def split(num, n_jobs):
-    chunk_size = num // n_jobs
-    results = []
-    for i in range(0, n_jobs):
-        chunk_start = i*chunk_size
-        if i == n_jobs - 1:
-            chunk_end = num
-        else:
-            chunk_end = (i+1)*chunk_size
-        results.append([chunk_start, chunk_end])
-
-    return results
-
-
-def slice_window(npts, segment_points, step_points):
-    if segment_points < npts:
-        slide_points = segment_points - step_points
-        win_num = 0
-        for i in range(0, int(npts/slide_points)):
-            if (i * slide_points + segment_points) <= npts:
-                win_num += 1
-            else:
-                break
-        win_info = np.empty((win_num, 2), dtype=int)
-        for i in range(win_num):
-            win_info[i, 0] = i * slide_points
-            win_info[i, 1] = i * slide_points + segment_points
-    elif segment_points == npts:
-        win_num = 1
-        win_info = np.array([[0, npts]], dtype=int)
-    else:
-        raise ValueError("error: segment-points length is larger than npts when slicing windows!")
-    
-    return win_info
-
-
-def moving_ave(A, N):
-    temp = np.zeros(A.shape[0] + 2*N)
-
-    temp_len = temp.shape[0]
-    temp[N:temp_len-N] = A
-    temp[0:N] = temp[N]
-    temp[temp_len-N:temp_len] = temp[temp_len-N-1]
-
-    nn = np.ones(N) / N
-    b1 = np.convolve(temp, nn, mode='full')
-
-    n1 = N + (N-1) // 2
-    n2 = N + (N-1 - (N-1) // 2)
-    B1 = b1[n1 : b1.shape[0] - n2]
-
-    return B1
-
-
-def whiten(rfft_data, dt, freq_norm_method, freqmin, freqmax, smoothspect_N, whiten_npad):
-    _i = 0.0 + 1.0j
-    _i0 = 0.0 + 0.0j
-    _pi = np.pi
-
-    win_num = rfft_data.shape[0]
-    fft_npts = rfft_data.shape[1]
-
-    freq_array = np.arange(fft_npts) / dt / 2.0 / (fft_npts-1) # note: must divide by 2.0, because rfft_npts is not npts.
-    J = np.where((freq_array>=freqmin) & (freq_array<=freqmax))[0]
-
-    low = J[0] - whiten_npad
-    if (low <= 0):
-        low = 0
-    left = J[0]
-    right = J[-1]
-    high = J[-1] + whiten_npad
-    if (high > fft_npts):
-        high = fft_npts
-
-    rfft_norm_data = _i0*np.ones((win_num, fft_npts))
-
-    for i in range(0, win_num):
-        #  left zero cut-off
-        # // xt::view(rfft_norm_data, i, xt::range(0, low)) = _i0*xt::view(rfft_data, i, xt::range(0, low));
-
-        # // left tapering
-        smo1 = np.power(np.cos( np.linspace(_pi/2, _pi, left-low)), 2)
-        exp1 = np.exp(_i*np.angle(rfft_data[i, low:left]))
-        rfft_norm_data[i, low:left] = smo1*exp1
- 
-        # // pass band
-        if freq_norm_method == "whiten":
-            smo2 = np.ones((right-left))
-            exp2 = np.exp(_i*np.angle(rfft_data[i, left: right]))
-            rfft_norm_data[ i, left:right] = smo2*exp2
-        elif freq_norm_method == "smooth_whiten":
-            data = rfft_data[i, left:right]
-            rfft_norm_data[ i, left:right] = data / moving_ave(np.abs(data), smoothspect_N)
-    
-        # // right tapering
-        smo3 = np.power(np.cos( np.linspace(0, _pi/2, high-right)), 2)
-        exp3 = np.exp(_i*np.angle(rfft_data[ i, right: high]))
-        rfft_norm_data[i, right: high] = smo3*exp3
-
-        # // right zero cut-off
-        # // xt::view(rfft_norm_data, i, xt::range(high, -1)) = _i0*xt::view(rfft_data, i, xt::range(high, -1));
-    
-    return rfft_norm_data
-
+import numpy as np
+
+
+def split(num, n_jobs):
+    chunk_size = num // n_jobs
+    results = []
+    for i in range(0, n_jobs):
+        chunk_start = i*chunk_size
+        if i == n_jobs - 1:
+            chunk_end = num
+        else:
+            chunk_end = (i+1)*chunk_size
+        results.append([chunk_start, chunk_end])
+
+    return results
+
+
+def slice_window(npts, segment_points, step_points):
+    if segment_points < npts:
+        slide_points = segment_points - step_points
+        win_num = 0
+        for i in range(0, int(npts/slide_points)):
+            if (i * slide_points + segment_points) <= npts:
+                win_num += 1
+            else:
+                break
+        win_info = np.empty((win_num, 2), dtype=int)
+        for i in range(win_num):
+            win_info[i, 0] = i * slide_points
+            win_info[i, 1] = i * slide_points + segment_points
+    elif segment_points == npts:
+        win_num = 1
+        win_info = np.array([[0, npts]], dtype=int)
+    else:
+        raise ValueError("error: segment-points length is larger than npts when slicing windows!")
+    
+    return win_info
+
+
+def moving_ave(A, N):
+    temp = np.zeros(A.shape[0] + 2*N)
+
+    temp_len = temp.shape[0]
+    temp[N:temp_len-N] = A
+    temp[0:N] = temp[N]
+    temp[temp_len-N:temp_len] = temp[temp_len-N-1]
+
+    nn = np.ones(N) / N
+    b1 = np.convolve(temp, nn, mode='full')
+
+    n1 = N + (N-1) // 2
+    n2 = N + (N-1 - (N-1) // 2)
+    B1 = b1[n1 : b1.shape[0] - n2]
+
+    return B1
+
+
+def whiten(rfft_data, dt, freq_norm_method, freqmin, freqmax, smoothspect_N, whiten_npad):
+    _i = 0.0 + 1.0j
+    _i0 = 0.0 + 0.0j
+    _pi = np.pi
+
+    win_num = rfft_data.shape[0]
+    fft_npts = rfft_data.shape[1]
+
+    freq_array = np.arange(fft_npts) / dt / 2.0 / (fft_npts-1) # note: must divide by 2.0, because rfft_npts is not npts.
+    J = np.where((freq_array>=freqmin) & (freq_array<=freqmax))[0]
+
+    low = J[0] - whiten_npad
+    if (low <= 0):
+        low = 0
+    left = J[0]
+    right = J[-1]
+    high = J[-1] + whiten_npad
+    if (high > fft_npts):
+        high = fft_npts
+
+    rfft_norm_data = _i0*np.ones((win_num, fft_npts))
+
+    for i in range(0, win_num):
+        #  left zero cut-off
+        # // xt::view(rfft_norm_data, i, xt::range(0, low)) = _i0*xt::view(rfft_data, i, xt::range(0, low));
+
+        # // left tapering
+        smo1 = np.power(np.cos( np.linspace(_pi/2, _pi, left-low)), 2)
+        exp1 = np.exp(_i*np.angle(rfft_data[i, low:left]))
+        rfft_norm_data[i, low:left] = smo1*exp1
+ 
+        # // pass band
+        if freq_norm_method == "whiten":
+            smo2 = np.ones((right-left))
+            exp2 = np.exp(_i*np.angle(rfft_data[i, left: right]))
+            rfft_norm_data[ i, left:right] = smo2*exp2
+        elif freq_norm_method == "smooth_whiten":
+            data = rfft_data[i, left:right]
+            rfft_norm_data[ i, left:right] = data / moving_ave(np.abs(data), smoothspect_N)
+    
+        # // right tapering
+        smo3 = np.power(np.cos( np.linspace(0, _pi/2, high-right)), 2)
+        exp3 = np.exp(_i*np.angle(rfft_data[ i, right: high]))
+        rfft_norm_data[i, right: high] = smo3*exp3
+
+        # // right zero cut-off
+        # // xt::view(rfft_norm_data, i, xt::range(high, -1)) = _i0*xt::view(rfft_data, i, xt::range(high, -1));
+    
+    return rfft_norm_data
+
```

## noiseflow/cc/rfftdata.py

 * *Ordering differences only*

```diff
@@ -1,185 +1,185 @@
-import os
-import h5py
-import numpy as np
-import matplotlib.pyplot as plt
-
-from scipy.io import savemat
-from obspy.imaging.spectrogram import spectrogram
-
-
-class RFFTData_Class(object):
-    def __init__(self,rfft_data, dt, cc_len, cc_step, 
-                time_norm, clip_std, smooth_N,
-                freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
-                flag, flag_gap, threads, jobs, py):
-        self.rfft_data = rfft_data
-        self.dt = dt
-        self.cc_len = cc_len
-        self.cc_step=cc_step 
-        self.time_norm=time_norm
-        self.clip_std=clip_std
-        self.smooth_N=smooth_N
-        self.freq_norm=freq_norm
-        self.freqmin=freqmin
-        self.freqmax=freqmax
-        self.whiten_npad=whiten_npad
-        self.smoothspect_N=smoothspect_N
-        self.flag=flag
-        self.flag_gap=flag_gap
-        self.threads=threads
-        self.jobs=jobs
-        self.py=py
-
-    # save data
-    def save(self, save_path, format='npz', compression=False, h5_compression_format='gzip', h5_compression_opts=3):
-        if format == 'npz':
-            if compression:
-                np.savez_compressed(save_path,
-                        rfft_data=self.rfft_data,
-                        dt=self.dt,
-                        cc_len=self.cc_len,
-                        cc_step=self.cc_step,
-                        time_norm=self.time_norm,
-                        clip_std=self.clip_std,
-                        smooth_N=self.smooth_N,
-                        freq_norm=self.freq_norm,
-                        freqmin=self.freqmin,
-                        freqmax=self.freqmax,
-                        whiten_npad=self.whiten_npad,
-                        smoothspect_N=self.smoothspect_N,
-                        flag=self.flag,
-                        flag_gap=self.flag_gap,
-                        threads=self.threads,
-                        jobs=self.jobs,
-                        py=self.py)
-            else:
-                np.savez(save_path,
-                        rfft_data=self.rfft_data,
-                        dt=self.dt,
-                        cc_len=self.cc_len,
-                        cc_step=self.cc_step,
-                        time_norm=self.time_norm,
-                        clip_std=self.clip_std,
-                        smooth_N=self.smooth_N,
-                        freq_norm=self.freq_norm,
-                        freqmin=self.freqmin,
-                        freqmax=self.freqmax,
-                        whiten_npad=self.whiten_npad,
-                        smoothspect_N=self.smoothspect_N,
-                        flag=self.flag,
-                        flag_gap=self.flag_gap,
-                        threads=self.threads,
-                        jobs=self.jobs,
-                        py=self.py)
-                
-        elif format == 'h5':
-            with h5py.File(save_path, 'w') as f:
-                group = f.create_group('noiseflow_group')
-                group.attrs['dt'] = self.dt
-                group.attrs['cc_len'] = self.cc_len
-                group.attrs['cc_step'] = self.cc_step
-                group.attrs['time_norm'] = self.time_norm
-                group.attrs['clip_std'] = self.clip_std
-                group.attrs['smooth_N'] = self.smooth_N
-                group.attrs['freq_norm'] = self.freq_norm
-                group.attrs['freqmin'] = self.freqmin
-                group.attrs['freqmax'] = self.freqmax
-                group.attrs['whiten_npad'] = self.whiten_npad
-                group.attrs['smoothspect_N'] = self.smoothspect_N
-                group.attrs['flag'] = self.flag
-                group.attrs['flag_gap'] = self.flag_gap
-                group.attrs['threads'] = self.threads
-                group.attrs['jobs'] = self.jobs
-                group.attrs['py'] = self.py
-                if compression:
-                    group.create_dataset('rfft_data', data=self.rfft_data, compression=h5_compression_format, compression_opts=h5_compression_opts)
-                else:
-                    group.create_dataset('rfft_data', data=self.rfft_data)
-
-        elif format == 'mat':
-            savemat(save_path, 
-                {'rfft_data': self.rfft_data,
-                'dt': self.dt,
-                'cc_len': self.cc_len,
-                'cc_step': self.cc_step,
-                'time_norm': self.time_norm,
-                'clip_std': self.clip_std,
-                'smooth_N': self.smooth_N,
-                'freq_norm': self.freq_norm,
-                'freqmin': self.freqmin,
-                'freqmax': self.freqmax,
-                'whiten_npad': self.whiten_npad,
-                'smoothspect_N': self.smoothspect_N,
-                'flag': self.flag,
-                'flag_gap': self.flag_gap,
-                'threads': self.threads,
-                'jobs': self.jobs,
-                'py': self.py},
-                do_compression=compression)
-            
-        else:
-            raise ValueError('format must be npz, h5, or mat')
-
-
-    # plot spectrum 
-    def spectrogram(self, 
-                    channel_indx=0, 
-                    win_indx=0, 
-                    raw_data=None,
-                    dbscale=False,
-                    log=True, 
-                    figsize=(10, 4),
-                    save=False, 
-                    save_path=None, 
-                    dpi=100):
-        
-        if raw_data is None:
-            win1 = win_indx * (int(self.cc_len/self.dt) - int(self.cc_step/self.dt))
-            win2 = win1 + int(self.cc_len/self.dt)
-            rfft_whitedata = np.fft.irfft(self.rfft_data[channel_indx,win_indx]).real
-
-            fig, ax = plt.subplots(figsize=figsize)
-            spectrogram(rfft_whitedata, 1/self.dt,  axes=ax, dbscale=dbscale, log=log)
-
-            ax.set_title("RFFTData: channel_indx=%d, win_indx=%d, time_norm=%s \nfreq_norm=%s, freq_band=[%.2f, %.2f] hz" % (channel_indx, win_indx, self.time_norm, self.freq_norm, self.freqmin, self.freqmax))
-            ax.set_xlim(0, self.cc_len)
-            ax.set_ylabel("Time(s)")
-            ax.set_ylim(self.freqmin/2, self.freqmax*2)
-            ax.set_ylabel("Frequency(hz)")
-            ax.plot([0, self.cc_len], [self.freqmin, self.freqmin], '--', color='red', lw=3, alpha=0.7)
-            ax.plot([0, self.cc_len], [self.freqmax, self.freqmax], '--', color='red', lw=3, alpha=0.7)
-
-        else:
-            win1 = win_indx * (int(self.cc_len/self.dt) - int(self.cc_step/self.dt))
-            win2 = win1 + int(self.cc_len/self.dt)
-            rfft_whitedata = np.fft.irfft(self.rfft_data[channel_indx,win_indx]).real
-
-            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize)
-            spectrogram(raw_data[win1:win2], 1/self.dt, axes=ax1, dbscale=dbscale, log=log)
-            spectrogram(rfft_whitedata, 1/self.dt, axes=ax2, dbscale=dbscale, log=log)
-
-            fig.suptitle("RFFTData: channel_indx=%d, win_indx=%d, time_norm=%s \nfreq_norm=%s, freq_band=[%.2f, %.2f] hz" % (channel_indx, win_indx, self.time_norm, self.freq_norm, self.freqmin, self.freqmax))
-            ax1.set_ylim(self.freqmin/2, self.freqmax*2)
-            ax1.set_xlim(0, self.cc_len)
-            ax1.set_ylabel("Frequency(hz)")
-            ax1.plot([0, self.cc_len], [self.freqmin, self.freqmin], '--', color='red', lw=3, alpha=0.7)
-            ax1.plot([0, self.cc_len], [self.freqmax, self.freqmax], '--', color='red', lw=3, alpha=0.7)
-            ax1.set_title("no whitening")
-
-            ax2.set_ylim(self.freqmin/2, self.freqmax*2)
-            ax2.set_xlim(0, self.cc_len)
-            ax2.set_ylabel("Frequency(hz)")
-            ax2.set_xlabel("Time(s)")
-            ax2.plot([0, self.cc_len], [self.freqmin, self.freqmin], '--', color='red', lw=3, alpha=0.7)
-            ax2.plot([0, self.cc_len], [self.freqmax, self.freqmax], '--', color='red', lw=3, alpha=0.7)
-            ax2.set_title("whitening")
-        
-        if save:
-            if save_path is None:
-                raise ValueError("save_path must be specified")
-            fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight')
-            plt.close(fig)
-        else:
-            plt.show()
-
-
+import os
+import h5py
+import numpy as np
+import matplotlib.pyplot as plt
+
+from scipy.io import savemat
+from obspy.imaging.spectrogram import spectrogram
+
+
+class RFFTData_Class(object):
+    def __init__(self,rfft_data, dt, cc_len, cc_step, 
+                time_norm, clip_std, smooth_N,
+                freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
+                flag, flag_gap, threads, jobs, py):
+        self.rfft_data = rfft_data
+        self.dt = dt
+        self.cc_len = cc_len
+        self.cc_step=cc_step 
+        self.time_norm=time_norm
+        self.clip_std=clip_std
+        self.smooth_N=smooth_N
+        self.freq_norm=freq_norm
+        self.freqmin=freqmin
+        self.freqmax=freqmax
+        self.whiten_npad=whiten_npad
+        self.smoothspect_N=smoothspect_N
+        self.flag=flag
+        self.flag_gap=flag_gap
+        self.threads=threads
+        self.jobs=jobs
+        self.py=py
+
+    # save data
+    def save(self, save_path, format='npz', compression=False, h5_compression_format='gzip', h5_compression_opts=3):
+        if format == 'npz':
+            if compression:
+                np.savez_compressed(save_path,
+                        rfft_data=self.rfft_data,
+                        dt=self.dt,
+                        cc_len=self.cc_len,
+                        cc_step=self.cc_step,
+                        time_norm=self.time_norm,
+                        clip_std=self.clip_std,
+                        smooth_N=self.smooth_N,
+                        freq_norm=self.freq_norm,
+                        freqmin=self.freqmin,
+                        freqmax=self.freqmax,
+                        whiten_npad=self.whiten_npad,
+                        smoothspect_N=self.smoothspect_N,
+                        flag=self.flag,
+                        flag_gap=self.flag_gap,
+                        threads=self.threads,
+                        jobs=self.jobs,
+                        py=self.py)
+            else:
+                np.savez(save_path,
+                        rfft_data=self.rfft_data,
+                        dt=self.dt,
+                        cc_len=self.cc_len,
+                        cc_step=self.cc_step,
+                        time_norm=self.time_norm,
+                        clip_std=self.clip_std,
+                        smooth_N=self.smooth_N,
+                        freq_norm=self.freq_norm,
+                        freqmin=self.freqmin,
+                        freqmax=self.freqmax,
+                        whiten_npad=self.whiten_npad,
+                        smoothspect_N=self.smoothspect_N,
+                        flag=self.flag,
+                        flag_gap=self.flag_gap,
+                        threads=self.threads,
+                        jobs=self.jobs,
+                        py=self.py)
+                
+        elif format == 'h5':
+            with h5py.File(save_path, 'w') as f:
+                group = f.create_group('noiseflow_group')
+                group.attrs['dt'] = self.dt
+                group.attrs['cc_len'] = self.cc_len
+                group.attrs['cc_step'] = self.cc_step
+                group.attrs['time_norm'] = self.time_norm
+                group.attrs['clip_std'] = self.clip_std
+                group.attrs['smooth_N'] = self.smooth_N
+                group.attrs['freq_norm'] = self.freq_norm
+                group.attrs['freqmin'] = self.freqmin
+                group.attrs['freqmax'] = self.freqmax
+                group.attrs['whiten_npad'] = self.whiten_npad
+                group.attrs['smoothspect_N'] = self.smoothspect_N
+                group.attrs['flag'] = self.flag
+                group.attrs['flag_gap'] = self.flag_gap
+                group.attrs['threads'] = self.threads
+                group.attrs['jobs'] = self.jobs
+                group.attrs['py'] = self.py
+                if compression:
+                    group.create_dataset('rfft_data', data=self.rfft_data, compression=h5_compression_format, compression_opts=h5_compression_opts)
+                else:
+                    group.create_dataset('rfft_data', data=self.rfft_data)
+
+        elif format == 'mat':
+            savemat(save_path, 
+                {'rfft_data': self.rfft_data,
+                'dt': self.dt,
+                'cc_len': self.cc_len,
+                'cc_step': self.cc_step,
+                'time_norm': self.time_norm,
+                'clip_std': self.clip_std,
+                'smooth_N': self.smooth_N,
+                'freq_norm': self.freq_norm,
+                'freqmin': self.freqmin,
+                'freqmax': self.freqmax,
+                'whiten_npad': self.whiten_npad,
+                'smoothspect_N': self.smoothspect_N,
+                'flag': self.flag,
+                'flag_gap': self.flag_gap,
+                'threads': self.threads,
+                'jobs': self.jobs,
+                'py': self.py},
+                do_compression=compression)
+            
+        else:
+            raise ValueError('format must be npz, h5, or mat')
+
+
+    # plot spectrum 
+    def spectrogram(self, 
+                    channel_indx=0, 
+                    win_indx=0, 
+                    raw_data=None,
+                    dbscale=False,
+                    log=True, 
+                    figsize=(10, 4),
+                    save=False, 
+                    save_path=None, 
+                    dpi=100):
+        
+        if raw_data is None:
+            win1 = win_indx * (int(self.cc_len/self.dt) - int(self.cc_step/self.dt))
+            win2 = win1 + int(self.cc_len/self.dt)
+            rfft_whitedata = np.fft.irfft(self.rfft_data[channel_indx,win_indx]).real
+
+            fig, ax = plt.subplots(figsize=figsize)
+            spectrogram(rfft_whitedata, 1/self.dt,  axes=ax, dbscale=dbscale, log=log)
+
+            ax.set_title("RFFTData: channel_indx=%d, win_indx=%d, time_norm=%s \nfreq_norm=%s, freq_band=[%.2f, %.2f] hz" % (channel_indx, win_indx, self.time_norm, self.freq_norm, self.freqmin, self.freqmax))
+            ax.set_xlim(0, self.cc_len)
+            ax.set_ylabel("Time(s)")
+            ax.set_ylim(self.freqmin/2, self.freqmax*2)
+            ax.set_ylabel("Frequency(hz)")
+            ax.plot([0, self.cc_len], [self.freqmin, self.freqmin], '--', color='red', lw=3, alpha=0.7)
+            ax.plot([0, self.cc_len], [self.freqmax, self.freqmax], '--', color='red', lw=3, alpha=0.7)
+
+        else:
+            win1 = win_indx * (int(self.cc_len/self.dt) - int(self.cc_step/self.dt))
+            win2 = win1 + int(self.cc_len/self.dt)
+            rfft_whitedata = np.fft.irfft(self.rfft_data[channel_indx,win_indx]).real
+
+            fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize)
+            spectrogram(raw_data[win1:win2], 1/self.dt, axes=ax1, dbscale=dbscale, log=log)
+            spectrogram(rfft_whitedata, 1/self.dt, axes=ax2, dbscale=dbscale, log=log)
+
+            fig.suptitle("RFFTData: channel_indx=%d, win_indx=%d, time_norm=%s \nfreq_norm=%s, freq_band=[%.2f, %.2f] hz" % (channel_indx, win_indx, self.time_norm, self.freq_norm, self.freqmin, self.freqmax))
+            ax1.set_ylim(self.freqmin/2, self.freqmax*2)
+            ax1.set_xlim(0, self.cc_len)
+            ax1.set_ylabel("Frequency(hz)")
+            ax1.plot([0, self.cc_len], [self.freqmin, self.freqmin], '--', color='red', lw=3, alpha=0.7)
+            ax1.plot([0, self.cc_len], [self.freqmax, self.freqmax], '--', color='red', lw=3, alpha=0.7)
+            ax1.set_title("no whitening")
+
+            ax2.set_ylim(self.freqmin/2, self.freqmax*2)
+            ax2.set_xlim(0, self.cc_len)
+            ax2.set_ylabel("Frequency(hz)")
+            ax2.set_xlabel("Time(s)")
+            ax2.plot([0, self.cc_len], [self.freqmin, self.freqmin], '--', color='red', lw=3, alpha=0.7)
+            ax2.plot([0, self.cc_len], [self.freqmax, self.freqmax], '--', color='red', lw=3, alpha=0.7)
+            ax2.set_title("whitening")
+        
+        if save:
+            if save_path is None:
+                raise ValueError("save_path must be specified")
+            fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight')
+            plt.close(fig)
+        else:
+            plt.show()
+
+
```

## noiseflow/cc/src/pybind11.cpp

 * *Ordering differences only*

```diff
@@ -1,114 +1,114 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-// Note: this file is used for generated a shared library for pythonic user.
-
-
-// base libraries
-#include <iostream>
-#include <string>
-
-// external libraries
-#include <pybind11/pybind11.h>
-#include <pybind11/stl.h>
-#define STRINGIFY(x) #x
-#define MACRO_STRINGIFY(x) STRINGIFY(x)
-#define FORCE_IMPORT_ARRAY // FORCE_IMPORT_ARRAY must be defined before including any header of xtensor-python, and must be defined only once.
-
-// me libraries
-#include "rfft.hpp"
-#include "corr.hpp"
-#include "stack.hpp"
-
-
-
-// **************************************************************************
-// *                        CC
-// **************************************************************************
-namespace CC {
-
-
-// ******** float version ********
-xt::pyarray<std::complex<float>> rfft_float(xt::pyarray<float>& raw_data, float dt, float cc_len, float cc_step, std::string time_norm, float clip_std, int smooth_N, std::string freq_norm, float freqmin, float freqmax, int whiten_npad, int smoothspect_N, bool flag, int flag_gap, int threads){
-    // Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
-    RFFTClass<float, xt::pyarray<float>, xt::pyarray<std::complex<float>>>  nfpy(raw_data, dt, cc_len, cc_step, time_norm, clip_std, smooth_N, freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N, flag, flag_gap, threads);
-    nfpy.run();
-
-    return nfpy.get_rfftdata();
-}
-
-
-xt::pyarray<float> corr_float(xt::pyarray<std::complex<float>>& rfft_data, float dt, std::string corr_method, xt::xtensor<int, 2> corr_pair, float maxlag, int smoothspect_N, bool flag, int flag_gap, int threads){
-    // Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
-    CorrClass<float, xt::pyarray<std::complex<float>>, xt::pyarray<float>>  nfpy(rfft_data, dt, corr_method, corr_pair, maxlag, smoothspect_N, flag, flag_gap, threads);
-    nfpy.run();
-
-    return nfpy.get_corrdata();
-}
-
-
-// ******** double version ********
-xt::pyarray<std::complex<double>> rfft_double(xt::pyarray<double>& raw_data, float dt, float cc_len, float cc_step, std::string time_norm, float clip_std, int smooth_N, std::string freq_norm, float freqmin, float freqmax, int whiten_npad, int smoothspect_N, bool flag, int flag_gap, int threads){
-    // Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
-    RFFTClass<double, xt::pyarray<double>, xt::pyarray<std::complex<double>>>  nfpy(raw_data, dt, cc_len, cc_step, time_norm, clip_std, smooth_N, freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N, flag, flag_gap, threads);
-    nfpy.run();
-
-    return nfpy.get_rfftdata();
-}
-
-
-xt::pyarray<double> corr_double(xt::pyarray<std::complex<double>>& rfft_data, float dt, std::string corr_method, xt::xtensor<int, 2> corr_pair, float maxlag, int smoothspect_N, bool flag, int flag_gap, int threads){
-    // Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
-    CorrClass<double, xt::pyarray<std::complex<double>>, xt::pyarray<double>>  nfpy(rfft_data, dt, corr_method, corr_pair, maxlag, smoothspect_N, flag, flag_gap, threads);
-    nfpy.run();
-
-    return nfpy.get_corrdata();
-}
-
-}
-
-
-
-
-// **************************************************************************
-// *                        PYBIND11_MODULE
-// **************************************************************************
-namespace py = pybind11;
-
-PYBIND11_MODULE(cc_share,m) 
-{
-    xt::import_numpy();
-
-    m.doc() = "Cross-correlation module for NoiseFlow";
-    
-    m.def("rfft_float", &CC::rfft_float, R"pbdoc(Do rfft in c++)pbdoc");
-    m.def("rfft_double", &CC::rfft_double, R"pbdoc(Do rfft in c++)pbdoc");
-
-    m.def("corr_float", &CC::corr_float, R"pbdoc(Do correlation in c++)pbdoc");
-    m.def("corr_double", &CC::corr_double, R"pbdoc(Do correlation in c++)pbdoc");
-
-    py::class_<CC::StackClass<float, xt::pyarray<float>, xt::pyarray<float>>>(m, "StackClass_float")
-        .def(py::init<xt::pyarray<float>&, std::string, bool, float, float, bool, float, float, bool, int, int>())
-        .def("run", &CC::StackClass<float, xt::pyarray<float>, xt::pyarray<float>>::run)
-        .def("get_ngood", &CC::StackClass<float, xt::pyarray<float>, xt::pyarray<float>>::get_ngood)
-        .def("get_stackdata", &CC::StackClass<float, xt::pyarray<float>, xt::pyarray<float>>::get_stackdata);
-
-    py::class_<CC::StackClass<double, xt::pyarray<double>, xt::pyarray<double>>>(m, "StackClass_double")
-        .def(py::init<xt::pyarray<double>&, std::string, bool, float, float, bool, float, float, bool, int, int>())
-        .def("run", &CC::StackClass<double, xt::pyarray<double>, xt::pyarray<double>>::run)
-        .def("get_ngood", &CC::StackClass<double, xt::pyarray<double>, xt::pyarray<double>>::get_ngood)
-        .def("get_stackdata", &CC::StackClass<double, xt::pyarray<double>, xt::pyarray<double>>::get_stackdata);
-
-
-#ifdef VERSION_INFO
-    m.attr("__version__") = MACRO_STRINGIFY(VERSION_INFO);
-#else
-    m.attr("__version__") = "dev";
-#endif
-
-}
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+// Note: this file is used for generated a shared library for pythonic user.
+
+
+// base libraries
+#include <iostream>
+#include <string>
+
+// external libraries
+#include <pybind11/pybind11.h>
+#include <pybind11/stl.h>
+#define STRINGIFY(x) #x
+#define MACRO_STRINGIFY(x) STRINGIFY(x)
+#define FORCE_IMPORT_ARRAY // FORCE_IMPORT_ARRAY must be defined before including any header of xtensor-python, and must be defined only once.
+
+// me libraries
+#include "rfft.hpp"
+#include "corr.hpp"
+#include "stack.hpp"
+
+
+
+// **************************************************************************
+// *                        CC
+// **************************************************************************
+namespace CC {
+
+
+// ******** float version ********
+xt::pyarray<std::complex<float>> rfft_float(xt::pyarray<float>& raw_data, float dt, float cc_len, float cc_step, std::string time_norm, float clip_std, int smooth_N, std::string freq_norm, float freqmin, float freqmax, int whiten_npad, int smoothspect_N, bool flag, int flag_gap, int threads){
+    // Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
+    RFFTClass<float, xt::pyarray<float>, xt::pyarray<std::complex<float>>>  nfpy(raw_data, dt, cc_len, cc_step, time_norm, clip_std, smooth_N, freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N, flag, flag_gap, threads);
+    nfpy.run();
+
+    return nfpy.get_rfftdata();
+}
+
+
+xt::pyarray<float> corr_float(xt::pyarray<std::complex<float>>& rfft_data, float dt, std::string corr_method, xt::xtensor<int, 2> corr_pair, float maxlag, int smoothspect_N, bool flag, int flag_gap, int threads){
+    // Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
+    CorrClass<float, xt::pyarray<std::complex<float>>, xt::pyarray<float>>  nfpy(rfft_data, dt, corr_method, corr_pair, maxlag, smoothspect_N, flag, flag_gap, threads);
+    nfpy.run();
+
+    return nfpy.get_corrdata();
+}
+
+
+// ******** double version ********
+xt::pyarray<std::complex<double>> rfft_double(xt::pyarray<double>& raw_data, float dt, float cc_len, float cc_step, std::string time_norm, float clip_std, int smooth_N, std::string freq_norm, float freqmin, float freqmax, int whiten_npad, int smoothspect_N, bool flag, int flag_gap, int threads){
+    // Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
+    RFFTClass<double, xt::pyarray<double>, xt::pyarray<std::complex<double>>>  nfpy(raw_data, dt, cc_len, cc_step, time_norm, clip_std, smooth_N, freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N, flag, flag_gap, threads);
+    nfpy.run();
+
+    return nfpy.get_rfftdata();
+}
+
+
+xt::pyarray<double> corr_double(xt::pyarray<std::complex<double>>& rfft_data, float dt, std::string corr_method, xt::xtensor<int, 2> corr_pair, float maxlag, int smoothspect_N, bool flag, int flag_gap, int threads){
+    // Template (T1, T2, T3) = (data-type, input-array-type, output-array-type)
+    CorrClass<double, xt::pyarray<std::complex<double>>, xt::pyarray<double>>  nfpy(rfft_data, dt, corr_method, corr_pair, maxlag, smoothspect_N, flag, flag_gap, threads);
+    nfpy.run();
+
+    return nfpy.get_corrdata();
+}
+
+}
+
+
+
+
+// **************************************************************************
+// *                        PYBIND11_MODULE
+// **************************************************************************
+namespace py = pybind11;
+
+PYBIND11_MODULE(cc_share,m) 
+{
+    xt::import_numpy();
+
+    m.doc() = "Cross-correlation module for NoiseFlow";
+    
+    m.def("rfft_float", &CC::rfft_float, R"pbdoc(Do rfft in c++)pbdoc");
+    m.def("rfft_double", &CC::rfft_double, R"pbdoc(Do rfft in c++)pbdoc");
+
+    m.def("corr_float", &CC::corr_float, R"pbdoc(Do correlation in c++)pbdoc");
+    m.def("corr_double", &CC::corr_double, R"pbdoc(Do correlation in c++)pbdoc");
+
+    py::class_<CC::StackClass<float, xt::pyarray<float>, xt::pyarray<float>>>(m, "StackClass_float")
+        .def(py::init<xt::pyarray<float>&, std::string, bool, float, float, bool, float, float, bool, int, int>())
+        .def("run", &CC::StackClass<float, xt::pyarray<float>, xt::pyarray<float>>::run)
+        .def("get_ngood", &CC::StackClass<float, xt::pyarray<float>, xt::pyarray<float>>::get_ngood)
+        .def("get_stackdata", &CC::StackClass<float, xt::pyarray<float>, xt::pyarray<float>>::get_stackdata);
+
+    py::class_<CC::StackClass<double, xt::pyarray<double>, xt::pyarray<double>>>(m, "StackClass_double")
+        .def(py::init<xt::pyarray<double>&, std::string, bool, float, float, bool, float, float, bool, int, int>())
+        .def("run", &CC::StackClass<double, xt::pyarray<double>, xt::pyarray<double>>::run)
+        .def("get_ngood", &CC::StackClass<double, xt::pyarray<double>, xt::pyarray<double>>::get_ngood)
+        .def("get_stackdata", &CC::StackClass<double, xt::pyarray<double>, xt::pyarray<double>>::get_stackdata);
+
+
+#ifdef VERSION_INFO
+    m.attr("__version__") = MACRO_STRINGIFY(VERSION_INFO);
+#else
+    m.attr("__version__") = "dev";
+#endif
+
+}
```

## noiseflow/cc/stackdata.py

 * *Ordering differences only*

```diff
@@ -1,869 +1,869 @@
-import os
-import h5py
-import numpy as np
-import matplotlib.pyplot as plt
-import matplotlib.colors as mcolors
-
-from scipy.io import savemat
-from obspy.core import UTCDateTime
-from obspy.signal.filter import bandpass
-from noiseflow.cc.utils_time import time_linspace
-
-
-class StackData_Class(object):
-    def __init__(self, stack_data, stack_ngood, dt,
-                 stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads, jobs, py):
-        self.stack_data = stack_data
-        self.stack_ngood = stack_ngood
-        self.dt = dt
-        self.stack_method = stack_method
-        self.par = par
-        self.stack_all = stack_all
-        self.stack_len = stack_len
-        self.stack_step = stack_step
-        self.pick = pick
-        self.median_high = median_high
-        self.median_low = median_low
-        self.flag=flag
-        self.flag_gap=flag_gap
-        self.threads=threads
-        self.jobs=jobs
-        self.py=py
-
-    # save data
-    def save(self, save_path, format='npz', compression=False, h5_compression_format='gzip', h5_compression_opts=3):
-        self.maxlag = self.dt * (self.stack_data.shape[2]-1)/2
-
-        if format == 'npz':
-            if compression:
-                np.savez_compressed(save_path,
-                                    stack_data = self.stack_data,
-                                    stack_ngood = self.stack_ngood,
-                                    dt = self.dt,
-                                    stack_method = self.stack_method,
-                                    par = self.par,
-                                    stack_all = self.stack_all,
-                                    stack_len = self.stack_len,
-                                    stack_step = self.stack_step,
-                                    pick = self.pick,
-                                    median_high = self.median_high,
-                                    median_low = self.median_low,
-                                    flag = self.flag,
-                                    flag_gap = self.flag_gap,
-                                    threads = self.threads,
-                                    jobs = self.jobs,
-                                    py = self.py,
-                                    maxlag = self.maxlag)
-            else:
-                np.savez(save_path,
-                        stack_data = self.stack_data,
-                        stack_ngood = self.stack_ngood,
-                        dt = self.dt,
-                        stack_method = self.stack_method,
-                        par = self.par,
-                        stack_all = self.stack_all,
-                        stack_len = self.stack_len,
-                        stack_step = self.stack_step,
-                        pick = self.pick,
-                        median_high = self.median_high,
-                        median_low = self.median_low,
-                        flag = self.flag,
-                        flag_gap = self.flag_gap,
-                        threads = self.threads,
-                        jobs = self.jobs,
-                        py = self.py,
-                        maxlag = self.maxlag)
-                
-        elif format == 'h5':
-            par_copy = self.par.copy()
-            with h5py.File(save_path, 'w') as f:
-                group = f.create_group('noiseflow_group')
-                group.attrs['dt'] = self.dt
-                group.attrs['stack_method'] = self.stack_method
-                group.attrs['stack_all'] = self.stack_all
-                group.attrs['stack_len'] = self.stack_len
-                group.attrs['stack_step'] = self.stack_step
-                group.attrs['pick'] = self.pick
-                group.attrs['median_high'] = self.median_high
-                group.attrs['median_low'] = self.median_low
-                group.attrs['flag'] = self.flag
-                group.attrs['flag_gap'] = self.flag_gap
-                group.attrs['threads'] = self.threads
-                group.attrs['jobs'] = self.jobs
-                group.attrs['py'] = self.py
-                group.attrs['maxlag'] = self.maxlag
-
-                for key, value in par_copy.items():
-                    if value is None:
-                        value = float('nan')
-                    group.attrs[key] = value
-
-                group.create_dataset('stack_ngood', data=self.stack_ngood)
-                if compression:
-                    group.create_dataset('stack_data', data=self.stack_data, compression=h5_compression_format, compression_opts=h5_compression_opts)
-                else:
-                    group.create_dataset('stack_data', data=self.stack_data)
-
-        elif format == 'mat':
-            par_copy = self.par.copy()
-            for key, value in par_copy.items():
-                if value is None:
-                    par_copy[key] = np.nan
-
-            savemat(save_path,
-                {'stack_data': self.stack_data,
-                'stack_ngood': self.stack_ngood,
-                'dt': self.dt,
-                'stack_method': self.stack_method,
-                'par': par_copy,
-                'stack_all': self.stack_all,
-                'stack_len': self.stack_len,
-                'stack_step': self.stack_step,
-                'pick': self.pick,
-                'median_high': self.median_high,
-                'median_low': self.median_low,
-                'flag': self.flag,
-                'flag_gap': self.flag_gap,
-                'threads': self.threads,
-                'jobs': self.jobs,
-                'py': self.py,
-                'maxlag': self.maxlag},
-                do_compression=compression)
-        else:
-            raise ValueError("format must be 'npz', 'h5' or 'mat'")
-        
-
-    # plot
-    def plot(self, 
-             pair_indx=0, 
-             t_min=UTCDateTime("1970-01-01T00:00:00.0"), 
-             stack_len=1, 
-             stack_step=0, 
-             cc_len=None, 
-             cc_step=None, 
-             win_start=None, 
-             win_end=None, 
-             lag_start=None, 
-             lag_end=None, 
-             amp_normalize=True, 
-             amp_scale=1, 
-             filter=False, 
-             f1=None, 
-             f2=None, 
-             corners=4, 
-             zerophase=True, 
-             win_interval=None, 
-             mode='waveform', 
-             cmap='seismic', 
-             linewidth=0.8,
-             yticklabel_num=5, 
-             figsize=(10, 6),
-             ngood_label=False, 
-             save=False, 
-             save_path=None, 
-             dpi=300): 
-        
-        self.maxlag = self.dt * (self.stack_data.shape[2]-1)/2
-
-        # check pair_indx
-        if pair_indx >= self.stack_data.shape[0]:
-            raise ValueError("pair_indx must be smaller than stack_data.shape[0]=%d" % self.stack_data.shape[0])
-
-        # init cc_len cc_step
-        if cc_len == None:
-            cc_len = self.stack_data.shape[2]*self.dt
-        if cc_step == None:
-            cc_step = 0.0
-
-        # define time vector
-        stack_win_num = self.stack_data.shape[1]
-        corr_win_num = (stack_len-stack_step)*(stack_win_num-1) + stack_len
-        t_max = t_min + (corr_win_num-1)*(cc_len-cc_step) + cc_len
-        stack_interval = (stack_len-stack_step)*(cc_len-cc_step)
-        win_vector = np.array([t_min + i*stack_interval for i in range(0, stack_win_num)])
-
-        # init win_start
-        if win_start == None:
-            win_start = t_min
-        if win_start < t_min:
-            raise ValueError("win_start must be larger than t_min=%s" % str(t_min))
-
-        # init win_end
-        if win_end == None:
-            win_end = t_max
-        if win_end > t_max:
-            raise ValueError("win_end must be smaller than t_max=%s" % str(t_max))
-
-        # init lag_start 
-        if lag_start == None:
-            lag_start = -self.maxlag
-        if lag_start < -self.maxlag:
-            raise ValueError("lag_start must be larger than -maxlag=-%f" % self.maxlag)
-        
-        # init lag_end
-        if lag_end == None:
-            lag_end = self.maxlag
-        if lag_end > self.maxlag:
-            raise ValueError("lag_end must be smaller than maxlag=%f" % self.maxlag)
-        
-        # lag vector
-        tt = np.arange(lag_start, lag_end+self.dt, self.dt)
-        tp_start = round((lag_start+self.maxlag)/self.dt)
-        tp_end = tp_start+len(tt)  # make sure same length, so do not use round((lag_end+self.maxlag+self.dt)/self.dt)
-
-        # check win_interval
-        if win_interval == None:
-            win_interval = (stack_len-stack_step)*(cc_len-cc_step)
-        if win_interval < (stack_len-stack_step)*(cc_len-cc_step):
-            raise ValueError("win_interval must be larger than (stack_len-stack_step)*(cc_len-cc_step)=%f" % (stack_len-stack_step)*(cc_len-cc_step))
-        if win_interval > t_max-stack_len*(cc_len-cc_step)-t_min:
-            raise ValueError("win_interval must be smaller than t_max-stack_len*(cc_len-cc_step)-t_min=%f" % (t_max-stack_len*(cc_len-cc_step)-t_min))
-        
-        # select win_indx data and filter --> data, ngood
-        win_indx = np.where((win_vector >= win_start) & (win_vector <= win_end))[0]
-        ngood = self.stack_ngood[pair_indx, win_indx]
-        if filter:
-            data=np.empty((len(win_indx), len(tt)))
-            for i in range(0, len(win_indx)):
-                data[i,:] = bandpass(self.stack_data[pair_indx, win_indx[i], tp_start:tp_end], f1, f2, int(1/self.dt), corners=corners, zerophase=zerophase)
-        else:
-            data = self.stack_data[pair_indx, win_indx, tp_start:tp_end]
-
-        # plot
-        if mode == 'waveform':
-            # init figure
-            fig, ax = plt.subplots(1, 2, gridspec_kw=dict(width_ratios=[5, 1]), sharey="row", figsize=figsize)
-            fig.subplots_adjust(wspace=0.01)
-
-            # normalize
-            if amp_normalize:
-                scale = np.max(np.abs(data), axis=1)[:,None]
-                if np.min(scale) != 0:
-                    data_plot = amp_scale*data/scale
-                else:
-                    raise ValueError("data is all zeros in amp_normalize=True")
-            else:
-                scale = np.max(np.abs(data))
-                if scale != 0:
-                    data_plot = amp_scale*data/scale
-                else:
-                    raise ValueError("data is all zeros in amp_normalize=False")
-
-            # select win_interval data
-            ydist_n=[]
-            ngood_n=[]
-            win_interval_n = round(win_interval/((stack_len-stack_step)*(cc_len-cc_step)))
-            for i in range(0, len(win_indx), win_interval_n):
-                ydist_n.append(i)
-                ngood_n.append(ngood[i])
-            ydist_n = np.array(ydist_n)
-            ngood_n = np.array(ngood_n)
-
-            # plot wavefrom
-            for i in range(0, len(ydist_n)):
-                ax[0].plot(tt, data_plot[int(ydist_n[i])]+ydist_n[i], 'k', linewidth=linewidth)
-            
-            # set x axis
-            ax[0].set_title("StackData: pair_indx=%d, filter=[%.2f, %.2f] hz" % (pair_indx, f1, f2))
-            ax[0].set_xlim(tt[0], tt[-1])
-            ax[0].set_xlabel('Time(s)')
-            
-            # set y axis
-            yy_tick = np.linspace(0, len(win_indx)-1, num=yticklabel_num)
-            yy_label_UTC = time_linspace(win_start, win_end, num=yticklabel_num)
-            yy_label = np.array([i.strftime('%Y-%m-%dT%H:%M:%S') for i in yy_label_UTC])
-            ax[0].set_yticks(yy_tick)
-            ax[0].set_yticklabels(yy_label, rotation=45)
-
-            # plot ngood 
-            (markers, stemlines, baseline) = ax[1].stem(ydist_n, ngood_n, orientation='horizontal')
-            plt.setp(markers, marker='D', markeredgecolor="orange", markeredgewidth=1.5)
-            plt.setp(stemlines, linestyle="-", color="olive", linewidth=linewidth)
-            if ngood_label:
-                for i in range(0, len(ngood_n)):
-                    ax[1].text(ngood_n[i]+np.max(ngood_n)/10, ydist_n[i], int(ngood_n[i]), va='center', ha='left')
-
-            ax[1].set_xlim(0, np.max(ngood_n)*1.2)
-            ax[1].set_xlabel('Ngood')
-            ax[1].get_yaxis().set_visible(False)
-            ax[1].spines['top'].set_visible(False)
-            ax[1].spines['right'].set_visible(False)
-            ax[1].spines['bottom'].set_visible(True)
-            ax[1].spines['left'].set_visible(True)
-
-            # save or show
-            if save:
-                if save_path is None:
-                    raise ValueError("save_path must be specified")
-                fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight')
-                plt.close(fig)
-            else:
-                plt.show()
-
-        elif mode == 'mat':
-            # init figure
-            fig, ax = plt.subplots(1, 2, gridspec_kw=dict(width_ratios=[5, 1]), sharey="row", figsize=figsize)
-            fig.subplots_adjust(wspace=0.01)
-
-            # average waveforms
-            cc_mean = np.mean(data, axis=0)/np.max(np.mean(data, axis=0))
-            ntrace = int((win_end-win_start)/win_interval)
-            ndata  = np.zeros(shape=(ntrace,len(tt)))
-            for i in range(0,ntrace):
-                tindx = np.where(((win_vector-win_start)>=i*win_interval) & ((win_vector-win_start)<(i+1)*win_interval))[0]
-                ndata[i] = np.mean(data[tindx],axis=0)
-
-            # normalize waveforms
-            if amp_normalize:
-                scale = np.max(np.abs(ndata), axis=1)[:,None]
-                if np.min(scale) != 0:
-                    ndata_plot = ndata/scale
-                else:
-                    raise ValueError("data is all zeros in amp_normalize=True")
-            else:
-                scale = np.max(np.abs(ndata))
-                if scale != 0:
-                    ndata_plot = ndata/scale
-                else:
-                    raise ValueError("data is all zeros in amp_normalize=False")
-                
-            ### plot mat
-            cax=ax[0].matshow(ndata_plot, extent=[lag_start, lag_end, ntrace, 0], aspect='auto', cmap=cmap)
-            ax[0].plot(tt,ntrace/10*cc_mean+ntrace/2,'k',linewidth=linewidth)
-            
-            # set x axis
-            ax[0].set_title("StackData: pair_indx=%d, filter=[%.2f, %.2f] hz" % (pair_indx, f1, f2))
-            ax[0].set_xlim(tt[0], tt[-1])
-            ax[0].set_xlabel('Time(s)')
-            ax[0].xaxis.set_ticks_position('bottom')
-
-            # set y axis
-            ax[0].invert_yaxis()
-            ax[0].set_ylim(0, ntrace)
-            yy_tick = np.linspace(0, ntrace, num=yticklabel_num)
-            yy_label_UTC = time_linspace(win_start, win_end, num=yticklabel_num)
-            yy_label = np.array([i.strftime('%Y-%m-%dT%H:%M:%S') for i in yy_label_UTC])
-            ax[0].set_yticks(yy_tick)
-            ax[0].set_yticklabels(yy_label, rotation=45)
-
-            ### plot ngood
-            ngood = self.stack_ngood[pair_indx, win_indx]
-            yy = np.linspace(0, ntrace, len(ngood))
-            (markers, stemlines, baseline) = ax[1].stem(yy, ngood, orientation='horizontal')
-            plt.setp(markers, marker='D', markeredgecolor="orange", markeredgewidth=1.5)
-            plt.setp(stemlines, linestyle="-", color="olive", linewidth=linewidth)
-            if ngood_label:
-                for i in range(0, len(ngood)):
-                    ax[1].text(ngood[i]+np.max(ngood)/10, yy[i], int(ngood[i]), va='center', ha='left')
-
-            ax[1].set_xlim(0, np.max(ngood)*1.2)
-            ax[1].set_xlabel('Ngood')
-            ax[1].get_yaxis().set_visible(False)
-            ax[1].spines['top'].set_visible(False)
-            ax[1].spines['right'].set_visible(False)
-            ax[1].spines['bottom'].set_visible(True)
-            ax[1].spines['left'].set_visible(True)
-            
-            # save
-            if save:
-                if save_path is None:
-                    raise ValueError("save_path must be specified")
-                fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches = 'tight') 
-                plt.close(fig)
-            else:
-                plt.show()
-
-        else:
-            raise ValueError("mode must be 'waveform' or 'mat'")
-        
-
-
-    def plot_moveout(self, 
-                corr_pair, 
-                pair_dist, 
-                source_indx=None, 
-                receiver_indx=None, 
-                dist_start=None, 
-                dist_end=None, 
-                amp_scale=1, 
-                amp_normalize=True,
-                win_num = 0, 
-                lag_start=None, 
-                lag_end=None, 
-                filter=False, 
-                f1=None, 
-                f2=None, 
-                corners=4, 
-                zerophase=True, 
-                dist_interval=None, 
-                mode='waveform', 
-                cmap='seismic',
-                linewidth=0.8, 
-                yticklabel_num=10, 
-                figsize=(10, 6),
-                dist_unit="m", 
-                velocity=[], 
-                save=False, 
-                save_path=None, 
-                dpi=100): 
-        
-        self.maxlag = self.dt * (self.stack_data.shape[2]-1)/2
-
-        # check source_indx and receiver_indx
-        if source_indx != None and receiver_indx != None:
-            raise ValueError("source_indx and receiver_indx cannot be specified at the same time")
-        elif source_indx != None:
-            if source_indx not in corr_pair[:,0]:
-                raise ValueError("source_indx must be in corr_pair[:,0]")
-        elif receiver_indx != None:
-            if receiver_indx not in corr_pair[:,1]:
-                raise ValueError("receiver_indx must be in corr_pair[:,1]")
-        else:
-            raise ValueError("source_indx or receiver_indx must be specified")
-        
-        # check corr_pair pair_dist
-        if corr_pair.shape[0] != len(pair_dist):
-            raise ValueError("the length of corr_pair is not consistent with pair_dist")
-        
-        # check demision of pair_dist
-        if pair_dist.ndim == 2:
-            pair_dist = pair_dist.reshape(-1)
-
-        # check dist_unit
-        if dist_unit not in ['m', 'km', 'degree']:
-            raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
-        
-        # init dist_start
-        if dist_start == None:
-            dist_start = np.min(pair_dist)
-        if dist_start < np.min(pair_dist):
-            raise ValueError("dist_start must be >= (np.min(pair_dist)=%f)" % np.min(pair_dist))
-        
-        # init dist_end
-        if dist_end == None:
-            dist_end = np.max(pair_dist)
-        if dist_end > np.max(pair_dist):
-            raise ValueError("dist_end must be <= (np.max(pair_dist)=%f)" % np.max(pair_dist))
-
-        # init lag_start 
-        if lag_start == None:
-            lag_start = -self.maxlag
-        if lag_start < -self.maxlag:
-            raise ValueError("lag_start must be >= (-maxlag=-%f)" % self.maxlag)
-        
-        # init lag_end
-        if lag_end == None:
-            lag_end = self.maxlag
-        if lag_end > self.maxlag:
-            raise ValueError("lag_end must be <= (maxlag=%f)" % self.maxlag)
-        
-        # lag vector
-        tt = np.arange(lag_start, lag_end+self.dt, self.dt)
-        tp_start = round((lag_start+self.maxlag)/self.dt)
-        tp_end = tp_start+len(tt)  # make sure same length, so do not use round((lag_end+self.maxlag+self.dt)/self.dt)
-
-        # select dist_start dist_end
-        if source_indx != None:
-            a_id = np.where((corr_pair[:,0]==source_indx))[0]
-            b_id = np.where((pair_dist>=dist_start) & (pair_dist<=dist_end))[0]
-            id = np.intersect1d(a_id ,b_id)
-        elif receiver_indx != None:
-            a_id = np.where((corr_pair[:,1]==receiver_indx))[0]
-            b_id = np.where((pair_dist>=dist_start) & (pair_dist<=dist_end))[0]
-            id = np.intersect1d(a_id, b_id)
-        else:
-            raise ValueError("source_indx or receiver_indx must be specified")
-        dist = pair_dist[id]
-
-        # init dist_interval
-        if dist_interval == None:
-            dist_interval = np.min(dist)
-        if dist_interval < np.diff(np.sort(dist)).min():
-            raise ValueError("win_interval must be >= (np.diff(np.sort(dist)).min()=%f)" % np.diff(np.sort(dist)).min())
-        if dist_interval > np.max(dist):
-            raise ValueError("win_interval must be <= (np.max(dist)=%f)" % np.max(dist))
-        
-        # filter --> data
-        if filter:
-            data=np.empty((len(id), len(tt)))
-            for i in range(0, len(id)):
-                data[i,:] = bandpass(self.stack_data[id[i], win_num, tp_start:tp_end], f1, f2, int(1/self.dt), corners=corners, zerophase=zerophase)
-        else:
-            data = self.stack_data[id, win_num, tp_start:tp_end]
-            
-        # plot
-        colors = list(mcolors.TABLEAU_COLORS.keys())
-        if mode == 'waveform':
-            if data.size != 0:
-                # init fig
-                fig, ax = plt.subplots(figsize=figsize)
-
-                # normalize data
-                if amp_normalize:
-                    scale = np.max(np.abs(data), axis=1)[:,None]
-                    if np.min(scale) != 0:
-                        data_plot = amp_scale*data/scale
-                    else:
-                        raise ValueError("data is all zeros in amp_normalize=True")
-                else:
-                    scale = np.max(np.abs(data))
-                    if scale != 0:
-                        data_plot = amp_scale*data/scale
-                    else:
-                        raise ValueError("data is all zeros in amp_normalize=False")
-                
-                # plot waveform
-                for i in range(0, data_plot.shape[0]):
-                    ax.plot(tt, amp_scale*data_plot[i]+dist[i], 'k', linewidth=linewidth)
-
-                # plot velocity
-                for i in range(0, len(velocity)):
-                    x0=0; y0=0
-                    if dist_unit == 'm':
-                        x1 = (dist_end-dist_start)/velocity[i]
-                        y1 = dist_end
-                    elif dist_unit == 'km':
-                        x1 = (dist_end-dist_start)/1000/velocity[i]
-                        y1 = dist_end
-                    elif dist_unit == 'degree':
-                        x1 = (dist_end-dist_start)/(111.2*1000)/velocity[i]
-                        y1 = dist_end
-                    else:
-                        raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
-                    ax.plot([x0,x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5, label=str(velocity[i])+'m/s')
-                    ax.plot([x0,-x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5)
-
-                # set legend
-                ax.legend(loc='upper right', fontsize=8, shadow=False)
-                ax.set_xlim(tt[0], tt[-1])
-                ax.set_xlabel('Time(s)')
-                ax.set_ylabel('Distance(%s)' % (dist_unit))
-
-                # set title
-                if source_indx != None:
-                    ax.set_title("StackData: source_indx=%d, win_num=%d, filter=[%.2f, %.2f] hz" % (source_indx, win_num, f1, f2))
-                elif receiver_indx != None:
-                    ax.set_title("StackData: receiver_indx=%d, win_num=%d, filter=[%.2f, %.2f] hz" % (source_indx, win_num, f1, f2))
-                else:
-                    raise ValueError("source_indx or receiver_indx must be specified")
-            
-                # save or show
-                if save:
-                    if save_path is None:
-                        raise ValueError("save_path must be specified")
-                    fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches = 'tight') 
-                    plt.close(fig)
-                else:
-                    plt.show()
-            else:
-                raise ValueError("data is empty")
-
-        elif mode=="mat":
-            if data.size != 0:
-                # init fig
-                fig, ax = plt.subplots(figsize=figsize)
-
-                # average waveforms
-                ntrace = int((dist_end-dist_start)/dist_interval)
-                ndata  = np.zeros(shape=(ntrace,len(tt)))
-                for i in range(0,ntrace):
-                    tindx = np.where(((dist-dist_start)>=i*dist_interval) & ((dist-dist_start)<(i+1)*dist_interval))[0]
-                    ndata[i] = np.mean(data[tindx],axis=0)
-
-                # normalize waveforms
-                if amp_normalize:
-                    scale = np.max(np.abs(ndata), axis=1)[:,None]
-                    if np.min(scale) != 0:
-                        ndata_plot = ndata/scale
-                    else:
-                        raise ValueError("data is all zeros in amp_normalize=True")
-                else:
-                    scale = np.max(np.abs(ndata))
-                    if scale != 0:
-                        ndata_plot = ndata/scale
-                    else:
-                        raise ValueError("data is all zeros in amp_normalize=False")
-                
-                # plot
-                cax=ax.matshow(ndata_plot, extent=[lag_start, lag_end, ntrace, 0], aspect='auto', cmap=cmap) # cmap=cmaps.MPL_jet,
-                for i in range(0, len(velocity)):
-                    x0=0
-                    y0=0
-                    if dist_unit == 'm':
-                        x1 = (dist_end-dist_start)/velocity[i]
-                        y1 = ntrace
-                    elif dist_unit == 'km':
-                        x1 = (dist_end-dist_start)/1000/velocity[i]
-                        y1 = ntrace
-                    elif dist_unit == 'degree':
-                        x1 = (dist_end-dist_start)/(111.2*1000)/velocity[i]
-                        y1 = ntrace
-                    else:
-                        raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
-                    ax.plot([x0,x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5, label=str(velocity[i])+'m/s')
-                    ax.plot([x0,-x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5)
-
-                # set x axis
-                ax.legend(loc='upper right', fontsize=7, shadow=False)
-                ax.set_xlim(tt[0], tt[-1])
-                ax.xaxis.set_ticks_position('bottom')
-                ax.set_xlabel('Time(s)')
-
-                # set y axis
-                ax.invert_yaxis()
-                yy_tick=np.linspace(0, ntrace, num=yticklabel_num)
-                yy_label = np.around(np.linspace(dist_start, dist_end, num=yticklabel_num), decimals=2)
-                ax.set_yticks(yy_tick)
-                ax.set_yticklabels(yy_label)
-                ax.set_ylabel('Distance(%s)' % (dist_unit))
-
-                # set title
-                if source_indx != None:
-                    ax.set_title("StackData: source_indx=%d, win_num=%d, filter=[%.2f, %.2f] hz" % (source_indx, win_num, f1, f2))
-                elif receiver_indx != None:
-                    ax.set_title("StackData: receiver_indx=%d, win_num=%d, filter=[%.2f, %.2f] hz" % (source_indx, win_num, f1, f2))
-                else:
-                    raise ValueError("source_indx or receiver_indx must be specified")
-                
-                # save or show
-                if save:
-                    if save_path is None:
-                        raise ValueError("save_path must be specified")
-                    fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight') 
-                    plt.close(fig)
-                else:
-                    plt.show()
-            else:
-                raise ValueError("data is empty")
-            
-        else:
-            raise ValueError("mode must be 'waveform' or 'mat'")
-
-
-
-    def plot_moveout_all(self, 
-                 corr_pair, 
-                 pair_dist, 
-                 dist_start=None, 
-                 dist_end=None, 
-                 amp_scale=1,
-                 amp_normalize=True, 
-                 win_num = 0, 
-                 lag_start=None, 
-                 lag_end=None, 
-                 filter=False, 
-                 f1=None, 
-                 f2=None,
-                 corners=4, 
-                 zerophase=True,  
-                 dist_interval=None, 
-                 mode='waveform', 
-                 cmap='seismic', 
-                 linewidth=0.8,
-                 yticklabel_num=10, 
-                 figsize=(10, 6),
-                 dist_unit="m", 
-                 velocity=[], 
-                 save=False, 
-                 save_path=None, 
-                 dpi=30):      
-        
-        self.maxlag = self.dt * (self.stack_data.shape[2]-1)/2
-        
-        # check corr_pair pair_dist
-        if corr_pair.shape[0] != len(pair_dist):
-            raise ValueError("the length of corr_pair is not consistent with pair_dist")
-        
-        # check demision of pair_dist
-        if pair_dist.ndim == 2:
-            pair_dist = pair_dist.reshape(-1)
-        
-        # check dist_unit
-        if dist_unit not in ['m', 'km', 'degree']:
-            raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
-        
-        # init dist_start
-        if dist_start == None:
-            dist_start = np.min(pair_dist)
-        if dist_start < np.min(pair_dist):
-            raise ValueError("dist_start must be >= (min(pair_dist)=%f)" % np.min(pair_dist))
-        
-        # init dist_end
-        if dist_end == None:
-            dist_end = np.max(pair_dist)
-        if dist_end > np.max(pair_dist):
-            raise ValueError("dist_end must be <= (max(pair_dist)=%f)" % np.max(pair_dist))
-
-        # init lag_start 
-        if lag_start == None:
-            lag_start = -self.maxlag
-        if lag_start < -self.maxlag:
-            raise ValueError("lag_start must be >= (-maxlag=-%f)" % self.maxlag)
-        
-        # init lag_end
-        if lag_end == None:
-            lag_end = self.maxlag
-        if lag_end > self.maxlag:
-            raise ValueError("lag_end must be <= (maxlag=%f)" % self.maxlag)
-        
-        # lag vector
-        tt = np.arange(lag_start, lag_end+self.dt, self.dt)
-        tp_start = round((lag_start+self.maxlag)/self.dt)
-        tp_end = tp_start+len(tt)  # make sure same length, so do not use round((lag_end+self.maxlag+self.dt)/self.dt)
-
-        # select dist_start dist_end
-        id = np.where((pair_dist>=dist_start) & (pair_dist<=dist_end))[0]
-        dist = pair_dist[id]
-
-        # init dist_interval
-        if dist_interval == None:
-            dist_interval = np.min(dist)
-        if dist_interval < np.diff(np.sort(dist)).min():
-            raise ValueError("win_interval must be >= (np.diff(np.sort(dist)).min()=%f)" % np.diff(np.sort(dist)).min())
-        if dist_interval > np.max(dist):
-            raise ValueError("win_interval must be <= (np.max(dist)=%f)" % np.max(dist))
-        
-        # filter --> data
-        if filter:
-            data=np.empty((len(id), len(tt)))
-            for i in range(0, len(id)):
-                data[i,:] = bandpass(self.stack_data[id[i], win_num, tp_start:tp_end], f1, f2, int(1/self.dt), corners=corners, zerophase=zerophase)
-        else:
-            data = self.stack_data[id, win_num, tp_start:tp_end]
-            
-        # plot
-        colors = list(mcolors.TABLEAU_COLORS.keys())
-        if mode == 'waveform':
-            if data.size != 0:
-                # init fig
-                fig, ax = plt.subplots(figsize=figsize)
-
-                # normalize data
-                if amp_normalize:
-                    scale = np.max(np.abs(data), axis=1)[:,None]
-                    if np.min(scale) != 0:
-                        data_plot = amp_scale*data/scale
-                    else:
-                        raise ValueError("data is all zeros in amp_normalize=True")
-                else:
-                    scale = np.max(np.abs(data))
-                    if scale != 0:
-                        data_plot = amp_scale*data/scale
-                    else:
-                        raise ValueError("data is all zeros in amp_normalize=False")
-                
-                # plot waveform
-                for i in range(0, data_plot.shape[0]):
-                    ax.plot(tt, amp_scale*data_plot[i]+dist[i], 'k', linewidth=linewidth)
-
-                # plot velocity
-                for i in range(0, len(velocity)):
-                    x0=0; y0=0
-                    if dist_unit == 'm':
-                        x1 = (dist_end-dist_start)/velocity[i]
-                        y1 = dist_end
-                    elif dist_unit == 'km':
-                        x1 = (dist_end-dist_start)/1000/velocity[i]
-                        y1 = dist_end
-                    elif dist_unit == 'degree':
-                        x1 = (dist_end-dist_start)/(111.2*1000)/velocity[i]
-                        y1 = dist_end
-                    else:
-                        raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
-                    ax.plot([x0,x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5, label=str(velocity[i])+'m/s')
-                    ax.plot([x0,-x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5)
-
-                # set axis
-                ax.set_xlim(tt[0], tt[-1])
-                ax.set_xlabel('Time(s)')
-                ax.set_ylabel('Distance(%s)' % (dist_unit))
-                ax.legend(loc='upper right', fontsize=8, shadow=False)
-                ax.set_title("StackData: win_num=%d, filter=[%.2f, %.2f] hz" % (win_num, f1, f2))
-            
-                # save or show
-                if save:
-                    if save_path is None:
-                        raise ValueError("save_path must be specified")
-                    fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches = 'tight') 
-                    plt.close(fig)
-                else:
-                    plt.show()
-
-            else:
-                raise ValueError("data is empty")
-
-        elif mode=="mat":
-            if data.size != 0:
-                # init fig
-                fig, ax = plt.subplots(figsize=figsize)
-
-                # average waveforms
-                ntrace = int((dist_end-dist_start)/dist_interval)
-                ndata  = np.zeros(shape=(ntrace,len(tt)))
-                for i in range(0,ntrace):
-                    tindx = np.where(((dist-dist_start)>=i*dist_interval) & ((dist-dist_start)<(i+1)*dist_interval))[0]
-                    ndata[i] = np.mean(data[tindx],axis=0)
-
-                # normalize waveforms
-                if amp_normalize:
-                    scale = np.max(np.abs(ndata), axis=1)[:,None]
-                    if np.min(scale) != 0:
-                        ndata_plot = ndata/scale
-                    else:
-                        raise ValueError("data is all zeros in amp_normalize=True")
-                else:
-                    scale = np.max(np.abs(ndata))
-                    if scale != 0:
-                        ndata_plot = ndata/scale
-                    else:
-                        raise ValueError("data is all zeros in amp_normalize=False")
-                
-                # plot
-                cax=ax.matshow(ndata_plot, extent=[lag_start, lag_end, ntrace, 0], aspect='auto', cmap=cmap) # cmap=cmaps.MPL_jet,
-                for i in range(0, len(velocity)):
-                    x0=0
-                    y0=0
-                    if dist_unit == 'm':
-                        x1 = (dist_end-dist_start)/velocity[i]
-                        y1 = ntrace
-                    elif dist_unit == 'km':
-                        x1 = (dist_end-dist_start)/1000/velocity[i]
-                        y1 = ntrace
-                    elif dist_unit == 'degree':
-                        x1 = (dist_end-dist_start)/(111.2*1000)/velocity[i]
-                        y1 = ntrace
-                    else:
-                        raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
-                    ax.plot([x0,x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5, label=str(velocity[i])+'m/s')
-                    ax.plot([x0,-x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5)
-
-                # set x axis
-                ax.set_title("StackData: win_num=%d, filter=[%.2f, %.2f] hz" % (win_num, f1, f2))
-                ax.legend(loc='upper right', fontsize=7, shadow=False)
-                ax.set_xlim(tt[0], tt[-1])
-                ax.xaxis.set_ticks_position('bottom')
-                ax.set_xlabel('Time(s)')
-
-                # set y axis
-                ax.invert_yaxis()
-                yy_tick=np.linspace(0, ntrace, num=yticklabel_num)
-                yy_label = np.around(np.linspace(dist_start, dist_end, num=yticklabel_num), decimals=2)
-                ax.set_yticks(yy_tick)
-                ax.set_yticklabels(yy_label)
-                ax.set_ylabel('Distance(%s)' % (dist_unit))
-
-                # save or show
-                if save:
-                    if save_path is None:
-                        raise ValueError("save_path must be specified")
-                    fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight') 
-                    plt.close(fig)
-                else:
-                    plt.show()
-            else:
-                raise ValueError("data is empty")
-            
-        else:
-            raise ValueError("mode must be 'waveform' or 'mat'")
-
-
+import os
+import h5py
+import numpy as np
+import matplotlib.pyplot as plt
+import matplotlib.colors as mcolors
+
+from scipy.io import savemat
+from obspy.core import UTCDateTime
+from obspy.signal.filter import bandpass
+from noiseflow.cc.utils_time import time_linspace
+
+
+class StackData_Class(object):
+    def __init__(self, stack_data, stack_ngood, dt,
+                 stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads, jobs, py):
+        self.stack_data = stack_data
+        self.stack_ngood = stack_ngood
+        self.dt = dt
+        self.stack_method = stack_method
+        self.par = par
+        self.stack_all = stack_all
+        self.stack_len = stack_len
+        self.stack_step = stack_step
+        self.pick = pick
+        self.median_high = median_high
+        self.median_low = median_low
+        self.flag=flag
+        self.flag_gap=flag_gap
+        self.threads=threads
+        self.jobs=jobs
+        self.py=py
+
+    # save data
+    def save(self, save_path, format='npz', compression=False, h5_compression_format='gzip', h5_compression_opts=3):
+        self.maxlag = self.dt * (self.stack_data.shape[2]-1)/2
+
+        if format == 'npz':
+            if compression:
+                np.savez_compressed(save_path,
+                                    stack_data = self.stack_data,
+                                    stack_ngood = self.stack_ngood,
+                                    dt = self.dt,
+                                    stack_method = self.stack_method,
+                                    par = self.par,
+                                    stack_all = self.stack_all,
+                                    stack_len = self.stack_len,
+                                    stack_step = self.stack_step,
+                                    pick = self.pick,
+                                    median_high = self.median_high,
+                                    median_low = self.median_low,
+                                    flag = self.flag,
+                                    flag_gap = self.flag_gap,
+                                    threads = self.threads,
+                                    jobs = self.jobs,
+                                    py = self.py,
+                                    maxlag = self.maxlag)
+            else:
+                np.savez(save_path,
+                        stack_data = self.stack_data,
+                        stack_ngood = self.stack_ngood,
+                        dt = self.dt,
+                        stack_method = self.stack_method,
+                        par = self.par,
+                        stack_all = self.stack_all,
+                        stack_len = self.stack_len,
+                        stack_step = self.stack_step,
+                        pick = self.pick,
+                        median_high = self.median_high,
+                        median_low = self.median_low,
+                        flag = self.flag,
+                        flag_gap = self.flag_gap,
+                        threads = self.threads,
+                        jobs = self.jobs,
+                        py = self.py,
+                        maxlag = self.maxlag)
+                
+        elif format == 'h5':
+            par_copy = self.par.copy()
+            with h5py.File(save_path, 'w') as f:
+                group = f.create_group('noiseflow_group')
+                group.attrs['dt'] = self.dt
+                group.attrs['stack_method'] = self.stack_method
+                group.attrs['stack_all'] = self.stack_all
+                group.attrs['stack_len'] = self.stack_len
+                group.attrs['stack_step'] = self.stack_step
+                group.attrs['pick'] = self.pick
+                group.attrs['median_high'] = self.median_high
+                group.attrs['median_low'] = self.median_low
+                group.attrs['flag'] = self.flag
+                group.attrs['flag_gap'] = self.flag_gap
+                group.attrs['threads'] = self.threads
+                group.attrs['jobs'] = self.jobs
+                group.attrs['py'] = self.py
+                group.attrs['maxlag'] = self.maxlag
+
+                for key, value in par_copy.items():
+                    if value is None:
+                        value = float('nan')
+                    group.attrs[key] = value
+
+                group.create_dataset('stack_ngood', data=self.stack_ngood)
+                if compression:
+                    group.create_dataset('stack_data', data=self.stack_data, compression=h5_compression_format, compression_opts=h5_compression_opts)
+                else:
+                    group.create_dataset('stack_data', data=self.stack_data)
+
+        elif format == 'mat':
+            par_copy = self.par.copy()
+            for key, value in par_copy.items():
+                if value is None:
+                    par_copy[key] = np.nan
+
+            savemat(save_path,
+                {'stack_data': self.stack_data,
+                'stack_ngood': self.stack_ngood,
+                'dt': self.dt,
+                'stack_method': self.stack_method,
+                'par': par_copy,
+                'stack_all': self.stack_all,
+                'stack_len': self.stack_len,
+                'stack_step': self.stack_step,
+                'pick': self.pick,
+                'median_high': self.median_high,
+                'median_low': self.median_low,
+                'flag': self.flag,
+                'flag_gap': self.flag_gap,
+                'threads': self.threads,
+                'jobs': self.jobs,
+                'py': self.py,
+                'maxlag': self.maxlag},
+                do_compression=compression)
+        else:
+            raise ValueError("format must be 'npz', 'h5' or 'mat'")
+        
+
+    # plot
+    def plot(self, 
+             pair_indx=0, 
+             t_min=UTCDateTime("1970-01-01T00:00:00.0"), 
+             stack_len=1, 
+             stack_step=0, 
+             cc_len=None, 
+             cc_step=None, 
+             win_start=None, 
+             win_end=None, 
+             lag_start=None, 
+             lag_end=None, 
+             amp_normalize=True, 
+             amp_scale=1, 
+             filter=False, 
+             f1=None, 
+             f2=None, 
+             corners=4, 
+             zerophase=True, 
+             win_interval=None, 
+             mode='waveform', 
+             cmap='seismic', 
+             linewidth=0.8,
+             yticklabel_num=5, 
+             figsize=(10, 6),
+             ngood_label=False, 
+             save=False, 
+             save_path=None, 
+             dpi=300): 
+        
+        self.maxlag = self.dt * (self.stack_data.shape[2]-1)/2
+
+        # check pair_indx
+        if pair_indx >= self.stack_data.shape[0]:
+            raise ValueError("pair_indx must be smaller than stack_data.shape[0]=%d" % self.stack_data.shape[0])
+
+        # init cc_len cc_step
+        if cc_len == None:
+            cc_len = self.stack_data.shape[2]*self.dt
+        if cc_step == None:
+            cc_step = 0.0
+
+        # define time vector
+        stack_win_num = self.stack_data.shape[1]
+        corr_win_num = (stack_len-stack_step)*(stack_win_num-1) + stack_len
+        t_max = t_min + (corr_win_num-1)*(cc_len-cc_step) + cc_len
+        stack_interval = (stack_len-stack_step)*(cc_len-cc_step)
+        win_vector = np.array([t_min + i*stack_interval for i in range(0, stack_win_num)])
+
+        # init win_start
+        if win_start == None:
+            win_start = t_min
+        if win_start < t_min:
+            raise ValueError("win_start must be larger than t_min=%s" % str(t_min))
+
+        # init win_end
+        if win_end == None:
+            win_end = t_max
+        if win_end > t_max:
+            raise ValueError("win_end must be smaller than t_max=%s" % str(t_max))
+
+        # init lag_start 
+        if lag_start == None:
+            lag_start = -self.maxlag
+        if lag_start < -self.maxlag:
+            raise ValueError("lag_start must be larger than -maxlag=-%f" % self.maxlag)
+        
+        # init lag_end
+        if lag_end == None:
+            lag_end = self.maxlag
+        if lag_end > self.maxlag:
+            raise ValueError("lag_end must be smaller than maxlag=%f" % self.maxlag)
+        
+        # lag vector
+        tt = np.arange(lag_start, lag_end+self.dt, self.dt)
+        tp_start = round((lag_start+self.maxlag)/self.dt)
+        tp_end = tp_start+len(tt)  # make sure same length, so do not use round((lag_end+self.maxlag+self.dt)/self.dt)
+
+        # check win_interval
+        if win_interval == None:
+            win_interval = (stack_len-stack_step)*(cc_len-cc_step)
+        if win_interval < (stack_len-stack_step)*(cc_len-cc_step):
+            raise ValueError("win_interval must be larger than (stack_len-stack_step)*(cc_len-cc_step)=%f" % (stack_len-stack_step)*(cc_len-cc_step))
+        if win_interval > t_max-stack_len*(cc_len-cc_step)-t_min:
+            raise ValueError("win_interval must be smaller than t_max-stack_len*(cc_len-cc_step)-t_min=%f" % (t_max-stack_len*(cc_len-cc_step)-t_min))
+        
+        # select win_indx data and filter --> data, ngood
+        win_indx = np.where((win_vector >= win_start) & (win_vector <= win_end))[0]
+        ngood = self.stack_ngood[pair_indx, win_indx]
+        if filter:
+            data=np.empty((len(win_indx), len(tt)))
+            for i in range(0, len(win_indx)):
+                data[i,:] = bandpass(self.stack_data[pair_indx, win_indx[i], tp_start:tp_end], f1, f2, int(1/self.dt), corners=corners, zerophase=zerophase)
+        else:
+            data = self.stack_data[pair_indx, win_indx, tp_start:tp_end]
+
+        # plot
+        if mode == 'waveform':
+            # init figure
+            fig, ax = plt.subplots(1, 2, gridspec_kw=dict(width_ratios=[5, 1]), sharey="row", figsize=figsize)
+            fig.subplots_adjust(wspace=0.01)
+
+            # normalize
+            if amp_normalize:
+                scale = np.max(np.abs(data), axis=1)[:,None]
+                if np.min(scale) != 0:
+                    data_plot = amp_scale*data/scale
+                else:
+                    raise ValueError("data is all zeros in amp_normalize=True")
+            else:
+                scale = np.max(np.abs(data))
+                if scale != 0:
+                    data_plot = amp_scale*data/scale
+                else:
+                    raise ValueError("data is all zeros in amp_normalize=False")
+
+            # select win_interval data
+            ydist_n=[]
+            ngood_n=[]
+            win_interval_n = round(win_interval/((stack_len-stack_step)*(cc_len-cc_step)))
+            for i in range(0, len(win_indx), win_interval_n):
+                ydist_n.append(i)
+                ngood_n.append(ngood[i])
+            ydist_n = np.array(ydist_n)
+            ngood_n = np.array(ngood_n)
+
+            # plot wavefrom
+            for i in range(0, len(ydist_n)):
+                ax[0].plot(tt, data_plot[int(ydist_n[i])]+ydist_n[i], 'k', linewidth=linewidth)
+            
+            # set x axis
+            ax[0].set_title("StackData: pair_indx=%d, filter=[%.2f, %.2f] hz" % (pair_indx, f1, f2))
+            ax[0].set_xlim(tt[0], tt[-1])
+            ax[0].set_xlabel('Time(s)')
+            
+            # set y axis
+            yy_tick = np.linspace(0, len(win_indx)-1, num=yticklabel_num)
+            yy_label_UTC = time_linspace(win_start, win_end, num=yticklabel_num)
+            yy_label = np.array([i.strftime('%Y-%m-%dT%H:%M:%S') for i in yy_label_UTC])
+            ax[0].set_yticks(yy_tick)
+            ax[0].set_yticklabels(yy_label, rotation=45)
+
+            # plot ngood 
+            (markers, stemlines, baseline) = ax[1].stem(ydist_n, ngood_n, orientation='horizontal')
+            plt.setp(markers, marker='D', markeredgecolor="orange", markeredgewidth=1.5)
+            plt.setp(stemlines, linestyle="-", color="olive", linewidth=linewidth)
+            if ngood_label:
+                for i in range(0, len(ngood_n)):
+                    ax[1].text(ngood_n[i]+np.max(ngood_n)/10, ydist_n[i], int(ngood_n[i]), va='center', ha='left')
+
+            ax[1].set_xlim(0, np.max(ngood_n)*1.2)
+            ax[1].set_xlabel('Ngood')
+            ax[1].get_yaxis().set_visible(False)
+            ax[1].spines['top'].set_visible(False)
+            ax[1].spines['right'].set_visible(False)
+            ax[1].spines['bottom'].set_visible(True)
+            ax[1].spines['left'].set_visible(True)
+
+            # save or show
+            if save:
+                if save_path is None:
+                    raise ValueError("save_path must be specified")
+                fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight')
+                plt.close(fig)
+            else:
+                plt.show()
+
+        elif mode == 'mat':
+            # init figure
+            fig, ax = plt.subplots(1, 2, gridspec_kw=dict(width_ratios=[5, 1]), sharey="row", figsize=figsize)
+            fig.subplots_adjust(wspace=0.01)
+
+            # average waveforms
+            cc_mean = np.mean(data, axis=0)/np.max(np.mean(data, axis=0))
+            ntrace = int((win_end-win_start)/win_interval)
+            ndata  = np.zeros(shape=(ntrace,len(tt)))
+            for i in range(0,ntrace):
+                tindx = np.where(((win_vector-win_start)>=i*win_interval) & ((win_vector-win_start)<(i+1)*win_interval))[0]
+                ndata[i] = np.mean(data[tindx],axis=0)
+
+            # normalize waveforms
+            if amp_normalize:
+                scale = np.max(np.abs(ndata), axis=1)[:,None]
+                if np.min(scale) != 0:
+                    ndata_plot = ndata/scale
+                else:
+                    raise ValueError("data is all zeros in amp_normalize=True")
+            else:
+                scale = np.max(np.abs(ndata))
+                if scale != 0:
+                    ndata_plot = ndata/scale
+                else:
+                    raise ValueError("data is all zeros in amp_normalize=False")
+                
+            ### plot mat
+            cax=ax[0].matshow(ndata_plot, extent=[lag_start, lag_end, ntrace, 0], aspect='auto', cmap=cmap)
+            ax[0].plot(tt,ntrace/10*cc_mean+ntrace/2,'k',linewidth=linewidth)
+            
+            # set x axis
+            ax[0].set_title("StackData: pair_indx=%d, filter=[%.2f, %.2f] hz" % (pair_indx, f1, f2))
+            ax[0].set_xlim(tt[0], tt[-1])
+            ax[0].set_xlabel('Time(s)')
+            ax[0].xaxis.set_ticks_position('bottom')
+
+            # set y axis
+            ax[0].invert_yaxis()
+            ax[0].set_ylim(0, ntrace)
+            yy_tick = np.linspace(0, ntrace, num=yticklabel_num)
+            yy_label_UTC = time_linspace(win_start, win_end, num=yticklabel_num)
+            yy_label = np.array([i.strftime('%Y-%m-%dT%H:%M:%S') for i in yy_label_UTC])
+            ax[0].set_yticks(yy_tick)
+            ax[0].set_yticklabels(yy_label, rotation=45)
+
+            ### plot ngood
+            ngood = self.stack_ngood[pair_indx, win_indx]
+            yy = np.linspace(0, ntrace, len(ngood))
+            (markers, stemlines, baseline) = ax[1].stem(yy, ngood, orientation='horizontal')
+            plt.setp(markers, marker='D', markeredgecolor="orange", markeredgewidth=1.5)
+            plt.setp(stemlines, linestyle="-", color="olive", linewidth=linewidth)
+            if ngood_label:
+                for i in range(0, len(ngood)):
+                    ax[1].text(ngood[i]+np.max(ngood)/10, yy[i], int(ngood[i]), va='center', ha='left')
+
+            ax[1].set_xlim(0, np.max(ngood)*1.2)
+            ax[1].set_xlabel('Ngood')
+            ax[1].get_yaxis().set_visible(False)
+            ax[1].spines['top'].set_visible(False)
+            ax[1].spines['right'].set_visible(False)
+            ax[1].spines['bottom'].set_visible(True)
+            ax[1].spines['left'].set_visible(True)
+            
+            # save
+            if save:
+                if save_path is None:
+                    raise ValueError("save_path must be specified")
+                fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches = 'tight') 
+                plt.close(fig)
+            else:
+                plt.show()
+
+        else:
+            raise ValueError("mode must be 'waveform' or 'mat'")
+        
+
+
+    def plot_moveout(self, 
+                corr_pair, 
+                pair_dist, 
+                source_indx=None, 
+                receiver_indx=None, 
+                dist_start=None, 
+                dist_end=None, 
+                amp_scale=1, 
+                amp_normalize=True,
+                win_num = 0, 
+                lag_start=None, 
+                lag_end=None, 
+                filter=False, 
+                f1=None, 
+                f2=None, 
+                corners=4, 
+                zerophase=True, 
+                dist_interval=None, 
+                mode='waveform', 
+                cmap='seismic',
+                linewidth=0.8, 
+                yticklabel_num=10, 
+                figsize=(10, 6),
+                dist_unit="m", 
+                velocity=[], 
+                save=False, 
+                save_path=None, 
+                dpi=100): 
+        
+        self.maxlag = self.dt * (self.stack_data.shape[2]-1)/2
+
+        # check source_indx and receiver_indx
+        if source_indx != None and receiver_indx != None:
+            raise ValueError("source_indx and receiver_indx cannot be specified at the same time")
+        elif source_indx != None:
+            if source_indx not in corr_pair[:,0]:
+                raise ValueError("source_indx must be in corr_pair[:,0]")
+        elif receiver_indx != None:
+            if receiver_indx not in corr_pair[:,1]:
+                raise ValueError("receiver_indx must be in corr_pair[:,1]")
+        else:
+            raise ValueError("source_indx or receiver_indx must be specified")
+        
+        # check corr_pair pair_dist
+        if corr_pair.shape[0] != len(pair_dist):
+            raise ValueError("the length of corr_pair is not consistent with pair_dist")
+        
+        # check demision of pair_dist
+        if pair_dist.ndim == 2:
+            pair_dist = pair_dist.reshape(-1)
+
+        # check dist_unit
+        if dist_unit not in ['m', 'km', 'degree']:
+            raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
+        
+        # init dist_start
+        if dist_start == None:
+            dist_start = np.min(pair_dist)
+        if dist_start < np.min(pair_dist):
+            raise ValueError("dist_start must be >= (np.min(pair_dist)=%f)" % np.min(pair_dist))
+        
+        # init dist_end
+        if dist_end == None:
+            dist_end = np.max(pair_dist)
+        if dist_end > np.max(pair_dist):
+            raise ValueError("dist_end must be <= (np.max(pair_dist)=%f)" % np.max(pair_dist))
+
+        # init lag_start 
+        if lag_start == None:
+            lag_start = -self.maxlag
+        if lag_start < -self.maxlag:
+            raise ValueError("lag_start must be >= (-maxlag=-%f)" % self.maxlag)
+        
+        # init lag_end
+        if lag_end == None:
+            lag_end = self.maxlag
+        if lag_end > self.maxlag:
+            raise ValueError("lag_end must be <= (maxlag=%f)" % self.maxlag)
+        
+        # lag vector
+        tt = np.arange(lag_start, lag_end+self.dt, self.dt)
+        tp_start = round((lag_start+self.maxlag)/self.dt)
+        tp_end = tp_start+len(tt)  # make sure same length, so do not use round((lag_end+self.maxlag+self.dt)/self.dt)
+
+        # select dist_start dist_end
+        if source_indx != None:
+            a_id = np.where((corr_pair[:,0]==source_indx))[0]
+            b_id = np.where((pair_dist>=dist_start) & (pair_dist<=dist_end))[0]
+            id = np.intersect1d(a_id ,b_id)
+        elif receiver_indx != None:
+            a_id = np.where((corr_pair[:,1]==receiver_indx))[0]
+            b_id = np.where((pair_dist>=dist_start) & (pair_dist<=dist_end))[0]
+            id = np.intersect1d(a_id, b_id)
+        else:
+            raise ValueError("source_indx or receiver_indx must be specified")
+        dist = pair_dist[id]
+
+        # init dist_interval
+        if dist_interval == None:
+            dist_interval = np.min(dist)
+        if dist_interval < np.diff(np.sort(dist)).min():
+            raise ValueError("win_interval must be >= (np.diff(np.sort(dist)).min()=%f)" % np.diff(np.sort(dist)).min())
+        if dist_interval > np.max(dist):
+            raise ValueError("win_interval must be <= (np.max(dist)=%f)" % np.max(dist))
+        
+        # filter --> data
+        if filter:
+            data=np.empty((len(id), len(tt)))
+            for i in range(0, len(id)):
+                data[i,:] = bandpass(self.stack_data[id[i], win_num, tp_start:tp_end], f1, f2, int(1/self.dt), corners=corners, zerophase=zerophase)
+        else:
+            data = self.stack_data[id, win_num, tp_start:tp_end]
+            
+        # plot
+        colors = list(mcolors.TABLEAU_COLORS.keys())
+        if mode == 'waveform':
+            if data.size != 0:
+                # init fig
+                fig, ax = plt.subplots(figsize=figsize)
+
+                # normalize data
+                if amp_normalize:
+                    scale = np.max(np.abs(data), axis=1)[:,None]
+                    if np.min(scale) != 0:
+                        data_plot = amp_scale*data/scale
+                    else:
+                        raise ValueError("data is all zeros in amp_normalize=True")
+                else:
+                    scale = np.max(np.abs(data))
+                    if scale != 0:
+                        data_plot = amp_scale*data/scale
+                    else:
+                        raise ValueError("data is all zeros in amp_normalize=False")
+                
+                # plot waveform
+                for i in range(0, data_plot.shape[0]):
+                    ax.plot(tt, amp_scale*data_plot[i]+dist[i], 'k', linewidth=linewidth)
+
+                # plot velocity
+                for i in range(0, len(velocity)):
+                    x0=0; y0=0
+                    if dist_unit == 'm':
+                        x1 = (dist_end-dist_start)/velocity[i]
+                        y1 = dist_end
+                    elif dist_unit == 'km':
+                        x1 = (dist_end-dist_start)/1000/velocity[i]
+                        y1 = dist_end
+                    elif dist_unit == 'degree':
+                        x1 = (dist_end-dist_start)/(111.2*1000)/velocity[i]
+                        y1 = dist_end
+                    else:
+                        raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
+                    ax.plot([x0,x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5, label=str(velocity[i])+'m/s')
+                    ax.plot([x0,-x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5)
+
+                # set legend
+                ax.legend(loc='upper right', fontsize=8, shadow=False)
+                ax.set_xlim(tt[0], tt[-1])
+                ax.set_xlabel('Time(s)')
+                ax.set_ylabel('Distance(%s)' % (dist_unit))
+
+                # set title
+                if source_indx != None:
+                    ax.set_title("StackData: source_indx=%d, win_num=%d, filter=[%.2f, %.2f] hz" % (source_indx, win_num, f1, f2))
+                elif receiver_indx != None:
+                    ax.set_title("StackData: receiver_indx=%d, win_num=%d, filter=[%.2f, %.2f] hz" % (source_indx, win_num, f1, f2))
+                else:
+                    raise ValueError("source_indx or receiver_indx must be specified")
+            
+                # save or show
+                if save:
+                    if save_path is None:
+                        raise ValueError("save_path must be specified")
+                    fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches = 'tight') 
+                    plt.close(fig)
+                else:
+                    plt.show()
+            else:
+                raise ValueError("data is empty")
+
+        elif mode=="mat":
+            if data.size != 0:
+                # init fig
+                fig, ax = plt.subplots(figsize=figsize)
+
+                # average waveforms
+                ntrace = int((dist_end-dist_start)/dist_interval)
+                ndata  = np.zeros(shape=(ntrace,len(tt)))
+                for i in range(0,ntrace):
+                    tindx = np.where(((dist-dist_start)>=i*dist_interval) & ((dist-dist_start)<(i+1)*dist_interval))[0]
+                    ndata[i] = np.mean(data[tindx],axis=0)
+
+                # normalize waveforms
+                if amp_normalize:
+                    scale = np.max(np.abs(ndata), axis=1)[:,None]
+                    if np.min(scale) != 0:
+                        ndata_plot = ndata/scale
+                    else:
+                        raise ValueError("data is all zeros in amp_normalize=True")
+                else:
+                    scale = np.max(np.abs(ndata))
+                    if scale != 0:
+                        ndata_plot = ndata/scale
+                    else:
+                        raise ValueError("data is all zeros in amp_normalize=False")
+                
+                # plot
+                cax=ax.matshow(ndata_plot, extent=[lag_start, lag_end, ntrace, 0], aspect='auto', cmap=cmap) # cmap=cmaps.MPL_jet,
+                for i in range(0, len(velocity)):
+                    x0=0
+                    y0=0
+                    if dist_unit == 'm':
+                        x1 = (dist_end-dist_start)/velocity[i]
+                        y1 = ntrace
+                    elif dist_unit == 'km':
+                        x1 = (dist_end-dist_start)/1000/velocity[i]
+                        y1 = ntrace
+                    elif dist_unit == 'degree':
+                        x1 = (dist_end-dist_start)/(111.2*1000)/velocity[i]
+                        y1 = ntrace
+                    else:
+                        raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
+                    ax.plot([x0,x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5, label=str(velocity[i])+'m/s')
+                    ax.plot([x0,-x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5)
+
+                # set x axis
+                ax.legend(loc='upper right', fontsize=7, shadow=False)
+                ax.set_xlim(tt[0], tt[-1])
+                ax.xaxis.set_ticks_position('bottom')
+                ax.set_xlabel('Time(s)')
+
+                # set y axis
+                ax.invert_yaxis()
+                yy_tick=np.linspace(0, ntrace, num=yticklabel_num)
+                yy_label = np.around(np.linspace(dist_start, dist_end, num=yticklabel_num), decimals=2)
+                ax.set_yticks(yy_tick)
+                ax.set_yticklabels(yy_label)
+                ax.set_ylabel('Distance(%s)' % (dist_unit))
+
+                # set title
+                if source_indx != None:
+                    ax.set_title("StackData: source_indx=%d, win_num=%d, filter=[%.2f, %.2f] hz" % (source_indx, win_num, f1, f2))
+                elif receiver_indx != None:
+                    ax.set_title("StackData: receiver_indx=%d, win_num=%d, filter=[%.2f, %.2f] hz" % (source_indx, win_num, f1, f2))
+                else:
+                    raise ValueError("source_indx or receiver_indx must be specified")
+                
+                # save or show
+                if save:
+                    if save_path is None:
+                        raise ValueError("save_path must be specified")
+                    fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight') 
+                    plt.close(fig)
+                else:
+                    plt.show()
+            else:
+                raise ValueError("data is empty")
+            
+        else:
+            raise ValueError("mode must be 'waveform' or 'mat'")
+
+
+
+    def plot_moveout_all(self, 
+                 corr_pair, 
+                 pair_dist, 
+                 dist_start=None, 
+                 dist_end=None, 
+                 amp_scale=1,
+                 amp_normalize=True, 
+                 win_num = 0, 
+                 lag_start=None, 
+                 lag_end=None, 
+                 filter=False, 
+                 f1=None, 
+                 f2=None,
+                 corners=4, 
+                 zerophase=True,  
+                 dist_interval=None, 
+                 mode='waveform', 
+                 cmap='seismic', 
+                 linewidth=0.8,
+                 yticklabel_num=10, 
+                 figsize=(10, 6),
+                 dist_unit="m", 
+                 velocity=[], 
+                 save=False, 
+                 save_path=None, 
+                 dpi=30):      
+        
+        self.maxlag = self.dt * (self.stack_data.shape[2]-1)/2
+        
+        # check corr_pair pair_dist
+        if corr_pair.shape[0] != len(pair_dist):
+            raise ValueError("the length of corr_pair is not consistent with pair_dist")
+        
+        # check demision of pair_dist
+        if pair_dist.ndim == 2:
+            pair_dist = pair_dist.reshape(-1)
+        
+        # check dist_unit
+        if dist_unit not in ['m', 'km', 'degree']:
+            raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
+        
+        # init dist_start
+        if dist_start == None:
+            dist_start = np.min(pair_dist)
+        if dist_start < np.min(pair_dist):
+            raise ValueError("dist_start must be >= (min(pair_dist)=%f)" % np.min(pair_dist))
+        
+        # init dist_end
+        if dist_end == None:
+            dist_end = np.max(pair_dist)
+        if dist_end > np.max(pair_dist):
+            raise ValueError("dist_end must be <= (max(pair_dist)=%f)" % np.max(pair_dist))
+
+        # init lag_start 
+        if lag_start == None:
+            lag_start = -self.maxlag
+        if lag_start < -self.maxlag:
+            raise ValueError("lag_start must be >= (-maxlag=-%f)" % self.maxlag)
+        
+        # init lag_end
+        if lag_end == None:
+            lag_end = self.maxlag
+        if lag_end > self.maxlag:
+            raise ValueError("lag_end must be <= (maxlag=%f)" % self.maxlag)
+        
+        # lag vector
+        tt = np.arange(lag_start, lag_end+self.dt, self.dt)
+        tp_start = round((lag_start+self.maxlag)/self.dt)
+        tp_end = tp_start+len(tt)  # make sure same length, so do not use round((lag_end+self.maxlag+self.dt)/self.dt)
+
+        # select dist_start dist_end
+        id = np.where((pair_dist>=dist_start) & (pair_dist<=dist_end))[0]
+        dist = pair_dist[id]
+
+        # init dist_interval
+        if dist_interval == None:
+            dist_interval = np.min(dist)
+        if dist_interval < np.diff(np.sort(dist)).min():
+            raise ValueError("win_interval must be >= (np.diff(np.sort(dist)).min()=%f)" % np.diff(np.sort(dist)).min())
+        if dist_interval > np.max(dist):
+            raise ValueError("win_interval must be <= (np.max(dist)=%f)" % np.max(dist))
+        
+        # filter --> data
+        if filter:
+            data=np.empty((len(id), len(tt)))
+            for i in range(0, len(id)):
+                data[i,:] = bandpass(self.stack_data[id[i], win_num, tp_start:tp_end], f1, f2, int(1/self.dt), corners=corners, zerophase=zerophase)
+        else:
+            data = self.stack_data[id, win_num, tp_start:tp_end]
+            
+        # plot
+        colors = list(mcolors.TABLEAU_COLORS.keys())
+        if mode == 'waveform':
+            if data.size != 0:
+                # init fig
+                fig, ax = plt.subplots(figsize=figsize)
+
+                # normalize data
+                if amp_normalize:
+                    scale = np.max(np.abs(data), axis=1)[:,None]
+                    if np.min(scale) != 0:
+                        data_plot = amp_scale*data/scale
+                    else:
+                        raise ValueError("data is all zeros in amp_normalize=True")
+                else:
+                    scale = np.max(np.abs(data))
+                    if scale != 0:
+                        data_plot = amp_scale*data/scale
+                    else:
+                        raise ValueError("data is all zeros in amp_normalize=False")
+                
+                # plot waveform
+                for i in range(0, data_plot.shape[0]):
+                    ax.plot(tt, amp_scale*data_plot[i]+dist[i], 'k', linewidth=linewidth)
+
+                # plot velocity
+                for i in range(0, len(velocity)):
+                    x0=0; y0=0
+                    if dist_unit == 'm':
+                        x1 = (dist_end-dist_start)/velocity[i]
+                        y1 = dist_end
+                    elif dist_unit == 'km':
+                        x1 = (dist_end-dist_start)/1000/velocity[i]
+                        y1 = dist_end
+                    elif dist_unit == 'degree':
+                        x1 = (dist_end-dist_start)/(111.2*1000)/velocity[i]
+                        y1 = dist_end
+                    else:
+                        raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
+                    ax.plot([x0,x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5, label=str(velocity[i])+'m/s')
+                    ax.plot([x0,-x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5)
+
+                # set axis
+                ax.set_xlim(tt[0], tt[-1])
+                ax.set_xlabel('Time(s)')
+                ax.set_ylabel('Distance(%s)' % (dist_unit))
+                ax.legend(loc='upper right', fontsize=8, shadow=False)
+                ax.set_title("StackData: win_num=%d, filter=[%.2f, %.2f] hz" % (win_num, f1, f2))
+            
+                # save or show
+                if save:
+                    if save_path is None:
+                        raise ValueError("save_path must be specified")
+                    fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches = 'tight') 
+                    plt.close(fig)
+                else:
+                    plt.show()
+
+            else:
+                raise ValueError("data is empty")
+
+        elif mode=="mat":
+            if data.size != 0:
+                # init fig
+                fig, ax = plt.subplots(figsize=figsize)
+
+                # average waveforms
+                ntrace = int((dist_end-dist_start)/dist_interval)
+                ndata  = np.zeros(shape=(ntrace,len(tt)))
+                for i in range(0,ntrace):
+                    tindx = np.where(((dist-dist_start)>=i*dist_interval) & ((dist-dist_start)<(i+1)*dist_interval))[0]
+                    ndata[i] = np.mean(data[tindx],axis=0)
+
+                # normalize waveforms
+                if amp_normalize:
+                    scale = np.max(np.abs(ndata), axis=1)[:,None]
+                    if np.min(scale) != 0:
+                        ndata_plot = ndata/scale
+                    else:
+                        raise ValueError("data is all zeros in amp_normalize=True")
+                else:
+                    scale = np.max(np.abs(ndata))
+                    if scale != 0:
+                        ndata_plot = ndata/scale
+                    else:
+                        raise ValueError("data is all zeros in amp_normalize=False")
+                
+                # plot
+                cax=ax.matshow(ndata_plot, extent=[lag_start, lag_end, ntrace, 0], aspect='auto', cmap=cmap) # cmap=cmaps.MPL_jet,
+                for i in range(0, len(velocity)):
+                    x0=0
+                    y0=0
+                    if dist_unit == 'm':
+                        x1 = (dist_end-dist_start)/velocity[i]
+                        y1 = ntrace
+                    elif dist_unit == 'km':
+                        x1 = (dist_end-dist_start)/1000/velocity[i]
+                        y1 = ntrace
+                    elif dist_unit == 'degree':
+                        x1 = (dist_end-dist_start)/(111.2*1000)/velocity[i]
+                        y1 = ntrace
+                    else:
+                        raise ValueError("dist_unit must be 'm', 'km', or 'degree'")
+                    ax.plot([x0,x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5, label=str(velocity[i])+'m/s')
+                    ax.plot([x0,-x1], [y0,y1], color=colors[i], linestyle='--', linewidth=1.5)
+
+                # set x axis
+                ax.set_title("StackData: win_num=%d, filter=[%.2f, %.2f] hz" % (win_num, f1, f2))
+                ax.legend(loc='upper right', fontsize=7, shadow=False)
+                ax.set_xlim(tt[0], tt[-1])
+                ax.xaxis.set_ticks_position('bottom')
+                ax.set_xlabel('Time(s)')
+
+                # set y axis
+                ax.invert_yaxis()
+                yy_tick=np.linspace(0, ntrace, num=yticklabel_num)
+                yy_label = np.around(np.linspace(dist_start, dist_end, num=yticklabel_num), decimals=2)
+                ax.set_yticks(yy_tick)
+                ax.set_yticklabels(yy_label)
+                ax.set_ylabel('Distance(%s)' % (dist_unit))
+
+                # save or show
+                if save:
+                    if save_path is None:
+                        raise ValueError("save_path must be specified")
+                    fig.savefig(os.path.join(save_path), dpi=dpi, format='pdf', bbox_inches='tight') 
+                    plt.close(fig)
+                else:
+                    plt.show()
+            else:
+                raise ValueError("data is empty")
+            
+        else:
+            raise ValueError("mode must be 'waveform' or 'mat'")
+
+
```

## noiseflow/cc/utils_load.py

 * *Ordering differences only*

```diff
@@ -1,355 +1,355 @@
-import h5py
-import numpy as np
-
-from scipy.io import loadmat
-from noiseflow.signal.rawdata import RawData_Class
-from noiseflow.cc.rfftdata import RFFTData_Class
-from noiseflow.cc.corrdata import CorrData_Class
-from noiseflow.cc.stackdata import StackData_Class
-
-
-def load_raw(filename, format="npz", only_header=False):
-    if format == "npz":
-        DD = np.load(filename)
-        if only_header:
-            data = None
-        else:
-            data = DD["data"]
-
-        sampling_rate = DD["sampling_rate"].reshape(1)[0]
-
-    elif format == "h5":
-        with h5py.File(filename, 'r') as f:
-            if only_header:
-                data = None
-            else:
-                data = f['noiseflow_group']['data'][:]
-
-            sampling_rate = f['noiseflow_group'].attrs['sampling_rate']
-
-    elif format == "mat":
-        DD = loadmat(filename)
-        if only_header:
-            data = None
-        else:
-            data = DD["data"][:,:]
-
-        sampling_rate = DD["sampling_rate"][0][0]
-
-    else:
-        ValueError("format must be 'npz', 'h5' or 'mat'")
-    
-    RawData = RawData_Class(data, sampling_rate)
-    
-    return RawData
-
-
-
-def load_rfft(filename, format="npz", only_header=False):
-    if format == "npz":
-        DD = np.load(filename)
-        if only_header:
-            rfft_data = None
-        else:
-            rfft_data = DD["rfft_data"]
-
-        dt = DD["dt"].reshape(1)[0]
-        cc_len = DD["cc_len"].reshape(1)[0]
-        cc_step = DD["cc_step"].reshape(1)[0]
-        time_norm = DD["time_norm"].reshape(1)[0]
-        clip_std = DD["clip_std"].reshape(1)[0]
-        smooth_N = DD["smooth_N"].reshape(1)[0]
-        freq_norm = DD["freq_norm"].reshape(1)[0]
-        freqmin = DD["freqmin"].reshape(1)[0]
-        freqmax = DD["freqmax"].reshape(1)[0]
-        whiten_npad = DD["whiten_npad"].reshape(1)[0]
-        smoothspect_N = DD["smoothspect_N"].reshape(1)[0]
-        flag = DD["flag"].reshape(1)[0]
-        flag_gap = DD["flag_gap"].reshape(1)[0]
-        threads = DD["threads"].reshape(1)[0]
-        jobs = DD["jobs"].reshape(1)[0]
-        py = DD["py"].reshape(1)[0]
-
-    elif format == "h5":
-        with h5py.File(filename, 'r') as f:
-            group = f['noiseflow_group']
-
-            if only_header:
-                rfft_data = None
-            else:
-                rfft_data = group['rfft_data'][:]
-
-            dt = group.attrs['dt']
-            cc_len = group.attrs['cc_len']
-            cc_step = group.attrs['cc_step']
-            time_norm = group.attrs['time_norm']
-            clip_std = group.attrs['clip_std']
-            smooth_N = group.attrs['smooth_N']
-            freq_norm = group.attrs['freq_norm']
-            freqmin = group.attrs['freqmin']
-            freqmax = group.attrs['freqmax']
-            whiten_npad = group.attrs['whiten_npad']
-            smoothspect_N = group.attrs['smoothspect_N']
-            flag = group.attrs['flag']
-            flag_gap = group.attrs['flag_gap']
-            threads = group.attrs['threads']
-            jobs = group.attrs['jobs']
-            py = group.attrs['py']
-
-    elif format == "mat":
-        DD = loadmat(filename)
-        if only_header:
-            rfft_data = None
-        else:
-            rfft_data = DD["rfft_data"][:,:,:]
-
-        if DD["flag"][0][0] == 1:
-            flag = True
-        else:
-            flag = False
-        
-        if DD["py"][0][0] == 1:
-            py = True
-        else:
-            py = False
-
-        dt = DD["dt"][0][0]
-        cc_len = DD["cc_len"][0][0]
-        cc_step = DD["cc_step"][0][0]
-        time_norm = DD["time_norm"][0]
-        clip_std = DD["clip_std"][0][0]
-        smooth_N = DD["smooth_N"][0][0]
-        freq_norm = DD["freq_norm"][0]
-        freqmin = DD["freqmin"][0][0]
-        freqmax = DD["freqmax"][0][0]
-        whiten_npad = DD["whiten_npad"][0][0]
-        smoothspect_N = DD["smoothspect_N"][0][0]
-        flag_gap = DD["flag_gap"][0][0]
-        threads = DD["threads"][0][0]
-        jobs = DD["jobs"][0][0]
-
-    else:
-        ValueError("format must be 'npz', 'h5' or 'mat'")
-    
-    RFFTData = RFFTData_Class(rfft_data, dt, cc_len, cc_step, 
-        time_norm, clip_std, smooth_N,
-        freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
-        flag, flag_gap,
-        threads, jobs, py)
-    
-    return RFFTData
-
-
-
-def load_corr(filename, format="npz", only_header=False):
-    if format == "npz":
-        DD = np.load(filename)
-        if only_header:
-            corr_data = None
-        else:
-            corr_data = DD["corr_data"]
-
-        corr_pair = DD["corr_pair"]
-        dt = DD["dt"].reshape(1)[0]
-        corr_method = DD["corr_method"].reshape(1)[0]
-        maxlag = DD["maxlag"].reshape(1)[0]
-        smoothspect_N = DD["smoothspect_N"].reshape(1)[0]
-        flag = DD["flag"].reshape(1)[0]
-        flag_gap = DD["flag_gap"].reshape(1)[0]
-        threads = DD["threads"].reshape(1)[0]
-        jobs = DD["jobs"].reshape(1)[0]
-        py = DD["py"].reshape(1)[0]
-
-    elif format == "h5":
-        with h5py.File(filename, 'r') as f:
-            group = f['noiseflow_group']
-
-            if only_header:
-                corr_data = None
-            else:
-                corr_data = group['corr_data'][:]
-
-            dt = group.attrs['dt']
-            corr_method = group.attrs['corr_method']
-            maxlag = group.attrs['maxlag']
-            smoothspect_N = group.attrs['smoothspect_N']
-            flag = group.attrs['flag']
-            flag_gap = group.attrs['flag_gap']
-            threads = group.attrs['threads']
-            corr_pair = group['corr_pair'][:]
-            jobs = group.attrs['jobs']
-            py = group.attrs['py']
-
-    elif format == "mat":
-        DD = loadmat(filename)
-        if only_header:
-            corr_data = None
-        else:
-            corr_data = DD["corr_data"][:,:,:]
-
-        if DD["flag"][0][0] == 1:
-            flag = True
-        else:
-            flag = False
-
-        if DD["py"][0][0] == 1:
-            py = True
-        else:
-            py = False
-        
-        dt = DD["dt"][0][0]
-        corr_method = DD["corr_method"][0]
-        maxlag = DD["maxlag"][0][0]
-        smoothspect_N = DD["smoothspect_N"][0][0]
-        flag_gap = DD["flag_gap"][0][0]
-        threads = DD["threads"][0][0]
-        corr_pair = DD["corr_pair"][:,:]
-        jobs = DD["jobs"][0][0]
-
-        
-    else:
-        raise ValueError("format must be 'npz', 'h5' or 'mat'")
-    
-    CorrData = CorrData_Class(corr_data, dt, corr_method, corr_pair, maxlag, smoothspect_N,
-        flag, flag_gap, threads, jobs, py)
-    
-    return CorrData
-
-
-
-def load_stack(filename, format="npz", only_header=False):
-    par = None
-
-    if format == "npz":
-        DD = np.load(filename, allow_pickle=True)
-        if only_header:
-            stack_data = None
-        else:
-            stack_data = DD["stack_data"]
-
-        stack_ngood = DD["stack_ngood"]
-        dt = DD["dt"].reshape(1)[0]
-        stack_method = DD["stack_method"].reshape(1)[0]
-        par = DD["par"].reshape(1)[0]
-        stack_all = DD["stack_all"].reshape(1)[0]
-        stack_len = DD["stack_len"].reshape(1)[0]
-        stack_step = DD["stack_step"].reshape(1)[0]
-        pick = DD["pick"].reshape(1)[0]
-        median_high = DD["median_high"].reshape(1)[0]
-        median_low = DD["median_low"].reshape(1)[0]
-        flag = DD["flag"].reshape(1)[0]
-        flag_gap = DD["flag_gap"].reshape(1)[0]
-        threads = DD["threads"].reshape(1)[0]
-        jobs = DD["jobs"].reshape(1)[0]
-        py = DD["py"].reshape(1)[0]
-
-    elif format == "h5":
-        with h5py.File(filename, 'r') as f:
-            group = f['noiseflow_group']
-
-            if only_header:
-                stack_data = None
-            else:
-                stack_data = group['stack_data'][:]
-
-            dt = group.attrs['dt']
-            stack_method = group.attrs['stack_method']
-            stack_all = group.attrs['stack_all']
-            stack_len = group.attrs['stack_len']
-            stack_step = group.attrs['stack_step']
-            pick = group.attrs['pick']
-            median_high = group.attrs['median_high']
-            median_low = group.attrs['median_low']
-            flag = group.attrs['flag']
-            flag_gap = group.attrs['flag_gap']
-            threads = group.attrs['threads']
-            stack_ngood = group['stack_ngood'][:]
-            jobs = group.attrs['jobs']
-            py = group.attrs['py']
-
-            par = {}
-            for key in group.attrs.keys():
-                value = group.attrs[key]
-                if isinstance(value, float) and np.isnan(value):
-                    value = None
-                par[key] = value
-
-    elif format == "mat":
-        DD = loadmat(filename)
-        if only_header:
-            stack_data = None
-        else:
-            stack_data = DD["stack_data"][:,:,:]
-
-        if DD["stack_all"][0][0] == 1:
-            stack_all = True
-        else:
-            stack_all = False
-
-        if DD["pick"][0][0] == 1:
-            pick = True
-        else:
-            pick = False
-
-        if DD["flag"][0][0] == 1:
-            flag = True
-        else:
-            flag = False
-        
-        if DD["py"][0][0] == 1:
-            py = True
-        else:
-            py = False
-        
-        dt = DD["dt"][0][0]
-        stack_method = DD["stack_method"][0]
-        stack_len = DD["stack_len"][0][0]
-        stack_step = DD["stack_step"][0][0]
-        median_high = DD["median_high"][0][0]
-        median_low = DD["median_low"][0][0]
-        flag_gap = DD["flag_gap"][0][0]
-        threads = DD["threads"][0][0]
-        stack_ngood = DD["stack_ngood"][:]
-        jobs = DD["jobs"][0][0]
-        par = decode_dict_from_mat(DD['par'][0][0])
-
-    else:
-        raise ValueError("format must be 'npz', 'h5' or 'mat'")
-    
-    StackData = StackData_Class(stack_data, stack_ngood, dt,
-                stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads, jobs, py)
-    
-    return StackData
-
-
-
-def decode_dict_from_mat(par_data):
-    par = {}
-
-    for field_name in par_data.dtype.names:
-        value = par_data[field_name][0, 0]
-    
-        if isinstance(value, np.ndarray) and value.size == 1:
-            value = value.item()
-    
-        if isinstance(value, float) and np.isnan(value):
-            value = None
-
-        par[field_name] = value
-
-    if par["stat"] == 1:
-        par["stat"] = True
-    else:
-        par["stat"] = False
-
-    if par["plot"] == 1:
-        par["plot"] = True
-    else:
-        par["plot"] = False
-
-    if par["normalize"] == 1:
-        par["normalize"] = True
-    else:
-        par["normalize"] = False
-
+import h5py
+import numpy as np
+
+from scipy.io import loadmat
+from noiseflow.signal.rawdata import RawData_Class
+from noiseflow.cc.rfftdata import RFFTData_Class
+from noiseflow.cc.corrdata import CorrData_Class
+from noiseflow.cc.stackdata import StackData_Class
+
+
+def load_raw(filename, format="npz", only_header=False):
+    if format == "npz":
+        DD = np.load(filename)
+        if only_header:
+            data = None
+        else:
+            data = DD["data"]
+
+        sampling_rate = DD["sampling_rate"].reshape(1)[0]
+
+    elif format == "h5":
+        with h5py.File(filename, 'r') as f:
+            if only_header:
+                data = None
+            else:
+                data = f['noiseflow_group']['data'][:]
+
+            sampling_rate = f['noiseflow_group'].attrs['sampling_rate']
+
+    elif format == "mat":
+        DD = loadmat(filename)
+        if only_header:
+            data = None
+        else:
+            data = DD["data"][:,:]
+
+        sampling_rate = DD["sampling_rate"][0][0]
+
+    else:
+        ValueError("format must be 'npz', 'h5' or 'mat'")
+    
+    RawData = RawData_Class(data, sampling_rate)
+    
+    return RawData
+
+
+
+def load_rfft(filename, format="npz", only_header=False):
+    if format == "npz":
+        DD = np.load(filename)
+        if only_header:
+            rfft_data = None
+        else:
+            rfft_data = DD["rfft_data"]
+
+        dt = DD["dt"].reshape(1)[0]
+        cc_len = DD["cc_len"].reshape(1)[0]
+        cc_step = DD["cc_step"].reshape(1)[0]
+        time_norm = DD["time_norm"].reshape(1)[0]
+        clip_std = DD["clip_std"].reshape(1)[0]
+        smooth_N = DD["smooth_N"].reshape(1)[0]
+        freq_norm = DD["freq_norm"].reshape(1)[0]
+        freqmin = DD["freqmin"].reshape(1)[0]
+        freqmax = DD["freqmax"].reshape(1)[0]
+        whiten_npad = DD["whiten_npad"].reshape(1)[0]
+        smoothspect_N = DD["smoothspect_N"].reshape(1)[0]
+        flag = DD["flag"].reshape(1)[0]
+        flag_gap = DD["flag_gap"].reshape(1)[0]
+        threads = DD["threads"].reshape(1)[0]
+        jobs = DD["jobs"].reshape(1)[0]
+        py = DD["py"].reshape(1)[0]
+
+    elif format == "h5":
+        with h5py.File(filename, 'r') as f:
+            group = f['noiseflow_group']
+
+            if only_header:
+                rfft_data = None
+            else:
+                rfft_data = group['rfft_data'][:]
+
+            dt = group.attrs['dt']
+            cc_len = group.attrs['cc_len']
+            cc_step = group.attrs['cc_step']
+            time_norm = group.attrs['time_norm']
+            clip_std = group.attrs['clip_std']
+            smooth_N = group.attrs['smooth_N']
+            freq_norm = group.attrs['freq_norm']
+            freqmin = group.attrs['freqmin']
+            freqmax = group.attrs['freqmax']
+            whiten_npad = group.attrs['whiten_npad']
+            smoothspect_N = group.attrs['smoothspect_N']
+            flag = group.attrs['flag']
+            flag_gap = group.attrs['flag_gap']
+            threads = group.attrs['threads']
+            jobs = group.attrs['jobs']
+            py = group.attrs['py']
+
+    elif format == "mat":
+        DD = loadmat(filename)
+        if only_header:
+            rfft_data = None
+        else:
+            rfft_data = DD["rfft_data"][:,:,:]
+
+        if DD["flag"][0][0] == 1:
+            flag = True
+        else:
+            flag = False
+        
+        if DD["py"][0][0] == 1:
+            py = True
+        else:
+            py = False
+
+        dt = DD["dt"][0][0]
+        cc_len = DD["cc_len"][0][0]
+        cc_step = DD["cc_step"][0][0]
+        time_norm = DD["time_norm"][0]
+        clip_std = DD["clip_std"][0][0]
+        smooth_N = DD["smooth_N"][0][0]
+        freq_norm = DD["freq_norm"][0]
+        freqmin = DD["freqmin"][0][0]
+        freqmax = DD["freqmax"][0][0]
+        whiten_npad = DD["whiten_npad"][0][0]
+        smoothspect_N = DD["smoothspect_N"][0][0]
+        flag_gap = DD["flag_gap"][0][0]
+        threads = DD["threads"][0][0]
+        jobs = DD["jobs"][0][0]
+
+    else:
+        ValueError("format must be 'npz', 'h5' or 'mat'")
+    
+    RFFTData = RFFTData_Class(rfft_data, dt, cc_len, cc_step, 
+        time_norm, clip_std, smooth_N,
+        freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
+        flag, flag_gap,
+        threads, jobs, py)
+    
+    return RFFTData
+
+
+
+def load_corr(filename, format="npz", only_header=False):
+    if format == "npz":
+        DD = np.load(filename)
+        if only_header:
+            corr_data = None
+        else:
+            corr_data = DD["corr_data"]
+
+        corr_pair = DD["corr_pair"]
+        dt = DD["dt"].reshape(1)[0]
+        corr_method = DD["corr_method"].reshape(1)[0]
+        maxlag = DD["maxlag"].reshape(1)[0]
+        smoothspect_N = DD["smoothspect_N"].reshape(1)[0]
+        flag = DD["flag"].reshape(1)[0]
+        flag_gap = DD["flag_gap"].reshape(1)[0]
+        threads = DD["threads"].reshape(1)[0]
+        jobs = DD["jobs"].reshape(1)[0]
+        py = DD["py"].reshape(1)[0]
+
+    elif format == "h5":
+        with h5py.File(filename, 'r') as f:
+            group = f['noiseflow_group']
+
+            if only_header:
+                corr_data = None
+            else:
+                corr_data = group['corr_data'][:]
+
+            dt = group.attrs['dt']
+            corr_method = group.attrs['corr_method']
+            maxlag = group.attrs['maxlag']
+            smoothspect_N = group.attrs['smoothspect_N']
+            flag = group.attrs['flag']
+            flag_gap = group.attrs['flag_gap']
+            threads = group.attrs['threads']
+            corr_pair = group['corr_pair'][:]
+            jobs = group.attrs['jobs']
+            py = group.attrs['py']
+
+    elif format == "mat":
+        DD = loadmat(filename)
+        if only_header:
+            corr_data = None
+        else:
+            corr_data = DD["corr_data"][:,:,:]
+
+        if DD["flag"][0][0] == 1:
+            flag = True
+        else:
+            flag = False
+
+        if DD["py"][0][0] == 1:
+            py = True
+        else:
+            py = False
+        
+        dt = DD["dt"][0][0]
+        corr_method = DD["corr_method"][0]
+        maxlag = DD["maxlag"][0][0]
+        smoothspect_N = DD["smoothspect_N"][0][0]
+        flag_gap = DD["flag_gap"][0][0]
+        threads = DD["threads"][0][0]
+        corr_pair = DD["corr_pair"][:,:]
+        jobs = DD["jobs"][0][0]
+
+        
+    else:
+        raise ValueError("format must be 'npz', 'h5' or 'mat'")
+    
+    CorrData = CorrData_Class(corr_data, dt, corr_method, corr_pair, maxlag, smoothspect_N,
+        flag, flag_gap, threads, jobs, py)
+    
+    return CorrData
+
+
+
+def load_stack(filename, format="npz", only_header=False):
+    par = None
+
+    if format == "npz":
+        DD = np.load(filename, allow_pickle=True)
+        if only_header:
+            stack_data = None
+        else:
+            stack_data = DD["stack_data"]
+
+        stack_ngood = DD["stack_ngood"]
+        dt = DD["dt"].reshape(1)[0]
+        stack_method = DD["stack_method"].reshape(1)[0]
+        par = DD["par"].reshape(1)[0]
+        stack_all = DD["stack_all"].reshape(1)[0]
+        stack_len = DD["stack_len"].reshape(1)[0]
+        stack_step = DD["stack_step"].reshape(1)[0]
+        pick = DD["pick"].reshape(1)[0]
+        median_high = DD["median_high"].reshape(1)[0]
+        median_low = DD["median_low"].reshape(1)[0]
+        flag = DD["flag"].reshape(1)[0]
+        flag_gap = DD["flag_gap"].reshape(1)[0]
+        threads = DD["threads"].reshape(1)[0]
+        jobs = DD["jobs"].reshape(1)[0]
+        py = DD["py"].reshape(1)[0]
+
+    elif format == "h5":
+        with h5py.File(filename, 'r') as f:
+            group = f['noiseflow_group']
+
+            if only_header:
+                stack_data = None
+            else:
+                stack_data = group['stack_data'][:]
+
+            dt = group.attrs['dt']
+            stack_method = group.attrs['stack_method']
+            stack_all = group.attrs['stack_all']
+            stack_len = group.attrs['stack_len']
+            stack_step = group.attrs['stack_step']
+            pick = group.attrs['pick']
+            median_high = group.attrs['median_high']
+            median_low = group.attrs['median_low']
+            flag = group.attrs['flag']
+            flag_gap = group.attrs['flag_gap']
+            threads = group.attrs['threads']
+            stack_ngood = group['stack_ngood'][:]
+            jobs = group.attrs['jobs']
+            py = group.attrs['py']
+
+            par = {}
+            for key in group.attrs.keys():
+                value = group.attrs[key]
+                if isinstance(value, float) and np.isnan(value):
+                    value = None
+                par[key] = value
+
+    elif format == "mat":
+        DD = loadmat(filename)
+        if only_header:
+            stack_data = None
+        else:
+            stack_data = DD["stack_data"][:,:,:]
+
+        if DD["stack_all"][0][0] == 1:
+            stack_all = True
+        else:
+            stack_all = False
+
+        if DD["pick"][0][0] == 1:
+            pick = True
+        else:
+            pick = False
+
+        if DD["flag"][0][0] == 1:
+            flag = True
+        else:
+            flag = False
+        
+        if DD["py"][0][0] == 1:
+            py = True
+        else:
+            py = False
+        
+        dt = DD["dt"][0][0]
+        stack_method = DD["stack_method"][0]
+        stack_len = DD["stack_len"][0][0]
+        stack_step = DD["stack_step"][0][0]
+        median_high = DD["median_high"][0][0]
+        median_low = DD["median_low"][0][0]
+        flag_gap = DD["flag_gap"][0][0]
+        threads = DD["threads"][0][0]
+        stack_ngood = DD["stack_ngood"][:]
+        jobs = DD["jobs"][0][0]
+        par = decode_dict_from_mat(DD['par'][0][0])
+
+    else:
+        raise ValueError("format must be 'npz', 'h5' or 'mat'")
+    
+    StackData = StackData_Class(stack_data, stack_ngood, dt,
+                stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads, jobs, py)
+    
+    return StackData
+
+
+
+def decode_dict_from_mat(par_data):
+    par = {}
+
+    for field_name in par_data.dtype.names:
+        value = par_data[field_name][0, 0]
+    
+        if isinstance(value, np.ndarray) and value.size == 1:
+            value = value.item()
+    
+        if isinstance(value, float) and np.isnan(value):
+            value = None
+
+        par[field_name] = value
+
+    if par["stat"] == 1:
+        par["stat"] = True
+    else:
+        par["stat"] = False
+
+    if par["plot"] == 1:
+        par["plot"] = True
+    else:
+        par["plot"] = False
+
+    if par["normalize"] == 1:
+        par["normalize"] = True
+    else:
+        par["normalize"] = False
+
     return par
```

## noiseflow/cc/utils_time.py

 * *Ordering differences only*

```diff
@@ -1,42 +1,42 @@
-import numpy as np
-
-from obspy.core import UTCDateTime
-
-
-# get rfft/corr timestamp vector
-def get_timestamp(win_num,             
-                cc_len, 
-                cc_step,
-                t_min=UTCDateTime("1970-01-01T00:00:00.0")):
-
-    t_max = t_min + (win_num-1)*(cc_len-cc_step) + cc_len
-    win_interval = cc_len-cc_step
-    win_start_vector = np.array([t_min + i*win_interval for i in range(0, win_num)])
-
-    return t_max, win_interval, win_start_vector
-
-
-# get stack timestamp vector
-def get_stack_timestamp(win_num,
-                        stack_len,
-                        stack_step,
-                        cc_len, 
-                        cc_step,
-                        t_min=UTCDateTime("1970-01-01T00:00:00.0")):
-    
-    corr_win_num = (win_num-1)*(stack_len-stack_step) + stack_len
-    t_max = t_min + (corr_win_num-1)*(cc_len-cc_step) + cc_len
-    win_len = stack_len*(cc_len-cc_step)
-    win_interval = (stack_len-stack_step)*(cc_len-cc_step)
-    win_start_vector = np.array([t_min + i*win_interval for i in range(0, win_num)])
-
-    return t_max, win_len, win_interval, win_start_vector
-    
-
-def time_linspace(start_time, end_time, num):
-    t_min = 0
-    t_max = end_time - start_time
-    t_vector = np.linspace(t_min, t_max, num=num)
-    date_vector = np.array([start_time + i for i in t_vector])
-              
-    return date_vector
+import numpy as np
+
+from obspy.core import UTCDateTime
+
+
+# get rfft/corr timestamp vector
+def get_timestamp(win_num,             
+                cc_len, 
+                cc_step,
+                t_min=UTCDateTime("1970-01-01T00:00:00.0")):
+
+    t_max = t_min + (win_num-1)*(cc_len-cc_step) + cc_len
+    win_interval = cc_len-cc_step
+    win_start_vector = np.array([t_min + i*win_interval for i in range(0, win_num)])
+
+    return t_max, win_interval, win_start_vector
+
+
+# get stack timestamp vector
+def get_stack_timestamp(win_num,
+                        stack_len,
+                        stack_step,
+                        cc_len, 
+                        cc_step,
+                        t_min=UTCDateTime("1970-01-01T00:00:00.0")):
+    
+    corr_win_num = (win_num-1)*(stack_len-stack_step) + stack_len
+    t_max = t_min + (corr_win_num-1)*(cc_len-cc_step) + cc_len
+    win_len = stack_len*(cc_len-cc_step)
+    win_interval = (stack_len-stack_step)*(cc_len-cc_step)
+    win_start_vector = np.array([t_min + i*win_interval for i in range(0, win_num)])
+
+    return t_max, win_len, win_interval, win_start_vector
+    
+
+def time_linspace(start_time, end_time, num):
+    t_min = 0
+    t_max = end_time - start_time
+    t_vector = np.linspace(t_min, t_max, num=num)
+    date_vector = np.array([start_time + i for i in t_vector])
+              
+    return date_vector
```

## noiseflow/cc/wrapper.py

 * *Ordering differences only*

```diff
@@ -1,227 +1,227 @@
-import os
-import re
-import json
-import numpy as np
-
-from noiseflow.cc.rfftdata import RFFTData_Class
-from noiseflow.cc.corrdata import CorrData_Class
-from noiseflow.cc.stackdata import StackData_Class
-from noiseflow.cc.python.rfft import RFFTClass_python
-from noiseflow.cc.python.corr import CorrClass_python
-from noiseflow.cc.python.stack import StackClass_python
-
-# Determine the absolute path to the config file
-env = os.environ.get('CONDA_DEFAULT_ENV')
-env = re.sub('[^a-zA-Z0-9_]', '', env)[0:50]
-config_path = os.path.abspath(os.path.expanduser(f'~/.noiseflow/config_{env}.json'))    
-
-# Read the config.json file
-with open(config_path) as f:
-    config = json.load(f)
-
-if config.get('NOISEFLOW_USE_CPP', False):
-    NOISEFLOW_USE_CPP = True
-    from noiseflow.lib import cc_share
-else:
-    NOISEFLOW_USE_CPP = False  
-
-
-def rfft(raw_data, dt,
-        cc_len, cc_step, 
-        time_norm, clip_std, smooth_N,
-        freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N, 
-        flag=False, flag_gap=None, threads=1, jobs=1, py=False):
-    
-    # check demision of raw_data
-    if raw_data.ndim == 1:
-        raw_data = raw_data.reshape(1, -1)
-
-    # check freqmax
-    if (freqmax > (1/(2*dt))):
-        raise ValueError("freqmax must be <= (%fhz) according to fmax=1/(2*dt) formula" % (1/(2*dt)))
-    
-    # check cc_len
-    if (cc_len > raw_data.shape[1]*dt):
-        raise ValueError("cc_len must be <= (raw_data.shape[1]*dt=%f)" % (raw_data.shape[1]*dt))
-
-    # check cc_step
-    if (cc_step >= cc_len):
-        raise ValueError("cc_step must be < (cc_len=%f)" % cc_len)
-
-    # check time_norm
-    if time_norm not in ['no', 'onebit', 'clip', 'smooth']:
-        raise ValueError("time_norm must be 'no', 'onebit', 'clip', or 'smooth'")
-    
-    # check freq_norm
-    if freq_norm not in ['no', 'whiten', 'smooth_whiten']:
-        raise ValueError("freq_norm must be 'no', 'whiten', or 'smooth_whiten'")
-    
-    # check threads
-    if threads > raw_data.shape[0]:
-        raise ValueError("threads must be <= (raw_data.shape[0]=%d)" % raw_data.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(raw_data.shape[0])
-
-    # run rfft
-    if py:
-        if raw_data.dtype == np.dtype(np.float32) or raw_data.dtype == np.dtype(np.float64):
-            m = RFFTClass_python(raw_data, dt,
-                         cc_len, cc_step, 
-                        time_norm, clip_std, smooth_N,
-                        freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
-                        flag, jobs)
-            m.run()
-            rfft_data = m.output_data
-        else:
-            raise TypeError("raw_data.dtype must be np.float32 or np.float64")
-    else:
-        if raw_data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            rfft_data = cc_share.rfft_float(raw_data, dt, 
-                cc_len, cc_step, 
-                time_norm, clip_std, smooth_N,
-                freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
-                flag, flag_gap,
-                threads)
-        elif raw_data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            rfft_data = cc_share.rfft_double(raw_data, dt, 
-                cc_len, cc_step, 
-                time_norm, clip_std, smooth_N,
-                freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
-                flag, flag_gap,
-                threads)
-        else:
-            raise TypeError("raw_data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-    # generate RFFTData object
-    RFFTData = RFFTData_Class(rfft_data, dt, cc_len, cc_step, 
-        time_norm, clip_std, smooth_N,
-        freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
-        flag, flag_gap,
-        threads, jobs, py)
-    
-    return RFFTData
-
-
-
-def corr(rfft_data, dt, corr_method, corr_pair, maxlag, smoothspect_N=10, 
-         flag=False, flag_gap=None, threads=1, jobs=1, py=False):
-    
-    # check corr_method
-    if corr_method not in ['xcorr', 'deconv', 'coherency']:
-        raise ValueError("corr_method must be 'xcorr', 'deconv', or 'coherency'")
-    
-    # check maxlag
-    if maxlag > dt*rfft_data.shape[2]:
-        raise ValueError("maxlag must be <= (dt*rfft_data.shape[2]=%f)" % (dt*rfft_data.shape[2]))
-    
-    # check threads
-    if threads > rfft_data.shape[0]:
-        raise ValueError("threads must be <= (rfft_data.shape[0]=%d)" % rfft_data.shape[0])
-
-    # check demision of corr_pair
-    if corr_pair.ndim == 1:
-        corr_pair = corr_pair.reshape(1, -1)
-
-    # check threads
-    if threads > corr_pair.shape[0]:
-        raise ValueError("threads must be <= (corr_pair.shape[0]=%d)" % corr_pair.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(corr_pair.shape[0])
-
-    # run corr
-    if py:
-        if rfft_data.dtype == np.dtype(np.complex64) or rfft_data.dtype == np.dtype(np.complex128):
-            m = CorrClass_python(rfft_data, dt, corr_method, corr_pair, maxlag,
-                smoothspect_N, flag, jobs)
-            m.run()
-            corr_data = m.output_data
-        else:
-            raise TypeError("rfft_data.dtype must be np.complex64 or np.complex128")
-    else:
-        if rfft_data.dtype == np.dtype(np.complex64) and NOISEFLOW_USE_CPP:
-            corr_data = cc_share.corr_float(rfft_data, dt, corr_method, corr_pair, maxlag,
-                smoothspect_N, flag, flag_gap, threads)
-        elif rfft_data.dtype == np.dtype(np.complex128) and NOISEFLOW_USE_CPP:
-            corr_data = cc_share.corr_double(rfft_data, dt, corr_method, corr_pair, maxlag,
-                smoothspect_N, flag, flag_gap, threads)
-        else:
-            raise TypeError("rfft_data.dtype must be np.complex64, np.complex128 or NOISEFLOW_USE_CPP=False")
-
-    # generate CorrData object
-    CorrData = CorrData_Class(corr_data, dt, corr_method, corr_pair, maxlag, smoothspect_N,
-        flag, flag_gap, threads, jobs, py)
-    
-    return CorrData
-
-
-
-def stack(corr_data, dt, stack_method, 
-          par=None, 
-          stack_all=True, stack_len=0, stack_step=0, 
-          pick=False, median_high=10, median_low=0.1, 
-          flag=False, flag_gap=None, threads=1, jobs=1, py=False):
-    
-    # check par
-    if par == None:
-        par = {"axis":0,"p":2,"g":1,"cc_min":0.0,"epsilon":1E-5,"maxstep":10,
-                "win":None,"stat":False,"h":0.75,'plot':False,'normalize':True,'ref':None},
-    
-    # check demision of corr_data
-    if corr_data.ndim == 2:
-        corr_data = corr_data.reshape(1, corr_data.shape[0], corr_data.shape[1])
-
-    # check stack_method
-    if stack_method not in ["linear","pws","robust","acf","nroot","selective","cluster","tfpws"]:
-        raise ValueError("stack_method must be 'linear', 'pws', 'robust', 'acf', 'nroot', 'selective', 'cluster', or 'tfpws'")
-    
-    # check stack_len
-    if (stack_len > corr_data.shape[1]):
-        raise ValueError("stack_len must be <= (corr_data.shape[1]=%d)" % corr_data.shape[1])
-
-    # check stack_step
-    if (stack_step >= stack_len):
-        raise ValueError("stack_step must be < (stack_len=%d)" % stack_len)
-    
-    # check threads
-    if threads > corr_data.shape[0]:
-        raise ValueError("threads must be <= (corr_data.shape[0]=%d)" % corr_data.shape[0])
-
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(corr_data.shape[0])
-
-    # run stack
-    if py:
-        if corr_data.dtype == np.dtype(np.float32) or corr_data.dtype == np.dtype(np.float64):
-            m = StackClass_python(corr_data, stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, jobs)
-            m.run()
-            stack_data = m.output_data
-            stack_ngood = m.ngood_all
-        else:
-            raise TypeError("corr_data.dtype must be np.float32 or np.float64")
-    else:
-        if corr_data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            m = cc_share.StackClass_float(corr_data, stack_method, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads)
-            m.run()
-            stack_data = m.get_stackdata()
-            stack_ngood = m.get_ngood()
-        elif corr_data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            m = cc_share.StackClass_double(corr_data, stack_method, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads)
-            m.run()
-            stack_data = m.get_stackdata()
-            stack_ngood = m.get_ngood()
-        else:
-            raise TypeError("corr_data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-    # generate StackData object
-    StackData = StackData_Class(stack_data, stack_ngood, dt,
-                 stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads, jobs, py)
-    
-    return StackData
-
-
-
+import os
+import re
+import json
+import numpy as np
+
+from noiseflow.cc.rfftdata import RFFTData_Class
+from noiseflow.cc.corrdata import CorrData_Class
+from noiseflow.cc.stackdata import StackData_Class
+from noiseflow.cc.python.rfft import RFFTClass_python
+from noiseflow.cc.python.corr import CorrClass_python
+from noiseflow.cc.python.stack import StackClass_python
+
+# Determine the absolute path to the config file
+env = os.environ.get('CONDA_DEFAULT_ENV')
+env = re.sub('[^a-zA-Z0-9_]', '', env)[0:50]
+config_path = os.path.abspath(os.path.expanduser(f'~/.noiseflow/config_{env}.json'))    
+
+# Read the config.json file
+with open(config_path) as f:
+    config = json.load(f)
+
+if config.get('NOISEFLOW_USE_CPP', False):
+    NOISEFLOW_USE_CPP = True
+    from noiseflow.lib import cc_share
+else:
+    NOISEFLOW_USE_CPP = False  
+
+
+def rfft(raw_data, dt,
+        cc_len, cc_step, 
+        time_norm, clip_std, smooth_N,
+        freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N, 
+        flag=False, flag_gap=None, threads=1, jobs=1, py=False):
+    
+    # check demision of raw_data
+    if raw_data.ndim == 1:
+        raw_data = raw_data.reshape(1, -1)
+
+    # check freqmax
+    if (freqmax > (1/(2*dt))):
+        raise ValueError("freqmax must be <= (%fhz) according to fmax=1/(2*dt) formula" % (1/(2*dt)))
+    
+    # check cc_len
+    if (cc_len > raw_data.shape[1]*dt):
+        raise ValueError("cc_len must be <= (raw_data.shape[1]*dt=%f)" % (raw_data.shape[1]*dt))
+
+    # check cc_step
+    if (cc_step >= cc_len):
+        raise ValueError("cc_step must be < (cc_len=%f)" % cc_len)
+
+    # check time_norm
+    if time_norm not in ['no', 'onebit', 'clip', 'smooth']:
+        raise ValueError("time_norm must be 'no', 'onebit', 'clip', or 'smooth'")
+    
+    # check freq_norm
+    if freq_norm not in ['no', 'whiten', 'smooth_whiten']:
+        raise ValueError("freq_norm must be 'no', 'whiten', or 'smooth_whiten'")
+    
+    # check threads
+    if threads > raw_data.shape[0]:
+        raise ValueError("threads must be <= (raw_data.shape[0]=%d)" % raw_data.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(raw_data.shape[0])
+
+    # run rfft
+    if py:
+        if raw_data.dtype == np.dtype(np.float32) or raw_data.dtype == np.dtype(np.float64):
+            m = RFFTClass_python(raw_data, dt,
+                         cc_len, cc_step, 
+                        time_norm, clip_std, smooth_N,
+                        freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
+                        flag, jobs)
+            m.run()
+            rfft_data = m.output_data
+        else:
+            raise TypeError("raw_data.dtype must be np.float32 or np.float64")
+    else:
+        if raw_data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            rfft_data = cc_share.rfft_float(raw_data, dt, 
+                cc_len, cc_step, 
+                time_norm, clip_std, smooth_N,
+                freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
+                flag, flag_gap,
+                threads)
+        elif raw_data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            rfft_data = cc_share.rfft_double(raw_data, dt, 
+                cc_len, cc_step, 
+                time_norm, clip_std, smooth_N,
+                freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
+                flag, flag_gap,
+                threads)
+        else:
+            raise TypeError("raw_data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+    # generate RFFTData object
+    RFFTData = RFFTData_Class(rfft_data, dt, cc_len, cc_step, 
+        time_norm, clip_std, smooth_N,
+        freq_norm, freqmin, freqmax, whiten_npad, smoothspect_N,
+        flag, flag_gap,
+        threads, jobs, py)
+    
+    return RFFTData
+
+
+
+def corr(rfft_data, dt, corr_method, corr_pair, maxlag, smoothspect_N=10, 
+         flag=False, flag_gap=None, threads=1, jobs=1, py=False):
+    
+    # check corr_method
+    if corr_method not in ['xcorr', 'deconv', 'coherency']:
+        raise ValueError("corr_method must be 'xcorr', 'deconv', or 'coherency'")
+    
+    # check maxlag
+    if maxlag > dt*rfft_data.shape[2]:
+        raise ValueError("maxlag must be <= (dt*rfft_data.shape[2]=%f)" % (dt*rfft_data.shape[2]))
+    
+    # check threads
+    if threads > rfft_data.shape[0]:
+        raise ValueError("threads must be <= (rfft_data.shape[0]=%d)" % rfft_data.shape[0])
+
+    # check demision of corr_pair
+    if corr_pair.ndim == 1:
+        corr_pair = corr_pair.reshape(1, -1)
+
+    # check threads
+    if threads > corr_pair.shape[0]:
+        raise ValueError("threads must be <= (corr_pair.shape[0]=%d)" % corr_pair.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(corr_pair.shape[0])
+
+    # run corr
+    if py:
+        if rfft_data.dtype == np.dtype(np.complex64) or rfft_data.dtype == np.dtype(np.complex128):
+            m = CorrClass_python(rfft_data, dt, corr_method, corr_pair, maxlag,
+                smoothspect_N, flag, jobs)
+            m.run()
+            corr_data = m.output_data
+        else:
+            raise TypeError("rfft_data.dtype must be np.complex64 or np.complex128")
+    else:
+        if rfft_data.dtype == np.dtype(np.complex64) and NOISEFLOW_USE_CPP:
+            corr_data = cc_share.corr_float(rfft_data, dt, corr_method, corr_pair, maxlag,
+                smoothspect_N, flag, flag_gap, threads)
+        elif rfft_data.dtype == np.dtype(np.complex128) and NOISEFLOW_USE_CPP:
+            corr_data = cc_share.corr_double(rfft_data, dt, corr_method, corr_pair, maxlag,
+                smoothspect_N, flag, flag_gap, threads)
+        else:
+            raise TypeError("rfft_data.dtype must be np.complex64, np.complex128 or NOISEFLOW_USE_CPP=False")
+
+    # generate CorrData object
+    CorrData = CorrData_Class(corr_data, dt, corr_method, corr_pair, maxlag, smoothspect_N,
+        flag, flag_gap, threads, jobs, py)
+    
+    return CorrData
+
+
+
+def stack(corr_data, dt, stack_method, 
+          par=None, 
+          stack_all=True, stack_len=0, stack_step=0, 
+          pick=False, median_high=10, median_low=0.1, 
+          flag=False, flag_gap=None, threads=1, jobs=1, py=False):
+    
+    # check par
+    if par == None:
+        par = {"axis":0,"p":2,"g":1,"cc_min":0.0,"epsilon":1E-5,"maxstep":10,
+                "win":None,"stat":False,"h":0.75,'plot':False,'normalize':True,'ref':None},
+    
+    # check demision of corr_data
+    if corr_data.ndim == 2:
+        corr_data = corr_data.reshape(1, corr_data.shape[0], corr_data.shape[1])
+
+    # check stack_method
+    if stack_method not in ["linear","pws","robust","acf","nroot","selective","cluster","tfpws"]:
+        raise ValueError("stack_method must be 'linear', 'pws', 'robust', 'acf', 'nroot', 'selective', 'cluster', or 'tfpws'")
+    
+    # check stack_len
+    if (stack_len > corr_data.shape[1]):
+        raise ValueError("stack_len must be <= (corr_data.shape[1]=%d)" % corr_data.shape[1])
+
+    # check stack_step
+    if (stack_step >= stack_len):
+        raise ValueError("stack_step must be < (stack_len=%d)" % stack_len)
+    
+    # check threads
+    if threads > corr_data.shape[0]:
+        raise ValueError("threads must be <= (corr_data.shape[0]=%d)" % corr_data.shape[0])
+
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(corr_data.shape[0])
+
+    # run stack
+    if py:
+        if corr_data.dtype == np.dtype(np.float32) or corr_data.dtype == np.dtype(np.float64):
+            m = StackClass_python(corr_data, stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, jobs)
+            m.run()
+            stack_data = m.output_data
+            stack_ngood = m.ngood_all
+        else:
+            raise TypeError("corr_data.dtype must be np.float32 or np.float64")
+    else:
+        if corr_data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            m = cc_share.StackClass_float(corr_data, stack_method, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads)
+            m.run()
+            stack_data = m.get_stackdata()
+            stack_ngood = m.get_ngood()
+        elif corr_data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            m = cc_share.StackClass_double(corr_data, stack_method, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads)
+            m.run()
+            stack_data = m.get_stackdata()
+            stack_ngood = m.get_ngood()
+        else:
+            raise TypeError("corr_data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+    # generate StackData object
+    StackData = StackData_Class(stack_data, stack_ngood, dt,
+                 stack_method, par, stack_all, stack_len, stack_step, pick, median_high, median_low, flag, flag_gap, threads, jobs, py)
+    
+    return StackData
+
+
+
```

## noiseflow/client/client.py

```diff
@@ -1,205 +1,201 @@
-import os
-import requests
-
-from tqdm import tqdm
-from pathlib import Path
-from concurrent.futures import ThreadPoolExecutor, as_completed
-
-try:
-    from faker import Faker
-except:
-    print("Please install faker via pip install faker")
-
-
-cpu_cores = os.cpu_count()
-requests.packages.urllib3.disable_warnings()
-
-
-def downloader(url, type='https', show_info = True, resume=True, filename=None, num_threads=cpu_cores, timeout=10, chunk_size=1024*1000, header=None, proxies=None):
-    if type == 'https':
-        d = downloader_https(url, show_info, resume, filename, num_threads, timeout, chunk_size, header, proxies)
-        d.download()
-    else:
-        pass
-
-
-class downloader_https():
-    def __init__(self, url, show_info = True, resume=True, filename=None, num_threads=cpu_cores, timeout=10, chunk_size=1024*1000, header=None, proxies=None):
-        """
-        :param url: link address
-        :param filename: file name
-        """
-        self.url = url
-        self.show_info = show_info
-        self.resume = resume
-        self.chunk_size = chunk_size 
-        self.filename = filename
-        self.num_threads = num_threads
-        self.proxies = proxies
-        self.timeout = timeout
-        self.file_type = None
-        self.accept_ranges = None
-        self.content_length = None
-        self.transfer_encoding = None
-        if header is None:
-            self.header = {}
-            self.header.setdefault('User-Agent', Faker().user_agent())
-        elif 'User-Agent' not in header:
-            self.header.setdefault('User-Agent', Faker().user_agent())
-        else:
-            self.header = header
-
- 
-    def check_url(self):
-        """
-        check url support break-point resume and support multi-thread downloading
-        """
-        _, filename = os.path.split(self.url)
-        self.filename = self.filename or filename
-
-        res = requests.head(self.url, headers=self.header, proxies=self.proxies, timeout=self.timeout, allow_redirects=True, verify=False)  # verify=False 关闭ssl双向验证，解决访问https报错问题
-
-        if not (200 <= res.status_code < 400):
-            raise Exception('Bad request!')
-
-        headers = res.headers
-        self.file_type = headers.get('Content-Type')
-        self.accept_ranges = headers.get('Accept-Ranges')
-        self.transfer_encoding = headers.get('Transfer-Encoding')
-
-        if self.transfer_encoding == "chunked" or self.transfer_encoding == "gzip, chunked":
-            self.num_threads = 1
-            self.content_length = 0
-        else:
-            lengths = headers.get('Content-Length')
-            if lengths == None:
-                self.content_length = 0
-            else:
-                self.content_length = int(lengths)
-
-
-    def get_range(self, start=0):
-        """
-        set download range
-        eg: [(0, 1023), (1024, 2047), (2048, 3071) ...]
-        """
-        if self.transfer_encoding == "chunked" or self.transfer_encoding == "gzip, chunked":
-            _range = [(start, '')]
-        else:
-            lst = range(start, self.content_length, self.chunk_size)   
-            _range = list(zip(lst[:-1], [i - 1 for i in lst[1:]]))
-            _range.append((lst[-1], ''))
-
-        return _range
-
-
-    def download_by_piece(self, _range):
-        start, stop = _range
-        headers = {**self.header, **{"Range": f"bytes={start}-{stop}"}} # merge
-
-        res = requests.get(self.url, headers=headers, proxies=self.proxies, timeout=self.timeout, allow_redirects=True, verify=False)
-        if res.status_code != 206:
-            raise Exception(f'Request raise error, url: {self.url}, range: {_range}')
-        return _range, res.content
-
-
-    def download(self):
-        start = 0
-        self.check_url()
-
-        if self.accept_ranges != "bytes":
-            if self.show_info:
-                print(f'--- Mission ---: {self.url} download from scratch || with single thread, do not support breakpoint resuming')
-            
-            file_path = Path(self.filename)
-
-            res = requests.get(self.url, 
-                                headers=self.header, 
-                                proxies=self.proxies, 
-                                timeout=self.timeout, 
-                                allow_redirects=True, 
-                                verify=False)
-
-            if res.status_code != 206:
-                raise Exception(f'Request raise error, url: {self.url}')
- 
-            # write
-            open(file_path, 'w').close() 
-            with open(self.filename, 'rb+') as fp:
-                fp.seek(0)
-                fp.write(res.content)
-
-            if self.show_info:
-                print(f'--- File ---: {self.filename} download completely')
-        else:
-            file_path = Path(self.filename)
-
-            if self.resume:
-                open(file_path, 'w+').close()
-                start = 0
-                if self.show_info:
-                    print(f'--- Mission ---: {self.url} download from scratch || with {self.num_threads} threads, support breakpoint resuming')
-
-            else:
-                if file_path.exists():
-                    # breakpoint resume
-                    start = file_path.lstat().st_size
-                    if self.show_info:
-                        print(f'--- Mission ---: {self.url} download from breakpoint || with {self.num_threads} threads, support breakpoint resuming')
-
-                    # If file have already downloaded 
-                    if start == self.content_length:
-                        if self.show_info:
-                            print(f'--- File ---: {self.filename} has already been downloaded completely')
-                        return
-                else:
-                    open(file_path, 'w+').close()
-                    start = 0
-                    if self.show_info:
-                        print(f'--- Mission ---: {self.url} download from scratch || with {self.num_threads} threads, support breakpoint resuming')
-
-            # init progress bar
-            if self.show_info:
-                pbar = tqdm(total=self.content_length,
-                        initial=start,
-                        unit='B',
-                        unit_scale=True,
-                        desc=self.filename,
-                        unit_divisor=1024)
-            
-            # multi-thread download
-            with ThreadPoolExecutor(max_workers=self.num_threads) as pool:
-                res = [pool.submit(self.download_by_piece, r) for r in self.get_range(start=start)] # or use map function
-
-                # write
-                with open(self.filename, 'rb+') as fp:
-                    for item in as_completed(res):
-                        _range, content = item.result()
-                        start, stop = _range
-                        fp.seek(start)
-                        fp.write(content)
-                        # update progress bar
-                        if self.show_info:
-                            pbar.update(self.chunk_size)
-
-            if self.show_info:
-                pbar.close()
-                print(f'--- File ---: {self.filename} download completely')
-
-
-    def print(self):
-        self.check_url()
-        print( "self.url = ", self.url, '\n',
-            "self.resume = ", self.resume, '\n',
-            "self.chunk_size = ", self.chunk_size, '\n',
-            "self.filename = ", self.filename, '\n',
-            "self.num_threads = ", self.num_threads, '\n',
-            "self.proxies = ", self.proxies, '\n',
-            "self.timeout = ", self.timeout, '\n',
-            "self.file_type = ", self.file_type, '\n',
-            "self.accept_ranges = ", self.accept_ranges, '\n',
-            "self.content_length = ", self.content_length, '\n',
-            "self.transfer_encoding = ", self.transfer_encoding, '\n',
-            "self.header = ", self.header
-            )
-
+import os
+import requests
+
+from tqdm import tqdm
+from faker import Faker
+from pathlib import Path
+from concurrent.futures import ThreadPoolExecutor, as_completed
+
+
+cpu_cores = os.cpu_count()
+requests.packages.urllib3.disable_warnings()
+
+
+def downloader(url, type='https', show_info = True, resume=True, filename=None, num_threads=cpu_cores, timeout=10, chunk_size=1024*1000, header=None, proxies=None):
+    if type == 'https':
+        d = downloader_https(url, show_info, resume, filename, num_threads, timeout, chunk_size, header, proxies)
+        d.download()
+    else:
+        pass
+
+
+class downloader_https():
+    def __init__(self, url, show_info = True, resume=True, filename=None, num_threads=cpu_cores, timeout=10, chunk_size=1024*1000, header=None, proxies=None):
+        """
+        :param url: link address
+        :param filename: file name
+        """
+        self.url = url
+        self.show_info = show_info
+        self.resume = resume
+        self.chunk_size = chunk_size 
+        self.filename = filename
+        self.num_threads = num_threads
+        self.proxies = proxies
+        self.timeout = timeout
+        self.file_type = None
+        self.accept_ranges = None
+        self.content_length = None
+        self.transfer_encoding = None
+        if header is None:
+            self.header = {}
+            self.header.setdefault('User-Agent', Faker().user_agent())
+        elif 'User-Agent' not in header:
+            self.header.setdefault('User-Agent', Faker().user_agent())
+        else:
+            self.header = header
+
+ 
+    def check_url(self):
+        """
+        check url support break-point resume and support multi-thread downloading
+        """
+        _, filename = os.path.split(self.url)
+        self.filename = self.filename or filename
+
+        res = requests.head(self.url, headers=self.header, proxies=self.proxies, timeout=self.timeout, allow_redirects=True, verify=False)  # verify=False 关闭ssl双向验证，解决访问https报错问题
+
+        if not (200 <= res.status_code < 400):
+            raise Exception('Bad request!')
+
+        headers = res.headers
+        self.file_type = headers.get('Content-Type')
+        self.accept_ranges = headers.get('Accept-Ranges')
+        self.transfer_encoding = headers.get('Transfer-Encoding')
+
+        if self.transfer_encoding == "chunked" or self.transfer_encoding == "gzip, chunked":
+            self.num_threads = 1
+            self.content_length = 0
+        else:
+            lengths = headers.get('Content-Length')
+            if lengths == None:
+                self.content_length = 0
+            else:
+                self.content_length = int(lengths)
+
+
+    def get_range(self, start=0):
+        """
+        set download range
+        eg: [(0, 1023), (1024, 2047), (2048, 3071) ...]
+        """
+        if self.transfer_encoding == "chunked" or self.transfer_encoding == "gzip, chunked":
+            _range = [(start, '')]
+        else:
+            lst = range(start, self.content_length, self.chunk_size)   
+            _range = list(zip(lst[:-1], [i - 1 for i in lst[1:]]))
+            _range.append((lst[-1], ''))
+
+        return _range
+
+
+    def download_by_piece(self, _range):
+        start, stop = _range
+        headers = {**self.header, **{"Range": f"bytes={start}-{stop}"}} # merge
+
+        res = requests.get(self.url, headers=headers, proxies=self.proxies, timeout=self.timeout, allow_redirects=True, verify=False)
+        if res.status_code != 206:
+            raise Exception(f'Request raise error, url: {self.url}, range: {_range}')
+        return _range, res.content
+
+
+    def download(self):
+        start = 0
+        self.check_url()
+
+        if self.accept_ranges != "bytes":
+            if self.show_info:
+                print(f'--- Mission ---: {self.url} download from scratch || with single thread, do not support breakpoint resuming')
+            
+            file_path = Path(self.filename)
+
+            res = requests.get(self.url, 
+                                headers=self.header, 
+                                proxies=self.proxies, 
+                                timeout=self.timeout, 
+                                allow_redirects=True, 
+                                verify=False)
+
+            if res.status_code != 206:
+                raise Exception(f'Request raise error, url: {self.url}')
+ 
+            # write
+            open(file_path, 'w').close() 
+            with open(self.filename, 'rb+') as fp:
+                fp.seek(0)
+                fp.write(res.content)
+
+            if self.show_info:
+                print(f'--- File ---: {self.filename} download completely')
+        else:
+            file_path = Path(self.filename)
+
+            if self.resume:
+                open(file_path, 'w+').close()
+                start = 0
+                if self.show_info:
+                    print(f'--- Mission ---: {self.url} download from scratch || with {self.num_threads} threads, support breakpoint resuming')
+
+            else:
+                if file_path.exists():
+                    # breakpoint resume
+                    start = file_path.lstat().st_size
+                    if self.show_info:
+                        print(f'--- Mission ---: {self.url} download from breakpoint || with {self.num_threads} threads, support breakpoint resuming')
+
+                    # If file have already downloaded 
+                    if start == self.content_length:
+                        if self.show_info:
+                            print(f'--- File ---: {self.filename} has already been downloaded completely')
+                        return
+                else:
+                    open(file_path, 'w+').close()
+                    start = 0
+                    if self.show_info:
+                        print(f'--- Mission ---: {self.url} download from scratch || with {self.num_threads} threads, support breakpoint resuming')
+
+            # init progress bar
+            if self.show_info:
+                pbar = tqdm(total=self.content_length,
+                        initial=start,
+                        unit='B',
+                        unit_scale=True,
+                        desc=self.filename,
+                        unit_divisor=1024)
+            
+            # multi-thread download
+            with ThreadPoolExecutor(max_workers=self.num_threads) as pool:
+                res = [pool.submit(self.download_by_piece, r) for r in self.get_range(start=start)] # or use map function
+
+                # write
+                with open(self.filename, 'rb+') as fp:
+                    for item in as_completed(res):
+                        _range, content = item.result()
+                        start, stop = _range
+                        fp.seek(start)
+                        fp.write(content)
+                        # update progress bar
+                        if self.show_info:
+                            pbar.update(self.chunk_size)
+
+            if self.show_info:
+                pbar.close()
+                print(f'--- File ---: {self.filename} download completely')
+
+
+    def print(self):
+        self.check_url()
+        print( "self.url = ", self.url, '\n',
+            "self.resume = ", self.resume, '\n',
+            "self.chunk_size = ", self.chunk_size, '\n',
+            "self.filename = ", self.filename, '\n',
+            "self.num_threads = ", self.num_threads, '\n',
+            "self.proxies = ", self.proxies, '\n',
+            "self.timeout = ", self.timeout, '\n',
+            "self.file_type = ", self.file_type, '\n',
+            "self.accept_ranges = ", self.accept_ranges, '\n',
+            "self.content_length = ", self.content_length, '\n',
+            "self.transfer_encoding = ", self.transfer_encoding, '\n',
+            "self.header = ", self.header
+            )
+
```

## noiseflow/dispersion/app_dispersion.py

 * *Ordering differences only*

```diff
@@ -1,4 +1,4 @@
-
-
-def one():
+
+
+def one():
     print("one")
```

## noiseflow/dispersion/test.py

 * *Ordering differences only*

```diff
@@ -1,4 +1,4 @@
-
-
-def tt():
+
+
+def tt():
     print("tt")
```

## noiseflow/real_time/watch_dog.py

 * *Ordering differences only*

```diff
@@ -1,12 +1,12 @@
-#%%
-import os
-import time
-import pickle
-import logging
-import threading
-import numpy as np
-# from watchdog.observers import Observer
-# from watchdog.events import FileSystemEventHandler
-
-
-# %%
+#%%
+import os
+import time
+import pickle
+import logging
+import threading
+import numpy as np
+# from watchdog.observers import Observer
+# from watchdog.events import FileSystemEventHandler
+
+
+# %%
```

## noiseflow/signal/include/decimate.hpp

 * *Ordering differences only*

```diff
@@ -1,80 +1,80 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-
-#ifndef DECIMATE_HPP
-#define DECIMATE_HPP
-
-#include "utils.hpp"
-
-namespace SIGNAL {
-
-using namespace kfr;
-
-
-
-// decimate
-template <class T1, class T2>
-T2 decimate(T2 &data, double df, double df_new, bool flag, int flag_gap, int threads) 
-{
-    int samples_num = data.shape(1);
-    int channels_num = data.shape(0);
-    int decimates_num = std::floor(samples_num * df_new/df);
-    int interval = std::round(df/df_new);
-    T2 re_data= xt::empty<T1>({channels_num, decimates_num});
-    auto start_time = std::chrono::high_resolution_clock::now();
-    auto end_time = start_time;
-
-#ifdef _OPENMP
-  omp_set_num_threads(threads);
-  if (flag) {
-    std::cout << "Start decimate with " << threads  << " threads using openmp..." << std::endl;
-  }
-  #pragma omp parallel for
-#else
-  if (flag) {
-    std::cout << "Start decimate with " << 1 << " threads without openmp..." << std::endl;
-  }
-#endif
-
-    for(int i=0; i<channels_num; i++){
-    // flag
-#ifdef _OPENMP
-    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-
-        for (int j=0; j<decimates_num; j++){
-            re_data(i, j) = data(i, j*interval);
-        }
-    }
-
-    end_time = std::chrono::high_resolution_clock::now();
-    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-    if (flag) {
-        std::cout << "End decimate with total time " << elapsed_time.count() << "s" <<std::endl;
-    }
-    return re_data;
-}
-
-// **************************************************************************
-// *                        end
-// **************************************************************************
-
-}
-
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+
+#ifndef DECIMATE_HPP
+#define DECIMATE_HPP
+
+#include "utils.hpp"
+
+namespace SIGNAL {
+
+using namespace kfr;
+
+
+
+// decimate
+template <class T1, class T2>
+T2 decimate(T2 &data, double df, double df_new, bool flag, int flag_gap, int threads) 
+{
+    int samples_num = data.shape(1);
+    int channels_num = data.shape(0);
+    int decimates_num = std::floor(samples_num * df_new/df);
+    int interval = std::round(df/df_new);
+    T2 re_data= xt::empty<T1>({channels_num, decimates_num});
+    auto start_time = std::chrono::high_resolution_clock::now();
+    auto end_time = start_time;
+
+#ifdef _OPENMP
+  omp_set_num_threads(threads);
+  if (flag) {
+    std::cout << "Start decimate with " << threads  << " threads using openmp..." << std::endl;
+  }
+  #pragma omp parallel for
+#else
+  if (flag) {
+    std::cout << "Start decimate with " << 1 << " threads without openmp..." << std::endl;
+  }
+#endif
+
+    for(int i=0; i<channels_num; i++){
+    // flag
+#ifdef _OPENMP
+    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+
+        for (int j=0; j<decimates_num; j++){
+            re_data(i, j) = data(i, j*interval);
+        }
+    }
+
+    end_time = std::chrono::high_resolution_clock::now();
+    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+    if (flag) {
+        std::cout << "End decimate with total time " << elapsed_time.count() << "s" <<std::endl;
+    }
+    return re_data;
+}
+
+// **************************************************************************
+// *                        end
+// **************************************************************************
+
+}
+
 #endif
```

## noiseflow/signal/include/detrend.hpp

 * *Ordering differences only*

```diff
@@ -1,89 +1,89 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-
-#ifndef DETREND_HPP
-#define DETREND_HPP
-
-#include "utils.hpp"
-
-namespace SIGNAL {
-
-using namespace kfr;
-
-
-
-// detrend
-template <class T1, class T2>
-void detrend(T2 &data, std::string type, bool flag, int flag_gap, int threads) 
-{
-    int samples_num = data.shape(1);
-    int channels_num = data.shape(0);
-    auto start_time = std::chrono::high_resolution_clock::now();
-    auto end_time = start_time;
-
-#ifdef _OPENMP
-  omp_set_num_threads(threads);
-  if (flag) {
-    std::cout << "Start detrend with " << threads  << " threads using openmp..." << std::endl;
-  }
-  #pragma omp parallel for
-#else
-  if (flag) {
-    std::cout << "Start detrend with " << 1 << " threads without openmp..." << std::endl;
-  }
-#endif
-    for(int i=0; i<channels_num; i++){
-    // flag
-#ifdef _OPENMP
-    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-        if (type == "linear"){
-            xt::xtensor<T1, 2> A = xt::ones<T1>({samples_num, 2});
-            xt::view(A, xt::all(), 0) = xt::arange(samples_num);
-            auto y = xt::view(data, i, xt::all());
-            auto result = xt::linalg::lstsq(A, y);
-            auto trend = xt::linalg::dot(A, std::get<0>(result));
-            xt::view(data, i, xt::all()) -= trend;
-        }
-        else if (type == "demean"){
-            auto dd = xt::view(data, i, xt::all());
-            auto trend = xt::mean(dd);
-            xt::view(data, i, xt::all()) -= trend;
-        }
-        else {
-            std::cout << "error: please input the correct detrend method." << std::endl;
-        }
-    }
-
-    end_time = std::chrono::high_resolution_clock::now();
-    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-    if (flag) {
-        std::cout << "End detrend with total time " << elapsed_time.count() << "s" <<std::endl;
-    }
-}
-
-
-
-// **************************************************************************
-// *                        end
-// **************************************************************************
-
-}
-
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+
+#ifndef DETREND_HPP
+#define DETREND_HPP
+
+#include "utils.hpp"
+
+namespace SIGNAL {
+
+using namespace kfr;
+
+
+
+// detrend
+template <class T1, class T2>
+void detrend(T2 &data, std::string type, bool flag, int flag_gap, int threads) 
+{
+    int samples_num = data.shape(1);
+    int channels_num = data.shape(0);
+    auto start_time = std::chrono::high_resolution_clock::now();
+    auto end_time = start_time;
+
+#ifdef _OPENMP
+  omp_set_num_threads(threads);
+  if (flag) {
+    std::cout << "Start detrend with " << threads  << " threads using openmp..." << std::endl;
+  }
+  #pragma omp parallel for
+#else
+  if (flag) {
+    std::cout << "Start detrend with " << 1 << " threads without openmp..." << std::endl;
+  }
+#endif
+    for(int i=0; i<channels_num; i++){
+    // flag
+#ifdef _OPENMP
+    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+        if (type == "linear"){
+            xt::xtensor<T1, 2> A = xt::ones<T1>({samples_num, 2});
+            xt::view(A, xt::all(), 0) = xt::arange(samples_num);
+            auto y = xt::view(data, i, xt::all());
+            auto result = xt::linalg::lstsq(A, y);
+            auto trend = xt::linalg::dot(A, std::get<0>(result));
+            xt::view(data, i, xt::all()) -= trend;
+        }
+        else if (type == "demean"){
+            auto dd = xt::view(data, i, xt::all());
+            auto trend = xt::mean(dd);
+            xt::view(data, i, xt::all()) -= trend;
+        }
+        else {
+            std::cout << "error: please input the correct detrend method." << std::endl;
+        }
+    }
+
+    end_time = std::chrono::high_resolution_clock::now();
+    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+    if (flag) {
+        std::cout << "End detrend with total time " << elapsed_time.count() << "s" <<std::endl;
+    }
+}
+
+
+
+// **************************************************************************
+// *                        end
+// **************************************************************************
+
+}
+
 #endif
```

## noiseflow/signal/include/filter.hpp

 * *Ordering differences only*

```diff
@@ -1,312 +1,312 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-
-#ifndef FILTER_HPP
-#define FILTER_HPP
-
-#include "utils.hpp"
-
-namespace SIGNAL {
-
-using namespace kfr;
-
-// bandpass_filter
-template <class T1>
-std::unique_ptr<biquad_filter<T1>> bandpass_filter(double freqmin, double freqmax, double df, int corners) {
-    double fe = 0.5 * df;
-    double low = freqmin / fe;
-    double high = freqmax / fe;
-
-    std::unique_ptr<biquad_filter<T1>> filter;
-    std::vector<biquad_params<T1>> bqs = to_sos(iir_bandpass(butterworth<T1>(corners), low, high));
-    filter.reset(new biquad_filter<T1>(bqs));
-
-    return filter;
-}
-
-
-template <class T1, class T2>
-void bandpass(T2 &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads) {
-    int samples_num = data.shape(1);
-    int channels_num = data.shape(0);
-    auto start_time = std::chrono::high_resolution_clock::now();
-    auto end_time = start_time;
-    std::vector<std::size_t> shape = {std::size_t(samples_num)};
-
-#ifdef _OPENMP
-  omp_set_num_threads(threads);
-  if (flag) {
-    std::cout << "Start bandpass with " << threads  << " threads using openmp..." << std::endl;
-  }
-  #pragma omp parallel for
-#else
-  if (flag) { 
-    std::cout << "Start bandpass with " << 1 << " threads without openmp..." << std::endl;
-  }
-#endif
-    for(int i=0; i<channels_num; i++){
-    // flag
-#ifdef _OPENMP
-    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-        std::unique_ptr<biquad_filter<T1>> filter = bandpass_filter<T1>(freqmin, freqmax, df, corners);
-        auto input = make_univector(data.data()+i*samples_num, samples_num);
-        univector<T1> output(samples_num);
-        if (zerophase) {
-            univector<T1> output_first(samples_num);
-            filter->apply(output_first, input);
-            std::reverse(output_first.begin(), output_first.end());
-            filter->apply(output, make_univector(output_first));
-            std::reverse(output.begin(), output.end());
-        }
-        else {
-            filter->apply(output, input);
-        }
-        xt::view(data, i, xt::all()) = xt::adapt(output.data(), samples_num, xt::no_ownership(), shape);
-    }
-
-    end_time = std::chrono::high_resolution_clock::now();
-    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-    if (flag) {
-        std::cout << "End bandpass with total time " << elapsed_time.count() << "s" <<std::endl;
-    }
-}
-
-
-
-// lowpass_filter
-template <class T1>
-std::unique_ptr<biquad_filter<T1>> lowpass_filter(double freqlow, double df, int corners) {
-    std::unique_ptr<biquad_filter<T1>> filter;
-    std::vector<biquad_params<T1>> bqs = to_sos(iir_lowpass(butterworth<T1>(corners), freqlow, df));
-    filter.reset(new biquad_filter<T1>(bqs));
-
-    return filter;
-}
-
-
-template <class T1, class T2>
-void lowpass(T2 &data, double freqlow, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads) {
-    int samples_num = data.shape(1);
-    int channels_num = data.shape(0);
-    auto start_time = std::chrono::high_resolution_clock::now();
-    auto end_time = start_time;
-    std::vector<std::size_t> shape = {std::size_t(samples_num)};
-
-#ifdef _OPENMP
-  omp_set_num_threads(threads);
-  if (flag) {
-    std::cout << "Start lowpass with " << threads  << " threads using openmp..." << std::endl;
-  }
-  #pragma omp parallel for
-#else
-  if (flag) {
-    std::cout << "Start lowpass with " << 1 << " threads without openmp..." << std::endl;
-  }
-#endif
-    for(int i=0; i<channels_num; i++){
-    // flag
-#ifdef _OPENMP
-    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-        std::unique_ptr<biquad_filter<T1>> filter = lowpass_filter<T1>(freqlow, df, corners);
-        auto input = make_univector(data.data()+i*samples_num, samples_num);
-        univector<T1> output(samples_num);
-        if (zerophase) {
-            univector<T1> output_first(samples_num);
-            filter->apply(output_first, input);
-            std::reverse(output_first.begin(), output_first.end());
-            filter->apply(output, make_univector(output_first));
-            std::reverse(output.begin(), output.end());
-        }
-        else {
-            filter->apply(output, input);
-        }
-        xt::view(data, i, xt::all()) = xt::adapt(output.data(), samples_num, xt::no_ownership(), shape);
-    }
-
-    end_time = std::chrono::high_resolution_clock::now();
-    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-    if (flag) {
-        std::cout << "End lowpass with total time " << elapsed_time.count() << "s" <<std::endl;
-    }
-}
-
-
-
-// highpass_filter
-template <class T1>
-std::unique_ptr<biquad_filter<T1>> highpass_filter(double freqhigh, double df, int corners) {
-    std::unique_ptr<biquad_filter<T1>> filter;
-    std::vector<biquad_params<T1>> bqs = to_sos(iir_highpass(butterworth<T1>(corners), freqhigh, df));
-    filter.reset(new biquad_filter<T1>(bqs));
-
-    return filter;
-}
-
-
-template <class T1, class T2>
-void highpass(T2 &data, double freqhigh, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads) {
-    int samples_num = data.shape(1);
-    int channels_num = data.shape(0);
-    auto start_time = std::chrono::high_resolution_clock::now();
-    auto end_time = start_time;
-    std::vector<std::size_t> shape = {std::size_t(samples_num)};
-
-#ifdef _OPENMP
-  omp_set_num_threads(threads);
-  if (flag) {
-    std::cout << "Start highpass with " << threads  << " threads using openmp..." << std::endl;
-  }
-  #pragma omp parallel for
-#else
-  if (flag) {
-    std::cout << "Start highpass with " << 1 << " threads without openmp..." << std::endl;
-  }
-#endif
-    for(int i=0; i<channels_num; i++){
-    // flag
-#ifdef _OPENMP
-    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-        std::unique_ptr<biquad_filter<T1>> filter = highpass_filter<T1>(freqhigh, df, corners);
-        auto input = make_univector(data.data()+i*samples_num, samples_num);
-        univector<T1> output(samples_num);
-        if (zerophase) {
-            univector<T1> output_first(samples_num);
-            filter->apply(output_first, input);
-            std::reverse(output_first.begin(), output_first.end());
-            filter->apply(output, make_univector(output_first));
-            std::reverse(output.begin(), output.end());
-        }
-        else {
-            filter->apply(output, input);
-        }
-        xt::view(data, i, xt::all()) = xt::adapt(output.data(), samples_num, xt::no_ownership(), shape);
-    }
-
-    end_time = std::chrono::high_resolution_clock::now();
-    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-    if (flag) {
-        std::cout << "End highpass with total time " << elapsed_time.count() << "s" <<std::endl;
-    }
-}
-
-
-
-
-// bandstop_filter
-template <class T1>
-std::unique_ptr<biquad_filter<T1>> bandstop_filter(double freqmin, double freqmax, double df, int corners) {
-    double fe = 0.5 * df;
-    double low = freqmin / fe;
-    double high = freqmax / fe;
-
-    std::unique_ptr<biquad_filter<T1>> filter;
-    std::vector<biquad_params<T1>> bqs = to_sos(iir_bandstop(butterworth<T1>(corners), low, high));
-    filter.reset(new biquad_filter<T1>(bqs));
-
-    return filter;
-}
-
-
-template <class T1, class T2>
-void bandstop(T2 &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads) {
-    int samples_num = data.shape(1);
-    int channels_num = data.shape(0);
-    auto start_time = std::chrono::high_resolution_clock::now();
-    auto end_time = start_time;
-    std::vector<std::size_t> shape = {std::size_t(samples_num)};
-
-#ifdef _OPENMP
-  omp_set_num_threads(threads);
-  if (flag) {
-    std::cout << "Start bandstop with " << threads  << " threads using openmp..." << std::endl;
-  }
-  #pragma omp parallel for
-#else
-  if (flag) {
-    std::cout << "Start bandstop with " << 1 << " threads without openmp..." << std::endl;
-  }
-#endif
-    for(int i=0; i<channels_num; i++){
-    // flag
-#ifdef _OPENMP
-    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-        std::unique_ptr<biquad_filter<T1>> filter = bandstop_filter<T1>(freqmin, freqmax, df, corners);
-        auto input = make_univector(data.data()+i*samples_num, samples_num);
-        univector<T1> output(samples_num);
-        if (zerophase) {
-            univector<T1> output_first(samples_num);
-            filter->apply(output_first, input);
-            std::reverse(output_first.begin(), output_first.end());
-            filter->apply(output, make_univector(output_first));
-            std::reverse(output.begin(), output.end());
-        }
-        else {
-            filter->apply(output, input);
-        }
-        xt::view(data, i, xt::all()) = xt::adapt(output.data(), samples_num, xt::no_ownership(), shape);
-    }
-
-    end_time = std::chrono::high_resolution_clock::now();
-    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-    if (flag) {
-        std::cout << "End bandstop with total time " << elapsed_time.count() << "s" <<std::endl;
-    }
-}
-
-// **************************************************************************
-// *                        end
-// **************************************************************************
-
-}
-
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+
+#ifndef FILTER_HPP
+#define FILTER_HPP
+
+#include "utils.hpp"
+
+namespace SIGNAL {
+
+using namespace kfr;
+
+// bandpass_filter
+template <class T1>
+std::unique_ptr<biquad_filter<T1>> bandpass_filter(double freqmin, double freqmax, double df, int corners) {
+    double fe = 0.5 * df;
+    double low = freqmin / fe;
+    double high = freqmax / fe;
+
+    std::unique_ptr<biquad_filter<T1>> filter;
+    std::vector<biquad_params<T1>> bqs = to_sos(iir_bandpass(butterworth<T1>(corners), low, high));
+    filter.reset(new biquad_filter<T1>(bqs));
+
+    return filter;
+}
+
+
+template <class T1, class T2>
+void bandpass(T2 &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads) {
+    int samples_num = data.shape(1);
+    int channels_num = data.shape(0);
+    auto start_time = std::chrono::high_resolution_clock::now();
+    auto end_time = start_time;
+    std::vector<std::size_t> shape = {std::size_t(samples_num)};
+
+#ifdef _OPENMP
+  omp_set_num_threads(threads);
+  if (flag) {
+    std::cout << "Start bandpass with " << threads  << " threads using openmp..." << std::endl;
+  }
+  #pragma omp parallel for
+#else
+  if (flag) { 
+    std::cout << "Start bandpass with " << 1 << " threads without openmp..." << std::endl;
+  }
+#endif
+    for(int i=0; i<channels_num; i++){
+    // flag
+#ifdef _OPENMP
+    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+        std::unique_ptr<biquad_filter<T1>> filter = bandpass_filter<T1>(freqmin, freqmax, df, corners);
+        auto input = make_univector(data.data()+i*samples_num, samples_num);
+        univector<T1> output(samples_num);
+        if (zerophase) {
+            univector<T1> output_first(samples_num);
+            filter->apply(output_first, input);
+            std::reverse(output_first.begin(), output_first.end());
+            filter->apply(output, make_univector(output_first));
+            std::reverse(output.begin(), output.end());
+        }
+        else {
+            filter->apply(output, input);
+        }
+        xt::view(data, i, xt::all()) = xt::adapt(output.data(), samples_num, xt::no_ownership(), shape);
+    }
+
+    end_time = std::chrono::high_resolution_clock::now();
+    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+    if (flag) {
+        std::cout << "End bandpass with total time " << elapsed_time.count() << "s" <<std::endl;
+    }
+}
+
+
+
+// lowpass_filter
+template <class T1>
+std::unique_ptr<biquad_filter<T1>> lowpass_filter(double freqlow, double df, int corners) {
+    std::unique_ptr<biquad_filter<T1>> filter;
+    std::vector<biquad_params<T1>> bqs = to_sos(iir_lowpass(butterworth<T1>(corners), freqlow, df));
+    filter.reset(new biquad_filter<T1>(bqs));
+
+    return filter;
+}
+
+
+template <class T1, class T2>
+void lowpass(T2 &data, double freqlow, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads) {
+    int samples_num = data.shape(1);
+    int channels_num = data.shape(0);
+    auto start_time = std::chrono::high_resolution_clock::now();
+    auto end_time = start_time;
+    std::vector<std::size_t> shape = {std::size_t(samples_num)};
+
+#ifdef _OPENMP
+  omp_set_num_threads(threads);
+  if (flag) {
+    std::cout << "Start lowpass with " << threads  << " threads using openmp..." << std::endl;
+  }
+  #pragma omp parallel for
+#else
+  if (flag) {
+    std::cout << "Start lowpass with " << 1 << " threads without openmp..." << std::endl;
+  }
+#endif
+    for(int i=0; i<channels_num; i++){
+    // flag
+#ifdef _OPENMP
+    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+        std::unique_ptr<biquad_filter<T1>> filter = lowpass_filter<T1>(freqlow, df, corners);
+        auto input = make_univector(data.data()+i*samples_num, samples_num);
+        univector<T1> output(samples_num);
+        if (zerophase) {
+            univector<T1> output_first(samples_num);
+            filter->apply(output_first, input);
+            std::reverse(output_first.begin(), output_first.end());
+            filter->apply(output, make_univector(output_first));
+            std::reverse(output.begin(), output.end());
+        }
+        else {
+            filter->apply(output, input);
+        }
+        xt::view(data, i, xt::all()) = xt::adapt(output.data(), samples_num, xt::no_ownership(), shape);
+    }
+
+    end_time = std::chrono::high_resolution_clock::now();
+    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+    if (flag) {
+        std::cout << "End lowpass with total time " << elapsed_time.count() << "s" <<std::endl;
+    }
+}
+
+
+
+// highpass_filter
+template <class T1>
+std::unique_ptr<biquad_filter<T1>> highpass_filter(double freqhigh, double df, int corners) {
+    std::unique_ptr<biquad_filter<T1>> filter;
+    std::vector<biquad_params<T1>> bqs = to_sos(iir_highpass(butterworth<T1>(corners), freqhigh, df));
+    filter.reset(new biquad_filter<T1>(bqs));
+
+    return filter;
+}
+
+
+template <class T1, class T2>
+void highpass(T2 &data, double freqhigh, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads) {
+    int samples_num = data.shape(1);
+    int channels_num = data.shape(0);
+    auto start_time = std::chrono::high_resolution_clock::now();
+    auto end_time = start_time;
+    std::vector<std::size_t> shape = {std::size_t(samples_num)};
+
+#ifdef _OPENMP
+  omp_set_num_threads(threads);
+  if (flag) {
+    std::cout << "Start highpass with " << threads  << " threads using openmp..." << std::endl;
+  }
+  #pragma omp parallel for
+#else
+  if (flag) {
+    std::cout << "Start highpass with " << 1 << " threads without openmp..." << std::endl;
+  }
+#endif
+    for(int i=0; i<channels_num; i++){
+    // flag
+#ifdef _OPENMP
+    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+        std::unique_ptr<biquad_filter<T1>> filter = highpass_filter<T1>(freqhigh, df, corners);
+        auto input = make_univector(data.data()+i*samples_num, samples_num);
+        univector<T1> output(samples_num);
+        if (zerophase) {
+            univector<T1> output_first(samples_num);
+            filter->apply(output_first, input);
+            std::reverse(output_first.begin(), output_first.end());
+            filter->apply(output, make_univector(output_first));
+            std::reverse(output.begin(), output.end());
+        }
+        else {
+            filter->apply(output, input);
+        }
+        xt::view(data, i, xt::all()) = xt::adapt(output.data(), samples_num, xt::no_ownership(), shape);
+    }
+
+    end_time = std::chrono::high_resolution_clock::now();
+    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+    if (flag) {
+        std::cout << "End highpass with total time " << elapsed_time.count() << "s" <<std::endl;
+    }
+}
+
+
+
+
+// bandstop_filter
+template <class T1>
+std::unique_ptr<biquad_filter<T1>> bandstop_filter(double freqmin, double freqmax, double df, int corners) {
+    double fe = 0.5 * df;
+    double low = freqmin / fe;
+    double high = freqmax / fe;
+
+    std::unique_ptr<biquad_filter<T1>> filter;
+    std::vector<biquad_params<T1>> bqs = to_sos(iir_bandstop(butterworth<T1>(corners), low, high));
+    filter.reset(new biquad_filter<T1>(bqs));
+
+    return filter;
+}
+
+
+template <class T1, class T2>
+void bandstop(T2 &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads) {
+    int samples_num = data.shape(1);
+    int channels_num = data.shape(0);
+    auto start_time = std::chrono::high_resolution_clock::now();
+    auto end_time = start_time;
+    std::vector<std::size_t> shape = {std::size_t(samples_num)};
+
+#ifdef _OPENMP
+  omp_set_num_threads(threads);
+  if (flag) {
+    std::cout << "Start bandstop with " << threads  << " threads using openmp..." << std::endl;
+  }
+  #pragma omp parallel for
+#else
+  if (flag) {
+    std::cout << "Start bandstop with " << 1 << " threads without openmp..." << std::endl;
+  }
+#endif
+    for(int i=0; i<channels_num; i++){
+    // flag
+#ifdef _OPENMP
+    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+        std::unique_ptr<biquad_filter<T1>> filter = bandstop_filter<T1>(freqmin, freqmax, df, corners);
+        auto input = make_univector(data.data()+i*samples_num, samples_num);
+        univector<T1> output(samples_num);
+        if (zerophase) {
+            univector<T1> output_first(samples_num);
+            filter->apply(output_first, input);
+            std::reverse(output_first.begin(), output_first.end());
+            filter->apply(output, make_univector(output_first));
+            std::reverse(output.begin(), output.end());
+        }
+        else {
+            filter->apply(output, input);
+        }
+        xt::view(data, i, xt::all()) = xt::adapt(output.data(), samples_num, xt::no_ownership(), shape);
+    }
+
+    end_time = std::chrono::high_resolution_clock::now();
+    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+    if (flag) {
+        std::cout << "End bandstop with total time " << elapsed_time.count() << "s" <<std::endl;
+    }
+}
+
+// **************************************************************************
+// *                        end
+// **************************************************************************
+
+}
+
 #endif
```

## noiseflow/signal/include/taper.hpp

 * *Ordering differences only*

```diff
@@ -1,137 +1,137 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-
-#ifndef TAPER_HPP
-#define TAPER_HPP
-
-#include "utils.hpp"
-
-namespace SIGNAL {
-
-using namespace kfr;
-
-
-
-// taper
-template <class T1, class T2>
-void taper(T2 &data, double max_percentage, std::string type, std::string side, bool flag, int flag_gap, int threads) 
-{
-    int samples_num = data.shape(1);
-    int channels_num = data.shape(0);
-    int wlen = std::floor(samples_num * max_percentage);
-
-    univector<T1> windows;
-    if (type == "hann"){
-        windows = window_hann(wlen*2+1);
-    }
-    else if (type == "hamming"){
-        windows = window_hamming(wlen*2+1);
-    }
-    else if (type == "blackman"){
-        windows = window_blackman(wlen*2+1);
-    }
-    else if (type == "blackman_harris"){
-        windows = window_blackman_harris(wlen*2+1);
-    }
-    else if (type == "gaussian"){
-        windows = window_gaussian(wlen*2+1);
-    }
-    else if (type == "triangular"){
-        windows = window_triangular(wlen*2+1);
-    }
-    else if (type == "bartlett"){
-        windows = window_bartlett(wlen*2+1);
-    }
-    else if (type == "cosine"){
-        windows = window_cosine(wlen*2+1);
-    }
-    else if (type == "cosine_np"){
-        windows = window_cosine_np(wlen*2+1);
-    }
-    else if (type == "bartlett_hann"){
-        windows = window_bartlett_hann(wlen*2+1);
-    }
-    else if (type == "bohman"){
-        windows = window_bohman(wlen*2+1);
-    }
-    else if (type == "lanczos"){
-        windows = window_lanczos(wlen*2+1);
-    }
-    else if (type == "flattop"){
-        windows = window_flattop(wlen*2+1);
-    }
-    else if (type == "window_kaiser"){
-        windows = window_kaiser(wlen*2+1, 2.5);
-    }
-    else {
-        std::cout << "error: please input the correct windows method." << std::endl;
-    }
-
-    std::vector<std::size_t> shape = {std::size_t(wlen*2+1)};
-    auto taper_sides = xt::adapt(windows.data(), wlen*2+1, xt::no_ownership(), shape);
-
-    xt::xarray<T1> taper;
-    if (side=="left"){
-        taper = xt::hstack(xtuple(xt::view(taper_sides, xt::range(0, wlen)), xt::ones<T1>({samples_num-wlen})));
-    }
-    else if (side=="right"){
-        taper = xt::hstack(xtuple(xt::ones<T1>({samples_num-wlen}), xt::view(taper_sides, xt::range(wlen+1, wlen*2+1))));
-    }
-    else if (side=="both"){
-        taper = xt::hstack(xtuple(xt::view(taper_sides, xt::range(0, wlen)), xt::ones<T1>({samples_num-wlen*2}), xt::view(taper_sides, xt::range(wlen+1, wlen*2+1))));
-    }
-
-    auto start_time = std::chrono::high_resolution_clock::now();
-    auto end_time = start_time;
-
-#ifdef _OPENMP
-  omp_set_num_threads(threads);
-  if (flag) {
-    std::cout << "Start taper with " << threads  << " threads using openmp..." << std::endl;
-  }
-  #pragma omp parallel for
-#else
-  if (flag) {
-    std::cout << "Start taper with " << 1 << " threads without openmp..." << std::endl;
-  }
-#endif
-
-    for(int i=0; i<channels_num; i++){
-    // flag
-#ifdef _OPENMP
-    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#else
-    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
-      end_time = std::chrono::high_resolution_clock::now();
-      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
-    }
-#endif
-        xt::view(data, i, xt::all()) *= taper;
-    }
-
-    end_time = std::chrono::high_resolution_clock::now();
-    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
-    if (flag) {
-        std::cout << "End taper with total time " << elapsed_time.count() << "s" <<std::endl;
-    }
-}
-
-
-// **************************************************************************
-// *                        end
-// **************************************************************************
-
-}
-
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+
+#ifndef TAPER_HPP
+#define TAPER_HPP
+
+#include "utils.hpp"
+
+namespace SIGNAL {
+
+using namespace kfr;
+
+
+
+// taper
+template <class T1, class T2>
+void taper(T2 &data, double max_percentage, std::string type, std::string side, bool flag, int flag_gap, int threads) 
+{
+    int samples_num = data.shape(1);
+    int channels_num = data.shape(0);
+    int wlen = std::floor(samples_num * max_percentage);
+
+    univector<T1> windows;
+    if (type == "hann"){
+        windows = window_hann(wlen*2+1);
+    }
+    else if (type == "hamming"){
+        windows = window_hamming(wlen*2+1);
+    }
+    else if (type == "blackman"){
+        windows = window_blackman(wlen*2+1);
+    }
+    else if (type == "blackman_harris"){
+        windows = window_blackman_harris(wlen*2+1);
+    }
+    else if (type == "gaussian"){
+        windows = window_gaussian(wlen*2+1);
+    }
+    else if (type == "triangular"){
+        windows = window_triangular(wlen*2+1);
+    }
+    else if (type == "bartlett"){
+        windows = window_bartlett(wlen*2+1);
+    }
+    else if (type == "cosine"){
+        windows = window_cosine(wlen*2+1);
+    }
+    else if (type == "cosine_np"){
+        windows = window_cosine_np(wlen*2+1);
+    }
+    else if (type == "bartlett_hann"){
+        windows = window_bartlett_hann(wlen*2+1);
+    }
+    else if (type == "bohman"){
+        windows = window_bohman(wlen*2+1);
+    }
+    else if (type == "lanczos"){
+        windows = window_lanczos(wlen*2+1);
+    }
+    else if (type == "flattop"){
+        windows = window_flattop(wlen*2+1);
+    }
+    else if (type == "window_kaiser"){
+        windows = window_kaiser(wlen*2+1, 2.5);
+    }
+    else {
+        std::cout << "error: please input the correct windows method." << std::endl;
+    }
+
+    std::vector<std::size_t> shape = {std::size_t(wlen*2+1)};
+    auto taper_sides = xt::adapt(windows.data(), wlen*2+1, xt::no_ownership(), shape);
+
+    xt::xarray<T1> taper;
+    if (side=="left"){
+        taper = xt::hstack(xtuple(xt::view(taper_sides, xt::range(0, wlen)), xt::ones<T1>({samples_num-wlen})));
+    }
+    else if (side=="right"){
+        taper = xt::hstack(xtuple(xt::ones<T1>({samples_num-wlen}), xt::view(taper_sides, xt::range(wlen+1, wlen*2+1))));
+    }
+    else if (side=="both"){
+        taper = xt::hstack(xtuple(xt::view(taper_sides, xt::range(0, wlen)), xt::ones<T1>({samples_num-wlen*2}), xt::view(taper_sides, xt::range(wlen+1, wlen*2+1))));
+    }
+
+    auto start_time = std::chrono::high_resolution_clock::now();
+    auto end_time = start_time;
+
+#ifdef _OPENMP
+  omp_set_num_threads(threads);
+  if (flag) {
+    std::cout << "Start taper with " << threads  << " threads using openmp..." << std::endl;
+  }
+  #pragma omp parallel for
+#else
+  if (flag) {
+    std::cout << "Start taper with " << 1 << " threads without openmp..." << std::endl;
+  }
+#endif
+
+    for(int i=0; i<channels_num; i++){
+    // flag
+#ifdef _OPENMP
+    if (flag && omp_get_thread_num()==0 && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << omp_get_thread_num() << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#else
+    if (flag && i%flag_gap==0 && flag_gap!=channels_num) {
+      end_time = std::chrono::high_resolution_clock::now();
+      auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+      std::cout << "Thread " << 0 << " starts to process channel " << i << " || " << elapsed_time.count() << "s" << std::endl;
+    }
+#endif
+        xt::view(data, i, xt::all()) *= taper;
+    }
+
+    end_time = std::chrono::high_resolution_clock::now();
+    auto elapsed_time = std::chrono::duration_cast<std::chrono::duration<double>>(end_time - start_time);
+    if (flag) {
+        std::cout << "End taper with total time " << elapsed_time.count() << "s" <<std::endl;
+    }
+}
+
+
+// **************************************************************************
+// *                        end
+// **************************************************************************
+
+}
+
 #endif
```

## noiseflow/signal/include/utils.hpp

 * *Ordering differences only*

```diff
@@ -1,43 +1,43 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-#include <iostream>
-#include <string>
-#include <vector>
-#include <kfr/base.hpp>
-#include <kfr/dsp.hpp>
-
-#ifndef UTILS_HPP
-#define UTILS_HPP
-
-#ifdef _OPENMP
-#include <omp.h>
-#endif
-
-// #include <ctime>
-#include <chrono>
-#include <exception>
-
-#include <xtensor/xarray.hpp>
-#include <xtensor/xtensor.hpp>
-#include <xtensor/xbuilder.hpp>
-#include <xtensor/xview.hpp>
-#include <xtensor/xmath.hpp>
-#include <xtensor/xcomplex.hpp>
-#include <xtensor/xmanipulation.hpp>
-#include <xtensor/xadapt.hpp>
-#include <xtensor/xsort.hpp>
-#include <xtensor/xoperation.hpp>
-#include <xtensor/xindex_view.hpp>
-#include <xsimd/xsimd.hpp>
-#include <xtensor-blas/xlinalg.hpp>
-#include <xtensor-python/pyarray.hpp>
-#include <xtensor-python/pytensor.hpp>
-
-
-
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+#include <iostream>
+#include <string>
+#include <vector>
+#include <kfr/base.hpp>
+#include <kfr/dsp.hpp>
+
+#ifndef UTILS_HPP
+#define UTILS_HPP
+
+#ifdef _OPENMP
+#include <omp.h>
+#endif
+
+// #include <ctime>
+#include <chrono>
+#include <exception>
+
+#include <xtensor/xarray.hpp>
+#include <xtensor/xtensor.hpp>
+#include <xtensor/xbuilder.hpp>
+#include <xtensor/xview.hpp>
+#include <xtensor/xmath.hpp>
+#include <xtensor/xcomplex.hpp>
+#include <xtensor/xmanipulation.hpp>
+#include <xtensor/xadapt.hpp>
+#include <xtensor/xsort.hpp>
+#include <xtensor/xoperation.hpp>
+#include <xtensor/xindex_view.hpp>
+#include <xsimd/xsimd.hpp>
+#include <xtensor-blas/xlinalg.hpp>
+#include <xtensor-python/pyarray.hpp>
+#include <xtensor-python/pytensor.hpp>
+
+
+
 #endif
```

## noiseflow/signal/python/decimate.py

 * *Ordering differences only*

```diff
@@ -1,33 +1,33 @@
-import scipy
-import numpy as np
-
-
-def decimate_py(data, df, df_new, flag=False, flag_gap=None):
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    test = decimate(data[0,:], df, df_new)
-    redata = np.empty((data.shape[0], test.shape[0]))
-
-    for i in range(0, data.shape[0]):
-        redata[i,:] = decimate(data[i,:], df, df_new)
-
-    return redata
-
-
-def decimate(data, df, df_new):
-    factor = int(df / df_new)
-    if factor > 13:
-        msg = (
-                "IRR filter is unstable for decimation factors above"
-                " 13. Call decimate multiple times."
-            )
-        raise ValueError(msg)
-    
-    redata = scipy.signal.decimate(data, factor, ftype='iir', axis=-1, zero_phase=True)
-
-    return redata
-
-
-
-
+import scipy
+import numpy as np
+
+
+def decimate_py(data, df, df_new, flag=False, flag_gap=None):
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    test = decimate(data[0,:], df, df_new)
+    redata = np.empty((data.shape[0], test.shape[0]))
+
+    for i in range(0, data.shape[0]):
+        redata[i,:] = decimate(data[i,:], df, df_new)
+
+    return redata
+
+
+def decimate(data, df, df_new):
+    factor = int(df / df_new)
+    if factor > 13:
+        msg = (
+                "IRR filter is unstable for decimation factors above"
+                " 13. Call decimate multiple times."
+            )
+        raise ValueError(msg)
+    
+    redata = scipy.signal.decimate(data, factor, ftype='iir', axis=-1, zero_phase=True)
+
+    return redata
+
+
+
+
```

## noiseflow/signal/python/detrend.py

 * *Ordering differences only*

```diff
@@ -1,71 +1,71 @@
-import numpy as np
-
-from scipy.signal import detrend as scipy_detrend
-from scipy.interpolate import LSQUnivariateSpline
-
-
-def detrend_py(data, type='linear', flag=False, flag_gap=None):
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    for i in range(0, data.shape[0]):
-        detrend(data[i,:], type)
-
-
-def spline(data, order=2, dspline=1000):
-    if not np.issubdtype(data.dtype, np.floating):
-        data = np.require(data, dtype=np.float64)
-
-    x = np.arange(len(data))
-    splknots = np.arange(dspline/2.0, len(data) - dspline/2.0 + 2, dspline)
-    spl = LSQUnivariateSpline(x=x, y=data, t=splknots, k=order)
-    fit = spl(x)
-    data -= fit
-
-    return data
-
-
-def detrend(data, type='linear', order=2, dspline=1000):
-    """
-    Detrend data.
-    :param data: The data to detrend.
-    :type data: :class:`numpy.ndarray`
-    :param type: The type of detrending to perform. Can be one of ``'demean'``,
-        ``'linear'``, or ``'spline'``.
-    :type type: str
-    :param overwrite_data: If True the data will be detrended in place.
-    :type overwrite_data: bool
-    :param dtype: The data type to use for the detrended data. Defaults to
-        ``np.float32``.
-    :type dtype: :class:`numpy.dtype`
-    :param order: The order of the spline to fit. Defaults to 2.
-    :type order: int
-    :param dspline: The distance between spline knots. Defaults to 1000.
-    :type dspline: int
-
-    :returns: The detrended data.
-    :rtype: :class:`numpy.ndarray`
-
-    .. rubric:: Example
-
-    >>> import numpy as np
-    >>> from noiseflow.signal import detrend
-    >>> data = np.array([1.1,2.7,3,3,3,6,7,8,9,10], overwrite_data=True)
-    >>> detrend(data, type='spline')
-
-    """
-
-    if type == 'demean':
-        data -= np.mean(data)
-    elif type == 'linear':
-        scipy_detrend(data, type='linear', overwrite_data=True)
-    elif type == 'spline':
-        spline(data, order=order, dspline=dspline)
-    else:
-        raise ValueError("type must be 'demean', 'linear', or 'spline'")
-
-
-
-
-
-
+import numpy as np
+
+from scipy.signal import detrend as scipy_detrend
+from scipy.interpolate import LSQUnivariateSpline
+
+
+def detrend_py(data, type='linear', flag=False, flag_gap=None):
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    for i in range(0, data.shape[0]):
+        detrend(data[i,:], type)
+
+
+def spline(data, order=2, dspline=1000):
+    if not np.issubdtype(data.dtype, np.floating):
+        data = np.require(data, dtype=np.float64)
+
+    x = np.arange(len(data))
+    splknots = np.arange(dspline/2.0, len(data) - dspline/2.0 + 2, dspline)
+    spl = LSQUnivariateSpline(x=x, y=data, t=splknots, k=order)
+    fit = spl(x)
+    data -= fit
+
+    return data
+
+
+def detrend(data, type='linear', order=2, dspline=1000):
+    """
+    Detrend data.
+    :param data: The data to detrend.
+    :type data: :class:`numpy.ndarray`
+    :param type: The type of detrending to perform. Can be one of ``'demean'``,
+        ``'linear'``, or ``'spline'``.
+    :type type: str
+    :param overwrite_data: If True the data will be detrended in place.
+    :type overwrite_data: bool
+    :param dtype: The data type to use for the detrended data. Defaults to
+        ``np.float32``.
+    :type dtype: :class:`numpy.dtype`
+    :param order: The order of the spline to fit. Defaults to 2.
+    :type order: int
+    :param dspline: The distance between spline knots. Defaults to 1000.
+    :type dspline: int
+
+    :returns: The detrended data.
+    :rtype: :class:`numpy.ndarray`
+
+    .. rubric:: Example
+
+    >>> import numpy as np
+    >>> from noiseflow.signal import detrend
+    >>> data = np.array([1.1,2.7,3,3,3,6,7,8,9,10], overwrite_data=True)
+    >>> detrend(data, type='spline')
+
+    """
+
+    if type == 'demean':
+        data -= np.mean(data)
+    elif type == 'linear':
+        scipy_detrend(data, type='linear', overwrite_data=True)
+    elif type == 'spline':
+        spline(data, order=order, dspline=dspline)
+    else:
+        raise ValueError("type must be 'demean', 'linear', or 'spline'")
+
+
+
+
+
+
```

## noiseflow/signal/python/filter.py

 * *Ordering differences only*

```diff
@@ -1,195 +1,195 @@
-import warnings
-
-from scipy.signal import iirfilter
-from scipy.signal import sosfilt
-from scipy.signal import zpk2sos
-
-
-
-def bandpass_py(data, freqmin, freqmax, df, corners=4, zerophase=True, flag=False, flag_gap=None):
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    for i in range(0, data.shape[0]):
-        data[i,:] = bandpass(data[i,:], freqmin, freqmax, df, corners, zerophase)
-
-
-def bandstop_py(data, freqmin, freqmax, df, corners=4, zerophase=True, flag=False, flag_gap=None):
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    for i in range(0, data.shape[0]):
-        data[i,:] = bandstop(data[i,:], freqmin, freqmax, df, corners, zerophase)
-
-
-def lowpass_py(data, freq, df, corners=4, zerophase=True, flag=False, flag_gap=None):
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    for i in range(0, data.shape[0]):
-        data[i,:] = lowpass(data[i,:], freq, df, corners, zerophase)
-
-
-def highpass_py(data, freq, df, corners=4, zerophase=True, flag=False, flag_gap=None):
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-        
-    for i in range(0, data.shape[0]):
-        data[i,:] = highpass(data[i,:], freq, df, corners, zerophase)
-
-
-
-def bandpass(data, freqmin, freqmax, df, corners=4, zerophase=False):
-    """
-    Butterworth-Bandpass Filter.
-    Filter data from ``freqmin`` to ``freqmax`` using ``corners``
-    corners.
-    The filter uses :func:`scipy.signal.iirfilter` (for design)
-    and :func:`scipy.signal.sosfilt` (for applying the filter).
-    :type data: numpy.ndarray
-    :param data: Data to filter.
-    :param freqmin: Pass band low corner frequency.
-    :param freqmax: Pass band high corner frequency.
-    :param df: Sampling rate in Hz.
-    :param corners: Filter corners / order.
-    :param zerophase: If True, apply filter once forwards and once backwards.
-        This results in twice the filter order but zero phase shift in
-        the resulting filtered trace.
-    :return: Filtered data.
-    """
-    fe = 0.5 * df
-    low = freqmin / fe
-    high = freqmax / fe
-    # raise for some bad scenarios
-    if high - 1.0 > -1e-6:
-        msg = ("Selected high corner frequency ({}) of bandpass is at or "
-               "above Nyquist ({}). Applying a high-pass instead.").format(
-            freqmax, fe)
-        warnings.warn(msg)
-        return highpass(data, freq=freqmin, df=df, corners=corners,
-                        zerophase=zerophase)
-    if low > 1:
-        msg = "Selected low corner frequency is above Nyquist."
-        raise ValueError(msg)
-    z, p, k = iirfilter(corners, [low, high], btype='band',
-                        ftype='butter', output='zpk')
-    sos = zpk2sos(z, p, k)
-    if zerophase:
-        firstpass = sosfilt(sos, data)
-        return sosfilt(sos, firstpass[::-1])[::-1]
-    else:
-        return sosfilt(sos, data)
-
-
-def bandstop(data, freqmin, freqmax, df, corners=4, zerophase=False):
-    """
-    Butterworth-Bandstop Filter.
-    Filter data removing data between frequencies ``freqmin`` and ``freqmax``
-    using ``corners`` corners.
-    The filter uses :func:`scipy.signal.iirfilter` (for design)
-    and :func:`scipy.signal.sosfilt` (for applying the filter).
-    :type data: numpy.ndarray
-    :param data: Data to filter.
-    :param freqmin: Stop band low corner frequency.
-    :param freqmax: Stop band high corner frequency.
-    :param df: Sampling rate in Hz.
-    :param corners: Filter corners / order.
-    :param zerophase: If True, apply filter once forwards and once backwards.
-        This results in twice the number of corners but zero phase shift in
-        the resulting filtered trace.
-    :return: Filtered data.
-    """
-    fe = 0.5 * df
-    low = freqmin / fe
-    high = freqmax / fe
-    # raise for some bad scenarios
-    if high > 1:
-        high = 1.0
-        msg = "Selected high corner frequency is above Nyquist. " + \
-              "Setting Nyquist as high corner."
-        warnings.warn(msg)
-    if low > 1:
-        msg = "Selected low corner frequency is above Nyquist."
-        raise ValueError(msg)
-    z, p, k = iirfilter(corners, [low, high],
-                        btype='bandstop', ftype='butter', output='zpk')
-    sos = zpk2sos(z, p, k)
-    if zerophase:
-        firstpass = sosfilt(sos, data)
-        return sosfilt(sos, firstpass[::-1])[::-1]
-    else:
-        return sosfilt(sos, data)
-
-
-def lowpass(data, freq, df, corners=4, zerophase=False):
-    """
-    Butterworth-Lowpass Filter.
-    Filter data removing data over certain frequency ``freq`` using ``corners``
-    corners.
-    The filter uses :func:`scipy.signal.iirfilter` (for design)
-    and :func:`scipy.signal.sosfilt` (for applying the filter).
-    :type data: numpy.ndarray
-    :param data: Data to filter.
-    :param freq: Filter corner frequency.
-    :param df: Sampling rate in Hz.
-    :param corners: Filter corners / order.
-    :param zerophase: If True, apply filter once forwards and once backwards.
-        This results in twice the number of corners but zero phase shift in
-        the resulting filtered trace.
-    :return: Filtered data.
-    """
-    fe = 0.5 * df
-    f = freq / fe
-    # raise for some bad scenarios
-    if f > 1:
-        f = 1.0
-        msg = "Selected corner frequency is above Nyquist. " + \
-              "Setting Nyquist as high corner."
-        warnings.warn(msg)
-    z, p, k = iirfilter(corners, f, btype='lowpass', ftype='butter',
-                        output='zpk')
-    sos = zpk2sos(z, p, k)
-    if zerophase:
-        firstpass = sosfilt(sos, data)
-        return sosfilt(sos, firstpass[::-1])[::-1]
-    else:
-        return sosfilt(sos, data)
-
-
-def highpass(data, freq, df, corners=4, zerophase=False):
-    """
-    Butterworth-Highpass Filter.
-    Filter data removing data below certain frequency ``freq`` using
-    ``corners`` corners.
-    The filter uses :func:`scipy.signal.iirfilter` (for design)
-    and :func:`scipy.signal.sosfilt` (for applying the filter).
-    :type data: numpy.ndarray
-    :param data: Data to filter.
-    :param freq: Filter corner frequency.
-    :param df: Sampling rate in Hz.
-    :param corners: Filter corners / order.
-    :param zerophase: If True, apply filter once forwards and once backwards.
-        This results in twice the number of corners but zero phase shift in
-        the resulting filtered trace.
-    :return: Filtered data.
-    """
-    fe = 0.5 * df
-    f = freq / fe
-    # raise for some bad scenarios
-    if f > 1:
-        msg = "Selected corner frequency is above Nyquist."
-        raise ValueError(msg)
-    z, p, k = iirfilter(corners, f, btype='highpass', ftype='butter',
-                        output='zpk')
-    sos = zpk2sos(z, p, k)
-    if zerophase:
-        firstpass = sosfilt(sos, data)
-        return sosfilt(sos, firstpass[::-1])[::-1]
-    else:
-        return sosfilt(sos, data)
-
-
-
-
-
-
+import warnings
+
+from scipy.signal import iirfilter
+from scipy.signal import sosfilt
+from scipy.signal import zpk2sos
+
+
+
+def bandpass_py(data, freqmin, freqmax, df, corners=4, zerophase=True, flag=False, flag_gap=None):
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    for i in range(0, data.shape[0]):
+        data[i,:] = bandpass(data[i,:], freqmin, freqmax, df, corners, zerophase)
+
+
+def bandstop_py(data, freqmin, freqmax, df, corners=4, zerophase=True, flag=False, flag_gap=None):
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    for i in range(0, data.shape[0]):
+        data[i,:] = bandstop(data[i,:], freqmin, freqmax, df, corners, zerophase)
+
+
+def lowpass_py(data, freq, df, corners=4, zerophase=True, flag=False, flag_gap=None):
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    for i in range(0, data.shape[0]):
+        data[i,:] = lowpass(data[i,:], freq, df, corners, zerophase)
+
+
+def highpass_py(data, freq, df, corners=4, zerophase=True, flag=False, flag_gap=None):
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+        
+    for i in range(0, data.shape[0]):
+        data[i,:] = highpass(data[i,:], freq, df, corners, zerophase)
+
+
+
+def bandpass(data, freqmin, freqmax, df, corners=4, zerophase=False):
+    """
+    Butterworth-Bandpass Filter.
+    Filter data from ``freqmin`` to ``freqmax`` using ``corners``
+    corners.
+    The filter uses :func:`scipy.signal.iirfilter` (for design)
+    and :func:`scipy.signal.sosfilt` (for applying the filter).
+    :type data: numpy.ndarray
+    :param data: Data to filter.
+    :param freqmin: Pass band low corner frequency.
+    :param freqmax: Pass band high corner frequency.
+    :param df: Sampling rate in Hz.
+    :param corners: Filter corners / order.
+    :param zerophase: If True, apply filter once forwards and once backwards.
+        This results in twice the filter order but zero phase shift in
+        the resulting filtered trace.
+    :return: Filtered data.
+    """
+    fe = 0.5 * df
+    low = freqmin / fe
+    high = freqmax / fe
+    # raise for some bad scenarios
+    if high - 1.0 > -1e-6:
+        msg = ("Selected high corner frequency ({}) of bandpass is at or "
+               "above Nyquist ({}). Applying a high-pass instead.").format(
+            freqmax, fe)
+        warnings.warn(msg)
+        return highpass(data, freq=freqmin, df=df, corners=corners,
+                        zerophase=zerophase)
+    if low > 1:
+        msg = "Selected low corner frequency is above Nyquist."
+        raise ValueError(msg)
+    z, p, k = iirfilter(corners, [low, high], btype='band',
+                        ftype='butter', output='zpk')
+    sos = zpk2sos(z, p, k)
+    if zerophase:
+        firstpass = sosfilt(sos, data)
+        return sosfilt(sos, firstpass[::-1])[::-1]
+    else:
+        return sosfilt(sos, data)
+
+
+def bandstop(data, freqmin, freqmax, df, corners=4, zerophase=False):
+    """
+    Butterworth-Bandstop Filter.
+    Filter data removing data between frequencies ``freqmin`` and ``freqmax``
+    using ``corners`` corners.
+    The filter uses :func:`scipy.signal.iirfilter` (for design)
+    and :func:`scipy.signal.sosfilt` (for applying the filter).
+    :type data: numpy.ndarray
+    :param data: Data to filter.
+    :param freqmin: Stop band low corner frequency.
+    :param freqmax: Stop band high corner frequency.
+    :param df: Sampling rate in Hz.
+    :param corners: Filter corners / order.
+    :param zerophase: If True, apply filter once forwards and once backwards.
+        This results in twice the number of corners but zero phase shift in
+        the resulting filtered trace.
+    :return: Filtered data.
+    """
+    fe = 0.5 * df
+    low = freqmin / fe
+    high = freqmax / fe
+    # raise for some bad scenarios
+    if high > 1:
+        high = 1.0
+        msg = "Selected high corner frequency is above Nyquist. " + \
+              "Setting Nyquist as high corner."
+        warnings.warn(msg)
+    if low > 1:
+        msg = "Selected low corner frequency is above Nyquist."
+        raise ValueError(msg)
+    z, p, k = iirfilter(corners, [low, high],
+                        btype='bandstop', ftype='butter', output='zpk')
+    sos = zpk2sos(z, p, k)
+    if zerophase:
+        firstpass = sosfilt(sos, data)
+        return sosfilt(sos, firstpass[::-1])[::-1]
+    else:
+        return sosfilt(sos, data)
+
+
+def lowpass(data, freq, df, corners=4, zerophase=False):
+    """
+    Butterworth-Lowpass Filter.
+    Filter data removing data over certain frequency ``freq`` using ``corners``
+    corners.
+    The filter uses :func:`scipy.signal.iirfilter` (for design)
+    and :func:`scipy.signal.sosfilt` (for applying the filter).
+    :type data: numpy.ndarray
+    :param data: Data to filter.
+    :param freq: Filter corner frequency.
+    :param df: Sampling rate in Hz.
+    :param corners: Filter corners / order.
+    :param zerophase: If True, apply filter once forwards and once backwards.
+        This results in twice the number of corners but zero phase shift in
+        the resulting filtered trace.
+    :return: Filtered data.
+    """
+    fe = 0.5 * df
+    f = freq / fe
+    # raise for some bad scenarios
+    if f > 1:
+        f = 1.0
+        msg = "Selected corner frequency is above Nyquist. " + \
+              "Setting Nyquist as high corner."
+        warnings.warn(msg)
+    z, p, k = iirfilter(corners, f, btype='lowpass', ftype='butter',
+                        output='zpk')
+    sos = zpk2sos(z, p, k)
+    if zerophase:
+        firstpass = sosfilt(sos, data)
+        return sosfilt(sos, firstpass[::-1])[::-1]
+    else:
+        return sosfilt(sos, data)
+
+
+def highpass(data, freq, df, corners=4, zerophase=False):
+    """
+    Butterworth-Highpass Filter.
+    Filter data removing data below certain frequency ``freq`` using
+    ``corners`` corners.
+    The filter uses :func:`scipy.signal.iirfilter` (for design)
+    and :func:`scipy.signal.sosfilt` (for applying the filter).
+    :type data: numpy.ndarray
+    :param data: Data to filter.
+    :param freq: Filter corner frequency.
+    :param df: Sampling rate in Hz.
+    :param corners: Filter corners / order.
+    :param zerophase: If True, apply filter once forwards and once backwards.
+        This results in twice the number of corners but zero phase shift in
+        the resulting filtered trace.
+    :return: Filtered data.
+    """
+    fe = 0.5 * df
+    f = freq / fe
+    # raise for some bad scenarios
+    if f > 1:
+        msg = "Selected corner frequency is above Nyquist."
+        raise ValueError(msg)
+    z, p, k = iirfilter(corners, f, btype='highpass', ftype='butter',
+                        output='zpk')
+    sos = zpk2sos(z, p, k)
+    if zerophase:
+        firstpass = sosfilt(sos, data)
+        return sosfilt(sos, firstpass[::-1])[::-1]
+    else:
+        return sosfilt(sos, data)
+
+
+
+
+
+
```

## noiseflow/signal/python/taper.py

 * *Ordering differences only*

```diff
@@ -1,85 +1,85 @@
-import scipy
-import warnings
-import numpy as np
-
-
-def taper_py(data, max_percentage=0.05, type='hann', side='both', flag=False, flag_gap=None):
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    for i in range(0, data.shape[0]):
-        taper(data[i,:], max_percentage, type, side)
-
-
-
-def taper(data, max_percentage=0.05, type='hann', side='both'):
-
-    side_valid = ['both', 'left', 'right']
-    npts = len(data)
-    if side not in side_valid:
-        raise ValueError("'side' has to be one of: %s" % side_valid)
-
-    # max_half_lenghts_1
-    max_half_lenghts_1 = None
-    if max_percentage is not None:
-        max_half_lenghts_1 = int(max_percentage * npts)
-
-    if 2 * max_half_lenghts_1 > npts:
-        msg = "The requested taper is longer than the data. " \
-                "The taper will be shortened to data length."
-        warnings.warn(msg)
-
-    # max_half_lenghts_2
-    max_half_lenghts_2 = int(npts / 2)
-    if max_half_lenghts_1 is None:
-        wlen = max_half_lenghts_2
-    else:
-        wlen = min(max_half_lenghts_1, max_half_lenghts_2)
-
-    if type == "hann":
-        taper_sides = scipy.signal.windows.hann(2*wlen+1)
-    elif type == "hamming":
-        taper_sides = scipy.signal.windows.hamming(2*wlen+1)
-    elif type == "bartlett":
-        taper_sides = scipy.signal.windows.bartlett(2*wlen+1)
-    elif type == "blackman":
-        taper_sides = scipy.signal.windows.blackman(2*wlen+1)
-    elif type == "flattop":
-        taper_sides = scipy.signal.windows.flattop(2*wlen+1)
-    elif type == "parzen":
-        taper_sides = scipy.signal.windows.parzen(2*wlen+1)
-    elif type == "bohman":
-        taper_sides = scipy.signal.windows.bohman(2*wlen+1)
-    elif type == "blackmanharris":
-        taper_sides = scipy.signal.windows.blackmanharris(2*wlen+1)
-    elif type == "nuttall":
-        taper_sides = scipy.signal.windows.nuttall(2*wlen+1)
-    elif type == "barthann":
-        taper_sides = scipy.signal.windows.barthann(2*wlen+1)
-    elif type == "kaiser":
-        taper_sides = scipy.signal.windows.kaiser(2*wlen+1, beta=14)
-    elif type == "gaussian":
-        taper_sides = scipy.signal.windows.gaussian(2*wlen+1, std=14)
-    elif type == "general_gaussian":
-        taper_sides = scipy.signal.windows.general_gaussian(2*wlen+1, p=1, sig=14)
-    else:
-        raise ValueError("Unknown taper type: %s" % type)
-
-    if side == 'left':
-        taper = np.hstack((taper_sides[:wlen], np.ones(npts - wlen)))
-    elif side == 'right':
-        taper = np.hstack((np.ones(npts - wlen),
-                            taper_sides[len(taper_sides) - wlen:]))
-    else:
-        taper = np.hstack((taper_sides[:wlen], np.ones(npts - 2 * wlen),
-                            taper_sides[len(taper_sides) - wlen:]))
-
-    # Convert data if it's not a floating point type.
-    if not np.issubdtype(data.dtype, np.floating):
-        data = np.require(data, dtype=np.float64)
-
-    data *= taper
-
-
-
-
+import scipy
+import warnings
+import numpy as np
+
+
+def taper_py(data, max_percentage=0.05, type='hann', side='both', flag=False, flag_gap=None):
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    for i in range(0, data.shape[0]):
+        taper(data[i,:], max_percentage, type, side)
+
+
+
+def taper(data, max_percentage=0.05, type='hann', side='both'):
+
+    side_valid = ['both', 'left', 'right']
+    npts = len(data)
+    if side not in side_valid:
+        raise ValueError("'side' has to be one of: %s" % side_valid)
+
+    # max_half_lenghts_1
+    max_half_lenghts_1 = None
+    if max_percentage is not None:
+        max_half_lenghts_1 = int(max_percentage * npts)
+
+    if 2 * max_half_lenghts_1 > npts:
+        msg = "The requested taper is longer than the data. " \
+                "The taper will be shortened to data length."
+        warnings.warn(msg)
+
+    # max_half_lenghts_2
+    max_half_lenghts_2 = int(npts / 2)
+    if max_half_lenghts_1 is None:
+        wlen = max_half_lenghts_2
+    else:
+        wlen = min(max_half_lenghts_1, max_half_lenghts_2)
+
+    if type == "hann":
+        taper_sides = scipy.signal.windows.hann(2*wlen+1)
+    elif type == "hamming":
+        taper_sides = scipy.signal.windows.hamming(2*wlen+1)
+    elif type == "bartlett":
+        taper_sides = scipy.signal.windows.bartlett(2*wlen+1)
+    elif type == "blackman":
+        taper_sides = scipy.signal.windows.blackman(2*wlen+1)
+    elif type == "flattop":
+        taper_sides = scipy.signal.windows.flattop(2*wlen+1)
+    elif type == "parzen":
+        taper_sides = scipy.signal.windows.parzen(2*wlen+1)
+    elif type == "bohman":
+        taper_sides = scipy.signal.windows.bohman(2*wlen+1)
+    elif type == "blackmanharris":
+        taper_sides = scipy.signal.windows.blackmanharris(2*wlen+1)
+    elif type == "nuttall":
+        taper_sides = scipy.signal.windows.nuttall(2*wlen+1)
+    elif type == "barthann":
+        taper_sides = scipy.signal.windows.barthann(2*wlen+1)
+    elif type == "kaiser":
+        taper_sides = scipy.signal.windows.kaiser(2*wlen+1, beta=14)
+    elif type == "gaussian":
+        taper_sides = scipy.signal.windows.gaussian(2*wlen+1, std=14)
+    elif type == "general_gaussian":
+        taper_sides = scipy.signal.windows.general_gaussian(2*wlen+1, p=1, sig=14)
+    else:
+        raise ValueError("Unknown taper type: %s" % type)
+
+    if side == 'left':
+        taper = np.hstack((taper_sides[:wlen], np.ones(npts - wlen)))
+    elif side == 'right':
+        taper = np.hstack((np.ones(npts - wlen),
+                            taper_sides[len(taper_sides) - wlen:]))
+    else:
+        taper = np.hstack((taper_sides[:wlen], np.ones(npts - 2 * wlen),
+                            taper_sides[len(taper_sides) - wlen:]))
+
+    # Convert data if it's not a floating point type.
+    if not np.issubdtype(data.dtype, np.floating):
+        data = np.require(data, dtype=np.float64)
+
+    data *= taper
+
+
+
+
```

## noiseflow/signal/rawdata.py

 * *Ordering differences only*

```diff
@@ -1,80 +1,80 @@
-#%%
-import h5py
-import numpy as np
-import matplotlib.pyplot as plt
-
-from scipy.io import savemat
-from noiseflow.signal.wrapper import bandpass, bandstop, lowpass, highpass, detrend, decimate, taper
-
-
-class RawData_Class(object):
-    def __init__(self, data, sampling_rate):
-        self.data = data
-        self.sampling_rate = sampling_rate
-
-
-    def detrend(self, type='linear', flag=False, flag_gap=None, threads=1, py=False):
-        detrend(self.data, type, flag, flag_gap, threads, py)
-
-
-    def taper(self, max_percentage=0.05, type='hann', side='both', flag=False, flag_gap=None, threads=1, py=False):  
-        taper(self.data, max_percentage, type, side, flag, flag_gap, threads, py)
-
-
-    def bandpass(self, freqmin, freqmax, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
-        bandpass(self.data, freqmin, freqmax, self.sampling_rate, corners, zerophase, flag, flag_gap, threads, py)
-
-
-    def bandstop(self, freqmin, freqmax, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):  
-        bandstop(self.data, freqmin, freqmax, self.sampling_rate, corners, zerophase, flag, flag_gap, threads, py)
-        
-
-    def lowpass(self, freq, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
-        lowpass(self.data, freq, self.sampling_rate, corners, zerophase, flag, flag_gap, threads, py)
-        
-
-    def highpass(self, freq, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
-        highpass(self.data, freq, self.sampling_rate, corners, zerophase, flag, flag_gap, threads, py)
-        
-
-    def decimate(self, sampling_rate_new, flag=False, flag_gap=None, threads=1, py=False):
-        results = decimate(self.data, self.sampling_rate, sampling_rate_new, flag, flag_gap, threads, py)
-        self.data = results
-        self.sampling_rate = sampling_rate_new
-
-
-    # save data
-    def save(self, save_path, format='npz', compression=False, h5_compression_format='gzip', h5_compression_opts=3):
-        if format == 'npz':
-            if compression:
-                np.savez_compressed(save_path,
-                                    data = self.data,
-                                    sampling_rate = self.sampling_rate)
-            else:
-                np.savez(save_path,
-                        data = self.data,
-                        sampling_rate = self.sampling_rate)
-                
-        elif format == 'h5':
-            with h5py.File(save_path, 'w') as f:
-                group = f.create_group('noiseflow_group')
-                group.attrs['sampling_rate'] = self.sampling_rate
-                if compression:
-                    group.create_dataset('data', data=self.data, compression=h5_compression_format, compression_opts=h5_compression_opts)
-                else:
-                    group.create_dataset('data', data=self.data)
-
-        elif format == 'mat':
-            savemat(save_path, 
-                {'data': self.data,
-                'sampling_rate': self.sampling_rate},
-                do_compression=compression)
-            
-        else:
-            raise ValueError('format must be npz, h5, or mat')
-
-
-    def plot(self, channel_num=0, win_num=0, save=False, save_path=None, dpi=100):
-        pass
-
-
+#%%
+import h5py
+import numpy as np
+import matplotlib.pyplot as plt
+
+from scipy.io import savemat
+from noiseflow.signal.wrapper import bandpass, bandstop, lowpass, highpass, detrend, decimate, taper
+
+
+class RawData_Class(object):
+    def __init__(self, data, sampling_rate):
+        self.data = data
+        self.sampling_rate = sampling_rate
+
+
+    def detrend(self, type='linear', flag=False, flag_gap=None, threads=1, py=False):
+        detrend(self.data, type, flag, flag_gap, threads, py)
+
+
+    def taper(self, max_percentage=0.05, type='hann', side='both', flag=False, flag_gap=None, threads=1, py=False):  
+        taper(self.data, max_percentage, type, side, flag, flag_gap, threads, py)
+
+
+    def bandpass(self, freqmin, freqmax, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
+        bandpass(self.data, freqmin, freqmax, self.sampling_rate, corners, zerophase, flag, flag_gap, threads, py)
+
+
+    def bandstop(self, freqmin, freqmax, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):  
+        bandstop(self.data, freqmin, freqmax, self.sampling_rate, corners, zerophase, flag, flag_gap, threads, py)
+        
+
+    def lowpass(self, freq, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
+        lowpass(self.data, freq, self.sampling_rate, corners, zerophase, flag, flag_gap, threads, py)
+        
+
+    def highpass(self, freq, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
+        highpass(self.data, freq, self.sampling_rate, corners, zerophase, flag, flag_gap, threads, py)
+        
+
+    def decimate(self, sampling_rate_new, flag=False, flag_gap=None, threads=1, py=False):
+        results = decimate(self.data, self.sampling_rate, sampling_rate_new, flag, flag_gap, threads, py)
+        self.data = results
+        self.sampling_rate = sampling_rate_new
+
+
+    # save data
+    def save(self, save_path, format='npz', compression=False, h5_compression_format='gzip', h5_compression_opts=3):
+        if format == 'npz':
+            if compression:
+                np.savez_compressed(save_path,
+                                    data = self.data,
+                                    sampling_rate = self.sampling_rate)
+            else:
+                np.savez(save_path,
+                        data = self.data,
+                        sampling_rate = self.sampling_rate)
+                
+        elif format == 'h5':
+            with h5py.File(save_path, 'w') as f:
+                group = f.create_group('noiseflow_group')
+                group.attrs['sampling_rate'] = self.sampling_rate
+                if compression:
+                    group.create_dataset('data', data=self.data, compression=h5_compression_format, compression_opts=h5_compression_opts)
+                else:
+                    group.create_dataset('data', data=self.data)
+
+        elif format == 'mat':
+            savemat(save_path, 
+                {'data': self.data,
+                'sampling_rate': self.sampling_rate},
+                do_compression=compression)
+            
+        else:
+            raise ValueError('format must be npz, h5, or mat')
+
+
+    def plot(self, channel_num=0, win_num=0, save=False, save_path=None, dpi=100):
+        pass
+
+
```

## noiseflow/signal/src/pybind11.cpp

 * *Ordering differences only*

```diff
@@ -1,177 +1,177 @@
-/***************************************************************************
- * Copyright (c) Fu Yin                                                     *
- *                                                                          *
- * Distributed under the terms of the BSD 3-Clause License.                 *
- *                                                                          *
- * The full license is in the file LICENSE, distributed with this software. *
- ****************************************************************************/
-
-// Note: this file is used for generated a shared library for pythonic user.
-
-
-// base libraries
-#include <iostream>
-#include <string>
-
-// external libraries
-#include <pybind11/pybind11.h>
-#include <pybind11/stl.h>
-#define STRINGIFY(x) #x
-#define MACRO_STRINGIFY(x) STRINGIFY(x)
-#define FORCE_IMPORT_ARRAY // FORCE_IMPORT_ARRAY must be defined before including any header of xtensor-python, and must be defined only once.
-
-// me libraries
-#include "filter.hpp"
-#include "decimate.hpp"
-#include "detrend.hpp"
-#include "taper.hpp"
-
-
-
-// **************************************************************************
-// *                        SIGNALL
-// **************************************************************************
-namespace SIGNAL {
-
-
-// **************************************************************************
-// *                        filter
-// **************************************************************************
-// bandpass
-void bandpass_float(xt::pyarray<float> &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
-{
-    bandpass<float, xt::pyarray<float>>(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads);
-}
-
-void bandpass_double(xt::pyarray<double> &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
-{
-    bandpass<double, xt::pyarray<double>>(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads);
-}
-
-
-// bandstop
-void bandstop_float(xt::pyarray<float> &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
-{
-    bandstop<float, xt::pyarray<float>>(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads);
-}
-
-void bandstop_double(xt::pyarray<double> &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
-{
-    bandstop<double, xt::pyarray<double>>(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads);
-}
-
-
-
-// lowpass
-void lowpass_float(xt::pyarray<float> &data, double freqlow, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
-{
-    lowpass<float, xt::pyarray<float>>(data, freqlow, df, corners, zerophase, flag, flag_gap, threads);
-}
-
-void lowpass_double(xt::pyarray<double> &data, double freqlow, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
-{
-    lowpass<double, xt::pyarray<double>>(data, freqlow, df, corners, zerophase, flag, flag_gap, threads);
-}
-
-
-// highpass
-void highpass_float(xt::pyarray<float> &data, double freqhigh, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
-{
-    highpass<float, xt::pyarray<float>>(data, freqhigh, df, corners, zerophase, flag, flag_gap, threads);
-}
-
-void highpass_double(xt::pyarray<double> &data, double freqhigh, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
-{
-    highpass<double, xt::pyarray<double>>(data, freqhigh, df, corners, zerophase, flag, flag_gap, threads);
-}
-
-
-
-// **************************************************************************
-// *                        DECIMATE
-// **************************************************************************
-xt::pyarray<float> decimate_float(xt::pyarray<float>  &data, double df, double df_new, bool flag, int flag_gap, int threads)
-{
-    xt::pyarray<float> results = decimate<float, xt::pyarray<float>>(data, df, df_new, flag, flag_gap, threads);
-
-    return results;
-}
-
-
-xt::pyarray<double> decimate_double(xt::pyarray<double>  &data, double df, double df_new, bool flag, int flag_gap, int threads)
-{
-    xt::pyarray<double> results = decimate<double, xt::pyarray<double>>(data, df, df_new, flag, flag_gap, threads);
-
-    return results;
-}
-
-
-// **************************************************************************
-// *                        DETREND
-// **************************************************************************
-void detrend_float(xt::pyarray<float>  &data, std::string type, bool flag, int flag_gap, int threads)
-{
-    detrend<float, xt::pyarray<float>>(data, type, flag, flag_gap, threads);
-}    
-
-
-void detrend_double(xt::pyarray<double>  &data, std::string type, bool flag, int flag_gap, int threads)
-{
-    detrend<double, xt::pyarray<double>>(data, type, flag, flag_gap, threads);
-}
-
-
-// **************************************************************************
-// *                        TAPER
-// **************************************************************************
-void taper_float(xt::pyarray<float> &data, double max_percentage, std::string type, std::string side, bool flag, int flag_gap, int threads) 
-{
-    taper<float, xt::pyarray<float>>(data, max_percentage, type, side, flag, flag_gap, threads);
-}
-
-
-void taper_double(xt::pyarray<double> &data, double max_percentage, std::string type, std::string side, bool flag, int flag_gap, int threads) 
-{
-    taper<double, xt::pyarray<double>>(data, max_percentage, type, side, flag, flag_gap, threads);
-}
-
-
-
-
-} // namespace SIGNAL
-// **************************************************************************
-// *                        PYBIND11_MODULE
-// **************************************************************************
-namespace py = pybind11;
-
-PYBIND11_MODULE(signal_share,m) 
-{
-    xt::import_numpy();
-
-    m.doc() = "Signal module for DasFlow";
-    
-    m.def("bandpass_float", &SIGNAL::bandpass_float, R"pbdoc(Do bandpass in c++)pbdoc");
-    m.def("bandstop_float", &SIGNAL::bandstop_float, R"pbdoc(Do bandstop in c++)pbdoc");
-    m.def("lowpass_float", &SIGNAL::lowpass_float, R"pbdoc(Do lowpass in c++)pbdoc");
-    m.def("highpass_float", &SIGNAL::highpass_float, R"pbdoc(Do highpass in c++)pbdoc");
-    m.def("decimate_float", &SIGNAL::decimate_float, R"pbdoc(Do decimate in c++)pbdoc");
-    m.def("detrend_float", &SIGNAL::detrend_float, R"pbdoc(Do detrend in c++)pbdoc");
-    m.def("taper_float", &SIGNAL::taper_float, R"pbdoc(Do taper in c++)pbdoc");
-
-    m.def("bandpass_double", &SIGNAL::bandpass_double, R"pbdoc(Do bandpass in c++)pbdoc");
-    m.def("bandstop_double", &SIGNAL::bandstop_double, R"pbdoc(Do bandstop in c++)pbdoc");
-    m.def("lowpass_double", &SIGNAL::lowpass_double, R"pbdoc(Do lowpass in c++)pbdoc");
-    m.def("highpass_double", &SIGNAL::highpass_double, R"pbdoc(Do highpass in c++)pbdoc");
-    m.def("decimate_double", &SIGNAL::decimate_double, R"pbdoc(Do decimate in c++)pbdoc");
-    m.def("detrend_double", &SIGNAL::detrend_double, R"pbdoc(Do detrend in c++)pbdoc");
-    m.def("taper_double", &SIGNAL::taper_double, R"pbdoc(Do taper in c++)pbdoc");
-
-
-
-#ifdef VERSION_INFO
-    m.attr("__version__") = MACRO_STRINGIFY(VERSION_INFO);
-#else
-    m.attr("__version__") = "dev";
-#endif
-
-}
+/***************************************************************************
+ * Copyright (c) Fu Yin                                                     *
+ *                                                                          *
+ * Distributed under the terms of the BSD 3-Clause License.                 *
+ *                                                                          *
+ * The full license is in the file LICENSE, distributed with this software. *
+ ****************************************************************************/
+
+// Note: this file is used for generated a shared library for pythonic user.
+
+
+// base libraries
+#include <iostream>
+#include <string>
+
+// external libraries
+#include <pybind11/pybind11.h>
+#include <pybind11/stl.h>
+#define STRINGIFY(x) #x
+#define MACRO_STRINGIFY(x) STRINGIFY(x)
+#define FORCE_IMPORT_ARRAY // FORCE_IMPORT_ARRAY must be defined before including any header of xtensor-python, and must be defined only once.
+
+// me libraries
+#include "filter.hpp"
+#include "decimate.hpp"
+#include "detrend.hpp"
+#include "taper.hpp"
+
+
+
+// **************************************************************************
+// *                        SIGNALL
+// **************************************************************************
+namespace SIGNAL {
+
+
+// **************************************************************************
+// *                        filter
+// **************************************************************************
+// bandpass
+void bandpass_float(xt::pyarray<float> &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
+{
+    bandpass<float, xt::pyarray<float>>(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads);
+}
+
+void bandpass_double(xt::pyarray<double> &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
+{
+    bandpass<double, xt::pyarray<double>>(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads);
+}
+
+
+// bandstop
+void bandstop_float(xt::pyarray<float> &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
+{
+    bandstop<float, xt::pyarray<float>>(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads);
+}
+
+void bandstop_double(xt::pyarray<double> &data, double freqmin, double freqmax, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
+{
+    bandstop<double, xt::pyarray<double>>(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads);
+}
+
+
+
+// lowpass
+void lowpass_float(xt::pyarray<float> &data, double freqlow, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
+{
+    lowpass<float, xt::pyarray<float>>(data, freqlow, df, corners, zerophase, flag, flag_gap, threads);
+}
+
+void lowpass_double(xt::pyarray<double> &data, double freqlow, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
+{
+    lowpass<double, xt::pyarray<double>>(data, freqlow, df, corners, zerophase, flag, flag_gap, threads);
+}
+
+
+// highpass
+void highpass_float(xt::pyarray<float> &data, double freqhigh, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
+{
+    highpass<float, xt::pyarray<float>>(data, freqhigh, df, corners, zerophase, flag, flag_gap, threads);
+}
+
+void highpass_double(xt::pyarray<double> &data, double freqhigh, double df, int corners, bool zerophase, bool flag, int flag_gap, int threads)
+{
+    highpass<double, xt::pyarray<double>>(data, freqhigh, df, corners, zerophase, flag, flag_gap, threads);
+}
+
+
+
+// **************************************************************************
+// *                        DECIMATE
+// **************************************************************************
+xt::pyarray<float> decimate_float(xt::pyarray<float>  &data, double df, double df_new, bool flag, int flag_gap, int threads)
+{
+    xt::pyarray<float> results = decimate<float, xt::pyarray<float>>(data, df, df_new, flag, flag_gap, threads);
+
+    return results;
+}
+
+
+xt::pyarray<double> decimate_double(xt::pyarray<double>  &data, double df, double df_new, bool flag, int flag_gap, int threads)
+{
+    xt::pyarray<double> results = decimate<double, xt::pyarray<double>>(data, df, df_new, flag, flag_gap, threads);
+
+    return results;
+}
+
+
+// **************************************************************************
+// *                        DETREND
+// **************************************************************************
+void detrend_float(xt::pyarray<float>  &data, std::string type, bool flag, int flag_gap, int threads)
+{
+    detrend<float, xt::pyarray<float>>(data, type, flag, flag_gap, threads);
+}    
+
+
+void detrend_double(xt::pyarray<double>  &data, std::string type, bool flag, int flag_gap, int threads)
+{
+    detrend<double, xt::pyarray<double>>(data, type, flag, flag_gap, threads);
+}
+
+
+// **************************************************************************
+// *                        TAPER
+// **************************************************************************
+void taper_float(xt::pyarray<float> &data, double max_percentage, std::string type, std::string side, bool flag, int flag_gap, int threads) 
+{
+    taper<float, xt::pyarray<float>>(data, max_percentage, type, side, flag, flag_gap, threads);
+}
+
+
+void taper_double(xt::pyarray<double> &data, double max_percentage, std::string type, std::string side, bool flag, int flag_gap, int threads) 
+{
+    taper<double, xt::pyarray<double>>(data, max_percentage, type, side, flag, flag_gap, threads);
+}
+
+
+
+
+} // namespace SIGNAL
+// **************************************************************************
+// *                        PYBIND11_MODULE
+// **************************************************************************
+namespace py = pybind11;
+
+PYBIND11_MODULE(signal_share,m) 
+{
+    xt::import_numpy();
+
+    m.doc() = "Signal module for DasFlow";
+    
+    m.def("bandpass_float", &SIGNAL::bandpass_float, R"pbdoc(Do bandpass in c++)pbdoc");
+    m.def("bandstop_float", &SIGNAL::bandstop_float, R"pbdoc(Do bandstop in c++)pbdoc");
+    m.def("lowpass_float", &SIGNAL::lowpass_float, R"pbdoc(Do lowpass in c++)pbdoc");
+    m.def("highpass_float", &SIGNAL::highpass_float, R"pbdoc(Do highpass in c++)pbdoc");
+    m.def("decimate_float", &SIGNAL::decimate_float, R"pbdoc(Do decimate in c++)pbdoc");
+    m.def("detrend_float", &SIGNAL::detrend_float, R"pbdoc(Do detrend in c++)pbdoc");
+    m.def("taper_float", &SIGNAL::taper_float, R"pbdoc(Do taper in c++)pbdoc");
+
+    m.def("bandpass_double", &SIGNAL::bandpass_double, R"pbdoc(Do bandpass in c++)pbdoc");
+    m.def("bandstop_double", &SIGNAL::bandstop_double, R"pbdoc(Do bandstop in c++)pbdoc");
+    m.def("lowpass_double", &SIGNAL::lowpass_double, R"pbdoc(Do lowpass in c++)pbdoc");
+    m.def("highpass_double", &SIGNAL::highpass_double, R"pbdoc(Do highpass in c++)pbdoc");
+    m.def("decimate_double", &SIGNAL::decimate_double, R"pbdoc(Do decimate in c++)pbdoc");
+    m.def("detrend_double", &SIGNAL::detrend_double, R"pbdoc(Do detrend in c++)pbdoc");
+    m.def("taper_double", &SIGNAL::taper_double, R"pbdoc(Do taper in c++)pbdoc");
+
+
+
+#ifdef VERSION_INFO
+    m.attr("__version__") = MACRO_STRINGIFY(VERSION_INFO);
+#else
+    m.attr("__version__") = "dev";
+#endif
+
+}
```

## noiseflow/signal/wrapper.py

 * *Ordering differences only*

```diff
@@ -1,260 +1,260 @@
-import os
-import re
-import json
-import numpy as np
-
-from noiseflow.signal.python.taper import taper_py
-from noiseflow.signal.python.detrend import detrend_py
-from noiseflow.signal.python.decimate import decimate_py
-from noiseflow.signal.python.filter import bandpass_py, bandstop_py, lowpass_py, highpass_py
-
-# Determine the absolute path to the config file
-env = os.environ.get('CONDA_DEFAULT_ENV')
-env = re.sub('[^a-zA-Z0-9_]', '', env)[0:50]
-config_path = os.path.abspath(os.path.expanduser(f'~/.noiseflow/config_{env}.json'))    
-
-# Read the config.json file
-with open(config_path) as f:
-    config = json.load(f)
-
-if config.get('NOISEFLOW_USE_CPP', False):
-    NOISEFLOW_USE_CPP = True
-    from noiseflow.lib import signal_share
-else:
-    NOISEFLOW_USE_CPP = False 
-
-
-
-def detrend(data, type='linear', flag=False, flag_gap=None, threads=1, py=False):
-    # check demision of data
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-    
-    # check type
-    if type not in ['linear', 'demean']:
-        raise ValueError("type must be 'linear' or 'demean'")
-    
-    # check threads
-    if threads > data.shape[0]:
-        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(data.shape[0])
-
-    if py:
-        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
-            detrend_py(data, type, flag, flag_gap)
-        else:
-            raise TypeError("data.dtype must be np.float32 or np.float64")
-    else:
-        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            signal_share.detrend_float(data, type, flag, flag_gap, threads)
-        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            signal_share.detrend_double(data, type, flag, flag_gap, threads)
-        else:
-            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-
-    
-def taper(data, max_percentage=0.05, type='hann', side='both', flag=False, flag_gap=None, threads=1, py=False):
-    # check demision of data
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    # check max_percentage
-    if max_percentage < 0 or max_percentage > 0.5:
-        raise ValueError("max_percentage must be between 0 and 0.5")
-    
-    # check type
-    if type not in ['hann', 'hamming', 'blackman', 'blackman_harris', 'gaussian', 'triangular', 'bartlett', 'cosine', 'cosine_np', 'bartlett_hann', 'bohman', 'lanczos', 'flattop', 'kaiser']:
-        raise ValueError("type must be 'hann', 'hamming', 'blackman', 'blackman_harris', 'gaussian', 'triangular', 'bartlett', 'cosine', 'cosine_np', 'bartlett_hann', 'bohman', 'lanczos', 'flattop', 'kaiser'")
-
-    # check side
-    if side not in ['both', 'left', 'right']:
-        raise ValueError("side must be 'both', 'left', or 'right'")
-    
-    # check threads
-    if threads > data.shape[0]:
-        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(data.shape[0])
-
-    if py:
-        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
-            taper_py(data, max_percentage, type, side, flag, flag_gap)
-        else:
-            raise TypeError("data.dtype must be np.float32 or np.float64")
-    else:
-        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            signal_share.taper_float(data, max_percentage, type, side, flag, flag_gap, threads)
-        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            signal_share.taper_double(data, max_percentage, type, side, flag, flag_gap, threads)
-        else:
-            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-
-
-def bandpass(data, freqmin, freqmax, df, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
-    # check demision of data
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    # check freq and df
-    if (freqmin >= df/2) or (freqmax >= df/2):
-        raise ValueError("freq must be < df/2")
-
-    # check threads
-    if threads > data.shape[0]:
-        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(data.shape[0])
-
-    if py:
-        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
-            bandpass_py(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap)
-        else:
-            raise TypeError("data.dtype must be np.float32 or np.float64")
-    else:
-        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            signal_share.bandpass_float(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads)
-        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            signal_share.bandpass_double(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads)
-        else:
-            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-
-
-def bandstop(data, freqmin, freqmax, df, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
-    # check demision of data
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    # check freq and df
-    if (freqmin >= df/2) or (freqmax >= df/2):
-        raise ValueError("freq must be < df/2")
-
-    # check threads
-    if threads > data.shape[0]:
-        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(data.shape[0])
-
-    if py:
-        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
-            bandstop_py(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap)
-        else:
-            raise TypeError("data.dtype must be np.float32 or np.float64")
-    else:
-        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            signal_share.bandstop_float(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads)
-        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            signal_share.bandstop_double(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads)
-        else:
-            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-
-
-def lowpass(data, freq, df, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
-    # check demision of data
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    # check freq and df
-    if freq >= df / 2:
-        raise ValueError("freq must be < df/2")
-
-    # check threads
-    if threads > data.shape[0]:
-        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(data.shape[0])
-
-    if py:
-        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
-            lowpass_py(data, freq, df, corners, zerophase, flag, flag_gap)
-        else:
-            raise TypeError("data.dtype must be np.float32 or np.float64")
-    else:
-        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            signal_share.lowpass_float(data, freq, df, corners, zerophase, flag, flag_gap, threads)
-        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            signal_share.lowpass_double(data, freq, df, corners, zerophase, flag, flag_gap, threads)
-        else:
-            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-
-
-def highpass(data, freq, df, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
-    # check demision of data
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    # check freq and df
-    if freq >= df / 2:
-        raise ValueError("freq must be < df/2")
-
-    # check threads
-    if threads > data.shape[0]:
-        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(data.shape[0])
-    if py:
-        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
-            highpass_py(data, freq, df, corners, zerophase, flag, flag_gap)
-        else:
-            raise TypeError("data.dtype must be np.float32 or np.float64")
-    else:
-        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            signal_share.highpass_float(data, freq, df, corners, zerophase, flag, flag_gap, threads)
-        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            signal_share.highpass_double(data, freq, df, corners, zerophase, flag, flag_gap, threads)
-        else:
-            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-
-
-def decimate(data, df, df_new, flag=False, flag_gap=None, threads=1, py=False):
-    # check demision of data
-    if data.ndim == 1:
-        data = data.reshape(1, -1)
-
-    # check df and df_new
-    if df % df_new != 0:
-        raise ValueError("Note df % df_new == 0")
-    if df_new > df:
-        raise ValueError("df_new must be <= df")
-    
-    # check threads
-    if threads > data.shape[0]:
-        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
-    
-    # check flag_gap
-    if flag_gap==None:
-        flag_gap = int(data.shape[0])
-
-    if py:
-        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
-            results = decimate_py(data, df, df_new, flag, flag_gap)
-        else:
-            raise TypeError("data.dtype must be np.float32 or np.float64")
-    else:
-        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
-            results = signal_share.decimate_float(data, df, df_new, flag, flag_gap, threads)
-        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
-            results = signal_share.decimate_double(data, df, df_new, flag, flag_gap, threads)
-        else:
-            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
-    
-    return results
-
+import os
+import re
+import json
+import numpy as np
+
+from noiseflow.signal.python.taper import taper_py
+from noiseflow.signal.python.detrend import detrend_py
+from noiseflow.signal.python.decimate import decimate_py
+from noiseflow.signal.python.filter import bandpass_py, bandstop_py, lowpass_py, highpass_py
+
+# Determine the absolute path to the config file
+env = os.environ.get('CONDA_DEFAULT_ENV')
+env = re.sub('[^a-zA-Z0-9_]', '', env)[0:50]
+config_path = os.path.abspath(os.path.expanduser(f'~/.noiseflow/config_{env}.json'))    
+
+# Read the config.json file
+with open(config_path) as f:
+    config = json.load(f)
+
+if config.get('NOISEFLOW_USE_CPP', False):
+    NOISEFLOW_USE_CPP = True
+    from noiseflow.lib import signal_share
+else:
+    NOISEFLOW_USE_CPP = False 
+
+
+
+def detrend(data, type='linear', flag=False, flag_gap=None, threads=1, py=False):
+    # check demision of data
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+    
+    # check type
+    if type not in ['linear', 'demean']:
+        raise ValueError("type must be 'linear' or 'demean'")
+    
+    # check threads
+    if threads > data.shape[0]:
+        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(data.shape[0])
+
+    if py:
+        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
+            detrend_py(data, type, flag, flag_gap)
+        else:
+            raise TypeError("data.dtype must be np.float32 or np.float64")
+    else:
+        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            signal_share.detrend_float(data, type, flag, flag_gap, threads)
+        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            signal_share.detrend_double(data, type, flag, flag_gap, threads)
+        else:
+            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+
+    
+def taper(data, max_percentage=0.05, type='hann', side='both', flag=False, flag_gap=None, threads=1, py=False):
+    # check demision of data
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    # check max_percentage
+    if max_percentage < 0 or max_percentage > 0.5:
+        raise ValueError("max_percentage must be between 0 and 0.5")
+    
+    # check type
+    if type not in ['hann', 'hamming', 'blackman', 'blackman_harris', 'gaussian', 'triangular', 'bartlett', 'cosine', 'cosine_np', 'bartlett_hann', 'bohman', 'lanczos', 'flattop', 'kaiser']:
+        raise ValueError("type must be 'hann', 'hamming', 'blackman', 'blackman_harris', 'gaussian', 'triangular', 'bartlett', 'cosine', 'cosine_np', 'bartlett_hann', 'bohman', 'lanczos', 'flattop', 'kaiser'")
+
+    # check side
+    if side not in ['both', 'left', 'right']:
+        raise ValueError("side must be 'both', 'left', or 'right'")
+    
+    # check threads
+    if threads > data.shape[0]:
+        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(data.shape[0])
+
+    if py:
+        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
+            taper_py(data, max_percentage, type, side, flag, flag_gap)
+        else:
+            raise TypeError("data.dtype must be np.float32 or np.float64")
+    else:
+        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            signal_share.taper_float(data, max_percentage, type, side, flag, flag_gap, threads)
+        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            signal_share.taper_double(data, max_percentage, type, side, flag, flag_gap, threads)
+        else:
+            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+
+
+def bandpass(data, freqmin, freqmax, df, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
+    # check demision of data
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    # check freq and df
+    if (freqmin >= df/2) or (freqmax >= df/2):
+        raise ValueError("freq must be < df/2")
+
+    # check threads
+    if threads > data.shape[0]:
+        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(data.shape[0])
+
+    if py:
+        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
+            bandpass_py(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap)
+        else:
+            raise TypeError("data.dtype must be np.float32 or np.float64")
+    else:
+        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            signal_share.bandpass_float(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads)
+        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            signal_share.bandpass_double(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads)
+        else:
+            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+
+
+def bandstop(data, freqmin, freqmax, df, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
+    # check demision of data
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    # check freq and df
+    if (freqmin >= df/2) or (freqmax >= df/2):
+        raise ValueError("freq must be < df/2")
+
+    # check threads
+    if threads > data.shape[0]:
+        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(data.shape[0])
+
+    if py:
+        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
+            bandstop_py(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap)
+        else:
+            raise TypeError("data.dtype must be np.float32 or np.float64")
+    else:
+        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            signal_share.bandstop_float(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads)
+        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            signal_share.bandstop_double(data, freqmin, freqmax, df, corners, zerophase, flag, flag_gap, threads)
+        else:
+            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+
+
+def lowpass(data, freq, df, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
+    # check demision of data
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    # check freq and df
+    if freq >= df / 2:
+        raise ValueError("freq must be < df/2")
+
+    # check threads
+    if threads > data.shape[0]:
+        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(data.shape[0])
+
+    if py:
+        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
+            lowpass_py(data, freq, df, corners, zerophase, flag, flag_gap)
+        else:
+            raise TypeError("data.dtype must be np.float32 or np.float64")
+    else:
+        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            signal_share.lowpass_float(data, freq, df, corners, zerophase, flag, flag_gap, threads)
+        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            signal_share.lowpass_double(data, freq, df, corners, zerophase, flag, flag_gap, threads)
+        else:
+            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+
+
+def highpass(data, freq, df, corners=4, zerophase=True, flag=False, flag_gap=None, threads=1, py=False):
+    # check demision of data
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    # check freq and df
+    if freq >= df / 2:
+        raise ValueError("freq must be < df/2")
+
+    # check threads
+    if threads > data.shape[0]:
+        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(data.shape[0])
+    if py:
+        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
+            highpass_py(data, freq, df, corners, zerophase, flag, flag_gap)
+        else:
+            raise TypeError("data.dtype must be np.float32 or np.float64")
+    else:
+        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            signal_share.highpass_float(data, freq, df, corners, zerophase, flag, flag_gap, threads)
+        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            signal_share.highpass_double(data, freq, df, corners, zerophase, flag, flag_gap, threads)
+        else:
+            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+
+
+def decimate(data, df, df_new, flag=False, flag_gap=None, threads=1, py=False):
+    # check demision of data
+    if data.ndim == 1:
+        data = data.reshape(1, -1)
+
+    # check df and df_new
+    if df % df_new != 0:
+        raise ValueError("Note df % df_new == 0")
+    if df_new > df:
+        raise ValueError("df_new must be <= df")
+    
+    # check threads
+    if threads > data.shape[0]:
+        raise ValueError("threads must be <= (data.shape[0]=%d)" % data.shape[0])
+    
+    # check flag_gap
+    if flag_gap==None:
+        flag_gap = int(data.shape[0])
+
+    if py:
+        if data.dtype == np.dtype(np.float32) or data.dtype == np.dtype(np.float64):
+            results = decimate_py(data, df, df_new, flag, flag_gap)
+        else:
+            raise TypeError("data.dtype must be np.float32 or np.float64")
+    else:
+        if data.dtype == np.dtype(np.float32) and NOISEFLOW_USE_CPP:
+            results = signal_share.decimate_float(data, df, df_new, flag, flag_gap, threads)
+        elif data.dtype == np.dtype(np.float64) and NOISEFLOW_USE_CPP:
+            results = signal_share.decimate_double(data, df, df_new, flag, flag_gap, threads)
+        else:
+            raise TypeError("data.dtype must be np.float32, np.float64 or NOISEFLOW_USE_CPP=False")
+    
+    return results
+
```

## Comparing `noiseflow-0.0.6.dist-info/LICENSE` & `noiseflow-0.0.6b0.dist-info/LICENSE`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,201 +1,201 @@
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
```

## Comparing `noiseflow-0.0.6.dist-info/METADATA` & `noiseflow-0.0.6b0.dist-info/METADATA`

 * *Files 5% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: noiseflow
-Version: 0.0.6
+Version: 0.0.6b0
 Summary: An ambient noise package
 License: Apache-2.0
 Author: Fu Yin
 Author-email: oucyinfu@gmail.com
 Requires-Python: >=3.9,<3.12
 Classifier: Development Status :: 2 - Pre-Alpha
 Classifier: Environment :: Console
@@ -19,14 +19,15 @@
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Topic :: Scientific/Engineering
 Classifier: Topic :: Scientific/Engineering :: Physics
 Provides-Extra: cpp
+Requires-Dist: faker (>=18.11.2,<19.0.0)
 Requires-Dist: h5py (>=3.9.0,<4.0.0)
 Requires-Dist: joblib (>=1.3.1,<2.0.0)
 Requires-Dist: matplotlib (>=3.7.1,<4.0.0)
 Requires-Dist: numpy (>=1.25.0,<2.0.0)
 Requires-Dist: obspy (>=1.4.0,<2.0.0)
 Requires-Dist: scipy (==1.10.1)
 Requires-Dist: tqdm (>=4.65.0,<5.0.0)
@@ -172,7 +173,24 @@
 conda_prefix = $(conda info --base)
 export CMAKE_PREFIX_PATH="${conda_prefix}/envs/${myenv}"
 
 
 cmake .. -DCMAKE_INSTALL_PREFIX=$CONDA_PREFIX -DCMAKE_PREFIX_PATH=$CONDA_PREFIX
 make install
 ```
+
+
+
+### [build-system]
+cmake = '^3.18.0'
+fftw = '^3.3.10'
+pybind11 = '^2.10.4'
+xtensor = '^0.24.6'
+xsimd = '8.0.5' # when the version is larger than 8.0.5, it will got error in compiling stage.
+xtl = '^0.7.5'
+xtensor_blas = '^0.20.0'
+xtensor_python = '^0.26.1'
+xtensor_fftw = '^0.2.6' # not show in conda env
+kfr = '^5.0.2' # not show in conda env
+
+### [optional-for-mac]
+libomp = '^16.0.6' # via brew
```

## Comparing `noiseflow-0.0.6.dist-info/RECORD` & `noiseflow-0.0.6b0.dist-info/RECORD`

 * *Files 24% similar despite different names*

```diff
@@ -1,48 +1,50 @@
-.gitmodules,sha256=EOcti4pBNLWsqKACxT2ErPHGN2Ggibw55sGCpjcYJOE,739
-CMakeLists.txt,sha256=imhqWi5o_sktRsT47yzIAs-n5ZF_Jfct3QtEv14--Zs,6149
-noiseflow/__init__.py,sha256=2vqpeN-0qQx1R-SCqjvMMH6_WYxIML5VkFbNZPIS3rA,1311
+.gitmodules,sha256=t0JqqX05q1kLS05UOf1csg5eKIKZy_V_xwEXSiO0Cnk,196
+CMakeLists.txt,sha256=bH0GsskEBE_5c2pRM1vPVaSqHm-NDSkCqV5mhwm-Rag,6015
+noiseflow/__init__.py,sha256=g-8J1IndetrzNB9ZBi_uHGatThz4lWwqdwYguFzdGDg,1270
 noiseflow/app/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 noiseflow/cc/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-noiseflow/cc/corrdata.py,sha256=F7xR2fsOSLsipAiYm4NCYuNXn-qA2nOXxzUVpko8MFc,12030
-noiseflow/cc/include/corr.hpp,sha256=11h5uZ8mdXkoj-6NdUTsvD94AjI7Moxmm8yRo8OHKhU,10467
-noiseflow/cc/include/rfft.hpp,sha256=vRaoQCSBLKHEis7vy9DK-9VYrotCXbcp1t36Dd9_gRo,10398
-noiseflow/cc/include/stack.hpp,sha256=yVlHD1bqsw6tP1_HV9HFANRI_KdpW3pINiE8GJ0b7es,11339
-noiseflow/cc/include/utils.hpp,sha256=0DU5CAmR-3DdsBooHepUsKYC8XlNlyevHkOwCQIesPc,8665
+noiseflow/cc/corrdata.py,sha256=pOEdNHf4NxaIqZgDVVD-Gkxwh39wc7uE2ZnOEkyMGRE,11738
+noiseflow/cc/include/corr.hpp,sha256=P0qn_P5dhdUIZaC8JRjwBQ7cEF9XbJY8orSRjxhM2SQ,10160
+noiseflow/cc/include/rfft.hpp,sha256=2Btdm4ntR3jSCpHHHIelk6vkGr_qbr9cYfhCv2WVUdg,10099
+noiseflow/cc/include/stack.hpp,sha256=gOzO_kEJLjc4ZJr1rM71u1rWfSvi-Bq529XO3gfyVbA,11023
+noiseflow/cc/include/utils.hpp,sha256=FmTRdfL101zp3MuNZfEQDNKeQwQj9IsR4ESW7FqFH7U,8396
 noiseflow/cc/python/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-noiseflow/cc/python/corr.py,sha256=MOBmAD4U1RcgpC5kzRSyLMYhFbltWccszfkA0M3Mf2o,6251
-noiseflow/cc/python/rfft.py,sha256=tFIZ_cUdONNds7w6HZW6mPLRaMHVo3ZHXYSdgt8ZyZw,5455
-noiseflow/cc/python/stack.py,sha256=LkpAcR9Tcvtd3KvZf0uHPHiAQixo627HHkYj_mgC1Ng,28068
-noiseflow/cc/python/utils.py,sha256=uujtgBGLVX5CfeGgge7-um8ZgkyG9jcShb0Jbon3FVg,3417
-noiseflow/cc/rfftdata.py,sha256=ol_lkDsc79V-S_lKaOGJb9LoDDI5lF_JmFPOuaAnyXE,8312
-noiseflow/cc/src/pybind11.cpp,sha256=EPTzs2iVgLUwbsov7Uv2-W0fduiW_GoRFwX6GbrZJwU,5626
-noiseflow/cc/stackdata.py,sha256=oHmyHbdB9Rj8-PmhguwcoujPl_FeJ5M-ohzS1Nh8b38,38192
-noiseflow/cc/utils_load.py,sha256=4AEernmXQwlHICtn_tdfrExSV0gNRLomZmx3xloJPbI,11000
-noiseflow/cc/utils_time.py,sha256=36SbCNEmBRVC5vfhrl5jyN7SHVCvegxCrSmADeV8aCw,1410
-noiseflow/cc/wrapper.py,sha256=8g15yFQvcnBUtaWYbFqVbmXwC4Ch6XR-EgOFc2TFf9E,9085
+noiseflow/cc/python/corr.py,sha256=D5zTh2VMAfaD3OGLGZr1sGv7PXCJYPKEX7PYhnQF1xs,6071
+noiseflow/cc/python/rfft.py,sha256=dt_Psp_8PXVHOA_1JcQDFOsgL1UH6FJ0Ng84RTIL7fM,5299
+noiseflow/cc/python/stack.py,sha256=TiXzA2AgDVR5FzoxEEpM5aLSv7voJV6cFNWjxEQwNsE,27277
+noiseflow/cc/python/utils.py,sha256=SbTYDM6yg98CFLGmvs60WOQ2Yqw_WDE9xVhUfuM_YSw,3310
+noiseflow/cc/rfftdata.py,sha256=a34zTA81i5-7xvZLAmgPKG4nmiapbqCHIU4ivZjBR-8,8127
+noiseflow/cc/src/pybind11.cpp,sha256=QVbX34vYX4v2_NVE2MO2Zqc_eZDouqo81yZRCe21X4k,5512
+noiseflow/cc/stackdata.py,sha256=uZXxYdoibfA7qbpeCYiCQMYe4gk1MYhfcHu6p7RM8Do,37323
+noiseflow/cc/utils_load.py,sha256=WQr30nEJ1GhjmAq9-YjNPgDeWtZgFybuMUwfrxbk4IU,10646
+noiseflow/cc/utils_time.py,sha256=y6Sy2w992hNDpwLIE8eMhhV4OQX0ou9wPQbt3xVou8s,1368
+noiseflow/cc/wrapper.py,sha256=5b-GZF7EA00gAq_5yLkD8IYrlsKznTXYQwYBjLszess,8858
 noiseflow/client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-noiseflow/client/client.py,sha256=j_6vRV21ShJTgD-yx1d4TiAiOo9bpzz-8tJ0WpOTl_M,8055
+noiseflow/client/client.py,sha256=sKtOhOLzsUXIaBARwpd9W-tacEC7Dbx3LnhDHB6F-XY,7776
 noiseflow/dispersion/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-noiseflow/dispersion/app_dispersion.py,sha256=V4dZ2Hs2kqnr3V-trN0Pd6FojpgoNFdAhzqJQF18U10,32
-noiseflow/dispersion/test.py,sha256=rHATk1NZRIK105VHKpMe9XNar92oVzWX0lfLWy7EXqk,30
+noiseflow/dispersion/app_dispersion.py,sha256=I-C-ZVveAJs3tmz14Pd_CboX9k5r6s5dnwS_DHA_a8c,29
+noiseflow/dispersion/test.py,sha256=AJE-t37_ABM5T4g-y0a8buwN1Ke3LVD3oZSDLPzu2tw,27
 noiseflow/dvv/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 noiseflow/dvv/monitoring.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-noiseflow/real_time/watch_dog.py,sha256=Bk0LKzfcPJW4mEyWFSI4we2vsMrGb_zaddSwgSDmJnU,205
+noiseflow/real_time/watch_dog.py,sha256=6o8NNuPtXuZCTD2My5D42p4lUtu8zWIQit8sYmEZDzg,193
 noiseflow/signal/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-noiseflow/signal/include/decimate.hpp,sha256=bO_uJ4o2qEff-p-osHGYTlBFYuoih3fi9P8ryCaFBJs,2978
-noiseflow/signal/include/detrend.hpp,sha256=juFThvKl9h3t9Q26lb7iLSVD3SO5D6HE2BRNwx8hI48,3379
-noiseflow/signal/include/filter.hpp,sha256=swIMNiexfx_qNy2zU_t-SDRhnEEVe90etJ1F86M3xN0,13019
-noiseflow/signal/include/taper.hpp,sha256=M306FpjA4_OdQ-hJVN1D7dP7izq7vuVIAij_a9Qk-I4,4873
-noiseflow/signal/include/utils.hpp,sha256=rwPRrXtTLwkhP-Slt7qGwzoZwJ6IajIVwMWvAcEIyCU,1326
+noiseflow/signal/include/decimate.hpp,sha256=w7rwDa-qVh035Hxl2hoBU-ZCHIJJklKvhfn6zGw_0l4,2899
+noiseflow/signal/include/detrend.hpp,sha256=9Guay7cNuLXQiV2v6RJMOKb8aFyTOOfU4TE6341XenY,3291
+noiseflow/signal/include/filter.hpp,sha256=2n5-rZ5P72ZvyE-k0EB2sy7w-4Z9mQ4IXWoZJfR-tLs,12708
+noiseflow/signal/include/taper.hpp,sha256=r_ibi6sRYcrhCfR3MekWkba07u9xUOZP8R-D4an4kLY,4737
+noiseflow/signal/include/utils.hpp,sha256=FWOc3P8gQeflkrKelXfmcBgyYc-ryYOPUoDu1llNmU0,1284
 noiseflow/signal/python/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-noiseflow/signal/python/decimate.py,sha256=UFGar_hLUta-QUVuEjKcsDRnFnLolnZ5mjuCdoLvWJw,780
-noiseflow/signal/python/detrend.py,sha256=L5apvRD35YnHL_ENIvs2GKlmwRsLrvFmKHdINB5fDCg,2075
-noiseflow/signal/python/filter.py,sha256=VZpat6rkNZ_AJONejGW61xn34mTI9_7XYfSt3he7Og8,7008
-noiseflow/signal/python/taper.py,sha256=FNZafi6FeVDDnx7shRtz-W6Mc2iEYoxzhNA8wx-ilxU,3002
-noiseflow/signal/rawdata.py,sha256=_bVtn_lj2tTD-doSuuNCvCEg-9sycHffxDEQKZwDCJM,3343
-noiseflow/signal/src/pybind11.cpp,sha256=zpDCYb83akSzP3jlg1_r31lHCoYehO_vOlUNf-KSRsg,7532
-noiseflow/signal/wrapper.py,sha256=3nh9G3ttmGYyZHEFwsKSwDaaRD0r-zY55mzRemxKZFE,10485
+noiseflow/signal/python/decimate.py,sha256=yN1uvHMyIvNRAJ1f60egAQaFU4FGvTP4TpBVFFj2jeY,747
+noiseflow/signal/python/detrend.py,sha256=XxLYloHAF7MzIWujwivZUmEQdP_Fs3zHstr84oCP4bQ,2004
+noiseflow/signal/python/filter.py,sha256=5LAO_hVG-R-cLX2Hz_rSZwmJfIR2nnv-pmjIt2gwIxI,6813
+noiseflow/signal/python/taper.py,sha256=kLRSGmFhXof1_b24RCqltnk_MGgdyBW87hR1E83_2CM,2917
+noiseflow/signal/rawdata.py,sha256=y7M-8qDGOiTXQPn_u-FoBgbRYEYNicdQ19o2ynFaCi8,3263
+noiseflow/signal/src/pybind11.cpp,sha256=JFbSDcIvgwC80SY7BDWXlaqGwO1-Y-QsxfjjrLq6idg,7355
+noiseflow/signal/wrapper.py,sha256=987avGVJocYGxA_Azpvshq2Bva7YA7ueDParvSjkdxM,10225
 noiseflow/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-noiseflow-0.0.6.dist-info/LICENSE,sha256=HrhfyXIkWY2tGFK11kg7vPCqhgh5DcxleloqdhrpyMY,11558
-noiseflow-0.0.6.dist-info/METADATA,sha256=Ou76czVUBP-TX2ThQXMW3RvQh12gWOYC3XZ9AhTnUlg,4558
-noiseflow-0.0.6.dist-info/WHEEL,sha256=HWscs3yOKFYW5qMGWiZd7gHNxWFJTJIM1zmy39sTAmA,98
-noiseflow-0.0.6.dist-info/RECORD,,
+noiseflow/lib/cc_share.cpython-39-x86_64-linux-gnu.so,sha256=3ypJx6BleDAfsfQrgOOYYIDxQW71Z5_VRpxdaRr2B3M,1257600
+noiseflow/lib/signal_share.cpython-39-x86_64-linux-gnu.so,sha256=IjgOnT4TYATLzixP6LfYg2-GdFRgIo6wcWtgb2JJ2fw,786144
+noiseflow-0.0.6b0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+noiseflow-0.0.6b0.dist-info/METADATA,sha256=9y-25SNmZKHGZQjLWQbesk1f7QGaU-FsGDyuykwySRk,5002
+noiseflow-0.0.6b0.dist-info/WHEEL,sha256=aAM9FLjwyrPH-XQbHFZYqvvxAzCgDR-v1M902hsW1tM,108
+noiseflow-0.0.6b0.dist-info/RECORD,,
```

